
@misc{__,
  title = {During {{Running}} in {{Place}}, {{Grid Cells Integrate Elapsed Time}} and {{Distance Run}} | {{Elsevier Enhanced Reader}}},
  doi = {10.1016/j.neuron.2015.09.031},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SUQMEH9J\\__.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\XW2YTPPL\\S089662731500820X.html},
  howpublished = {https://reader.elsevier.com/reader/sd/pii/S089662731500820X?token=91F5A7D995E925A51545B4CBA19F37171728D81C668FDFA5247CC852CB4F216BCA7EAC6E0B0D0793A6E51CA44033E794},
  language = {en}
}

@misc{__a,
  title = {Inbox - g.William.Chapman.Iv@gmail.Com - {{Gmail}}},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IQC68QW9\\0.html},
  howpublished = {https://mail.google.com/mail/u/0/\#inbox}
}

@article{abadachi_mohajerani_2020,
  title = {Spatiotemporal Patterns of Neocortical Activity around Hippocampal Sharp-Wave Ripples},
  author = {Abadachi, Javad Karimi and Mohajerani, Majid},
  year = {2020},
  pages = {86},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9LYB6X8A\\McNaughton and Mohajerani - 12 Corresponding authors.pdf},
  language = {en}
}

@article{abbott_abbott_2008,
  title = {Theoretical Neuroscience Rising.},
  author = {Abbott, L F},
  year = {2008},
  month = nov,
  volume = {60},
  pages = {489--95},
  issn = {1097-4199},
  doi = {10.1016/j.neuron.2008.10.019},
  abstract = {Theoretical neuroscience has experienced explosive growth over the past 20 years. In addition to bringing new researchers into the field with backgrounds in physics, mathematics, computer science, and engineering, theoretical approaches have helped to introduce new ideas and shape directions of neuroscience research. This review presents some of the developments that have occurred and the lessons they have taught us.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\47QENCK8\\Abbott - 2008 - Theoretical neuroscience rising.pdf},
  journal = {Neuron},
  keywords = {Algorithms,Animals,Information Theory,Mathematics,Models,Nerve Net,Nerve Net: physiology,Neurological,Neurons,Neurons: physiology,Neurosciences,Theoretical},
  number = {3},
  pmid = {18995824}
}

@article{abbott_memmesheimer_2016,
  title = {Building Functional Networks of Spiking Model Neurons},
  author = {Abbott, L F and DePasquale, Brian and Memmesheimer, Raoul-Martin},
  year = {2016},
  month = mar,
  volume = {19},
  pages = {350--355},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn.4241},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\N72SGRDS\\Abbott et al. - 2016 - Building functional networks of spiking model neur.pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {3}
}

@article{abderrahmane_miramond_2020,
  title = {Design {{Space Exploration}} of {{Hardware Spiking Neurons}} for {{Embedded Artificial Intelligence}}},
  author = {Abderrahmane, Nassim and Lemaire, Edgar and Miramond, Beno{\^i}t},
  year = {2020},
  month = jan,
  volume = {121},
  pages = {366--386},
  issn = {08936080},
  doi = {10.1016/j.neunet.2019.09.024},
  abstract = {Machine learning is yielding unprecedented interest in research and industry, due to recent success in many applied contexts such as image classification and object recognition. However, the deployment of these systems requires huge computing capabilities, thus making them unsuitable for embedded systems. To deal with this limitation, many researchers are investigating brain-inspired computing, which would be a perfect alternative to the conventional Von Neumann architecture based computers (CPU/GPU) that meet the requirements for computing performance, but not for energy-efficiency. Therefore, neuromorphic hardware circuits that are adaptable for both parallel and distributed computations need to be designed. In this paper, we focus on Spiking Neural Networks (SNNs) with a comprehensive study of neural coding methods and hardware exploration. In this context, we propose a framework for neuromorphic hardware design space exploration, which allows to define a suitable architecture based on application-specific constraints and starting from a wide variety of possible architectural choices. For this framework, we have developed a behavioral level simulator for neuromorphic hardware architectural exploration named NAXT. Moreover, we propose modified versions of the standard Rate Coding technique to make trade-offs with the Time Coding paradigm, which is characterized by the low number of spikes propagating in the network. Thus, we are able to reduce the number of spikes while keeping the same neuron's model, which results in an SNN with fewer events to process. By doing so, we seek to reduce the amount of power consumed by the hardware. Furthermore, we present three neuromorphic hardware architectures in order to quantitatively study the implementation of SNNs. One of these architectures integrates a novel hybrid structure: a highly-parallel computation core for most solicited layers, and time-multiplexed computation units for deeper layers. These architectures are derived from a novel funnel-like Design Space Exploration framework for neuromorphic hardware.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FSXM5YUY\\Abderrahmane et al. - 2020 - Design Space Exploration of Hardware Spiking Neuro.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\P2L872SL\\Abderrahmane et al. - 2020 - Design Space Exploration of Hardware Spiking Neuro.pdf},
  journal = {Neural Networks},
  language = {en}
}

@article{abdullah_saparon_2017,
  title = {Functional Integration across Oscillation Frequencies by Cross-Frequency Phase Synchronization},
  author = {Abdullah, Ezmin and Idris, Azlina and Saparon, Azilah},
  year = {2017},
  volume = {12},
  pages = {3218--3221},
  issn = {18196608},
  doi = {10.1111/ijlh.12426},
  abstract = {Introduction: D-dimer assay, generally evaluated according to cutoff points calibrated for VTE exclusion, is used to estimate the individual risk of recurrence after a first idiopathic event of venous thromboembolism (VTE). Methods: Commercial D-dimer assays, evaluated according to predetermined cutoff levels for each assay, specific for age (lower in subjects \textbackslash textless70 years) and gender (lower in males), were used in the recent DULCIS study. The present analysis compared the results obtained in the DULCIS with those that might have been had using the following different cutoff criteria: traditional cutoff for VTE exclusion, higher levels in subjects aged {$\geq$}60 years, or age multiplied by 10. Results: In young subjects, the DULCIS low cutoff levels resulted in half the recurrent events that would have occurred using the other criteria. In elderly patients, the DULCIS results were similar to those calculated for the two age-adjusted criteria. The adoption of traditional VTE exclusion criteria would have led to positive results in the large majority of elderly subjects, without a significant reduction in the rate of recurrent event. Conclusion: The results confirm the usefulness of the cutoff levels used in DULCIS.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZA6X24Q3\\Abdullah, Idris, Saparon - 2017 - Functional integration across oscillation frequencies by cross-frequency phase synchronization.pdf},
  journal = {ARPN Journal of Engineering and Applied Sciences},
  keywords = {MIMO-OFDM,Peak-average power ratio,SCS,Space-time-frequency block codes},
  number = {10},
  pmid = {27935037}
}

@book{abe_kashimori_2018,
  title = {Visual and {{Category Representations Shaped}} by the {{Interaction Between Inferior Temporal}} and {{Prefrontal Cortices}}},
  author = {Abe, Yuki and Fujita, Kazuhisa and Kashimori, Yoshiki},
  year = {2018},
  doi = {10.1007/s12559-018-9570-0},
  abstract = {The ability to group items and events into functional categories is a fundamental function for visual recognition. Experimental studies have shown the different roles in information representations of inferior temporal (IT) and prefrontal cortices (PFC) in a categorization task. However, it remains elusive how category information is generated in PFC and maintained in a delay period and how the interaction between IT and PFC influences category performance. To address these issues, we develop a network model of visual system, which performs a delayed match-to-category task. The model consists of networks of V4, IT, and PFC. We show that in IT visual information required for categorization is represented by a combination of prototype features. We also show that category information in PFC is represented by two dynamical attractors weakly linked, resulting from the difference in firing thresholds of PFC neurons. Lower and higher firing thresholds contribute to working memory maintenance and decision-making, respectively. Furthermore, we show that top-down signal from PFC to IT improves the ability of PFC neurons to categorize the mixed images that are closer to a category boundary. Our model may provide a clue for understanding the neural mechanism underlying categorization task.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GC3K7FG5\\Abe, Fujita, Kashimori - Unknown - Visual and Category Representations Shaped by the Interaction Between Inferior Temporal and Prefronta.pdf},
  keywords = {Categorization,Inferior temporal cortex,Neural model,Prefrontal cortex,Top-down}
}

@article{ablavsky_sclaroff_2011,
  title = {Layered {{Graphical Models}} for {{Tracking Partially Occluded Objects}}},
  author = {Ablavsky, V. and Sclaroff, S.},
  year = {2011},
  month = sep,
  volume = {33},
  pages = {1758--1775},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.2011.43},
  abstract = {We propose a representation for scenes containing relocatable objects that can cause partial occlusions of people in a camera's field of view. In many practical applications, relocatable objects tend to appear often; therefore, models for them can be learned offline and stored in a database. We formulate an occluder-centric representation, called a graphical model layer, where a person's motion in the ground plane is defined as a first-order Markov process on activity zones, while image evidence is aggregated in 2D observation regions that are depth-ordered with respect to the occlusion mask of the relocatable object. We represent real-world scenes as a composition of depth-ordered, interacting graphical model layers, and account for image evidence in a way that handles mutual overlap of the observation regions and their occlusions by the relocatable objects. These layers interact: Proximate ground-plane zones of different model instances are linked to allow a person to move between the layers, and image evidence is shared between the observation regions of these models. We demonstrate our formulation in tracking pedestrians in the vicinity of parked vehicles. Our results compare favorably with a sprite-learning algorithm, with a pedestrian tracker based on deformable contours, and with pedestrian detectors.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\322B8PLG\\Ablavsky_Sclaroff_2011_Layered Graphical Models for Tracking Partially Occluded Objects.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\7CBTZJTU\\5728820.html},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  number = {9}
}

@article{abrams_paull_2008,
  title = {Altered Vision near the Hands},
  author = {Abrams, Richard A and Davoli, Christopher C and Du, Feng and Knapp, William H and Paull, Daniel},
  year = {2008},
  volume = {107},
  pages = {1035--1047},
  issn = {00100277},
  doi = {10.1016/j.cognition.2007.09.006},
  abstract = {The present study explored the manner in which hand position may affect visual processing. We studied three classic visual attention tasks (visual search, inhibition of return, and attentional blink) during which the participants held their hands either near the stimulus display, or far from the display. Remarkably, the hands altered visual processing: people shifted their attention between items more slowly when their hands were near the display. The same results were observed for both visible and invisible hands. This enhancement in vision for objects near the hands reveals a mechanism that could facilitate the detailed evaluation of objects for potential manipulation, or the assessment of potentially dangerous objects for a defensive response. ?? 2007 Elsevier B.V. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\76982SWF\\Abrams et al. - 2008 - Altered vision near the hands.pdf},
  journal = {Cognition},
  keywords = {Attention,Inhibition of return,Reaching,Vision,Visual attention,Visual search},
  number = {3},
  pmid = {17977524}
}

@article{abrams_weidler_2013,
  title = {Trade-Offs in Visual Processing for Stimuli near the Hands.},
  author = {Abrams, Richard A and Weidler, Blaire J},
  year = {2013},
  pages = {383--390},
  issn = {1943-393X},
  doi = {10.3758/s13414-013-0583-1},
  abstract = {It is known that stimuli near the hands receive preferential processing. In the present study, we explored changes in early vision near the hands. Participants were more sensitive to low-spatial-frequency information and less sensitive to high-spatial-frequency information for stimuli presented close to the hands. This pattern suggests enhanced processing in the magnocellular visual pathway for such stimuli, and impaired processing in the parvocellular pathway. Consistent with that possibility, we found that the effects of hand proximity in several tasks were eliminated by illumination with red diffuse light-a manipulation known to impair magnocellular processing. These results help clarify how the hands affect vision.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8KHHEJZD\\Abrams, Weidler - 2013 - Trade-offs in visual processing for stimuli near the hands.pdf},
  journal = {Attention, perception \{\&\} psychophysics},
  keywords = {changes in the perfor-,embodied perception,for example,mance of a number,of tasks that depend,on the proximity of,researchers have recently reported,stimuli being evaluated,the hands to the,visual perception},
  number = {November 2013},
  pmid = {24222266}
}

@unpublished{abrossimoff_gaussier_2020,
  title = {Working-Memory Prefrontal Model for Cognitive Flexibility in Task-Switching and Selection},
  author = {Abrossimoff, Julien and Pitti, Alexandre and Gaussier, Philippe},
  year = {2020},
  month = may,
  abstract = {We propose a working-memory model inspired by the prefrontal cortex for flexible cognitive tasks. Our neural model categorizes contexts depending on the task features and selects the most appropriate one relative to inputs. Output errors led to a reevaluation of the context confidence level and a shift to another or the creation of a new one. Tests on the Wisconsin card task show the relevance of our model. Impairments of brain parts that regulate the neuromodulators for context evaluation or output selection produces similar prefrontal disorder and degeneration found in the brain literature.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Y7E7E32I\\abrossimoff_gaussier_2020.pdf},
  keywords = {bottom-up learning,Index Terms-top-down learning,rules inference,task-set shifting,working memory}
}

@article{abstract_abstract_2018,
  title = {Origin of {{Gamma Frequency Power}} during {{Hippocampal Sharp}}-{{Wave Ripples}}},
  author = {Abstract, Graphical},
  year = {2018},
  doi = {10.1016/j.celrep.2018.10.066},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\77UUKPYB\\Abstract - 2018 - Origin of Gamma Frequency Power during Hippocampal Sharp-Wave Ripples.pdf}
}

@article{aceituno_jost_2020,
  title = {Spiking Time-Dependent Plasticity Leads to Efficient Coding of Predictions},
  author = {Aceituno, Pau and Ehsani, Masud and Jost, J{\"u}rgen},
  year = {2020},
  month = feb,
  volume = {114},
  pages = {43--61},
  issn = {0340-1200, 1432-0770},
  doi = {10.1007/s00422-019-00813-w},
  abstract = {Latency reduction in postsynaptic spikes is a well-known effect of spiking time-dependent plasticity. We expand this notion for long postsynaptic spike trains on single neurons, showing that, for a fixed input spike train, STDP reduces the number of postsynaptic spikes and concentrates the remaining ones. Then, we study the consequences of this phenomena in terms of coding, finding that this mechanism improves the neural code by increasing the signal-to-noise ratio and lowering the metabolic costs of frequent stimuli. Finally, we illustrate that the reduction in postsynaptic latencies can lead to the emergence of predictions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9UUTQRC2\\Vilimelis Aceituno et al. - 2020 - Spiking time-dependent plasticity leads to efficie.pdf},
  journal = {Biological Cybernetics},
  language = {en},
  number = {1}
}

@article{acharya_mehta_2016,
  title = {Causal {{Influence}} of {{Visual Cues}} on {{Hippocampal Article Causal Influence}} of {{Visual Cues}} on {{Hippocampal Directional Selectivity}}},
  author = {Acharya, Lavanya and Aghajan, Zahra M and Vuong, Cliff and Moore, Jason J and Mehta, Mayank R and Acharya, Lavanya and Aghajan, Zahra M and Vuong, Cliff and Moore, Jason J and Mehta, Mayank R},
  year = {2016},
  pages = {1--11},
  issn = {0092-8674},
  doi = {10.1016/j.cell.2015.12.015},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CQRNQZLA\\Acharya et al. - 2016 - Causal Influence of Visual Cues on Hippocampal Article Causal Influence of Visual Cues on Hippocampal Directiona.pdf},
  journal = {Cell}
}

@inproceedings{adamos_micheloyannis_2018,
  title = {Harnessing Functional Segregation across Brain Rhythms as a Means to Detect {{EEG}} Oscillatory Multiplexing during Music Listening},
  booktitle = {Journal of {{Neural Engineering}}},
  author = {Adamos, Dimitrios A. and Laskaris, Nikolaos A. and Micheloyannis, Sifis},
  year = {2018},
  volume = {15},
  doi = {10.1088/1741-2552/aaac36},
  abstract = {Objective. Music, being a multifaceted stimulus evolving at multiple timescales, modulates brain function in a manifold way that encompasses not only the distinct stages of auditory perception, but also higher cognitive processes like memory and appraisal. Network theory is apparently a promising approach to describe the functional reorganization of brain oscillatory dynamics during music listening. However, the music induced changes have so far been examined within the functional boundaries of isolated brain rhythms. Approach. Using naturalistic music, we detected the functional segregation patterns associated with different cortical rhythms, as these were reflected in the surface electroencephalography (EEG) measurements. The emerged structure was compared across frequency bands to quantify the interplay among rhythms. It was also contrasted against the structure from the rest and noise listening conditions to reveal the specific components stemming from music listening. Our methodology includes an efficient graph-partitioning algorithm, which is further utilized for mining prototypical modular patterns, and a novel algorithmic procedure for identifying 'switching nodes' (i.e. recording sites) that consistently change module during music listening. Main results. Our results suggest the multiplex character of the music-induced functional reorganization and particularly indicate the dependence between the networks reconstructed from the {$\delta$} and {$\beta$} H rhythms. This dependence is further justified within the framework of nested neural oscillations and fits perfectly within the context of recently introduced cortical entrainment to music. Significance. Complying with the contemporary trends towards a multi-scale examination of the brain network organization, our approach specifies the form of neural coordination among rhythms during music listening. Considering its computational efficiency, and in conjunction with the flexibility of in situ electroencephalography, it may lead to novel assistive tools for real-life applications.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4QA53JET\\Unknown - Unknown - Harnessing functional segregation across brain rhythms as a means to detect EEG oscillatory multiplexing during musi.pdf},
  keywords = {functional reorganization,Functional segregation,node-switching}
}

@article{adesnik_naka_2018,
  title = {Perspective {{Cracking}} the {{Function}} of {{Layers}} in the {{Sensory Cortex}}},
  author = {Adesnik, Hillel and Naka, Alexander},
  year = {2018},
  volume = {100},
  pages = {1028--1043},
  doi = {10.1016/j.neuron.2018.10.032},
  abstract = {Understanding how cortical activity generates sensory perceptions requires a detailed dissection of the function of cortical layers. Despite our relatively extensive knowledge of their anatomy and wiring, we have a limited grasp of what each layer contributes to cortical computation. We need to develop a theory of cortical function that is rooted solidly in each layer's component cell types and fine circuit architecture and produces predictions that can be validated by specific perturbations. Here we briefly review the progress toward such a theory and suggest an experimental road map toward this goal. We discuss new methods for the all-optical interrogation of cortical layers, for correlating in vivo function with precise identification of transcriptional cell type, and for mapping local and long-range activity in vivo with synaptic resolution. The new technologies that can crack the function of cortical layers are finally on the immediate horizon.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FJTZIRMA\\Adesnik, Naka - 2018 - Perspective Cracking the Function of Layers in the Sensory Cortex.pdf},
  journal = {Neuron},
  keywords = {cortex,cortical layers,cortical microcircuits,inhibitory circuits,neural circuits,neural codes,neural computation,neurotechnology,optogenetics}
}

@article{adhikari_bernard_2012,
  title = {Brain State Dependent Postinhibitory Rebound in Entorhinal Cortex Interneurons.},
  author = {Adhikari, Mohit H and Quilichini, Pascale P and Roy, Dipanjan and Jirsa, Viktor and Bernard, Christophe},
  year = {2012},
  month = may,
  volume = {32},
  pages = {6501--10},
  issn = {1529-2401},
  doi = {10.1523/JNEUROSCI.5871-11.2012},
  abstract = {Postinhibitory rebound (PIR) is believed to play an important role in the genesis and maintenance of biological rhythms. While it has been demonstrated during several in vitro studies, in vivo evidence for PIR remains scarce. Here, we report that PIR can be observed in the dorsomedial entorhinal cortex of anesthetized rats, mostly between putatively connected GABAergic interneurons, and that it is more prevalent during the theta (4-6 Hz) oscillation state than the slow (0.5-2 Hz) oscillation state. Functional inhibition was also found to be brain state and postsynaptic cell type dependent but that alone could not explain this brain state dependence of PIR. A theoretical analysis, using two Fitzhugh-Nagumo neurons coupled to an external periodic drive, predicted that the modulation of a faster spiking rate by the slower periodic drive could account for the brain state dependence of PIR. Model predictions were verified experimentally. We conclude that PIR is cell type and brain state dependent and propose that this could impact network synchrony and rhythmogenesis.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AS4RIWNW\\Adhikari et al. - 2012 - Brain state dependent postinhibitory rebound in entorhinal cortex interneurons.pdf},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  keywords = {Animals,Brain,Brain: physiology,Entorhinal Cortex,Entorhinal Cortex: physiology,Interneurons,Interneurons: physiology,Male,Neural Inhibition,Neural Inhibition: physiology,Rats,Sprague-Dawley},
  number = {19},
  pmid = {22573672}
}

@techreport{adjodah_joseph_2018,
  title = {Symbolic {{Relation Networks}} for {{Reinforcement Learning}}},
  author = {Adjodah, Dhaval and Klinger, Tim and Joseph, Joshua},
  year = {2018},
  abstract = {In recent years, reinforcement learning techniques have enjoyed considerable success in a variety of challenging domains, but are typically sample inefficient and often fail to generalize well to new environments or tasks. Humans, by contrast, are able to learn robust skills with orders of magnitude less training. One hypothesis for this discrepancy is that humans view the world in terms of objects and relations between them. Such a bias may be useful reducing sample complexity and improving interpretability and generalization. In this paper, we present a novel relational architecture which has multiple neural network sub-modules called relational units which operate on objects and output values in the unit interval. Our model transforms the input state representation into a relational representation, which is then supplied as input to a Q-learner. Experiments on a goal-seeking game with random boards show better performance over several baselines: a multi-headed attention model, a standard MLP, a pixel MLP and a symbolic RL model. We also find that the relations learned in the network are interpretable.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BNQ3ZNIE\\Adjodah, Klinger, Joseph - Unknown - Symbolic Relation Networks for Reinforcement Learning.pdf}
}

@book{aggleton_christiansen_2015,
  title = {The Subiculum: The Heart of the Extended Hippocampal System},
  author = {Aggleton, John P. and Christiansen, Kat},
  year = {2015},
  edition = {First},
  volume = {219},
  publisher = {{Elsevier B.V.}},
  doi = {10.1016/bs.pbr.2015.03.003},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\D8M2CLZT\\Aggleton, Christiansen - 2015 - The subiculum the heart of the extended hippocampal system.pdf},
  keywords = {ca1 field,CA1 field,hippocampus,Hippocampus,memory,Memory,parahippocampal region,Parahippocampal region,parasubiculum,Parasubiculum,postsubiculum,Postsubiculum,presubiculum,Presubiculum,space,Space,subicular complex,Subicular complex}
}

@techreport{agnes_vogels_2019,
  title = {Complementary Inhibitory Weight Profiles Emerge from Plasticity and Allow Attentional Switching of Receptive Fields},
  author = {Agnes, Everton J. and Luppi, Andrea I. and Vogels, Tim P.},
  year = {2019},
  month = aug,
  institution = {{Neuroscience}},
  doi = {10.1101/729988},
  abstract = {Cortical areas comprise multiple types of inhibitory interneurons with stereotypical connectivity motifs, but their combined effect on postsynaptic dynamics has been largely unexplored. Here, we analyse the response of a single postsynaptic model neuron receiving tuned excitatory connections alongside inhibition from two plastic populations. Depending on the inhibitory plasticity rule, synapses remain unspecific (flat), become anti-correlated to, or mirror excitatory synapses. Crucially, the neuron's receptive field, i.e., its response to presynaptic stimuli, depends on the modulatory state of inhibition. When both inhibitory populations are active, inhibition balances excitation, resulting in uncorrelated postsynaptic responses regardless of the inhibitory tuning profiles. Modulating the activity of a given inhibitory population produces strong correlations to either preferred or non-preferred inputs, in line with recent experimental findings showing dramatic context-dependent changes of neurons' receptive fields. We thus confirm that a neuron's receptive field doesn't follow directly from the weight profiles of its presynaptic afferents.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\K2JH7XWD\\Agnes et al. - 2019 - Complementary inhibitory weight profiles emerge fr.pdf},
  language = {en},
  type = {Preprint}
}

@article{ahn_zhang_2017,
  title = {Revealing {{Neurocomputational Mechanisms}} of {{Reinforcement Learning}} and {{Decision}}-{{Making With}} the {{hBayesDM Package}}},
  author = {Ahn, Woo-Young and Haines, Nathaniel and Zhang, Lei},
  year = {2017},
  doi = {10.1162/cpsy_a_00002},
  abstract = {Reinforcement learning and decision-making (RLDM) provide a quantitative framework and computational theories with which we can disentangle psychiatric conditions into the basic dimensions of neurocognitive functioning. RLDM offer a novel approach to assessing and potentially diagnosing psychiatric patients, and there is growing enthusiasm for both RLDM and computational psychiatry among clinical researchers. Such a framework can also provide insights into the brain substrates of particular RLDM processes, as exemplified by model-based analysis of data from functional magnetic resonance imaging (fMRI) or electroencephalography (EEG). However, researchers often find the approach too technical and have difficulty adopting it for their research. Thus, a critical need remains to develop a user-friendly tool for the wide dissemination of computational psychiatric methods. We introduce an R package called hBayesDM (hierarchical Bayesian modeling of Decision-Making tasks), which offers computational modeling of an array of RLDM tasks and social exchange games. The hBayesDM package offers state-of-the-art hierarchical Bayesian modeling, in which both individual and group parameters (i.e., posterior distributions) are estimated simultaneously in a mutually constraining fashion. At the same time, the package is extremely user-friendly: users can perform computational modeling, output visualization, and Bayesian model comparisons, each with a single line of coding. Users can also extract the trial-by-trial latent variables (e.g., prediction errors) required for model-based fMRI/EEG. With the hBayesDM package, we anticipate that anyone with minimal knowledge of programming can take advantage of cutting-edge computational-modeling approaches to investigate the underlying processes of and interactions between multiple decision-making (e.g., goal-directed, habitual, and Pavlovian) systems. In this way, we expect that the hBayesDM package will contribute to the dissemination of advanced modeling approaches and enable a wide range of researchers to easily perform computational psychiatric research within different populations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RMTY3HJ2\\Ahn, Haines, Zhang - 2017 - Revealing Neurocomputational Mechanisms of Reinforcement Learning and Decision-Making With the hBayesDM Pack.pdf},
  keywords = {decision-making,hierarchical Bayesian modeling,model-based fMRI,reinforcement learning}
}

@article{ahrens_aldridge_2016,
  title = {Neural {{Activity}} in the {{Ventral Pallidum Encodes Variation}} in the {{Incentive Value}} of a {{Reward Cue}}},
  author = {Ahrens, Allison M and Meyer, Paul J and Ferguson, Lindsay M and Robinson, Terry E and Aldridge, J Wayne},
  year = {2016},
  volume = {36},
  pages = {7957--7970},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.0736-16.2016},
  abstract = {UNLABELLED There is considerable individual variation in the extent to which reward cues are attributed with incentive salience. For example, a food-predictive conditioned stimulus (CS; an illuminated lever) becomes attractive, eliciting approach toward it only in some rats ("sign trackers," STs), whereas others ("goal trackers," GTs) approach the food cup during the CS period. The purpose of this study was to determine how individual differences in Pavlovian approach responses are represented in neural firing patterns in the major output structure of the mesolimbic system, the ventral pallidum (VP). Single-unit in vivo electrophysiology was used to record neural activity in the caudal VP during the performance of ST and GT conditioned responses. All rats showed neural responses to both cue onset and reward delivery but, during the CS period, STs showed greater neural activity than GTs both in terms of the percentage of responsive neurons and the magnitude of the change in neural activity. Furthermore, neural activity was positively correlated with the degree of attraction to the cue. Given that the CS had equal predictive value in STs and GTs, we conclude that neural activity in the VP largely reflects the degree to which the CS was attributed with incentive salience. SIGNIFICANCE STATEMENT Cues associated with reward can acquire motivational properties (i.e., incentive salience) that cause them to have a powerful influence on desire and motivated behavior. There are individual differences in sensitivity to reward-paired cues, with some individuals attaching greater motivational value to cues than others. Here, we investigated the neural activity associated with these individual differences in incentive salience. We found that cue-evoked neural firing in the ventral pallidum (VP) reflected the strength of incentive motivation, with the greatest neural responses occurring in individuals that demonstrated the strongest attraction to the cue. This suggests that the VP plays an important role in the process by which cues gain control over motivation and behavior.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JD8PTXGF\\Ahrens et al. - 2016 - Neural Activity in the Ventral Pallidum Encodes Variation in the Incentive Value of a Reward Cue.pdf},
  journal = {The Journal of Neuroscience},
  keywords = {goal tracking,motivation,Pavlovian conditioning,rats,sign tracking,ventral pallidum},
  number = {30},
  pmid = {27466340}
}

@article{ahveninen_jaaskelainen_2016,
  title = {Interacting Parallel Pathways Associate Sounds with Visual Identity in Auditory Cortices},
  author = {Ahveninen, Jyrki and Huang, Samantha and Ahlfors, Seppo P and H{\"a}m{\"a}l{\"a}inen, Matti and Rossi, Stephanie and Sams, Mikko and J{\"a}{\"a}skel{\"a}inen, Iiro P},
  year = {2016},
  volume = {124},
  pages = {858--868},
  doi = {10.1016/j.neuroimage.2015.09.044},
  abstract = {a b s t r a c t Spatial and non-spatial information of sound events is presumably processed in parallel auditory cortex (AC) " what " and " where " streams, which are modulated by inputs from the respective visual-cortex subsystems. How these parallel processes are integrated to perceptual objects that remain stable across time and the source agent's movements is unknown. We recorded magneto-and electroencephalography (MEG/EEG) data while subjects viewed animated video clips featuring two audiovisual objects, a black cat and a gray cat. Adaptor-probe events were either linked to the same object (the black cat meowed twice in a row in the same location) or included a visually conveyed identity change (the black and then the gray cat meowed with identical voices in the same location). In addition to effects in visual (including fusiform, middle temporal or MT areas) and frontoparietal association areas, the visually conveyed object-identity change was associated with a release from adaptation of early (50\textendash 150 ms) activity in posterior ACs, spreading to left anterior ACs at 250\textendash 450 ms in our combined MEG/EEG source estimates. Repetition of events belonging to the same object resulted in increased theta-band (4\textendash 8 Hz) synchronization within the " what " and " where " pathways (e.g., between anterior AC and fusiform areas). In contrast, the visually conveyed identity changes resulted in distributed synchronization at higher frequencies (alpha and beta bands, 8\textendash 32 Hz) across different auditory, visual, and association areas. The results suggest that sound events become initially linked to perceptual objects in posterior AC, followed by mod-ulations of representations in anterior AC. Hierarchical what and where pathways seem to operate in parallel after repeating audiovisual associations, whereas the resetting of such associations engages a distributed network across auditory, visual, and multisensory areas.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7Z5MFPRV\\Ahveninen et al. - 2016 - Interacting parallel pathways associate sounds with visual identity in auditory cortices.pdf},
  journal = {NeuroImage}
}

@article{aisa_oreilly_2008,
  title = {The {{Emergent}} Neural Modeling System},
  author = {Aisa, Brad and Mingus, Brian and O'Reilly, Randall C},
  year = {2008},
  volume = {21},
  pages = {1146--1152},
  issn = {08936080},
  doi = {10.1016/j.neunet.2008.06.016},
  abstract = {Emergent (http://grey.colorado.edu/emergent) is a powerful tool for the simulation of biologically plausible, complex neural systems that was released in August 2007. Inheriting decades of research and experience in network algorithms and modeling principles from its predecessors, PDP++??and PDP, Emergent has been redesigned as an efficient workspace for academic research and an engaging, easy-to-navigate environment for students. The system provides a modern and intuitive interface for programming and visualization centered around hierarchical, tree-based navigation and drag-and-drop reorganization. Emergent contains familiar, high-level simulation constructs such as Layers and Projections, a wide variety of algorithms, general-purpose data handling and analysis facilities and an integrated virtual environment for developing closed-loop cognitive agents. For students, the traditional role of a textbook has been enhanced by wikis embedded in every project that serve to explain, document, and help newcomers engage the interface and step through models using familiar hyperlinks. For advanced users, the software is easily extensible in all respects via runtime plugins, has a powerful shell with an integrated debugger, and a scripting language that is fully symmetric with the interface. Emergent strikes a balance between detailed, computationally expensive spiking neuron models and abstract, Bayesian or symbolic systems. This middle level of detail allows for the rapid development and successful execution of complex cognitive models while maintaining biological plausibility. ?? 2008 Elsevier Ltd. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\A4CNQJRH\\Aisa, Mingus, O'Reilly - 2008 - The Emergent neural modeling system.pdf},
  journal = {Neural Networks},
  keywords = {Neural networks,Robotics,Simulator},
  number = {8},
  pmid = {18684591}
}

@article{ajemian_grossberg_2001,
  title = {A Model of Movement Coordinates in the Motor Cortex: Posture-Dependent Changes in the Gain and Direction of Single Cell Tuning Curves.},
  author = {Ajemian, R and Bullock, D and Grossberg, S},
  year = {2001},
  month = dec,
  volume = {11},
  pages = {1124--35},
  issn = {1047-3211},
  abstract = {This article outlines a methodology for investigating the coordinate systems by which movement variables are encoded in the firing rates of individual motor cortical neurons. Recent neurophysiological experiments have probed the issue of underlying coordinates by examining how cellular preferred directions (as determined by the center-out task) change with posture. Several key experimental findings have resulted that constrain hypotheses about how motor cortical cells encode movement information. But while the significance of shifts in preferred direction is well known and widely accepted, posture-dependent changes in the depth of modulation of a cell's tuning curve\textendash that is, gain changes\textendash have not been similarly identified as a means of coordinate inference. This article develops a vector field framework in which the preferred direction and the gain of a cell's tuning curve are viewed as dual components of a unitary response vector. The formalism can be used to compute how each aspect of cell response covaries with posture as a function of the coordinate system in which a given cell is hypothesized to encode its movement information. Such an integrated approach leads to a model of motor cortical cell activity that codifies the following four observations: (i) cell activity correlates with hand movement direction; (ii) cell activity correlates with hand movement speed; (iii) preferred directions vary with posture; and (iv) the modulation depth of tuning curves varies with posture. Finally, the model suggests general methods for testing coordinate hypotheses at the single-cell level and simulates an example protocol for three possible coordinate systems: Cartesian spatial, shoulder-centered, and joint angle.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EGXF76EJ\\Ajemian, Bullock, Grossberg - 2001 - A model of movement coordinates in the motor cortex posture-dependent changes in the gain and direc.pdf},
  journal = {Cerebral cortex (New York, N.Y. : 1991)},
  keywords = {Animals,Arm,Humans,Models,Motor Cortex,Motor Cortex: cytology,Motor Cortex: physiology,Movement,Movement: physiology,Neurological,Neurons,Neurons: physiology},
  number = {12},
  pmid = {11709483}
}

@article{akil_josic_2020,
  title = {Synaptic {{Plasticity}} in {{Correlated Balanced Networks}}},
  author = {Akil, Alan Eric and Rosenbaum, Robert and Josi{\'c}, Kre{\v s}imir},
  year = {2020},
  month = apr,
  abstract = {The dynamics of local cortical networks are irregular, but correlated. Dynamic excitatory--inhibitory balance is a plausible mechanism that generates such irregular activity, but it remains unclear how balance is achieved and maintained in plastic neural networks. In particular, it is not fully understood how plasticity induced changes in the network affect balance, and in turn, how correlated, balanced activity impacts learning. How does the dynamics of balanced networks change under different plasticity rules? How does correlated spiking activity in recurrent networks change the evolution of weights, their eventual magnitude, and structure across the network? To address these questions, we develop a general theory of plasticity in balanced networks. We show that balance can be attained and maintained under plasticity induced weight changes. We find that correlations in the input mildly, but significantly affect the evolution of synaptic weights. Under certain plasticity rules, we find an emergence of correlations between firing rates and synaptic weights. Under these rules, synaptic weights converge to a stable manifold in weight space with their final configuration dependent on the initial state of the network. Lastly, we show that our framework can also describe the dynamics of plastic balanced networks when subsets of neurons receive targeted optogenetic input.},
  archivePrefix = {arXiv},
  eprint = {2004.12453},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JNR8YVCI\\akil_josic_2020.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\DD5I2LJZ\\2004.html},
  journal = {arXiv:2004.12453 [q-bio]},
  keywords = {Quantitative Biology - Neurons and Cognition},
  primaryClass = {q-bio}
}

@article{akrami_brody_2018,
  title = {Posterior Parietal Cortex Represents Sensory History and Mediates Its Effects on Behavior},
  author = {Akrami, Athena and Kopec, Charles D. and Diamond, Mathew E. and Brody, Carlos D.},
  year = {2018},
  volume = {554},
  pages = {182246},
  issn = {0028-0836},
  doi = {10.1101/182246},
  abstract = {Many models of cognition and of neural computations posit the use and estimation of prior stimulus statistics: it has long been known that working memory and perception are strongly impacted by previous sensory experience, even when that sensory history is irrelevant for the current task at hand. Nevertheless, the neural mechanisms and brain regions necessary for computing and using such priors are unknown. Here we report that the posterior parietal cortex (PPC) is a critical locus for the representation and use of prior stimulus information. We trained rats in an auditory Parametric Working Memory (PWM) task, and found that rats displayed substantial and readily quantifiable behavioral effects of sensory stimulus history, similar to those observed in humans and monkeys. Earlier proposals that PPC supports working memory predict that optogenetic silencing of this region would impair behavior in our working memory task. Contrary to this prediction, silencing PPC significantly improved performance. Quantitative analyses of behavior revealed that this improvement was due to the selective reduction of the effects of prior sensory stimuli. Electrophysiological recordings showed that PPC neurons carried far more information about sensory stimuli of previous trials than about stimuli of the current trial. Furthermore, the more information about previous trial sensory history in the neural firing rates of a given rat's PPC, the greater the behavioral effect of sensory history in that rat, suggesting a tight link between behavior and PPC representations of stimulus history. Our results indicate that the PPC is a central component in the processing of sensory stimulus history, and open a window for neurobiological investigation of long-standing questions regarding how perception and working memory are affected by prior sensory information.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\58MMGP53\\Akrami et al. - 2018 - Posterior parietal cortex represents sensory history and mediates its effects on behavior.pdf},
  journal = {bioRxiv},
  number = {7692},
  pmid = {29414944}
}

@article{alemi_slotine_2017,
  title = {Learning Arbitrary Dynamics in Efficient, Balanced Spiking Networks Using Local Plasticity Rules},
  author = {Alemi, Alireza and Machens, Christian and Den{\`e}ve, Sophie and Slotine, Jean-Jacques},
  year = {2017},
  month = aug,
  abstract = {Understanding how recurrent neural circuits can learn to implement dynamical systems is a fundamental challenge in neuroscience. The credit assignment problem, i.e. determining the local contribution of each synapse to the network's global output error, is a major obstacle in deriving biologically plausible local learning rules. Moreover, spiking recurrent networks implementing such tasks should not be hugely costly in terms of number of neurons and spikes, as they often are when adapted from rate models. Finally, these networks should be robust to noise and neural deaths in order to sustain these representations in the face of such naturally occurring perturbation. We approach this problem by fusing the theory of efficient, balanced spiking networks (EBN) with nonlinear adaptive control theory. Local learning rules are ensured by feeding back into the network its own error, resulting in a synaptic plasticity rule depending solely on presynaptic inputs and post-synaptic feedback. The spiking efficiency and robustness of the network are guaranteed by maintaining a tight excitatory/inhibitory balance, ensuring that each spike represents a local projection of the global output error and minimizes a loss function. The resulting networks can learn to implement complex dynamics with very small numbers of neurons and spikes, exhibit the same spike train variability as observed experimentally, and are extremely robust to noise and neuronal loss.},
  archivePrefix = {arXiv},
  eprint = {1705.08026},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9Z7LN6JC\\Alemi et al. - 2017 - Learning arbitrary dynamics in efficient, balanced.pdf},
  journal = {arXiv:1705.08026 [q-bio]},
  language = {en},
  primaryClass = {q-bio}
}

@article{alemi_slotine_2018,
  title = {Learning {{Nonlinear Dynamics}} in {{Efficient}}, {{Balanced Spiking Networks Using Local Plasticity Rules}}},
  author = {Alemi, Aireza and Machens, Christian K and Deneve, Sophie and Slotine, Jean-Jacques},
  year = {2018},
  pages = {8},
  abstract = {The brain uses spikes in neural circuits to perform many dynamical computations. The computations are performed with properties such as spiking efficiency, i.e. minimal number of spikes, and robustness to noise. A major obstacle for learning computations in artificial spiking neural networks with such desired biological properties is due to lack of our understanding of how biological spiking neural networks learn computations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MFFH5LAL\\Alemi et al. - Learning Nonlinear Dynamics in Efficient, Balanced.pdf},
  language = {en}
}

@article{alemi_zecchina_2015,
  title = {A Three-Threshold Learning Rule Approaches the Maximal Capacity of Recurrent Neural Networks},
  author = {Alemi, Alireza and Baldassi, Carlo and Brunel, Nicolas and Zecchina, Riccardo},
  year = {2015},
  month = aug,
  pages = {1--24},
  doi = {10.1371/journal.pcbi.1004439},
  abstract = {Understanding the theoretical foundations of how memories are encoded and retrieved in neural populations is a central challenge in neuroscience. A popular theoretical scenario for modeling memory function is the attractor neural network scenario, whose prototype is the Hopfield model. The model has a poor storage capacity, compared with the capacity achieved with perceptron learning algorithms. Here, by transforming the perceptron learning rule, we present an online learning rule for a recurrent neural network that achieves near-maximal storage capacity without an explicit supervisory error signal, relying only upon locally accessible information. The fully-connected network consists of excitatory binary neurons with plastic recurrent connections and non-plastic inhibitory feedback stabilizing the network dynamics; the memory patterns are presented online as strong afferent currents, producing a bimodal distribution for the neuron synaptic inputs. Synapses corresponding to active inputs are modified as a function of the value of the local fields with respect to three thresholds. Above the highest threshold, and below the lowest threshold, no plasticity occurs. In between these two thresholds, potentiation/depression occurs when the local field is above/below an intermediate threshold. We simulated and analyzed a network of binary neurons implementing this rule and measured its storage capacity for different sizes of the basins of attraction. The storage capacity obtained through numerical simulations is shown to be close to the value predicted by analytical calculations. We also measured the dependence of capacity on the strength of external inputs. Finally, we quantified the statistics of the resulting synaptic connectivity matrix, and found that both the fraction of zero weight synapses and the degree of symmetry of the weight matrix increase with the number of stored patterns.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GVTILBGU\\Alemi et al. - 2015 - A three-threshold learning rule approaches the maximal capacity of recurrent neural networks.pdf},
  journal = {arXiv}
}

@article{alexander_brown_2018,
  title = {Frontal Cortex Function as Derived from Hierarchical Predictive Coding},
  author = {Alexander, William H and Brown, Joshua W},
  year = {2018},
  doi = {10.1038/s41598-018-21407-9},
  abstract = {The frontal lobes are essential for human volition and goal-directed behavior, yet their function remains unclear. While various models have highlighted working memory, reinforcement learning, and cognitive control as key functions, a single framework for interpreting the range of effects observed in prefrontal cortex has yet to emerge. Here we show that a simple computational motif based on predictive coding can be stacked hierarchically to learn and perform arbitrarily complex goal-directed behavior. The resulting Hierarchical Error Representation (HER) model simulates a wide array of findings from fMRI, ERP, single-units, and neuropsychological studies of both lateral and medial prefrontal cortex. By reconceptualizing lateral prefrontal activity as anticipating prediction errors, the HER model provides a novel unifying account of prefrontal cortex function with broad implications for understanding the frontal cortex across multiple levels of description, from the level of single neurons to behavior. The frontal lobes are central to volition and higher cognitive function, especially goal-directed behavior 1\textendash 3 . Recent work has highlighted reinforcement learning 4\textendash 6 , performance monitoring 7,8 , and hierarchical abstraction and working memory 9\textendash 11 as key elements of frontal function, often under the framework of cognitive control 12 . Considering the range of methods and perspectives applied to investigating prefrontal cortex (PFC), there is a clear need for a common framework for interpreting the variety of functions assigned to the frontal lobes. Within the past decade, predictive coding has emerged as just such a potentially unifying framework for understanding the organization and function of the brain 13},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GXRPMDIL\\Alexander and Brown - 2018 - Frontal cortex function as derived from hierarchic.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\L77NR6JG\\Alexander, Brown - Unknown - Frontal cortex function as derived from hierarchical predictive coding.pdf}
}

@article{alexander_hasselmo_2019,
  title = {Egocentric Boundary Vector Tuning of the Retrosplenial Cortex},
  author = {Alexander, Andrew S. and Carstensen, Lucas C. and Hinman, James R. and Raudies, Florian and Chapman, G. William and Hasselmo, Michael E.},
  year = {2019},
  month = jul,
  doi = {10.1101/702712},
  abstract = {Abstract           The retrosplenial cortex is reciprocally connected with a majority of structures implicated in spatial cognition and damage to the region itself produces numerous spatial impairments. However, in many ways the retrosplenial cortex remains understudied. Here, we sought to characterize spatial correlates of neurons within the region during free exploration in two-dimensional environments. We report that a large percentage of retrosplenial cortex neurons have spatial receptive fields that are active when environmental boundaries are positioned at a specific orientation and distance relative to the animal itself. We demonstrate that this vector-based location signal is encoded in egocentric coordinates, localized to the dysgranular retrosplenial sub-region, independent of self-motion, and context invariant. Further, we identify a sub-population of neurons with this response property that are synchronized with the hippocampal theta oscillation. Accordingly, the current work identifies a robust egocentric spatial code in retrosplenial cortex that can facilitate spatial coordinate system transformations and support the anchoring, generation, and utilization of allocentric representations.},
  copyright = {All rights reserved},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\US9UT4WR\\Alexander et al. - 2019 - Egocentric boundary vector tuning of the retrosple.pdf},
  journal = {Science Advances},
  language = {en}
}

@article{alexander_nitz_2015,
  title = {Retrosplenial Cortex Maps the Conjunction of Internal and External Spaces.},
  author = {Alexander, Andrew and a Nitz, Douglas},
  year = {2015},
  volume = {18},
  pages = {1--12},
  issn = {1546-1726},
  doi = {10.1038/nn.4058},
  abstract = {Intelligent behavior demands not only multiple forms of spatial representation, but also coordination among the brain regions mediating those representations. Retrosplenial cortex is densely interconnected with the majority of cortical and subcortical brain structures that register an animal's position in multiple internal and external spatial frames of reference. This unique anatomy suggests that it functions to integrate distinct forms of spatial information and provides an interface for transformations between them. Evidence for this was found in rats traversing two different routes placed at different environmental locations. Retrosplenial ensembles robustly encoded conjunctions of progress through the current route, position in the larger environment and the left versus right turning behavior of the animal. Thus, the retrosplenial cortex has the requisite dynamics to serve as an intermediary between brain regions generating different forms of spatial mapping, a result that is consistent with navigational and episodic memory impairments following damage to this region in humans.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VCZ7WQU4\\Alexander, Nitz - 2015 - Retrosplenial cortex maps the conjunction of internal and external spaces(2).pdf},
  journal = {Nature neuroscience},
  number = {July},
  pmid = {26147532}
}

@article{alexander_nitz_2017,
  title = {Spatially {{Periodic Activation Patterns}} of {{Retrosplenial Cortex Encode Route Sub}}-Spaces and {{Distance Traveled}}},
  author = {Alexander, Andrew and Nitz, Douglas A.},
  year = {2017},
  volume = {27},
  pages = {1551--1560.e4},
  issn = {09609822},
  doi = {10.1016/j.cub.2017.04.036},
  abstract = {Traversal of a complicated route is often facilitated by considering it as a set of related sub-spaces. Such compartmentalization processes could occur within retrosplenial cortex, a structure whose neurons simultaneously encode position within routes and other spatial coordinate systems. Here, retrosplenial cortex neurons were recorded as rats traversed a track having recurrent structure at multiple scales. Consistent with a major role in compartmentalization of complex routes, individual retrosplenial cortex (RSC) neurons exhibited periodic activation patterns that repeated across route segments having the same shape. Concurrently, a larger population of RSC neurons exhibited single-cycle periodicity over the full route, effectively defining a framework for encoding of sub-route positions relative to the whole. The same population simultaneously provides a novel metric for distance from each route position to all others. Together, the findings implicate retrosplenial cortex in the extraction of path sub-spaces, the encoding of their spatial relationships to each other, and path integration.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\B9HWBM46\\Alexander, Nitz - 2017 - Spatially Periodic Activation Patterns of Retrosplenial Cortex Encode Route Sub-spaces and Distance Traveled.pdf},
  journal = {Current Biology},
  keywords = {distance,fragmentation,hippocampus,path integration,periodicity,retrosplenial cortex,spatial navigation,spatial representation,sub-route,sub-space},
  number = {11},
  pmid = {28528904}
}

@article{alexanderthiele_alexanderthiele_2018,
  title = {Neuromodulation of {{Attention}}},
  author = {{Alexander Thiele}},
  year = {2018},
  volume = {97},
  pages = {769--785},
  doi = {10.1016/j.neuron.2018.01.008},
  abstract = {Attention is critical to high-level cognition and attention deficits are a hallmark of neurologic and neuropsy-chiatric disorders. Although years of research indicates that distinct neuromodulators influence attentional control, a mechanistic account that traverses levels of analysis (cells, circuits, behavior) is missing. However, such an account is critical to guide the development of next-generation pharmacotherapies aimed at forestalling or remediating the global burden associated with disorders of attention. Here, we summarize current neuroscientific understanding of how attention affects single neurons and networks of neurons. We then review key results that have informed our understanding of how neuromodulation shapes these neuron and network properties and thereby enables the appropriate allocation of attention to relevant external or internal events. Finally, we highlight areas where we believe hypotheses can be formulated and tackled experimentally in the near future, thereby critically increasing our mechanistic understanding of how attention is implemented at the cellular and network levels. The limited processing capacity of the perceptual system poses a complex computational problem for humans and other organisms: which inputs are relevant to current behavioral goals? Decades of research has now been devoted to understanding how neurons instantiate the required ''selectivity'' that allows an organism to prioritize, or bias, the processing of relevant over irrelevant inputs. Neuronal processing may be biased by both bottom-up and top-down influences. The former reflects the biasing of sensory processing due to stimulus saliency (brightness, movement, size, for example), which causes features to ''pop-out'' from their surroundings to capture attention. Top-down processing on the other hand reflects the voluntary guidance of attention to locations, features, or objects in the environment. In this way, top-down attention allows for the voluntary processing of relevant over irrelevant inputs in line with the current behavioral goals of the organism (Desimone and Duncan, 1995). A network of prefrontal and parietal cortical areas is critically involved in the selection required for top-down attention, and other high-level cognitive functions such as working memory or inhibitory control (Bichot et al., 2015; Corbetta and Shulman, 2002; Fedorenko et al., 2013; Moore and Armstrong, 2003). The state and functionality of this network depend on tightly controlled activity in brainstem neurons that release neuromodu-lators at their target sites. Neuromodulators configure neuronal circuits and thereby specify output properties (Marder, 2012). They thus shape information processing in local and large-scale neuronal networks, such that relevant, over irrelevant, information is prioritized. This in turn drives behavior the subject hopes to be rewarding or behavior that minimizes adverse outcomes. Understanding precisely how this is achieved at the level of single neurons, local networks, or large-scale networks is vital for basic and clinical neuroscience. Neuromodulators most strongly implicated in high-level cognitive functions are acetyl-choline (ACh), dopamine (DA), noradrenaline (NA), and serotonin (5-HT). In this review, we focus on their relevance for top-down attentional control. While we will focus on their role in relation to attention, the above neuromodulators have major roles in other aspects of cognition, such as reward signaling (e. An important point to address from the outset is how attention , i.e., the top-down prioritization of behaviorally relevant inputs, differs from working memory. Working memory can be conceived as an active process whereby stimulus or internal representations are stored ''on-line'' to prevent temporal decay or intrusion from competing or distracting stimuli that are outside the current focus of attention. Dissociating effects of attention from those of working memory is difficult and in practice the two processes are highly interactive (Awh and Jonides, 2001). Attention, as conceptualized in this paper, is a selection mechanism that allows for the preferential processing of task-relevant information over irrelevant (distracting) information, i.e., it is a filter mechanism. This selection is driven by currently active behavioral goals held in working memory. In that sense, attention acts in the service of working memory. However, behavioral paradigms employed in neurophysiological studies highlight the potentially close coupling of attention and working memory (e.g., cue-guided spatial working memory tasks or cue-guided spatial attention task). In the cue-guided spatial working memory task, a brief spatial cue will capture attention, which then triggers the working memory signal that enacts the behavioral goal of a memory-guided saccade to cued spatial location. We contend that covert spatial attention would also be allocated to the cued location during the memory period, rendering the two Neuron 97, February 21,},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4EWRECC8\\Ach, Delong Rutledge - 2018 - Neuromodulation of Attention.pdf},
  journal = {Neuron},
  keywords = {attention,attractor networks,neuromodulators,pharmacology,population coding,top-down}
}

@article{ali_khan_2014,
  title = {A {{Broadcast}}-{{Based Key Agreement Scheme Using Set Reconciliation}} for {{Wireless Body Area Networks}}},
  author = {Ali, Aftab and Khan, Farrukh Aslam},
  year = {2014},
  volume = {38},
  pages = {33},
  issn = {0148-5598},
  doi = {10.1007/s10916-014-0033-1},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZQCP6LYI\\Ali, Khan - 2014 - A Broadcast-Based Key Agreement Scheme Using Set Reconciliation for Wireless Body Area Networks.pdf},
  journal = {Journal of Medical Systems},
  number = {5}
}

@article{aljadeff_kleinfeld_2016,
  title = {Analysis of {{Neuronal Spike Trains}}, {{Deconstructed}}},
  author = {Aljadeff, Johnatan and Lansdell, Benjamin J. and Fairhall, Adrienne L. and Kleinfeld, David},
  year = {2016},
  month = jul,
  volume = {91},
  pages = {221--259},
  issn = {08966273},
  doi = {10.1016/j.neuron.2016.05.039},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CQU4SYCP\\Aljadeff et al. - 2016 - Analysis of Neuronal Spike Trains, Deconstructed.pdf},
  journal = {Neuron},
  language = {en},
  number = {2}
}

@article{alme_moser_2014,
  title = {Place Cells in the Hippocampus: {{Eleven}} Maps for Eleven Rooms},
  author = {Alme, Charlotte B. and Miao, Chenglin and Jezek, Karel and Treves, Alessandro and Moser, Edvard I. and Moser, May-Britt},
  year = {2014},
  month = dec,
  pages = {201421056},
  issn = {0027-8424},
  doi = {10.1073/pnas.1421056111},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NTH4NZKP\\Alme et al. - 2014 - Place cells in the hippocampus Eleven maps for eleven rooms.pdf},
  journal = {Proceedings of the National Academy of Sciences}
}

@article{alonso_klink_1993,
  title = {Differential Electroresponsiveness of Stellate and Pyramidal-like Cells of Medial Entorhinal Cortex Layer {{II}}.},
  author = {Alonso, a and Klink, R},
  year = {1993},
  month = jul,
  volume = {70},
  pages = {128--43},
  issn = {0022-3077},
  abstract = {1. The electroresponsive properties of neurons from layer II of the rat medial entorhinal cortex (MEC) were studied by intracellular recording under current clamp in an in vitro brain slice preparation. From a total of 184 cells that fulfilled our criteria for recording stability, two groups of projection neurons were distinguished on the basis of their intrinsic biophysical properties and morphological characteristics (demonstrated by intracellular biocytin injection; n = 34). 2. Stellate cells (SCs) were the most abundant (69\%). They were highly electroresponsive, and minimal changes (1-3 mV) of membrane potential generated an active response. Subthreshold depolarizing or hyperpolarizing current pulse injection always caused the membrane potential to attain an early peak and then sag to a lower level. Depolarization-induced "sags" were larger and determined early firing in all cells. The voltage-current relationship of SCs was markedly non-linear, demonstrating robust inward rectification in the hyperpolarizing and depolarizing range. 3. SCs generated persistent rhythmic subthreshold voltage oscillations on DC depolarization positive to -60 mV. The mean frequency of the oscillations was 8.6 Hz (theta range) at a membrane potential of approximately -55 mV, at which level occasional single spiking also occurred. At slightly more positive potentials, a striking 1- to 3-Hz repetitive bursting pattern emerged. This consisted of nonadapting trains of spikes ("clusters") interspersed with subthreshold oscillations that had a mean frequency of 21.7 Hz (beta range). 4. Nonstellate cells (39\%; mostly pyramidal-like) displayed time-dependent inward rectification that was less pronounced than that of SCs, and minimal depolarization-induced sags. On threshold depolarization, firing was always preceded by a slowly rising ramp depolarization and thus occurred with a long delay. Inward rectification in the depolarizing range was very pronounced. However, non-SCs did not generate persistent rhythmic subthreshold oscillatory activity or spike clusters. 5. Of the electrophysiological parameters quantified, spike threshold, spike duration, depolarizing afterpotential amplitude and apparent membrane time constant demonstrated statistically significant differences between SCs and non-SCs. 6. The repetitive hiring properties in response to square current pulses of short duration (\textbackslash textless 500 ms) were also different between SCs and non-SCs. First, most SCs displayed a bilinear frequency-current (f-I) relationship for only the first interspike interval, whereas most non-SCs displayed a bilinear relationship for all intervals. Second, SCs had a much steeper primary f-I slope for early intervals than non-SCs. Finally, SCs displayed more pronounced and faster spike frequency adaptation than non-SCs.(ABSTRACT TRUNCATED AT 400 WORDS)},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZVZ4VRMV\\Alonso, Klink - 1993 - Differential electroresponsiveness of stellate and pyramidal-like cells of medial entorhinal cortex layer II.pdf},
  journal = {Journal of neurophysiology},
  keywords = {Animals,Cerebral Cortex,Cerebral Cortex: physiology,Culture Techniques,Electric Stimulation,Evoked Potentials,Evoked Potentials: physiology,Hippocampus,Hippocampus: physiology,Interneurons,Interneurons: physiology,Limbic System,Limbic System: physiology,Male,Membrane Potentials,Membrane Potentials: physiology,Neurons,Neurons: physiology,Rats,Sensory Thresholds,Sensory Thresholds: physiology,Synapses,Synapses: physiology,Synaptic Transmission,Synaptic Transmission: physiology},
  number = {1},
  pmid = {8395571}
}

@article{aly_hasson_2018,
  title = {Learning {{Naturalistic Temporal Structure}} in the {{Posterior Medial Network}}},
  author = {Aly, Mariam and Chen, Janice and {Turk-Browne}, Nicholas B and Hasson, Uri},
  year = {2018},
  doi = {10.1162/jocn_a_01308},
  abstract = {\ding{110} The posterior medial network is at the apex of a temporal integration hierarchy in the brain, integrating information over many seconds of viewing intact, but not scrambled, movies. This has been interpreted as an effect of temporal structure. Such structure in movies depends on preexisting event schemas, but temporal structure can also arise de novo from learning. Here, we examined the relative role of schema-consistent temporal structure and arbitrary but consistent temporal structure on the human posterior medial network. We tested whether, with repeated viewing, the network becomes engaged by scrambled movies with temporal structure. Replicating prior studies, activity in posterior medial regions was immediately locked to stimulus structure upon exposure to intact, but not scrambled, movies. However, for temporally structured scrambled movies, functional coupling within the network increased across stimulus repetitions, rising to the level of intact movies. Thus, temporal structure is a key determinant of network dynamics and function in the posterior medial network. \ding{110}},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FSZY9I8T\\Aly et al. - 2018 - Learning Naturalistic Temporal Structure in the Posterior Medial Network.pdf}
}

@article{amarasingham_geman_2012,
  title = {Conditional Modeling and the Jitter Method of Spike Resampling},
  author = {Amarasingham, Asohan and Harrison, Matthew T. and Hatsopoulos, Nicholas G. and Geman, Stuart},
  year = {2012},
  month = jan,
  volume = {107},
  pages = {517--531},
  issn = {0022-3077, 1522-1598},
  doi = {10.1152/jn.00633.2011},
  abstract = {The existence and role of fine-temporal structure in the spiking activity of central neurons is the subject of an enduring debate among physiologists. To a large extent, the problem is a statistical one: what inferences can be drawn from neurons monitored in the absence of full control over their presynaptic environments? In principle, properly crafted resampling methods can still produce statistically correct hypothesis tests. We focus on the approach to resampling known as jitter. We review a wide range of jitter techniques, illustrated by both simulation experiments and selected analyses of spike data from motor cortical neurons. We rely on an intuitive and rigorous statistical framework known as conditional modeling to reveal otherwise hidden assumptions and to support precise conclusions. Among other applications, we review statistical tests for exploring any proposed limit on the rate of change of spiking probabilities, exact tests for the significance of repeated fine-temporal patterns of spikes, and the construction of acceptance bands for testing any purported relationship between sensory or motor variables and synchrony or other fine-temporal events.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XQKF2U2K\\Amarasingham et al. - 2012 - Conditional modeling and the jitter method of spik.pdf},
  journal = {Journal of Neurophysiology},
  language = {en},
  number = {2}
}

@article{ambrose_foster_2016,
  title = {Reverse {{Replay}} of {{Hippocampal Place Cells Is Uniquely Modulated}} by {{Changing Reward}}},
  author = {Ambrose, R. Ellen and Pfeiffer, Brad E. and Foster, David J.},
  year = {2016},
  month = sep,
  volume = {91},
  pages = {1124--1136},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2016.07.047},
  abstract = {Summary Hippocampal replays are episodes of sequential place cell activity during sharp-wave ripple oscillations (SWRs). Conflicting hypotheses implicate awake replay in learning from reward and in memory retrieval for decision making. Further, awake replays can be forward, in the same order as experienced, or reverse, in the opposite order. However, while the presence or absence of reward has been reported to modulate SWR rate, the effect of reward changes on replay, and on replay direction in particular, has not been examined. Here we report divergence in the response of forward and reverse replays to changing reward. While both classes of replays were observed at reward locations, only reverse replays increased their rate at increased reward or decreased their rate at decreased reward, while forward replays were unchanged. These data demonstrate a unique relationship between reverse replay and reward processing and point to a functional distinction between different directions of replay. Video Abstract},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KLSS3H54\\Ambrose et al. - 2016 - Reverse Replay of Hippocampal Place Cells Is Uniqu.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\SGFMNC6W\\S0896627316304639.html},
  journal = {Neuron},
  number = {5}
}

@article{ames_snider_2012,
  title = {Advances in {{Neuromorphic Memristor Science}} and {{Applications}}},
  author = {Ames, Heather and Versace, Massimiliano and Gorchetchnikov, Anatoli and Chandler, Benjamin and Livitz, Gennady and L{\'e}veill{\'e}, Jasmin and Mingolla, Ennio and Carter, Dick and Abdalla, Hisham and Snider, Greg},
  editor = {Kozma, Robert and Pino, Robinson E. and Pazienza, Giovanni E.},
  year = {2012},
  pages = {37--61},
  doi = {10.1007/978-94-007-4491-2},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TERJMQJX\\Ames et al. - 2012 - Advances in Neuromorphic Memristor Science and Applications.pdf}
}

@article{amiez_procyk_2006,
  title = {Reward Encoding in the Monkey Anterior Cingulate Cortex},
  author = {Amiez, C and Joseph, J P and Procyk, E},
  year = {2006},
  volume = {16},
  pages = {1040--1055},
  issn = {10473211},
  doi = {10.1093/cercor/bhj046},
  abstract = {The anterior cingulate cortex (ACC) is known to play a crucial role in the fast adaptations of behavior based on immediate reward values. What is less certain is whether the ACC is also involved in long-term adaptations to situations with uncertain outcomes. To study this issue, we placed macaque monkeys in a probabilistic context in which the appropriate strategy to maximize reward was to identify the stimulus with the highest reward value (optimal stimulus). Only knowledge of the theoretical average reward value associated with this stimulus\textendash referred to as 'the task value'\textendash was available. Remarkably, in each trial, ACC pre-reward activity correlated with the task value. Importantly, this neuronal activity was observed prior to the discovery of the optimal stimulus. We hypothesize that the received rewards and the task value, constructed a priori through learning, are used to guide behavior and identify the optimal stimulus. We tested this hypothesis by muscimol deactivation of the ACC. As predicted, this inactivation impaired the search for the optimal stimulus. We propose that ACC participates in long-term adaptation of voluntary reward-based behaviors by encoding general task values and received rewards.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FD3JN55H\\Amiez, Joseph, Procyk - Unknown - Reward Encoding in the Monkey Anterior Cingulate Cortex.pdf},
  journal = {Cerebral Cortex},
  keywords = {anterior cingulate,Choice task,Long-term adaptation,Rewards,Strategy},
  number = {7},
  pmid = {16207931}
}

@article{andersen_buneo_2002,
  title = {Intentional {{Maps}} in {{Posterior Parietal Cortex}}},
  author = {Andersen, Richard A. and Buneo, Christopher A.},
  year = {2002},
  month = mar,
  volume = {25},
  pages = {189--220},
  issn = {0147-006X, 1545-4126},
  doi = {10.1146/annurev.neuro.25.112701.142922},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LL3VDUJE\\Andersen and Buneo - 2002 - Intentional Maps in Posterior Parietal Cortex.pdf},
  journal = {Annual Review of Neuroscience},
  language = {en},
  number = {1}
}

@article{andersen_cui_2009,
  title = {Intention, {{Action Planning}}, and {{Decision Making}} in {{Parietal}}-{{Frontal Circuits}}},
  author = {Andersen, Richard A. and Cui, He},
  year = {2009},
  month = sep,
  volume = {63},
  pages = {568--583},
  issn = {08966273},
  doi = {10.1016/j.neuron.2009.08.028},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FLK6MDG6\\Andersen and Cui - 2009 - Intention, Action Planning, and Decision Making in.pdf},
  journal = {Neuron},
  language = {en},
  number = {5}
}

@book{anderson_anderson_2010,
  title = {Neural Reuse: {{A}} Fundamental Organizational Principle of the Brain},
  author = {Anderson, Michael L},
  year = {2010},
  volume = {33},
  doi = {10.1017/S0140525X10000853},
  abstract = {An emerging class of theories concerning the functional structure of the brain takes the reuse of neural circuitry for various cognitive purposes to be a central organizational principle. According to these theories, it is quite common for neural circuits established for one purpose to be exapted (exploited, recycled, redeployed) during evolution or normal development, and be put to different uses, often without losing their original functions. Neural reuse theories thus differ from the usual understanding of the role of neural plasticity (which is, after all, a kind of reuse) in brain organization along the following lines: According to neural reuse, circuits can continue to acquire new uses after an initial or original function is established; the acquisition of new uses need not involve unusual circumstances such as injury or loss of established function; and the acquisition of a new use need not involve (much) local change to circuit structure (e.g., it might involve only the establishment of functional connections to new neural partners). Thus, neural reuse theories offer a distinct perspective on several topics of general interest, such as: the evolution and development of the brain, including (for instance) the evolutionary-developmental pathway supporting primate tool use and human language; the degree of modularity in brain organization; the degree of localization of cognitive function; and the cortical parcellation problem and the prospects (and proper methods to employ) for function to structure mapping. The idea also has some practical implications in the areas of rehabilitative medicine and machine interface design.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XPZ5ELTD\\Anderson - 2010 - Neural reuse A fundamental organizational principle of the brain.pdf},
  isbn = {1469-1825 (Electronic)\$\textbackslash backslash\$r0140-525X (Linking)},
  keywords = {brain,development,evolution,exaptation,functional architecture,localization,modularity},
  pmid = {20964882}
}

@article{anderson_fincham_2014,
  title = {Extending Problem-Solving Procedures through Reflection},
  author = {Anderson, John R and Fincham, Jon M},
  year = {2014},
  volume = {74},
  pages = {1--34},
  doi = {10.1016/j.cogpsych.2014.06.002},
  abstract = {a b s t r a c t A large-sample (n = 75) fMRI study guided the development of a the-ory of how people extend their problem-solving procedures by reflecting on them. Both children and adults were trained on a new mathematical procedure and then were challenged with novel prob-lems that required them to change and extend their procedure to solve these problems. The fMRI data were analyzed using a combina-tion of hidden Markov models (HMMs) and multi-voxel pattern analysis (MVPA). This HMM\textendash MVPA analysis revealed the existence of 4 stages: Encoding, Planning, Solving, and Responding. Using this analysis as a guide, an ACT-R model was developed that improved the performance of the HMM\textendash MVPA and explained the variation in the durations of the stages across 128 different problems. The model assumes that participants can reflect on declarative representations of the steps of their problem-solving procedures. A Metacognitive module can hold these steps, modify them, create new declarative steps, and rehearse them. The Metacognitive module is associated with activity in the rostrolateral prefrontal cortex (RLPFC). The ACT-R model predicts the activity in the RLPFC and other regions associated with its other cognitive modules (e.g., vision, retrieval). Differences between children and adults seemed related to differ-ences in background knowledge and computational fluency, but not to the differences in their capability to modify procedures.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\G2WGALD6\\Anderson, Fincham - 2014 - Extending problem-solving procedures through reflection.pdf},
  journal = {COGNITIVE PSYCHOLOGY},
  keywords = {Cognitive modeling,Hidden Markov models,Mathematical problem solving,mvpa,Reflection}
}

@article{anderson_lebiere_2003,
  title = {The {{Newell}} Test for a Theory of Cognition},
  author = {Anderson, John R. and Lebiere, Christian},
  year = {2003},
  volume = {26},
  pages = {587--601},
  issn = {0140525X},
  doi = {10.1017/S0140525X0300013X},
  abstract = {Newell (1980; 1990) proposed that cognitive theories be developed in an effort to satisfy multiple criteria and to avoid theoretical myopia. He provided two overlapping lists of 13 criteria that the human cognitive architecture would have to satisfy in order to be functional. We have distilled these into 12 criteria: flexible behavior, real-time performance, adaptive behavior, vast knowledge base, dynamic behavior, knowledge integration, natural language, learning, development, evolution, and brain realization. There would be greater theoretical progress if we evaluated theories by a broad set of criteria such as these and attended to the weaknesses such evaluations revealed. To illustrate how theories can be evaluated we apply these criteria to both classical connectionism (McClelland \& Rumelhart 1986; Rumelhart \& McClelland 1986b) and the ACT-R theory (Anderson \& Lebiere 1998). The strengths of classical connectionism on this test derive from its intense effort in addressing empirical phenomena in such domains as language and cognitive development. Its weaknesses derive from its failure to acknowledge a symbolic level to thought. In contrast, ACT-R includes both symbolic and sub-symbolic components. The strengths of the ACT-R theory derive from its tight integration of the symbolic component with the sub-symbolic component. Its weaknesses largely derive from its failure, as yet, to adequately engage in intensive analyses of issues related to certain criteria on Newell's list.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RSHLFNGM\\Anderson, Lebiere - 2003 - The Newell test for a theory of cognition.pdf},
  journal = {Behavioral and Brain Sciences},
  keywords = {Cognitive architecture,Connectionism,Hybrid systems,Language,Learning symbolic systems},
  number = {5},
  pmid = {15179936}
}

@article{anderson_moon_2015,
  title = {The Sequential Structure of Brain Activation Predicts Skill},
  author = {Anderson, John R and Bothell, Daniel and Fincham, Jon M and Moon, Jungaa},
  year = {2015},
  volume = {81},
  pages = {94--106},
  doi = {10.1016/j.neuropsychologia.2015.12.014},
  abstract = {a b s t r a c t In an fMRI study, participants were trained to play a complex video game. They were scanned early and then again after substantial practice. While better players showed greater activation in one region (right dorsal striatum) their relative skill was better diagnosed by considering the sequential structure of whole brain activation. Using a cognitive model that played this game, we extracted a characterization of the mental states that are involved in playing a game and the statistical structure of the transitions among these states. There was a strong correspondence between this measure of sequential structure and the skill of different players. Using multi-voxel pattern analysis, it was possible to recognize, with relatively high accuracy, the cognitive states participants were in during particular scans. We used the sequential structure of these activation-recognized states to predict the skill of individual players. These findings indicate that important features about information-processing strategies can be identified from a model-based analysis of the sequential structure of brain activation.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\35QFTQSR\\Anderson et al. - 2015 - The sequential structure of brain activation predicts skill.pdf},
  journal = {Neuropsychologia},
  keywords = {Computational Modeling,Expertize,fmri,Learning}
}

@book{anderson_okeefe_2007,
  title = {The {{Hippocampus}} Book},
  editor = {Anderson, Per and Morris, Richard and Amaral, David and Bliss, Tim and O'Keefe, John},
  year = {2007},
  edition = {First},
  publisher = {{Oxford University Press}},
  address = {{New York, NY}},
  doi = {10.1093/acprof:oso/9780195100273.001.0001},
  abstract = {The hippocampus is one of the most widely studied regions of the brain and is of interest to a wide spectrum of neuroscien- tists, ranging from those who study its normal structure and function to others who study its malfunction in various dis- eases and pathological conditions. Information about it has accrued across a considerable span of time and is spread over a wide variety of publications. It seems all the more remark- able, therefore, given the explosion of texts on every conceiv- able topic in neuroscience, that there is no single, comprehensive source of information on the hippocampal formation. It would clearly be helpful to the community of hippocampologists to have the essential information about hippocampal neurobiology gathered together in one volume. This book is our attempt at a reasonably comprehensive sur- vey of hippocampal research, as viewed through many eyes and collected with a wide variety of methods. We hope that the book will be useful at several levels. For those new to the arena of hippocampal research,we hope it will act as a primer pointing to the important advances of the past decades and suggesting important research paths to be pursued; for hip- pocampal veterans, we hope that by laying bare the many uncertainties and open questions that remain, it will provide ample stimulus to see old problems with new eyes and to pur- sue them with renewed vigor},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QKUG7MUK\\Unknown - 2007 - The Hippocampus book.pdf},
  isbn = {978-0-19-510027-3},
  pmid = {14281431}
}

@article{anderson_qin_2004,
  title = {An Integrated Theory of the Mind.},
  author = {Anderson, John R and Bothell, Daniel and Byrne, Michael D and Douglass, Scott and Lebiere, Christian and Qin, Yulin},
  year = {2004},
  volume = {111},
  pages = {1036--1060},
  issn = {0033-295X},
  doi = {10.1037/0033-295X.111.4.1036},
  abstract = {Adaptive control of thought-rational (ACT-R; J. R. Anderson \& C. Lebiere, 1998) has evolved into a theory that consists of multiple modules but also explains how these modules are integrated to produce coherent cognition. The perceptual-motor modules, the goal module, and the declarative memory module are presented as examples of specialized systems in ACT-R. These modules are associated with distinct cortical regions. These modules place chunks in buffers where they can be detected by a production system that responds to patterns of information in the buffers. At any point in time, a single production rule is selected to respond to the current pattern. Subsymbolic processes serve to guide the selection of rules to fire as well as the internal operations of some modules. Much of learning involves tuning of these subsymbolic processes. A number of simple and complex empirical examples are described to illustrate how these modules function singly and in concert.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KPU23VUM\\Anderson et al. - 2004 - An integrated theory of the mind.pdf},
  journal = {Psychological review},
  number = {4},
  pmid = {15482072}
}

@article{andreas_klein_2015,
  title = {Neural {{Module Networks}}},
  author = {Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Klein, Dan},
  year = {2015},
  month = nov,
  abstract = {Visual question answering is fundamentally compositional in nature---a question like "where is the dog?" shares substructure with questions like "what color is the dog?" and "where is the cat?" This paper seeks to simultaneously exploit the representational capacity of deep networks and the compositional linguistic structure of questions. We describe a procedure for constructing and learning *neural module networks*, which compose collections of jointly-trained neural "modules" into deep networks for question answering. Our approach decomposes questions into their linguistic substructures, and uses these structures to dynamically instantiate modular networks (with reusable components for recognizing dogs, classifying colors, etc.). The resulting compound networks are jointly trained. We evaluate our approach on two challenging datasets for visual question answering, achieving state-of-the-art results on both the VQA natural image dataset and a new dataset of complex questions about abstract shapes.},
  archivePrefix = {arXiv},
  eprint = {1511.02799},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\W58SWRU2\\andreas_et_al_2015_neural_module_networks.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\DXNXRFNT\\1511.html},
  journal = {arXiv:1511.02799 [cs]},
  primaryClass = {cs}
}

@article{antzoulatos_miller_2011,
  title = {Differences between {{Neural Activity}} in {{Prefrontal Cortex}} and {{Striatum}} during {{Learning}} of {{Novel Abstract Categories}}},
  author = {Antzoulatos, Evan G. and Miller, Earl K},
  year = {2011},
  volume = {71},
  pages = {243--249},
  issn = {08966273},
  doi = {10.1016/j.neuron.2011.05.040},
  abstract = {Learning to classify diverse experiences into meaningful groups, like categories, is fundamental to normal cognition. To understand its neural basis, we simultaneously recorded from multiple electrodes in lateral prefrontal cortex and dorsal striatum, two interconnected brain structures critical for learning. Each day, monkeys learned to associate novel abstract, dot-based categories with a right versus left saccade. Early on, when they could acquire specific stimulus-response associations, striatum activity was an earlier predictor of the corresponding saccade. However, as the number of exemplars increased and monkeys had to learn to classify them, PFC activity began to predict the saccade associated with each category before the striatum. While monkeys were categorizing novel exemplars at a high rate, PFC activity was a strong predictor of their corresponding saccade early in the trial before the striatal neurons. These results suggest that striatum plays a greater role in stimulus-response association and PFC in abstraction of categories. Video Abstract: ?? 2011 Elsevier Inc.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LV7NYIMI\\Antzoulatos, Miller - 2011 - Differences between Neural Activity in Prefrontal Cortex and Striatum during Learning of Novel Abstract Cat.pdf},
  journal = {Neuron},
  number = {2},
  pmid = {21791284}
}

@article{ardid_kopell_2018,
  title = {Biased Competition in the Absence of Input Bias: Predictions from Corticostriatal Computation},
  author = {Ardid, Salva and Sherfey, Jason S and Mccarthy, Michelle M and Hass, Joachim and {Pittman-Polletta}, Benjamin R and Kopell, Nancy},
  year = {2018},
  pages = {1--15},
  doi = {10.1101/258053},
  abstract = {Classical accounts of biased competition (BC) require an input bias to resolve the competition between neuronal ensembles driving downstream processing. However, flexible and reliable selection of behaviorally-relevant ensembles can occur with unbiased stimulation: striatal D1 and D2 medium spiny neurons (MSNs) receive balanced cortical input, yet their activity determines the choice between GO and NO-GO pathways in the basal ganglia. We present a corticos-triatal model identifying three candidate mechanisms that rely on physiologi-cal asymmetries to effect rate-and time-coded BC in the presence of balanced inputs. First, tonic input strength determines which MSN phenotype exhibit higher mean firing rate (FR). Second, low strength oscillatory inputs induce higher FR in D2 MSNs but higher coherence between D1 MSNs. Third, high strength inputs oscillating at distinct frequencies preferentially activate D1 or D2 MSN populations. Of these candidate mechanisms, only the latter accom-modates observed rhythmic activity supporting rule-based decision making in prefrontal cortex.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LLK56K5H\\Ardid et al. - 2018 - Biased competition in the absence of input bias predictions from corticostriatal computation.pdf},
  journal = {bioRxiv}
}

@article{arnal_giraud_2012,
  title = {Cortical Oscillations and Sensory Predictions},
  author = {Arnal, Luc H. and Giraud, Anne Lise},
  year = {2012},
  volume = {16},
  pages = {390--398},
  issn = {13646613},
  doi = {10.1016/j.tics.2012.05.003},
  abstract = {Many theories of perception are anchored in the central notion that the brain continuously updates an internal model of the world to infer the probable causes of sensory events. In this framework, the brain needs not only to predict the causes of sensory input, but also when they are most likely to happen. In this article, we review the neurophysiological bases of sensory predictions of "what' (predictive coding) and 'when' (predictive timing), with an emphasis on low-level oscillatory mechanisms. We argue that neural rhythms offer distinct and adapted computational solutions to predicting 'what' is going to happen in the sensory environment and 'when'. \textcopyright{} 2012 Elsevier Ltd.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3SPUU77L\\Arnal, Giraud - 2012 - Cortical oscillations and sensory predictions.pdf},
  journal = {Trends in Cognitive Sciences},
  number = {7},
  pmid = {22682813}
}

@article{arnal_poeppel_2015,
  title = {Delta\textendash Beta Coupled Oscillations Underlie Temporal Prediction Accuracy},
  author = {Arnal, Luc H. and Doelling, Keith B. and Poeppel, David},
  year = {2015},
  month = sep,
  volume = {25},
  pages = {3077--3085},
  issn = {1047-3211},
  doi = {10.1093/cercor/bhu103},
  abstract = {The ability to generate temporal predictions is fundamental for adaptive behavior. Precise timing at the time-scale of seconds is critical, for instance to predict trajectories or to select relevant information. What mechanisms form the basis for such accurate timing? Recent evidence suggests that (1) temporal predictions adjust sensory selection by controlling neural oscillations in time and (2) the motor system plays an active role in inferring ``when'' events will happen. We hypothesized that oscillations in the delta and beta bands are instrumental in predicting the occurrence of auditory targets. Participants listened to brief rhythmic tone sequences and detected target delays while undergoing magnetoencephalography recording. Prior to target occurrence, we found that coupled delta (1\textendash 3 Hz) and beta (18\textendash 22 Hz) oscillations temporally align with upcoming targets and bias decisions towards correct responses, suggesting that delta\textendash beta coupled oscillations underpin prediction accuracy. Subsequent to target occurrence, subjects update their decisions using the magnitude of the alpha-band (10\textendash 14 Hz) response as internal evidence of target timing. These data support a model in which the orchestration of oscillatory dynamics between sensory and motor systems is exploited to accurately select sensory information in time.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5MPAF964\\Arnal_et_al_2015_Delta–beta_coupled_oscillations_underlie_temporal_prediction_accuracy.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\DI8UK3SE\\2926125.html},
  journal = {Cerebral Cortex},
  language = {en},
  number = {9}
}

@article{asabuki_fukai_2020,
  title = {Somatodendritic Consistency Check for Temporal Feature Segmentation},
  author = {Asabuki, Toshitake and Fukai, Tomoki},
  year = {2020},
  month = dec,
  volume = {11},
  pages = {1554},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-15367-w},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GYGV9GUB\\Asabuki and Fukai - 2020 - Somatodendritic consistency check for temporal fea.pdf},
  journal = {Nature Communications},
  language = {en},
  number = {1}
}

@article{asai_asai_2019,
  title = {Unsupervised {{Grounding}} of {{Plannable First}}-{{Order Logic Representation}} from {{Images}}},
  author = {Asai, Masataro},
  year = {2019},
  month = feb,
  abstract = {Recently, there is an increasing interest in obtaining the relational structures of the environment in the Reinforcement Learning community. However, the resulting "relations" are not the discrete, logical predicates compatible to the symbolic reasoning such as classical planning or goal recognition. Meanwhile, Latplan (Asai and Fukunaga 2018) bridged the gap between deep-learning perceptual systems and symbolic classical planners. One key component of the system is a Neural Network called State AutoEncoder (SAE), which encodes an image-based input into a propositional representation compatible to classical planning. To get the best of both worlds, we propose First-Order State AutoEncoder, an unsupervised architecture for grounding the first-order logic predicates and facts. Each predicate models a relationship between objects by taking the interpretable arguments and returning a propositional value. In the experiment using 8-Puzzle and a photo-realistic Blocksworld environment, we show that (1) the resulting predicates capture the interpretable relations (e.g. spatial), (2) they help obtaining the compact, abstract model of the environment, and finally, (3) the resulting model is compatible to symbolic classical planning.},
  archivePrefix = {arXiv},
  eprint = {1902.08093},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CS76HW2H\\asai_2019_unsupervised_grounding_of_plannable_first-order_logic_representation_from_images.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\7UV7J2Z8\\1902.html},
  journal = {arXiv:1902.08093 [cs]},
  primaryClass = {cs}
}

@article{asai_fukunaga_2017,
  title = {Classical {{Planning}} in {{Deep Latent Space}}: {{Bridging}} the {{Subsymbolic}}-{{Symbolic Boundary}}},
  shorttitle = {Classical {{Planning}} in {{Deep Latent Space}}},
  author = {Asai, Masataro and Fukunaga, Alex},
  year = {2017},
  month = apr,
  abstract = {Current domain-independent, classical planners require symbolic models of the problem domain and instance as input, resulting in a knowledge acquisition bottleneck. Meanwhile, although deep learning has achieved significant success in many fields, the knowledge is encoded in a subsymbolic representation which is incompatible with symbolic systems such as planners. We propose LatPlan, an unsupervised architecture combining deep learning and classical planning. Given only an unlabeled set of image pairs showing a subset of transitions allowed in the environment (training inputs), and a pair of images representing the initial and the goal states (planning inputs), LatPlan finds a plan to the goal state in a symbolic latent space and returns a visualized plan execution. The contribution of this paper is twofold: (1) State Autoencoder, which finds a propositional state representation of the environment using a Variational Autoencoder. It generates a discrete latent vector from the images, based on which a PDDL model can be constructed and then solved by an off-the-shelf planner. (2) Action Autoencoder / Discriminator, a neural architecture which jointly finds the action symbols and the implicit action models (preconditions/effects), and provides a successor function for the implicit graph search. We evaluate LatPlan using image-based versions of 3 planning domains: 8-puzzle, Towers of Hanoi and LightsOut.},
  archivePrefix = {arXiv},
  eprint = {1705.00154},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5XVG9HA4\\asai_fukunaga_2017_classical_planning_in_deep_latent_space.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\7B4NLAWM\\asai_fukunaga_2017_classical_planning_in_deep_latent_space.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\8Y42MXVN\\1705.html;C\:\\Users\\wchapman\\Zotero\\storage\\K78GTDFI\\1705.html},
  journal = {arXiv:1705.00154 [cs]},
  primaryClass = {cs}
}

@article{ashburner_friston_2006,
  title = {Segmentation},
  author = {Ashburner, J and Friston, Karl J},
  year = {2006},
  pages = {81--91},
  doi = {10.1016/B978-0-12-372560-8.50006-1},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\C5RH8HFY\\Ashburner, Friston - 2006 - Segmentation.pdf},
  journal = {Statistical parametric mapping: The analysis of funtional brain images}
}

@article{astolfi_babiloni_2005,
  title = {Assessing Cortical Functional Connectivity by Linear Inverse Estimation and Directed Transfer Function: Simulations and Application to Real Data},
  shorttitle = {Assessing Cortical Functional Connectivity by Linear Inverse Estimation and Directed Transfer Function},
  author = {Astolfi, L. and Cincotti, F. and Mattia, D. and Babiloni, C. and Carducci, F. and Basilisco, A. and Rossini, P.M. and Salinari, S. and Ding, L. and Ni, Y. and He, B. and Babiloni, F.},
  year = {2005},
  month = apr,
  volume = {116},
  pages = {920--932},
  issn = {13882457},
  doi = {10.1016/j.clinph.2004.10.012},
  abstract = {Objective: To test a technique called Directed Transfer Function (DTF) for the estimation of human cortical connectivity, by means of simulation study and human study, using high resolution EEG recordings related to finger movements. Methods: The method of the Directed Transfer Function (DTF) is a frequency-domain approach, based on a multivariate autoregressive modeling of time series and on the concept of Granger causality. Since the spreading of the potential from the cortex to the sensors makes it difficult to infer the relation between the spatial patterns on the sensor space and those on the cortical sites, we propose the use of the DTF method on cortical signals estimated from high resolution EEG recordings, which exhibit a higher spatial resolution than conventional cerebral electromagnetic measures. The simulation study was followed by an analysis of variance (ANOVA) of the results obtained for different levels of Signal to Noise Ratio (SNR) and temporal length, as they have been systematically imposed on simulated signals. The whole methodology was then applied to high resolution EEG data recorded during a visually paced finger movement. Results: The statistical analysis performed returns that during simulations, DTF is able to estimate correctly the imposed connectivity patterns under reasonable operative conditions, i.e. when data exhibit a SNR of at least 3 and a length of at least 75 s of non-consecutive recordings at 64 Hz of sampling rate, equivalent, more generally, to 4800 data samples. Conclusions: Functional connectivity patterns of cortical activity can be effectively estimated under general conditions met in any practical EEG recordings, by combining high resolution EEG techniques, linear inverse estimation and the DTF method. Significance: The estimation of cortical connectivity can be performed not only with hemodynamic measurements, by using functional MRI recordings, but also with modern EEG recordings treated with advanced computational techniques. q 2004 International Federation of Clinical Neurophysiology. Published by Elsevier Ireland Ltd. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\M3TY4TEV\\Astolfi et al. - 2005 - Assessing cortical functional connectivity by line.pdf},
  journal = {Clinical Neurophysiology},
  language = {en},
  number = {4}
}

@article{atallah_oreilly_2007,
  title = {Separate Neural Substrates for Skill Learning and Performance in the Ventral and Dorsal Striatum},
  author = {Atallah, Hisham E and {Lopez-Paniagua}, Dan and Rudy, Jerry W and O'Reilly, Randall C},
  year = {2007},
  month = jan,
  volume = {10},
  pages = {126--131},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn1817},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YQIJYRXJ\\Atallah et al. - 2007 - Separate neural substrates for skill learning and .pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {1}
}

@article{author_address_2017,
  title = {A Simple Neural Network Module for Relational Reasoning},
  author = {Author, Anonymous and Address, Affiliation},
  year = {2017},
  pages = {1--16},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Y4G6P77W\\Author, Address - 2017 - A simple neural network module for relational reasoning.pdf},
  number = {Nips}
}

@article{avena-koenigsberger_sporns_2018,
  title = {Communication Dynamics in Complex Brain Networks},
  author = {{Avena-Koenigsberger}, Andrea and Misic, Bratislav and Sporns, Olaf},
  year = {2018},
  month = jan,
  volume = {19},
  pages = {17--33},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn.2017.149},
  abstract = {Neuronal signalling and communication underpin virtually all aspects of brain activity and function. Network science approaches to modelling and analysing the dynamics of communication on networks have proved useful for simulating functional brain connectivity and predicting emergent network states. This Review surveys important aspects of communication dynamics in brain networks. We begin by sketching a conceptual framework that views communication dynamics as a necessary link between the empirical domains of structural and functional connectivity. We then consider how different local and global topological attributes of structural networks support potential patterns of network communication, and how the interactions between network topology and dynamic models can provide additional insights and constraints. We end by proposing that communication dynamics may act as potential generative models of effective connectivity and can offer insight into the mechanisms by which brain networks transform and process information.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LUHQ2EYK\\Avena-Koenigsberger et al. - 2018 - Communication dynamics in complex brain networks.pdf},
  journal = {Nature Reviews Neuroscience},
  language = {en},
  number = {1}
}

@article{averkin_szemenyei_2016,
  title = {Identified {{Cellular Correlates}} of {{Neocortical Ripple}} and {{High}}-{{Gamma Oscillations}} during {{Spindles}} of {{Natural Sleep}}},
  author = {Averkin, Robert G and Szemenyei, Viktor},
  year = {2016},
  pages = {1--13},
  issn = {08966273},
  doi = {10.1016/j.neuron.2016.09.032},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\84WW2ZUW\\Averkin, Szemenyei - 2016 - Identified Cellular Correlates of Neocortical Ripple and High-Gamma Oscillations during Spindles of Natural.pdf}
}

@article{avillac_duhamel_2005,
  title = {Reference Frames for Representing Visual and Tactile Locations in Parietal Cortex},
  author = {Avillac, Marie and Den{\`e}ve, Sophie and Olivier, Etienne and Pouget, Alexandre and Duhamel, Jean Ren{\'e}},
  year = {2005},
  volume = {8},
  pages = {941--949},
  issn = {10976256},
  doi = {10.1038/nn1480},
  abstract = {The ventral intraparietal area (VIP) receives converging inputs from visual, somatosensory, auditory and vestibular systems that use diverse reference frames to encode sensory information. A key issue is how VIP combines those inputs together. We mapped the visual and tactile receptive fields of multimodal VIP neurons in macaque monkeys trained to gaze at three different stationary targets. Tactile receptive fields were found to be encoded into a single somatotopic, or head-centered, reference frame, whereas visual receptive fields were widely distributed between eye- to head-centered coordinates. These findings are inconsistent with a remapping of all sensory modalities in a common frame of reference. Instead, they support an alternative model of multisensory integration based on multidirectional sensory predictions (such as predicting the location of a visual stimulus given where it is felt on the skin and vice versa). This approach can also explain related findings in other multimodal areas.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LKP4PRGA\\Avillac et al. - 2005 - Reference frames for representing visual and tacti.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\YU6PIYWP\\Avillac et al. - 2005 - Reference frames for representing visual and tactile locations in parietal cortex.pdf},
  journal = {Nature Neuroscience},
  number = {7},
  pmid = {15951810}
}

@article{axmacher_axmacher_2016,
  title = {A Useful Code for Sequences},
  author = {Axmacher, N},
  year = {2016},
  volume = {19},
  pages = {1276--1277},
  issn = {1097-6256},
  doi = {10.1038/nn.4391},
  abstract = {A neural code for sequences needs to allow the recruitment of plasticity mechanisms that link successive items. New results suggest that this is achieved by coupling gamma band activity to specific phases of theta oscillations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XP24XFJF\\Axmacher - 2016 - A useful code for sequences.pdf},
  journal = {Nature Neuroscience},
  number = {10},
  pmid = {27669986}
}

@article{azuar_levy_2014,
  title = {Testing the Model of Caudo-Rostral Organization of Cognitive Control in the Human with Frontal Lesions},
  author = {Azuar, C. and Reyes, P. and Slachevsky, A. and Volle, E. and Kinkingnehun, S. and Kouneiher, F. and Bravo, E. and Dubois, B. and Koechlin, E. and Levy, R.},
  year = {2014},
  volume = {84},
  pages = {1053--1060},
  issn = {10959572},
  doi = {10.1016/j.neuroimage.2013.09.031},
  abstract = {The cascade model of cognitive control, mostly relying on functional neuroimaging studies, stipulates that the lateral frontal cortex (LFC) is organized as a cascade of executive processes involving three levels of cognitive control, implemented in distinct LFC areas from the premotor to the anterior prefrontal regions. The present experiment tested this model in patients with LFC lesions and studied the hierarchy of executive functions along the caudo-rostral axis, i.e. the respective roles of the different LFC areas in the control of behavior. Voxel-based lesion-symptom mapping and region of interest group analyses were conducted in 32 patients with focal LFC lesions who performed cognitive tasks assessing the cascade model. We first showed that three different LFC areas along the caudo-rostral axis subserved three distinct control levels, whose integrity is necessary for adaptive behavior. Second, we found that prefrontal cognitive control has an asymmetric organization: higher control processes involving more anterior prefrontal regions rely on the integrity of lower control processes in more posterior regions, while lower control processes can operate irrespective of the integrity of higher control processes. Altogether, these findings support a caudo-rostral cascade of executive processes from premotor to anterior prefrontal regions. ?? 2013 Elsevier Inc.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\A49FQ5VV\\Azuar et al. - 2014 - Testing the model of caudo-rostral organization of cognitive control in the human with frontal lesions.pdf},
  journal = {NeuroImage},
  keywords = {Executive functions,Human behavior,Lesion study,Prefrontal cortex},
  pmid = {24064070}
}

@article{b_krichmar_2016,
  title = {An {{Evolutionary Framework}} for {{Replicating Neurophysiological Data}} with {{Spiking Neural Networks}}},
  author = {B, Emily L Rounds and Scott, Eric O and Alexander, Andrew and Jong, Kenneth A De and Nitz, Douglas A and Krichmar, Jeffrey L},
  year = {2016},
  volume = {9921},
  pages = {537--547},
  doi = {10.1007/978-3-319-45823-6 50},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\R4DGP4JD\\B et al. - 2016 - An Evolutionary Framework for Replicating Neurophysiological Data with Spiking Neural Networks.pdf},
  keywords = {data,evolutionary algorithms,indirect encoding,matching,neurophysiological recordings,parallel computing,plasticity,spiking neural networks}
}

@article{babiloni_he_2005,
  title = {Estimation of the Cortical Functional Connectivity with the Multimodal Integration of High-Resolution {{EEG}} and {{fMRI}} Data by Directed Transfer Function},
  author = {Babiloni, F. and Cincotti, F. and Babiloni, C. and Carducci, F. and Mattia, D. and Astolfi, L. and Basilisco, A. and Rossini, P.M. and Ding, L. and Ni, Y. and Cheng, J. and Christine, K. and Sweeney, J. and He, B.},
  year = {2005},
  month = jan,
  volume = {24},
  pages = {118--131},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2004.09.036},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FUE8JMR2\\Babiloni et al. - 2005 - Estimation of the cortical functional connectivity.pdf},
  journal = {NeuroImage},
  language = {en},
  number = {1}
}

@article{baccala_sameshima_2016,
  title = {Directed {{Transfer Function}}: {{Unified Asymptotic Theory}} and {{Some}} of {{Its Implications}}},
  author = {Baccala, Luiz A. and Takahashi, Daniel Y and Sameshima, Koichi},
  year = {2016},
  volume = {63},
  pages = {2450--2460},
  issn = {15582531},
  doi = {10.1109/TBME.2016.2550199},
  abstract = {Objective: To present a unified mathematical derivation of the frequency-dependent asymptotic behavior of the three main forms of directed transfer function (DTF). Methods: A synthesis of the results (proved in an extended Appendix) is followed by a series of Monte Carlo simulations of representative examples. Results: DTF estimators are asymptotically normal when the true values are different from zero. Under the null hypothesis \$H\_0: DTF=0\$, the estimator is distributed as a linear combination of independent \$\textbackslash backslashchi \^2\_1\$ variables. Conclusions: Null DTF rejection is shown to be achievable with identical performance irrespective of which DTF form is adopted. Significance: Together with recent allied partial directed coherence results, this paper rounds up connectivity inference tools for a class of frequency-domain connectivity estimators. [ABSTRACT FROM AUTHOR]},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2XLZ3ETB\\Baccala, Takahashi, Sameshima - 2016 - Directed Transfer Function Unified Asymptotic Theory and Some of Its Implications.pdf},
  journal = {IEEE Transactions on Biomedical Engineering},
  keywords = {Directed transfer function (DTF) asymptotics,DTF connectivity,partial directed coherence (PDC)},
  number = {12}
}

@article{bach_dayan_2017,
  title = {Opinion: {{Algorithms}} for Survival: A Comparative Perspective on Emotions},
  author = {Bach, Dominik R. and Dayan, Peter},
  year = {2017},
  volume = {18},
  pages = {311--319},
  issn = {1471-003X},
  doi = {10.1038/nrn.2017.35},
  abstract = {The nature and neural implementation of emotions is the subject of vigorous debate. Here, we use Bayesian decision theory to address key complexities in this field and conceptualize emotions in terms of their relationship to survival-relevant behavioural choices. Decision theory indicates which behaviours are optimal in a given situation; however, the calculations required are radically intractable. We therefore conjecture that the brain uses a range of pre-programmed algorithms that provide approximate solutions. These solutions seem to produce specific behavioural manifestations of emotions and can also be associated with core affective dimensions. We identify principles according to which these algorithms are implemented in the brain and illustrate our approach by considering decision making in the face of proximal threat.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BIDZ432K\\Bach, Dayan - 2017 - Opinion Algorithms for survival a comparative perspective on emotions.pdf},
  journal = {Nature Reviews Neuroscience},
  number = {5}
}

@article{baddeley_baddeley_2012,
  title = {Working {{Memory}}: {{Theories}}, {{Models}}, and {{Controversies}}},
  author = {Baddeley, Alan},
  year = {2012},
  volume = {63},
  pages = {1--29},
  doi = {10.1146/annurev-psych-120710-100422},
  abstract = {I present an account of the origins and development of the multicom-ponent approach to working memory, making a distinction between the overall theoretical framework, which has remained relatively stable, and the attempts to build more specific models within this framework. I follow this with a brief discussion of alternative models and their rela-tionship to the framework. I conclude with speculations on further de-velopments and a comment on the value of attempting to apply models and theories beyond the laboratory studies on which they are typically based.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3Y7D2AN2\\Baddeley - 2012 - Working Memory Theories, Models, and Controversies.pdf},
  journal = {Annu. Rev. Psychol}
}

@article{badre_desposito_2009,
  title = {Is the Rostro-Caudal Axis of the Frontal Lobe Hierarchical?},
  author = {Badre, David and D'Esposito, Mark},
  year = {2009},
  volume = {10},
  pages = {659--669},
  issn = {1471-003X},
  doi = {10.1038/nrn2667},
  abstract = {The frontal lobes in the brain are a component of the cerebral system that supports goal-directed behaviour. However, their functional organization remains controversial. Recent studies have reported rostro-caudal distinctions in frontal cortex activity based on the abstractness of action representations. In addition, some have proposed that these differences reflect a hierarchical organization, whereby anterior frontal regions influence processing by posterior frontal regions during the realization of abstract action goals as motor acts. However, few have considered whether the anatomy and physiology of the frontal lobes support such a scheme. To address this gap, this Review surveys anatomical, neuroimaging, electrophysiological and developmental findings, and considers the question: could the organization of the frontal cortex be hierarchical?},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\K9HU8VI3\\Badre, D'Esposito - 2009 - Is the rostro-caudal axis of the frontal lobe hierarchical.pdf},
  journal = {Nature reviews. Neuroscience},
  number = {9},
  pmid = {19672274}
}

@article{badre_frank_2012,
  title = {Mechanisms of Hierarchical Reinforcement Learning in Cortico-Striatal Circuits 2: {{Evidence}} from {{fMRI}}},
  author = {Badre, David and Frank, Michael J},
  year = {2012},
  volume = {22},
  pages = {527--536},
  issn = {10473211},
  doi = {10.1093/cercor/bhr117},
  abstract = {The frontal lobes may be organized hierarchically such that more rostral frontal regions modulate cognitive control operations in caudal regions. In our companion paper (Frank MJ, Badre D. 2011. Mechanisms of hierarchical reinforcement learning in corticostriatal circuits I: computational analysis. 22:509-526), we provide novel neural circuit and algorithmic models of hierarchical cognitive control in cortico-striatal circuits. Here, we test key model predictions using functional magnetic resonance imaging (fMRI). Our neural circuit model proposes that contextual representations in rostral frontal cortex influence the striatal gating of contextual representations in caudal frontal cortex. Reinforcement learning operates at each level, such that the system adaptively learns to gate higher order contextual information into rostral regions. Our algorithmic Bayesian "mixture of experts" model captures the key computations of this neural model and provides trial-by-trial estimates of the learner's latent hypothesis states. In the present paper, we used these quantitative estimates to reanalyze fMRI data from a hierarchical reinforcement learning task reported in Badre D, Kayser AS, D'Esposito M. 2010. Frontal cortex and the discovery of abstract action rules. Neuron. 66:315\textendash 326. Results validate key predictions of the models and provide evidence for an individual cortico-striatal circuit for reinforcement learning of hierarchical structure at a specific level of policy abstraction. These findings are initially consistent with the proposal that hierarchical control in frontal cortex may emerge from interactions among nested cortico-striatal circuits at different levels of abstraction.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AGHIUIJH\\Badre, Frank - 2012 - Mechanisms of hierarchical reinforcement learning in cortico-striatal circuits 2 Evidence from fMRI.pdf},
  journal = {Cerebral Cortex},
  keywords = {basal ganglia,cognitive control,fmri,prefrontal cortex,reinforcement learning},
  number = {3},
  pmid = {21693491}
}

@article{badre_nee_2018,
  title = {Frontal {{Cortex}} and the {{Hierarchical Control}} of {{Behavior}}},
  author = {Badre, David and Nee, Derek Evan},
  year = {2018},
  volume = {22},
  pages = {170--188},
  doi = {10.1016/j.tics.2017.11.005},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\E8P3E4JB\\Badre, Nee - 2018 - Frontal Cortex and the Hierarchical Control of Behavior(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\GYZY2D9G\\Badre, Nee - 2017 - Frontal Cortex and the Hierarchical Control of Behavior.pdf},
  journal = {Trends in Cognitive Sciences},
  keywords = {cognitive control,executive function,frontal lobes}
}

@article{bahramisharif_lisman_2018,
  title = {Serial Representation of Items during Working Memory Maintenance at Letter-Selective Cortical Sites},
  author = {Bahramisharif, Ali and Jensen, Ole and Jacobs, Joshua and Lisman, John},
  year = {2018},
  doi = {10.1371/journal.pbio.2003805},
  abstract = {A key component of working memory is the ability to remember multiple items simultaneously. To understand how the human brain maintains multiple items in memory, we examined direct brain recordings of neural oscillations from neurosurgical patients as they performed a working memory task. We analyzed the data to identify the neural representations of individual memory items by identifying recording sites with broadband gamma activity that varied according to the identity of the letter a subject viewed. Next, we tested a previously proposed model of working memory, which had hypothesized that the neural representations of individual memory items sequentially occurred at different phases of the theta/alpha cycle. Consistent with this model, the phase of the theta/alpha oscillation when stimulus-related gamma activity occurred during maintenance reflected the order of list presentation. These results suggest that working memory is organized by a cortical phase code coordinated by coupled theta/alpha and gamma oscillations and, more broadly, provide support for the serial representation of items in working memory.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\26IQV6NJ\\Bahramisharif et al. - 2018 - Serial representation of items during working memory maintenance at letter-selective cortical sites.pdf}
}

@techreport{bakst_mcguire_2019,
  title = {Eye Movements Reflect Adaptive Predictions and Predictive Precision},
  author = {Bakst, Leah and McGuire, Joseph},
  year = {2019},
  month = jul,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/gh7a5},
  abstract = {Successful decision making requires accurate predictions about uncertain future events. Prior work suggests that decision makers represent not only predictive point estimates but also the associated level of uncertainty, and studies of explicit predictive inference have shown that uncertainty has a role in governing belief updating in dynamic environments. However, it is unknown whether the same adaptive belief-updating dynamics occur spontaneously, outside the context of a task requiring predictions to be explicitly reported. Here, we introduce a predictive inference paradigm in which gaze position serves as an implicit index of both predictions and their precision. We found that (1) predictive inference manifests in spontaneous gaze dynamics; (2) the updating of gaze-based predictions reflects adaptation to environmental structure; and (3) anticipatory gaze variability reflects predictive uncertainty. This suggests that oculomotor behavior carries useful information about the full probability distributions that characterize internal predictive beliefs.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CW5CVV27\\Bakst and McGuire - 2019 - Eye movements reflect adaptive predictions and pre.pdf},
  language = {en},
  type = {Preprint}
}

@article{baladron_hamker_2015,
  title = {A Spiking Neural Network Based on the Basal Ganglia Functional Anatomy},
  author = {Baladron, Javier and Hamker, Fred H.},
  year = {2015},
  volume = {67},
  pages = {1--13},
  issn = {18792782},
  doi = {10.1016/j.neunet.2015.03.002},
  abstract = {We introduce a spiking neural network of the basal ganglia capable of learning stimulus-action associations. We model learning in the three major basal ganglia pathways, direct, indirect and hyperdirect, by spike time dependent learning and considering the amount of dopamine available (reward). Moreover, we allow to learn a cortico-thalamic pathway that bypasses the basal ganglia. As a result the system develops new functionalities for the different basal ganglia pathways: The direct pathway selects actions by disinhibiting the thalamus, the hyperdirect one suppresses alternatives and the indirect pathway learns to inhibit common mistakes. Numerical experiments show that the system is capable of learning sets of either deterministic or stochastic rules.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\B8XK4K64\\Baladron, Hamker - 2015 - A spiking neural network based on the basal ganglia functional anatomy.pdf},
  journal = {Neural Networks},
  keywords = {Basal ganglia,Cognitive modeling,Reinforcement learning,Spiking neurons},
  pmid = {25863288}
}

@book{ballard_ballard_2015,
  title = {Brain Computation as Hierarchical Abstraction},
  author = {Ballard, Dana H.},
  year = {2015},
  publisher = {{The MIT Press}},
  address = {{Cambridge, Massachusetts}},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\E8JB48X8\\Ballard - 2015 - Brain computation as hierarchical abstraction.pdf},
  isbn = {978-0-262-02861-5},
  language = {en},
  lccn = {QP357.5 .B35 2015},
  series = {Computational Neuroscience}
}

@article{ballard_mcclure_2019,
  title = {Hippocampal Pattern Separation Supports Reinforcement Learning},
  author = {Ballard, Ian C. and Wagner, Anthony D. and McClure, Samuel M.},
  year = {2019},
  month = dec,
  volume = {10},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-08998-1},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AAUXY2D3\\Ballard et al. - 2019 - Hippocampal pattern separation supports reinforcem.pdf},
  journal = {Nature Communications},
  language = {en},
  number = {1}
}

@book{bamford_sulzer_2018,
  title = {Dopamine's {{Effects}} on {{Corticostriatal Synapses}} during {{Reward}}-{{Based Behaviors}}},
  author = {Bamford, Nigel S and Wightman, R Mark and Sulzer, David},
  year = {2018},
  volume = {97},
  doi = {10.1016/j.neuron.2018.01.006},
  abstract = {Many learned responses depend on the coordinated activation and inhibition of synaptic pathways in the striatum. Local dopamine neurotransmission acts in concert with a variety of neurotransmitters to regulate cortical, thalamic, and limbic excitatory inputs to drive the direct and indirect striatal spiny projection neuron outputs that determine the activity, sequence, and timing of learned behaviors. We review recent advances in the characterization of stereotyped neuronal and operant responses that predict and then obtain rewards. These depend on the local release of dopamine at discrete times during behavioral sequences, which, acting with glutamate, provides a presynaptic filter to select which excitatory synapses are inhibited and which signals pass to indirect pathway circuits. This is followed by dopamine-dependent activation of specific direct pathway circuits to procure a reward. These steps may provide a means by which higher organisms learn behaviors in response to feedback from the environment. Several neurotransmitters regulate striatal spiny projection neurons that synchronize reward-driven behaviors. Bamford et al. review advances in the measurement of functional neurotransmitter dynamics. These approaches reveal that local dopamine release is differentially regulated in adjacent circuits to coordinate these behaviors.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\W26RXHN6\\Bamford, Wightman, Sulzer - 2018 - Review Dopamine's Effects on Corticostriatal Synapses during Reward-Based Behaviors.pdf},
  isbn = {1097-4199 (Electronic) 0896-6273 (Linking)},
  keywords = {direct pathway,indirect pathway,learning,motor,nucleus accumbens,reward,striatum,substantia nigra,synapse,ventral tegmental area},
  pmid = {29420932}
}

@article{banino_kumaran_2018,
  title = {Vector-Based Navigation Using Grid-like Representations in Artificial Agents},
  author = {Banino, Andrea and Barry, Caswell and Uria, Benigno and Blundell, Charles and Lillicrap, Timothy and Mirowski, Piotr and Pritzel, Alexander and Chadwick, Martin J and Degris, Thomas and Modayil, Joseph and Wayne, Greg and Soyer, Hubert and Viola, Fabio and Zhang, Brian and Goroshin, Ross and Rabinowitz, Neil and Pascanu, Razvan and Beattie, Charlie and Petersen, Stig and Sadik, Amir and Gaffney, Stephen and King, Helen and Kavukcuoglu, Koray and Hassabis, Demis and Hadsell, Raia and Kumaran, Dharshan},
  year = {2018},
  volume = {557},
  pages = {429--433},
  issn = {14764687},
  doi = {10.1038/s41586-018-0102-6},
  abstract = {Deep neural networks have achieved impressive successes in fields ranging from object recognition to complex games such as Go1,2. Navigation, however, remains a substantial challenge for artificial agents, with deep neural networks trained by reinforcement learning3\textendash 5 failing to rival the proficiency of mammalian spatial behaviour, which is underpinned by grid cells in the entorhinal cortex 6 . Grid cells are thought to provide a multi-scale periodic representation that functions as a metric for coding space7,8 and is critical for integrating self-motion (path integration)6,7,9 and planning direct trajectories to goals (vector-based navigation)7,10,11. Here we set out to leverage the computational functions of grid cells to develop a deep reinforcement learning agent with mammal-like navigational abilities. We first trained a recurrent network to perform path integration, leading to the emergence of representations resembling grid cells, as well as other entorhinal cell types 12 . We then showed that this representation provided an effective basis for an agent to locate goals in challenging, unfamiliar, and changeable environments\textemdash optimizing the primary objective of navigation through deep reinforcement learning. The performance of agents endowed with grid-like representations surpassed that of an expert human and comparison agents, with the metric quantities necessary for vector-based navigation derived from grid-like units within the network. Furthermore, grid-like representations enabled agents to conduct shortcut behaviours reminiscent of those performed by mammals. Our findings show that emergent grid-like representations furnish agents with a Euclidean spatial metric and associated vector operations, providing a foundation for proficient navigation. As such, our results support neuroscientific theories that see grid cells as critical for vector-based navigation7,10,11, demonstrating that the latter can be combined with path-based strategies to support navigation in challenging environments.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8ML4MJDM\\Banino et al. - 2018 - Vector-based navigation using grid-like representations in artificial agents.pdf},
  journal = {Nature},
  number = {7705},
  pmid = {29743670}
}

@article{baras_meir_2007,
  title = {Reinforcement Learning, Spike-Time-Dependent Plasticity, and the {{BCM}} Rule},
  author = {Baras, Dorit and Meir, Ron},
  year = {2007},
  volume = {19},
  pages = {2245--2279},
  issn = {1530888X},
  doi = {10.1162/neco.2007.19.8.2245},
  abstract = {Learning agents, whether natural or artificial, must update their internal parameters in order to improve their behavior over time. In reinforcement learning, this plasticity is influenced by an environmental signal, termed a reward, that directs the changes in appropriate directions. We apply a recently introduced policy learning algorithm from machine learning to networks of spiking neurons and derive a spike-time-dependent plasticity rule that ensures convergence to a local optimum of the expected average reward. The approach is applicable to a broad class of neuronal models, including the Hodgkin-Huxley model. We demonstrate the effectiveness of the derived rule in several toy problems. Finally, through statistical analysis, we show that the synaptic plasticity rule established is closely related to the widely used BCM rule, for which good biological evidence exists.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QPMMBESM\\Baras, Meir - 2007 - Communicated by Jochen Triesch Reinforcement Learning, Spike-Time-Dependent Plasticity, and the BCM Rule.pdf},
  journal = {Neural Computation},
  number = {8},
  pmid = {17571943}
}

@article{barbera_lin_2016,
  title = {Spatially {{Compact Neural Clusters}} in the {{Dorsal Striatum Encode Locomotion Relevant Information}}},
  author = {Barbera, Giovanni and Liang, Bo and Zhang, Lifeng and Gerfen, Charles R. and Culurciello, Eugenio and Chen, Rong and Li, Yun and Lin, Da Ting},
  year = {2016},
  volume = {92},
  pages = {202--213},
  issn = {10974199},
  doi = {10.1016/j.neuron.2016.08.037},
  abstract = {An influential striatal model postulates that neural activities in the striatal direct and indirect pathways promote and inhibit movement, respectively. Normal behavior requires coordinated activity in the direct pathway to facilitate intended locomotion and indirect pathway to inhibit unwanted locomotion. In this striatal model, neuronal population activity is assumed to encode locomotion relevant information. Here, we propose a novel encoding mechanism for the dorsal striatum. We identified spatially compact neural clusters in both the direct and indirect pathways. Detailed characterization revealed similar cluster organization between the direct and indirect pathways, and cluster activities from both pathways were correlated with mouse locomotion velocities. Using machine-learning algorithms, cluster activities could be used to decode locomotion relevant behavioral states and locomotion velocity. We propose that neural clusters in the dorsal striatum encode locomotion relevant information and that coordinated activities of direct and indirect pathway neural clusters are required for normal striatal controlled behavior. Video Abstract},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3Z8UIMI9\\Barbera et al. - 2016 - Spatially Compact Neural Clusters in the Dorsal Striatum Encode Locomotion Relevant Information.pdf},
  journal = {Neuron},
  number = {1},
  pmid = {27667003}
}

@article{barbey_grafman_2013,
  title = {Dorsolateral Prefrontal Contributions to Human Working Memory},
  author = {Barbey, Aron K. and Koenigs, Michael and Grafman, Jordan},
  year = {2013},
  month = may,
  volume = {49},
  pages = {1195--1205},
  issn = {00109452},
  doi = {10.1016/j.cortex.2012.05.022},
  abstract = {Although neuroscience has made remarkable progress in understanding the involvement of prefrontal cortex (PFC) in human memory, the necessity of dorsolateral PFC (dlPFC) for key competencies of working memory remains largely unexplored. We therefore studied human brain lesion patients to determine whether dlPFC is necessary for working memory function, administering subtests of the Wechsler Memory Scale, the Wechsler Adult Intelligence Scale, and the N-Back Task to three participant groups: dlPFC lesions (n {$\frac{1}{4}$} 19), non-dlPFC lesions (n {$\frac{1}{4}$} 152), and no brain lesions (n {$\frac{1}{4}$} 54). DlPFC damage was associated with deficits in the manipulation of verbal and spatial knowledge, with left dlPFC necessary for manipulating information in working memory and right dlPFC critical for manipulating information in a broader range of reasoning contexts. Our findings elucidate the architecture of working memory, providing key neuropsychological evidence for the necessity of dlPFC in the manipulation of verbal and spatial knowledge.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4HGV9WKL\\Barbey et al. - 2013 - Dorsolateral prefrontal contributions to human wor.pdf},
  journal = {Cortex},
  language = {en},
  number = {5}
}

@article{barbey_grafman_2013a,
  title = {Dorsolateral Prefrontal Contributions to Human Intelligence},
  author = {Barbey, Aron K. and Colom, Roberto and Grafman, Jordan},
  year = {2013},
  month = jun,
  volume = {51},
  pages = {1361--1369},
  issn = {00283932},
  doi = {10.1016/j.neuropsychologia.2012.05.017},
  abstract = {Although cognitive neuroscience has made remarkable progress in understanding the involvement of the prefrontal cortex in executive control functions for human intelligence, the necessity of the dorsolateral prefrontal cortex (dlPFC) for key competencies of general intelligence and executive function remains to be well established. Here we studied human brain lesion patients with dlPFC lesions to investigate whether this region is computationally necessary for performance on neuropsychological tests of general intelligence and executive function, administering the Wechsler Adult Intelligence Scale (WAIS) and subtests of the Delis Kaplan Executive Function System (D-KEFS) to three groups: dlPFC lesions (n {$\frac{1}{4}$} 19), non-dlPFC lesions (n {$\frac{1}{4}$} 152), and no brain lesions (n {$\frac{1}{4}$}55). The results indicate that: (1) patients with focal dlPFC damage exhibit lower scores, at the latent variable level, than controls in general intelligence (g) and executive function; (2) dlPFC patients demonstrate lower scores than controls in several executive measures; and (3) these latter differences are no longer significant when the pervasive influence of the general factor of intelligence (g) is statistically removed. The observed findings support a central role for the dlPFC in global aspects of general intelligence and make specific recommendations for the interpretation and application of the WAIS and D-KEFS to the study of high-level cognition in health and disease.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KUAGBK45\\Barbey et al. - 2013 - Dorsolateral prefrontal contributions to human int.pdf},
  journal = {Neuropsychologia},
  language = {en},
  number = {7}
}

@techreport{barcelo_barcelo_2020,
  title = {A Predictive Processing Account of the {{Wisconsin}} Card Sorting Test: {{Fast}} Proactive and Reactive Frontoparietal Cortical Dynamics during Inference and Learning of Perceptual Categories},
  shorttitle = {A Predictive Processing Account of the {{Wisconsin}} Card Sorting Test},
  author = {Barcelo, Francisco},
  year = {2020},
  month = aug,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/zsw3t},
  abstract = {For decades a common assumption in Cognitive Neuroscience has been that prefrontal executive control is mainly engaged during target detection (Posner \& Petersen, 1990, 3: 25\textendash 42, Ann Rev Neurosci.). More recently, predictive processing theories of frontal function under the Bayesian brain hypothesis emphasize a key role of proactive control for anticipatory action selection (i.e., planning as active inference). Here, we review evidence of fast and widespread electroencephalographic (EEG) and magnetoencephalographic (MEG) fronto-temporo-parietal cortical activations elicited by feedback cues and target cards in the Wisconsin Card Sorting Test (WCST). This evidence is best interpreted when considering negative and positive feedback as predictive cues (i.e., sensory outcomes) for proactively updating beliefs about unknown perceptual categories. Such predictive cues inform posterior beliefs about high-level hidden categories governing subsequent response selection at target onset. Quite remarkably, these new views concur with Don Stuss' early findings concerning two broad classes of P300 cortical responses evoked by feedback cues and target cards in a computerized WCST analogue. Stuss' discussion of those P300 responses \textemdash in terms of the resolution of uncertainty about response (policy) selection, and the subject's expectancies for future perceptual or motor activities and their timing\textemdash{} were prescient of current predictive processing and active (Bayesian) inference theories. From these new premises, a domain-general frontoparietal cortical network is rapidly engaged during two temporarily distinct stages of inference and learning of perceptual categories that underwrite goal-directed card sorting behavior, and they each engage prefrontal executive functions in fundamentally distinct ways.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\38TINLXT\\Barcelo - 2020 - A predictive processing account of the Wisconsin c.pdf},
  language = {en},
  type = {Preprint}
}

@article{barker_munakata_2014,
  title = {Less-Structured Time in Children's Daily Lives Predicts Self-Directed Executive Functioning},
  author = {Barker, Jane E. and Semenov, Andrei D. and Michaelson, Laura and Provan, Lindsay S. and Snyder, Hannah R. and Munakata, Yuko},
  year = {2014},
  volume = {5},
  pages = {1--16},
  issn = {16641078},
  doi = {10.3389/fpsyg.2014.00593},
  abstract = {Executive functions (EFs) in childhood predict important life outcomes. Thus, there is great interest in attempts to improve EFs early in life. Many interventions are led by trained adults, including structured training activities in the lab, and less-structured activities implemented in schools. Such programs have yielded gains in children's externally-driven executive functioning, where they are instructed on what goal-directed actions to carry out and when. However, it is less clear how children's experiences relate to their development of self-directed executive functioning, where they must determine on their own what goal-directed actions to carry out and when. We hypothesized that time spent in less-structured activities would give children opportunities to practice self-directed executive functioning, and lead to benefits. To investigate this possibility, we collected information from parents about their 6-7 year-old children's daily, annual, and typical schedules. We categorized children's activities as "structured" or "less-structured" based on categorization schemes from prior studies on child leisure time use. We assessed children's self-directed executive functioning using a well-established verbal fluency task, in which children generate members of a category and can decide on their own when to switch from one subcategory to another. The more time that children spent in less-structured activities, the better their self-directed executive functioning. The opposite was true of structured activities, which predicted poorer self-directed executive functioning. These relationships were robust (holding across increasingly strict classifications of structured and less-structured time) and specific (time use did not predict externally-driven executive functioning). We discuss implications, caveats, and ways in which potential interpretations can be distinguished in future work, to advance an understanding of this fundamental aspect of growing up.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9ADJRIMB\\Barker et al. - 2014 - Less-structured time in children's daily lives predicts self-directed executive functioning.pdf},
  journal = {Frontiers in Psychology},
  keywords = {Cognitive development,Leisure time,Self-directed executive function,Unstructured activities,Verbal fluency},
  number = {JUN},
  pmid = {25071617}
}

@article{barnett_seth_2014,
  title = {The {{MVGC}} Multivariate {{Granger}} Causality Toolbox: {{A}} New Approach to {{Granger}}-Causal Inference},
  author = {Barnett, Lionel and Seth, Anil K},
  year = {2014},
  volume = {223},
  pages = {50--68},
  issn = {1872678X},
  doi = {10.1016/j.jneumeth.2013.10.018},
  abstract = {Background: Wiener-Granger causality ("G-causality") is a statistical notion of causality applicable to time series data, whereby cause precedes, and helps predict, effect. It is defined in both time and frequency domains, and allows for the conditioning out of common causal influences. Originally developed in the context of econometric theory, it has since achieved broad application in the neurosciences and beyond. Prediction in the G-causality formalism is based on VAR (vector autoregressive) modelling. New method: The MVGC Matlab\textcopyright{} Toolbox approach to G-causal inference is based on multiple equivalent representations of a VAR model by (i) regression parameters, (ii) the autocovariance sequence and (iii) the cross-power spectral density of the underlying process. It features a variety of algorithms for moving between these representations, enabling selection of the most suitable algorithms with regard to computational efficiency and numerical accuracy. Results: In this paper we explain the theoretical basis, computational strategy and application to empirical G-causal inference of the MVGC Toolbox. We also show via numerical simulations the advantages of our Toolbox over previous methods in terms of computational accuracy and statistical inference. Comparison with existing method(s): The standard method of computing G-causality involves estimation of parameters for both a full and a nested (reduced) VAR model. The MVGC approach, by contrast, avoids explicit estimation of the reduced model, thus eliminating a source of estimation error and improving statistical power, and in addition facilitates fast and accurate estimation of the computationally awkward case of conditional G-causality in the frequency domain. Conclusions: The MVGC Toolbox implements a flexible, powerful and efficient approach to G-causal inference. \textcopyright{} 2013 Elsevier B.V.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IPNNP6LB\\Barnett, Seth - 2014 - The MVGC multivariate Granger causality toolbox A new approach to Granger-causal inference.pdf},
  journal = {Journal of Neuroscience Methods},
  keywords = {Granger causality,Time series analysis,Vector autoregressive modelling},
  pmid = {24200508}
}

@article{barredo_badre_2016,
  title = {Organization of Cortico-Cortical Pathways Supporting Memory Retrieval across Subregions of the Left Ventrolateral Prefrontal Cortex.},
  author = {Barredo, Jennifer and Verstynen, Timothy D and Badre, David},
  year = {2016},
  volume = {02908},
  pages = {jn.00157.2016},
  issn = {1522-1598},
  doi = {10.1152/jn.00157.2016},
  abstract = {Functional magnetic resonance imaging (fMRI) evidence indicates that different subregions of ventrolateral prefrontal cortex (VLPFC) participate in distinct cortical networks. These networks have been shown to support separable cognitive functions: anterior VLPFC (IFG pars orbitalis) functionally correlates with a ventral fronto-temporal network associated with top-down influences on memory retrieval, while mid-VLPFC (inferior frontal gyrus [IFG] pars triangularis) functionally correlates with a dorsal fronto-parietal network associated with post-retrieval control. However, it is not known to what extent subregional differences in network affiliation and function are driven by differences in the organization of underlying white matter pathways. We used high-angular resolution diffusion spectrum imaging and functional connectivity analysis in un-anesthetized humans to address whether the organization of white matter connectivity differs between subregions of left VLPFC. Our results demonstrate a ventral-dorsal division within IFG. Ventral IFG as a whole connects broadly to lateral temporal cortex. Though several different individual white matter tracts form connections between ventral IFG and lateral temporal cortex, functional connectivity analysis of fMRI data indicates that these are part of the same ventral functional network. By contrast, across subdivisions, dorsal IFG was connected with the mid-frontal gyrus and correlated as a separate dorsal functional network. These qualitative differences in white matter organization within larger macroanatomical subregions of left VLPFC support prior functional distinctions across subregions observed in task-based and functional connectivity fMRI. These results are consistent with the proposal that anatomical connectivity is a crucial determinant of systems-level functional organization of frontal cortex and the brain in general.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HDLWZFYM\\Barredo, Verstynen, Badre - 2016 - Organization of cortico-cortical pathways supporting memory retrieval across subregions of the left v.pdf},
  journal = {Journal of neurophysiology},
  keywords = {anatomical connectivity,diffusion spectrum imaging,Functional connectivity,prefrontal organization,VLPFC},
  pmid = {27281745}
}

@article{barrett_lillicrap_2018,
  title = {Measuring Abstract Reasoning in Neural Networks},
  author = {Barrett, David G T and Hill, Felix and Santoro, Adam and Morcos, Ari S and Lillicrap, Timothy},
  year = {2018},
  issn = {1938-7228},
  abstract = {Whether neural networks can learn abstract reasoning or whether they merely rely on superficial statistics is a topic of recent debate. Here, we propose a dataset and challenge designed to probe abstract reasoning, inspired by a well-known human IQ test. To succeed at this challenge, models must cope with various generalisation `regimes' in which the training and test data differ in clearly-defined ways. We show that popular models such as ResNets perform poorly, even when the training and test sets differ only minimally, and we present a novel architecture, with a structure designed to encourage reasoning, that does significantly better. When we vary the way in which the test questions and training data differ, we find that our model is notably proficient at certain forms of generalisation, but notably weak at others. We further show that the model's ability to generalise improves markedly if it is trained to predict symbolic explanations for its answers. Altogether, we introduce and explore ways to both measure and induce stronger abstract reasoning in neural networks. Our freely-available dataset should motivate further progress in this direction.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4Q6YDUTU\\Barrett et al. - Unknown - Measuring abstract reasoning in neural networks.pdf},
  journal = {Proceedings of the 35th International Conference on Machine Learning}
}

@article{barrett_macke_2019,
  title = {Analyzing Biological and Artificial Neural Networks: Challenges with Opportunities for Synergy?},
  shorttitle = {Analyzing Biological and Artificial Neural Networks},
  author = {Barrett, David GT and Morcos, Ari S and Macke, Jakob H},
  year = {2019},
  month = apr,
  volume = {55},
  pages = {55--64},
  issn = {09594388},
  doi = {10.1016/j.conb.2019.01.007},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\25JTAKHU\\Barrett et al. - 2019 - Analyzing biological and artificial neural network.pdf},
  journal = {Current Opinion in Neurobiology},
  language = {en}
}

@article{barron_friston_2020,
  title = {Prediction and Memory: A Predictive Coding Account},
  shorttitle = {Prediction and Memory},
  author = {Barron, Helen C. and Auksztulewicz, Ryszard and Friston, Karl},
  year = {2020},
  month = may,
  pages = {101821},
  issn = {03010082},
  doi = {10.1016/j.pneurobio.2020.101821},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\V35NUSV7\\Barron et al. - 2020 - Prediction and memory a predictive coding account.pdf},
  journal = {Progress in Neurobiology},
  language = {en}
}

@article{barry_burgess_2012,
  title = {Grid Cell Firing Patterns Signal Environmental Novelty by Expansion},
  author = {Barry, C and Ginzberg, L. L. and O'Keefe, J. and Burgess, Neil},
  year = {2012},
  volume = {109},
  pages = {17687--17692},
  issn = {0027-8424},
  doi = {10.1073/pnas.1209918109},
  abstract = {The hippocampal formation plays key roles in representing an animal's location and in detecting environmental novelty to create or update those representations. However, the mechanisms behind this latter function are unclear. Here, we show that environmental novelty causes the spatial firing patterns of grid cells to expand in scale and reduce in regularity, reverting to their familiar scale as the environment becomes familiar. Simultaneously recorded place cell firing fields remapped and showed a smaller, temporary expansion. Grid expansion provides a potential mechanism for novelty signaling and may enhance the formation of new hippocampal representations, whereas the subsequent slow reduction in scale provides a potential familiarity signal.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PXLZHD9S\\Barry et al. - 2012 - Grid cell firing patterns signal environmental novelty by expansion(3).pdf},
  journal = {Proceedings of the National Academy of Sciences},
  number = {43},
  pmid = {23045662}
}

@article{barry_hasselmo_2012,
  title = {Possible Role of Acetylcholine in Regulating Spatial Novelty Effects on Theta Rhythm and Grid Cells.},
  author = {Barry, Caswell and Heys, James G and Hasselmo, Michael E},
  year = {2012},
  month = jan,
  volume = {6},
  pages = {5},
  issn = {1662-5110},
  doi = {10.3389/fncir.2012.00005},
  abstract = {Existing pharmacological and lesion data indicate that acetylcholine plays an important role in memory formation. For example, increased levels of acetylcholine in the hippocampal formation are known to be associated with successful encoding while disruption of the cholinergic system leads to impairments on a range of mnemonic tasks. However, cholinergic signaling from the medial septum also plays a central role in generating and pacing theta-band oscillations throughout the hippocampal formation. Recent experimental results suggest a potential link between these distinct phenomena. Environmental novelty, a condition associated with strong cholinergic drive, has been shown to induce an expansion in the firing pattern of entorhinal grid cells and a reduction in the frequency of theta measured from the LFP. Computational modeling suggests the spatial activity of grid cells is produced by interference between neuronal oscillators; scale being determined by theta-band oscillations impinging on entorhinal stellate cells, the frequency of which is modulated by acetylcholine. Here we propose that increased cholinergic signaling in response to environmental novelty triggers grid expansion by reducing the frequency of the oscillations. Furthermore, we argue that cholinergic induced grid expansion may enhance, or even induce, encoding by producing a mismatch between expanded grid cells and other spatial inputs to the hippocampus, such as boundary vector cells. Indeed, a further source of mismatch is likely to occur between grid cells of different native scales which may expand by different relative amounts.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RJUU4AM6\\Barry, Heys, Hasselmo - 2012 - Possible role of acetylcholine in regulating spatial novelty effects on theta rhythm and grid cells.pdf},
  journal = {Frontiers in neural circuits},
  keywords = {grid cell,place cell,stell,stellate cell,theta},
  number = {February},
  pmid = {22363266}
}

@article{barry_maguire_2019,
  title = {Remote {{Memory}} and the {{Hippocampus}}: {{A Constructive Critique}}},
  shorttitle = {Remote {{Memory}} and the {{Hippocampus}}},
  author = {Barry, Daniel N. and Maguire, Eleanor A.},
  year = {2019},
  month = feb,
  volume = {23},
  pages = {128--142},
  issn = {13646613},
  doi = {10.1016/j.tics.2018.11.005},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NXDE3UIZ\\Barry and Maguire - 2019 - Remote Memory and the Hippocampus A Constructive .pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {2}
}

@article{barsalou_barsalou_2008,
  title = {Grounded {{Cognition}}},
  author = {Barsalou, Lawrence W},
  year = {2008},
  volume = {59},
  pages = {617--45},
  doi = {10.1146/annurev.psych.59.103006.093639},
  abstract = {Grounded cognition rejects traditional views that cognition is com-putation on amodal symbols in a modular system, independent of the brain's modal systems for perception, action, and introspec-tion. Instead, grounded cognition proposes that modal simulations, bodily states, and situated action underlie cognition. Accumulating behavioral and neural evidence supporting this view is reviewed from research on perception, memory, knowledge, language, thought, so-cial cognition, and development. Theories of grounded cognition are also reviewed, as are origins of the area and common misperceptions of it. Theoretical, empirical, and methodological issues are raised whose future treatment is likely to affect the growth and impact of grounded cognition.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XA67BARV\\Barsalou - 2008 - Grounded Cognition.pdf},
  journal = {Annu. Rev. Psychol},
  keywords = {cognitive architecture,imagery,representation,simulation,situated action}
}

@article{bastos_friston_2012,
  title = {Canonical {{Microcircuits}} for {{Predictive Coding}}},
  author = {Bastos, Andre M and Usrey, W Martin and Adams, Rick A and Mangun, George R and Fries, Pascal and Friston, Karl J},
  year = {2012},
  volume = {76},
  pages = {695--711},
  issn = {08966273},
  doi = {10.1016/j.neuron.2012.10.038},
  abstract = {This Perspective considers the influential notion of a canonical (cortical) microcircuit in light of recent theories about neuronal processing. Specifically, we conciliate quantitative studies of microcircuitry and the functional logic of neuronal computations. We revisit the established idea that message passing among hierarchical cortical areas implements a form of Bayesian inference-paying careful attention to the implications for intrinsic connections among neuronal populations. By deriving canonical forms for these computations, one can associate specific neuronal populations with specific computational roles. This analysis discloses a remarkable correspondence between the microcircuitry of the cortical column and the connectivity implied by predictive coding. Furthermore, it provides some intuitive insights into the functional asymmetries between feedforward and feedback connections and the characteristic frequencies over which they operate.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AITDMGQS\\Bastos et al. - 2012 - Perspective Canonical Microcircuits for Predictive Coding(2).pdf},
  journal = {Neuron},
  keywords = {canonical microcircuit,predictive learning},
  number = {4},
  pmid = {23177956}
}

@article{bastos_miller_2018,
  title = {Laminar Recordings in Frontal Cortex Suggest Distinct Layers for Maintenance and Control of Working Memory},
  author = {Bastos, Andr{\'e} M and Loonis, Roman and Kornblith, Simon and Lundqvist, Mikael and Miller, Earl K},
  year = {2018},
  pages = {201710323},
  issn = {0027-8424},
  doi = {10.1073/pnas.1710323115},
  abstract = {All of the cerebral cortex has some degree of laminar organization. These different layers are composed of neurons with distinct connectivity patterns, embryonic origins, and molecular profiles. There are little data on the laminar specificity of cognitive functions in the frontal cortex, however. We recorded neuronal spiking/local field potentials (LFPs) using laminar probes in the frontal cortex (PMd, 8A, 8B, SMA/ACC, DLPFC, and VLPFC) of monkeys performing working memory (WM) tasks. LFP power in the gamma band (50-250 Hz) was strongest in superficial layers, and LFP power in the alpha/beta band (4-22 Hz) was strongest in deep layers. Memory delay activity, including spiking and stimulus-specific gamma bursting, was predominately in superficial layers. LFPs from superficial and deep layers were synchronized in the alpha/beta bands. This was primarily unidirectional, with alpha/beta bands in deep layers driving superficial layer activity. The phase of deep layer alpha/beta modulated superficial gamma bursting associated with WM encoding. Thus, alpha/beta rhythms in deep layers may regulate the superficial layer gamma bands and hence maintenance of the contents of WM.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HMHFL5XN\\Bastos et al. - 2018 - Laminar recordings in frontal cortex suggest distinct layers for maintenance and control of working memory.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\XVBNBNMM\\Bastos et al. - 2018 - Laminar recordings in frontal cortex suggest distinct layers for maintenance and control of working memory.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  pmid = {29339471}
}

@techreport{bastos_miller_2020,
  title = {Layer and Rhythm Specificity for Predictive Routing},
  author = {Bastos, Andr{\'e} M. and Lundqvist, Mikael and Waite, Ayan S. and Kopell, Nancy and Miller, Earl K.},
  year = {2020},
  month = jan,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.01.27.921783},
  abstract = {In predictive coding, experience generates predictions that attenuate the feeding forward of predicted stimuli while passing forward unpredicted ``errors''. Different models have different neural implementations of predictive coding. We recorded spikes and local field potentials from laminar electrodes in five cortical areas (V4, LIP, area 7A, FEF, and PFC) while monkeys performed a task that modulated visual stimulus predictability. Pre-stimulus predictions were associated with increased alpha/beta (8-30 Hz) power/coherence that fed back the cortical hierarchy primarily via deep-layer cortex. Unpredictable stimuli were associated with increases in spiking and in gamma-band (40-90 Hz) power/coherence that fed forward up the cortical hierarchy via superficial-layer cortex. Area 7A uniquely showed increases in high-beta (\textasciitilde 22-28 Hz) power/coherence to unpredicted stimuli. These results suggest that predictive coding may be implemented via lower-frequency alpha/beta rhythms that ``prepare'' pathways processing predicted inputs by inhibiting feedforward gamma rhythms and associated spiking.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7LU2G8X5\\Bastos et al. - 2020 - Layer and rhythm specificity for predictive routin.pdf},
  language = {en},
  type = {Preprint}
}

@article{bastos_schoffelen_2016,
  title = {A {{Tutorial Review}} of {{Functional Connectivity Analysis Methods}} and {{Their Interpretational Pitfalls}}},
  author = {Bastos, Andr{\'e} M and Schoffelen, Jan-Mathijs},
  year = {2016},
  volume = {9},
  issn = {1662-5137},
  doi = {10.3389/fnsys.2015.00175},
  abstract = {Oscillatory neuronal activity may provide a mechanism for dynamic network coordination. Rhythmic neuronal interactions can be quantified using multiple metrics, each with their own advantages and disadvantages. This tutorial will review and summarize current analysis methods used in the field of invasive and non-invasive electrophysiology to study the dynamic connections between neuronal populations. First, we review metrics for functional connectivity, including coherence, phase synchronization, phase-slope index, and Granger causality, with the specific aim to provide an intuition for how these metrics work, as well as their quantitative definition. Next, we highlight a number of interpretational caveats and common pitfalls that can arise when performing functional connectivity analysis, including the common reference problem, the signal to noise ratio problem, the volume conduction problem, the common input problem, and the trial sample size bias problem. These pitfalls will be illustrated by presenting a set of MATLAB-scripts, which can be executed by the reader to simulate each of these potential problems. We discuss of how these issues can be addressed using current methods.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\W9CEZ2XW\\Bastos, Schoffelen - 2015 - A Tutorial Review of Functional Connectivity Analysis Methods and Their Interpretational Pitfalls.pdf},
  journal = {Frontiers in Systems Neuroscience},
  keywords = {coherence analysis,electrophysiology,functional connectivity (FC),granger causality,oscillations,phase synchronization},
  number = {9},
  pmid = {26778976}
}

@article{battistoni_peelen_2017,
  title = {Preparatory Attention in Visual Cortex},
  author = {Battistoni, Elisa and Stein, Timo and Peelen, Marius V},
  year = {2017},
  volume = {1396},
  pages = {92--107},
  issn = {17496632},
  doi = {10.1111/nyas.13320},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SQR8T4M4\\Battistoni et al. - 2017 - Preparatory attention in visual cortex Preparator.pdf},
  journal = {Annals of the New York Academy of Sciences},
  keywords = {Biased competition,Neuroimaging,Search template,Top-down attention,Visual search}
}

@article{bean_bean_2007,
  title = {The Action Potential in Mammalian Central Neurons.},
  author = {Bean, Bruce P},
  year = {2007},
  month = jun,
  volume = {8},
  pages = {451--465},
  issn = {1471-003X},
  doi = {10.1038/nrn2148},
  abstract = {The action potential of the squid giant axon is formed by just two voltage-dependent conductances in the cell membrane, yet mammalian central neurons typically express more than a dozen different types of voltage-dependent ion channels. This rich repertoire of channels allows neurons to encode information by generating action potentials with a wide range of shapes, frequencies and patterns. Recent work offers an increasingly detailed understanding of how the expression of particular channel types underlies the remarkably diverse firing behaviour of various types of neurons.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4SXHZAPP\\Bean - 2007 - The action potential in mammalian central neurons.pdf},
  journal = {Nature reviews. Neuroscience},
  keywords = {Animals,Axons,Axons: physiology,Calcium Channels,Calcium Channels: physiology,Cell Membrane,Cell Membrane: physiology,Central Nervous System,Central Nervous System: physiology,Humans,Ion Channels,Ion Channels: physiology,Neurons,Neurons: physiology,Neurons: ultrastructure,Potassium Channels,Potassium Channels: physiology,Sodium Channels,Sodium Channels: physiology},
  number = {6},
  pmid = {17514198}
}

@article{becker_becker_2009,
  title = {Europe {{PMC Funders Group Remembering}} the Past and Imagining the Future :},
  author = {Becker, Suzanna},
  year = {2009},
  volume = {114},
  pages = {340--375},
  doi = {10.1037/0033-295X.114.2.340.Remembering},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9NXDHTVW\\Becker - 2009 - Europe PMC Funders Group Remembering the past and imagining the future.pdf},
  keywords = {computational model,hippocampus,navigation,path integration,representational neglect},
  number = {2}
}

@article{behrens_kurth-nelson_2018,
  title = {Perspective {{What Is}} a {{Cognitive Map}}? {{Organizing Knowledge}} for {{Flexible Behavior}}},
  author = {Behrens, Timothy E J and Muller, Timothy H and Whittington, James C R and Mark, Shirley and Baram, Alon B and Stachenfeld, Kimberly L and {Kurth-Nelson}, Zeb},
  year = {2018},
  doi = {10.1016/j.neuron.2018.10.002},
  abstract = {It is proposed that a cognitive map encoding the relationships between entities in the world supports flexible behavior, but the majority of the neural evidence for such a system comes from studies of spatial navigation. Recent work describing neuronal parallels between spatial and non-spatial behaviors has rekindled the notion of a systematic organization of knowledge across multiple domains. We review experimental evidence and theoretical frameworks that point to principles unifying these apparently disparate functions. These principles describe how to learn and use abstract, generalizable knowledge and suggest that map-like representations observed in a spatial context may be an instance of general coding mechanisms capable of organizing knowledge of all kinds. We highlight how artificial agents endowed with such principles exhibit flexible behavior and learn map-like representations observed in the brain. Finally, we speculate on how these principles may offer insight into the extreme generalizations, abstractions, and inferences that characterize human cognition. Introduction In the last two decades and more, computational and behavioral neuroscientists have found formal explanations of neural signals that control behavior in carefully controlled repetitive scenarios (e.g., Behrens et al., 2007; Daw et al., 2006; O'Doherty et al., 2004; Platt and Glimcher, 1999; Schultz et al., 1997). In some instances , these models predict neuronal activity with truly exquisite precision (Cohen et al., 2012; Gold and Shadlen, 2007; Schultz et al., 1997), and when paired with heavy computational resources, related algorithms have had extraordinary successes in training artificial agents to superhuman levels in games as diverse as Atari (Mnih et al., 2015) and Go (Silver et al., 2016). However, there is a stark gap between the types of behavior these models can account for and the sophisticated inferences that characterize much of human behavior. Human and animal behavior is flexible. We can choose how to act by exploiting actions that have worked in the past but also based on experiences that are only loosely related; we can imagine the consequences of entirely novel choices. We can abstract important features of experiences and generalize them to new situations. These differences were clearly articulated by Tolman as he watched rats make flexible inferences in complex mazes. They would learn rich details of the mazes in the absence of any rewards and to the benefit of future behavior. For example, after unrewarded exposure to mazes, rats would take shortcuts to reach rewards (Tolman and Honzik, 1930) or would find new routes when old ones were blocked (Tolman et al., 1946). Such behaviors inspired Tolman to coin the term ''cognitive map,'' referring to a rich internal model of the world that accounts for the relationships between events and predicts the consequences of actions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\43L4TULQ\\Behrens_et_al_2018_What_is_a_cognitive_map.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\9DK28QAF\\Behrens et al. - 2018 - Perspective What Is a Cognitive Map Organizing Knowledge for Flexible Behavior.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\4Z9TG26W\\S0896627318308560.html}
}

@article{behrens_rushworth_2007,
  title = {Learning the Value of Information in an Uncertain World},
  author = {Behrens, Timothy E J and Woolrich, Mark W and Walton, Mark E and Rushworth, Matthew F S},
  year = {2007},
  month = sep,
  volume = {10},
  pages = {1214--1221},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn1954},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LPSW8UFA\\Behrens et al. - 2007 - Learning the value of information in an uncertain .pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {9}
}

@article{bellana_grady_2019,
  title = {Recollection and Prior Knowledge Recruit the Left Angular Gyrus during Recognition},
  author = {Bellana, Buddhika and {Ladyka-Wojcik}, Natalia and Lahan, Shany and Moscovitch, Morris and Grady, Cheryl},
  year = {2019},
  month = feb,
  doi = {10.1101/561910},
  abstract = {The human angular gyrus (AG) is implicated in recollection, or our ability to retrieve detailed memory content from a specific study episode. Parallel work also highlights a key role of the AG in the representation of general knowledge and semantics. How these two lines of research converge remains unclear. The present fMRI experiment used a remember-know paradigm with famous and non-famous faces to test whether activity in the AG could be modulated by both task-specific recollection and general prior knowledge in the same participants. Increased BOLD activity in the left AG was observed during both recollection in the absence of prior knowledge (i.e., recollected \&gt; non-recollected or correctly rejected non-famous faces) and when prior knowledge was accessed in the absence of recollection (i.e., famous \&gt; non-famous correct rejections). This pattern was unique to the left AG, and was not present in any other regions of the lateral inferior parietal lobe. Furthermore, the response profile of the left AG was consistent with accounts of recollection strength. Recollection-related activity was greater for faces with longer exposures at encoding than those with shorter exposures and was greater for stimuli with prior knowledge than those without, despite prior knowledge being incidental to the recognition decision. Therefore, the left AG is recruited during the access of both task-specific recollection and general prior knowledge, with greater activity as the amount of retrieved information increases, irrespective of its episodic or semantic nature.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\A5PGXMP9\\Bellana et al. - 2019 - Recollection and prior knowledge recruit the left .pdf},
  journal = {bioRxiv},
  language = {en}
}

@article{bellec_maass_2019,
  title = {Biologically Inspired Alternatives to Backpropagation through Time for Learning in Recurrent Neural Nets},
  author = {Bellec, Guillaume and Scherr, Franz and Hajek, Elias and Salaj, Darjan and Legenstein, Robert and Maass, Wolfgang},
  year = {2019},
  month = feb,
  abstract = {The way how recurrently connected networks of spiking neurons in the brain acquire powerful information processing capabilities through learning has remained a mystery. This lack of understanding is linked to a lack of learning algorithms for recurrent networks of spiking neurons (RSNNs) that are both functionally powerful and can be implemented by known biological mechanisms. Since RSNNs are simultaneously a primary target for implementations of brain-inspired circuits in neuromorphic hardware, this lack of algorithmic insight also hinders technological progress in that area. The gold standard for learning in recurrent neural networks in machine learning is back-propagation through time (BPTT), which implements stochastic gradient descent with regard to a given loss function. But BPTT is unrealistic from a biological perspective, since it requires a transmission of error signals backwards in time and in space, i.e., from post- to presynaptic neurons. We show that an online merging of locally available information during a computation with suitable top-down learning signals in real-time provides highly capable approximations to BPTT. For tasks where information on errors arises only late during a network computation, we enrich locally available information through feedforward eligibility traces of synapses that can easily be computed in an online manner. The resulting new generation of learning algorithms for recurrent neural networks provides a new understanding of network learning in the brain that can be tested experimentally. In addition, these algorithms provide efficient methods for on-chip training of RSNNs in neuromorphic hardware.},
  archivePrefix = {arXiv},
  eprint = {1901.09049},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SUBQFBKE\\Bellec et al. - 2019 - Biologically inspired alternatives to backpropagat.pdf},
  journal = {arXiv:1901.09049 [cs]},
  language = {en},
  primaryClass = {cs}
}

@article{belluscio_buzsaki_2012,
  title = {Cross-Frequency Phase\textendash Phase Coupling between Theta and Gamma Oscillations in the Hippocampus},
  author = {Belluscio, Mariano A and Mizuseki, Keji and Schmidt, Robert and Kempter, Richard and Buzs{\'a}ki, Gy{\"o}rgy},
  year = {2012},
  volume = {32},
  pages = {423--435},
  doi = {10.1523/JNEUROSCI.4122-11.2012.Cross-frequency},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QVEM7RFE\\Belluscio et al. - 2012 - Cross-frequency phase–phase coupling between theta and gamma oscillations in the hippocampus.pdf},
  journal = {The Journal of neuroscience},
  number = {2}
}

@article{bengio_wu_2016,
  title = {From {{STDP}} towards {{Biologically Plausible Deep Learning}}},
  author = {Bengio, Yoshua and Fischer, Asja and Mesnard, Thomas and Zhang, Saizheng and Wu, Yuhai},
  year = {2016},
  pages = {11},
  abstract = {We introduce a predictive objective function for the rate aspect of spike-timing dependent plasticity (STDP), i.e., ignoring the effects of synchrony of spikes but looking at spiking rate changes. The proposed weight update is proportional to the presynaptic spiking (or firing) rate times the temporal change of the integrated postsynaptic activity. We present an intuitive explanation for the relationship between spike-timing and weight change that arises when the weight change follows this rule. Spike-based simulations agree with the proposed relationship between spike timing and the temporal change of postsynaptic activity and show a strong correlation between the biologically observed STDP behavior and the behavior obtained from simulations where the weight change follows the gradient of the predictive objective function. Finally, we draw links between this objective function, neural computation as inference, score matching, and variational EM.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QA8F5DXF\\Bengio et al. - From STDP towards Biologically Plausible Deep Lear.pdf},
  language = {en}
}

@article{bennett_bennett_2020,
  title = {An {{Attempt}} at a {{Unified Theory}} of the {{Neocortical Microcircuit}} in {{Sensory Cortex}}},
  author = {Bennett, Max},
  year = {2020},
  month = jul,
  volume = {14},
  pages = {40},
  issn = {1662-5110},
  doi = {10.3389/fncir.2020.00040},
  abstract = {The neocortex performs a wide range of functions, including working memory, sensory perception, and motor planning. Despite this diversity in function, evidence suggests that the neocortex is made up of repeating subunits (``macrocolumns''), each of which is largely identical in circuitry. As such, the specific computations performed by these macrocolumns are of great interest to neuroscientists and AI researchers. Leading theories of this microcircuit include models of predictive coding, hierarchical temporal memory (HTM), and Adaptive Resonance Theory (ART). However, these models have not yet explained: (1) how microcircuits learn sequences input with delay (i.e., working memory); (2) how networks of columns coordinate processing on precise timescales; or (3) how top-down attention modulates sensory processing. I provide a theory of the neocortical microcircuit that extends prior models in all three ways. Additionally, this theory provides a novel working memory circuit that extends prior models to support simultaneous multi-item storage without disrupting ongoing sensory processing. I then use this theory to explain the functional origin of a diverse set of experimental findings, such as cortical oscillations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\W556TNHZ\\Bennett - 2020 - An Attempt at a Unified Theory of the Neocortical .pdf},
  journal = {Frontiers in Neural Circuits},
  language = {en}
}

@article{bennett_olsen_2019,
  title = {Higher-{{Order Thalamic Circuits Channel Parallel Streams}} of {{Visual Information}} in {{Mice}}},
  author = {Bennett, Corbett and Gale, Samuel D. and Garrett, Marina E. and Newton, Melissa L. and Callaway, Edward M. and Murphy, Gabe J. and Olsen, Shawn R.},
  year = {2019},
  month = apr,
  volume = {102},
  pages = {477-492.e5},
  issn = {08966273},
  doi = {10.1016/j.neuron.2019.02.010},
  abstract = {Higher-order thalamic nuclei, such as the visual pulvinar, play essential roles in cortical function by connecting functionally related cortical and subcortical brain regions. A coherent framework describing pulvinar function remains elusive because of its anatomical complexity and involvement in diverse cognitive processes. We combined large-scale anatomical circuit mapping with highdensity electrophysiological recordings to dissect a homolog of the pulvinar in mice, the lateral posterior thalamic nucleus (LP). We define three broad LP subregions based on correspondence between connectivity and functional properties. These subregions form corticothalamic loops biased toward ventral or dorsal stream cortical areas and contain separate representations of visual space. Silencing the visual cortex or superior colliculus revealed that they drive visual tuning properties in separate LP subregions. Thus, by specifying the driving input sources, functional properties, and downstream targets of LP circuits, our data provide a roadmap for understanding the mechanisms of higher-order thalamic function in vision.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\K835GXMI\\Bennett et al. - 2019 - Higher-Order Thalamic Circuits Channel Parallel St.pdf},
  journal = {Neuron},
  language = {en},
  number = {2}
}

@article{berry_davis_2018,
  title = {Dopamine {{Neurons Mediate Learning}} and {{Forgetting}} through {{Bidirectional Modulation}} of a {{Memory Trace In Brief}}},
  author = {Berry, Jacob A and Phan, Anna and Davis, Ronald L},
  year = {2018},
  volume = {25},
  pages = {651--662},
  doi = {10.1016/j.celrep.2018.09.051},
  abstract = {Graphical Abstract Highlights d A short-term memory trace is encoded in and retrieved from MBOn-g2a 0 1 d A single dopamine neuron participates in forming and disrupting this memory trace d New learning simultaneously disrupts old memory traces while forming new ones In Drosophila, dopamine neurons regulate both learning and forgetting. Berry et al. identify a locus for the storage and retrieval of a short-term memory trace and show that a single dopamine neuron regulates both formation and disruption of this trace. These findings elucidate circuit mechanisms underlying memory storage and removal.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\33HK9YFB\\Berry, Phan, Davis - 2018 - Dopamine Neurons Mediate Learning and Forgetting through Bidirectional Modulation of a Memory Trace In Brief.pdf},
  journal = {Cell Reports}
}

@article{bertolero_bassett_,
  title = {On the {{Nature}} of {{Explanations Offered}} by {{Network Science}}: {{A Perspective From}} and for {{Practicing Neuroscientists}}},
  shorttitle = {On the {{Nature}} of {{Explanations Offered}} by {{Network Science}}},
  author = {Bertolero, Maxwell A. and Bassett, Danielle S.},
  volume = {n/a},
  issn = {1756-8765},
  doi = {10.1111/tops.12504},
  abstract = {Network neuroscience represents the brain as a collection of regions and inter-regional connections. Given its ability to formalize systems-level models, network neuroscience has generated unique explanations of neural function and behavior. The mechanistic status of these explanations and how they can contribute to and fit within the field of neuroscience as a whole has received careful treatment from philosophers. However, these philosophical contributions have not yet reached many neuroscientists. Here we complement formal philosophical efforts by providing an applied perspective from and for neuroscientists. We discuss the mechanistic status of the explanations offered by network neuroscience and how they contribute to, enhance, and interdigitate with other types of explanations in neuroscience. In doing so, we rely on philosophical work concerning the role of causality, scale, and mechanisms in scientific explanations. In particular, we make the distinction between an explanation and the evidence supporting that explanation, and we argue for a scale-free nature of mechanistic explanations. In the course of these discussions, we hope to provide a useful applied framework in which network neuroscience explanations can be exercised across scales and combined with other fields of neuroscience to gain deeper insights into the brain and behavior.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/tops.12504},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NGYZZESB\\bertolero_bassett_.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\RC76IJGM\\tops.html},
  journal = {Topics in Cognitive Science},
  keywords = {Causality,Explanation,Mechanisms,Network neuroscience},
  language = {en},
  number = {n/a}
}

@article{bertram_wu_2014,
  title = {Two Neural Streams, One Voice: Pathways for Theme and Variation in the Songbird Brain.},
  author = {Bertram, R and Daou, A and Hyson, R L and Johnson, F and Wu, W},
  year = {2014},
  month = sep,
  volume = {277},
  pages = {806--17},
  issn = {1873-7544},
  doi = {10.1016/j.neuroscience.2014.07.061},
  abstract = {Birdsong offers a unique model system to understand how a developing brain - once given a set of purely acoustic targets - teaches itself the vocal-tract gestures necessary to imitate those sounds. Like human infants, to juvenile male zebra finches (Taeniopygia guttata) falls the burden of initiating the vocal-motor learning of adult sounds. In both species, adult caregivers provide only a set of sounds to be imitated, with little or no information about the vocal-tract gestures used to produce the sounds. Here, we focus on the central control of birdsong and review the recent discovery that zebra finch song is under dual premotor control. Distinct forebrain pathways for structured (theme) and unstructured (variation) singing not only raise new questions about mechanisms of sensory-motor integration, but also provide a fascinating new research opportunity. A cortical locus for a motor memory of the learned song is now firmly established, meaning that anatomical, physiological, and computational approaches are poised to reveal the neural mechanisms used by the brain to compose the songs of birds.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EJNEJME6\\Bertram et al. - 2014 - Two neural streams, one voice pathways for theme and variation in the songbird brain.pdf},
  journal = {Neuroscience},
  keywords = {anterior forebrain pathway,basal ganglia,gesture trajectory extrema,GTE,lateral magnocellular nucleus of the anterior nido,LMAN,motor memory,NIf,nucleus interface,nucleus uvaeformis,premotor cortex,RA,robust nucleus of the arcopallium,sensory-motor integration,Uva},
  pmid = {25106128}
}

@article{besold_zaverucha_2017,
  title = {Neural-{{Symbolic Learning}} and {{Reasoning}}: {{A Survey}} and {{Interpretation}}},
  author = {Besold, Tarek R and {d'Avila Garcez}, Artur and Bader, Sebastian and Bowman, Howard and Domingos, Pedro and Hitzler, Pascal and Kuehnberger, Kai-Uwe and Lamb, Luis C and Lowd, Daniel and Lima, Priscila Machado Vieira and {de Penning}, Leo and Pinkas, Gadi and Poon, Hoifung and Zaverucha, Gerson},
  year = {2017},
  abstract = {The study and understanding of human behaviour is relevant to computer science, artificial intelligence, neural computation, cognitive science, philosophy, psychology, and several other areas. Presupposing cognition as basis of behaviour, among the most prominent tools in the modelling of behaviour are computational-logic systems, connectionist models of cognition, and models of uncertainty. Recent studies in cognitive science, artificial intelligence, and psychology have produced a number of cognitive models of reasoning, learning, and language that are underpinned by computation. In addition, efforts in computer science research have led to the development of cognitive computational systems integrating machine learning and automated reasoning. Such systems have shown promise in a range of applications, including computational biology, fault diagnosis, training and assessment in simulators, and software verification. This joint survey reviews the personal ideas and views of several researchers on neural-symbolic learning and reasoning. The article is organised in three parts: Firstly, we frame the scope and goals of neural-symbolic computation and have a look at the theoretical foundations. We then proceed to describe the realisations of neural-symbolic computation, systems, and applications. Finally we present the challenges facing the area and avenues for further research.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ULXMWKST\\Besold et al. - 2017 - Neural-Symbolic Learning and Reasoning A Survey and Interpretation.pdf},
  journal = {arXiv},
  keywords = {neural-symbolic,to-read}
}

@article{bettencourt_somers_2009,
  title = {Effects of Target Enhancement and Distractor Suppression on Multiple Object Tracking Capacity.},
  author = {Bettencourt, Katherine C and Somers, David C},
  year = {2009},
  month = jan,
  volume = {9},
  pages = {9},
  issn = {1534-7362},
  doi = {10.1167/9.7.9},
  abstract = {Mounting evidence suggests that visual attention may be simultaneously deployed to multiple distinct object locations, but the constraints upon this multi-object attentional system are still debated. Results from multiple object tracking (MOT) experiments have been interpreted as revealing a fixed attentional capacity limit of 4 objects, while other evidence has suggested that attentional capacity may be more fluid. Here, we investigated the influence of target stimulus factors, such as speed and size, and of distractor filtering factors, such as number of distractors and screen density, on MOT performance. Each factor had significant effects on capacity, producing values that ranged from above 6 objects down to one object, depending on the task demands. Although our results support the view that crowding effects modulate the effective capacity of attention, we also find evidence that central processes related to distractor suppression and target enhancement modulate capacity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PM8DEL3J\\Bettencourt, Somers - 2009 - Effects of target enhancement and distractor suppression on multiple object tracking capacity.pdf},
  journal = {Journal of vision},
  keywords = {Attention,Attention: physiology,Humans,Perceptual Masking,Photic Stimulation,Photic Stimulation: methods,Pursuit,Smooth,Smooth: physiology,Time Factors},
  number = {7},
  pmid = {19761324}
}

@article{beyeler_krichmar_2013,
  title = {Categorization and Decision-Making in a Neurobiologically Plausible Spiking Network Using a {{STDP}}-like Learning Rule},
  author = {Beyeler, Michael and Dutt, Nikil D. and Krichmar, Jeffrey L.},
  year = {2013},
  month = dec,
  volume = {48},
  pages = {109--124},
  issn = {08936080},
  doi = {10.1016/j.neunet.2013.07.012},
  abstract = {Understanding how the human brain is able to efficiently perceive and understand a visual scene is still a field of ongoing research. Although many studies have focused on the design and optimization of neural networks to solve visual recognition tasks, most of them either lack neurobiologically plausible learning rules or decision-making processes. Here we present a large-scale model of a hierarchical spiking neural network (SNN) that integrates a low-level memory encoding mechanism with a higher-level decision process to perform a visual classification task in real-time. The model consists of Izhikevich neurons and conductance-based synapses for realistic approximation of neuronal dynamics, a spike-timing-dependent plasticity (STDP) synaptic learning rule with additional synaptic dynamics for memory encoding, and an accumulator model for memory retrieval and categorization. The full network, which comprised 71,026 neurons and approximately 133 million synapses, ran in real-time on a single off-the-shelf graphics processing unit (GPU). The network was constructed on a publicly available SNN simulator that supports general-purpose neuromorphic computer chips. The network achieved 92\% correct classifications on MNIST in 100 rounds of random sub-sampling, which is comparable to other SNN approaches and provides a conservative and reliable performance metric. Additionally, the model correctly predicted reaction times from psychophysical experiments. Because of the scalability of the approach and its neurobiological fidelity, the current model can be extended to an efficient neuromorphic implementation that supports more generalized object recognition and decision-making architectures found in the brain.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DHYLWSGT\\1-s2.0-S0893608013001986-main.pdf},
  journal = {Neural Networks},
  language = {en}
}

@article{beyeler_leinekugel_2013,
  title = {Recruitment of {{Perisomatic Inhibition}} during {{Spontaneous Hippocampal Activity In Vitro}}},
  author = {Beyeler, Anna and Retailleau, Aude and Molter, Colin and Mehidi, Amine and Szabadics, Janos and Leinekugel, Xavier},
  year = {2013},
  volume = {8},
  issn = {19326203},
  doi = {10.1371/journal.pone.0066509},
  abstract = {It was recently shown that perisomatic GABAergic inhibitory postsynaptic potentials (IPSPs) originating from basket and chandelier cells can be recorded as population IPSPs from the hippocampal pyramidal layer using extracellular electrodes (eIPSPs). Taking advantage of this approach, we have investigated the recruitment of perisomatic inhibition during spontaneous hippocampal activity in vitro. Combining intracellular and extracellular recordings from pyramidal cells and interneurons, we confirm that inhibitory signals generated by basket cells can be recorded extracellularly, but our results suggest that, during spontaneous activity, eIPSPs are mostly confined to the CA3 rather than CA1 region. CA3 eIPSPs produced the powerful time-locked inhibition of multi-unit activity expected from perisomatic inhibition. Analysis of the temporal dynamics of spike discharges relative to eIPSPs suggests significant but moderate recruitment of excitatory and inhibitory neurons within the CA3 network on a 10 ms time scale, within which neurons recruit each other through recurrent collaterals and trigger powerful feedback inhibition. Such quantified parameters of neuronal interactions in the hippocampal network may serve as a basis for future characterisation of pathological conditions potentially affecting the interactions between excitation and inhibition in this circuit.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\W7C2BXY6\\Beyeler et al. - 2013 - Recruitment of Perisomatic Inhibition during Spontaneous Hippocampal Activity In Vitro.pdf},
  journal = {PLoS ONE},
  number = {6},
  pmid = {23805227}
}

@article{bezaire_soltesz_2016,
  title = {Interneuronal Mechanisms of Hippocampal Theta Oscillations in a Full-Scale Model of the Rodent {{CA1}} Circuit},
  author = {Bezaire, Marianne J and Raikov, Ivan and Burk, Kelly and Vyas, Dhrumil and Soltesz, Ivan},
  year = {2016},
  doi = {10.7554/eLife.18566.001},
  abstract = {The hippocampal theta rhythm plays important roles in information processing; however, the mechanisms of its generation are not well understood. We developed a data-driven, supercomputer-based, full-scale (1:1) model of the rodent CA1 area and studied its interneurons during theta oscillations. Theta rhythm with phase-locked gamma oscillations and phase-preferential discharges of distinct interneuronal types spontaneously emerged from the isolated CA1 circuit without rhythmic inputs. Perturbation experiments identified parvalbumin-expressing interneurons and neurogliaform cells, as well as interneuronal diversity itself, as important factors in theta generation. These simulations reveal new insights into the spatiotemporal organization of the CA1 circuit during theta oscillations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CSAZRAX6\\Bezaire et al. - 2016 - Interneuronal mechanisms of hippocampal theta oscillations in a full-scale model of the rodent CA1 circuit.pdf}
}

@article{bhandari_badre_2018,
  title = {Learning and Transfer of Working Memory Gating Policies},
  author = {Bhandari, Apoorva and Badre, David},
  year = {2018},
  month = mar,
  volume = {172},
  pages = {89--100},
  issn = {00100277},
  doi = {10.1016/j.cognition.2017.12.001},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AG7C8SEA\\Bhandari, Badre - 2018 - Learning and transfer of working memory gating policies(2).pdf},
  journal = {Cognition}
}

@article{bi_zhou_2020,
  title = {Understanding the Computation of Time Using Neural Network Models},
  author = {Bi, Zedong and Zhou, Changsong},
  year = {2020},
  month = may,
  volume = {117},
  pages = {10530--10540},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1921609117},
  abstract = {To maximize future rewards in this ever-changing world, animals must be able to discover the temporal structure of stimuli and then anticipate or act correctly at the right time. How do animals perceive, maintain, and use time intervals ranging from hundreds of milliseconds to multiseconds in working memory? How is temporal information processed concurrently with spatial information and decision making? Why are there strong neuronal temporal signals in tasks in which temporal information is not required? A systematic understanding of the underlying neural mechanisms is still lacking. Here, we addressed these problems using supervised training of recurrent neural network models. We revealed that neural networks perceive elapsed time through state evolution along stereotypical trajectory, maintain time intervals in working memory in the monotonic increase or decrease of the firing rates of interval-tuned neurons, and compare or produce time intervals by scaling state evolution speed. Temporal and nontemporal information is coded in subspaces orthogonal with each other, and the state trajectories with time at different nontemporal information are quasiparallel and isomorphic. Such coding geometry facilitates the decoding generalizability of temporal and nontemporal information across each other. The network structure exhibits multiple feedforward sequences that mutually excite or inhibit depending on whether their preferences of nontemporal information are similar or not. We identified four factors that facilitate strong temporal signals in nontiming tasks, including the anticipation of coming events. Our work discloses fundamental computational principles of temporal processing, and it is supported by and gives predictions to a number of experimental phenomena.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\946QIP3I\\Bi and Zhou - 2020 - Understanding the computation of time using neural.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {19}
}

@article{bian_li_2014,
  title = {Relative Power and Coherence of {{EEG}} Series Are Related to Amnestic Mild Cognitive Impairment in Diabetes},
  author = {Bian, Zhijie and Li, Qiuli and Wang, Lei and Lu, Chengbiao and Yin, Shimin and Li, Xiaoli},
  year = {2014},
  volume = {6},
  pages = {1--9},
  issn = {16634365},
  doi = {10.3389/fnagi.2014.00011},
  abstract = {Objective: Diabetes is a risk factor for dementia and mild cognitive impairment. The aim of this study was to investigate whether some features of resting-state EEG (rsEEG) could be applied as a biomarker to distinguish the subjects with amnestic mild cognitive impairment (aMCI) from normal cognitive function in type 2 diabetes. Materials and Methods: In this study, 28 patients with type 2 diabetes (16 aMCI patients and 12 controls) were investigated. Recording of the rsEEG series and neuropsychological assessments were performed. The rsEEG signal was first decomposed into delta, theta, alpha, beta, gamma frequency bands. The relative power of each given band/sum of power and the coherence of waves from different brain areas were calculated. The extracted features from rsEEG and neuropsychological assessments were analyzed as well. Results: The main findings of this study were that: (1) compared with the control group, the ratios of power in theta band [P(theta)] vs. power in alpha band [P(alpha)] [P(theta)/P(alpha)] in the frontal region and left temporal region were significantly higher for aMCI, and (2) for aMCI, the alpha coherences in posterior, fronto-right temporal, fronto-posterior, right temporo-posterior were decreased; the theta coherences in left central-right central (LC-RC) and left posterior-right posterior (LP-RP) regions were also decreased; but the delta coherences in left temporal-right temporal (LT-RT) region were increased. Conclusion: The proposed indexes from rsEEG recordings could be employed to track cognitive function of diabetic patients and also to help in the diagnosis of those who develop aMCI.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6AI5QI7G\\Bian et al. - 2014 - Relative power and coherence of EEG series are related to amnestic mild cognitive impairment in diabetes.pdf},
  journal = {Frontiers in Aging Neuroscience},
  keywords = {Coherence,Diabetes,mci,Relative power,Resting-state EEG},
  number = {FEB},
  pmid = {24550827}
}

@article{biasiucci_murray_2019,
  title = {Electroencephalography},
  author = {Biasiucci, Andrea and Franceschiello, Benedetta and Murray, Micah M.},
  year = {2019},
  month = feb,
  volume = {29},
  pages = {R80-R85},
  issn = {09609822},
  doi = {10.1016/j.cub.2018.11.052},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TAQCGBE4\\Biasiucci et al. - 2019 - Electroencephalography.pdf},
  journal = {Current Biology},
  language = {en},
  number = {3}
}

@article{bicanski_burgess_2018,
  title = {A {{Neural Level Model}} of {{Spatial Memory}} and {{Imagery}}},
  author = {Bicanski, Andrej and Burgess, Neil},
  year = {2018},
  volume = {7, e33752},
  issn = {2050-084X},
  doi = {10.7554/eLife.33752},
  abstract = {We present a model of how neural representations of egocentric spatial experiences in parietal cortex interface with viewpoint-independent representations in medial temporal areas, via retrosplenial cortex, to enable many key aspects of spatial cognition. This account shows how previously reported neural responses (place, head-direction and grid cells, allocentric boundary- and object-vector cells, gain-field neurons) can map onto higher cognitive function in a modular way, and predicts new cell types (egocentric and head-direction-modulated boundary- and object-vector cells). The model predicts how these neural populations should interact across multiple brain regions to support spatial memory, scene construction, novelty-detection, `trace cells', and mental navigation. Simulated behavior and firing rate maps are compared to experimental data, for example showing how object-vector cells allow items to be remembered within a contextual representation based on environmental boundaries, and how grid cells could update the viewpoint in imagery during planning and short-cutting by driving sequential place cell activity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Z9EUKPUM\\Bicanski, Burgess - 2015 - A Neural Level Model of Spatial Memory and Imagery.pdf},
  journal = {eLife}
}

@article{bichot_desimone_2015,
  title = {A {{Source}} for {{Feature}}-{{Based Attention}} in the {{Prefrontal Cortex}}},
  author = {Bichot, Narcisse P. and Heard, Matthew T. and DeGennaro, Ellen M. and Desimone, Robert},
  year = {2015},
  month = nov,
  volume = {88},
  pages = {832--844},
  issn = {08966273},
  doi = {10.1016/j.neuron.2015.10.001},
  abstract = {In cluttered scenes, we can use feature-based attention to quickly locate a target object. To understand how feature attention is used to find and select objects for action, we focused on the ventral prearcuate (VPA) region of prefrontal cortex. In a visual search task, VPA cells responded selectively to search cues, maintained their feature selectivity throughout the delay and subsequent saccades, and discriminated the search target in their receptive fields with a time course earlier than in FEF or IT cortex. Inactivation of VPA impaired the animals' ability to find targets, and simultaneous recordings in FEF revealed that the effects of feature attention were eliminated while leaving the effects of spatial attention in FEF intact. Altogether, the results suggest that VPA neurons compute the locations of objects with the features sought and send this information to FEF to guide eye movements to those relevant stimuli.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\P5WL96AU\\Bichot et al. - 2015 - A Source for Feature-Based Attention in the Prefro.pdf},
  journal = {Neuron},
  language = {en},
  number = {4}
}

@article{bichot_desimone_2019,
  title = {The Role of Prefrontal Cortex in the Control of Feature Attention in Area {{V4}}},
  author = {Bichot, Narcisse P. and Xu, Rui and Ghadooshahy, Azriel and Williams, Michael L. and Desimone, Robert},
  year = {2019},
  month = dec,
  volume = {10},
  pages = {5727},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-13761-7},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BUKVXS6M\\Bichot et al. - 2019 - The role of prefrontal cortex in the control of fe.pdf},
  journal = {Nature Communications},
  language = {en},
  number = {1}
}

@article{bienenstock_munro_1982,
  title = {Theory for the Development of Neuron Selectivity: Orientation Specificity and Binocular Interaction in Visual Cortex.},
  author = {Bienenstock, Elie L and Cooper, Leon N and Munro, Paul W},
  year = {1982},
  volume = {2},
  pages = {32--48},
  issn = {0270-6474},
  doi = {10.1371/journal.ppat.0020109},
  abstract = {The development of stimulus selectivity in the primary sensory cortex of higher vertebrates is considered in a general mathematical framework. A synaptic evolution scheme of a new kind is proposed in which incoming patterns rather than converging afferents compete. The change in the efficacy of a given synapse depends not only on instantaneous pre- and postsynaptic activities but also on a slowly varying time-averaged value of the postsynaptic activity. Assuming an appropriate nonlinear form for this dependence, development of selectivity is obtained under quite general conditions on the sensory environment. One does not require nonlinearity of the neuron's integrative power nor does one need to assume any particular form for intracortical circuitry. This is first illustrated in simple cases, e.g., when the environment consists of only two different stimuli presented alternately in a random manner. The following formal statement then holds: the state of the system converges with probability 1 to points of maximum selectivity in the state space. We next consider the problem of early development of orientation selectivity and binocular interaction in primary visual cortex. Giving the environment an appropriate form, we obtain orientation tuning curves and ocular dominance comparable to what is observed in normally reared adult cats or monkeys. Simulations with binocular input and various types of normal or altered environments show good agreement with the relevant experimental data. Experiments are suggested that could test our theory further.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XPQ68J7X\\Bienenstock, Cooper, Munro - 1982 - Theory for the development of neuron selectivity orientation specificity and binocular interaction i.pdf},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  keywords = {Animals,Cats,Cerebral,Dominance,Mathematics,Models,Neurological,Neurons,Orientation,physiology,Retina,Sensory Deprivation,Synapses,Visual Cortex,Visual Pathways,Visual Perception},
  number = {1},
  pmid = {7054394}
}

@article{bigdely-shamlo_robbins_2015,
  title = {The {{PREP}} Pipeline: Standardized Preprocessing for Large-Scale {{EEG}} Analysis},
  author = {{Bigdely-Shamlo}, Nima and Mullen, Tim and Kothe, Christian and Su, Kyung-Min and Robbins, Kay A.},
  year = {2015},
  volume = {9},
  pages = {1--20},
  issn = {1662-5196},
  doi = {10.3389/fninf.2015.00016},
  abstract = {The technology to collect brain imaging and physiological measures has become portable and ubiquitous, opening the possibility of large-scale analysis of real-world human imaging. By its nature, such data is large and complex, making automated processing essential. This paper shows how lack of attention to the very early stages of an EEG preprocessing pipeline can reduce the signal-to-noise ratio and introduce unwanted artifacts into the data, particularly for computations done in single precision. We demonstrate that ordinary average referencing improves the signal-to-noise ratio, but that noisy channels can contaminate the results. We also show that identification of noisy channels depends on the reference and examine the complex interaction of filtering, noisy channel identification, and referencing. We introduce a multi-stage robust referencing scheme to deal with the noisy channel-reference interaction. We propose a standardized early-stage EEG processing pipeline (PREP) and discuss the application of the pipeline to more than 600 EEG datasets. The pipeline includes an automatically generated report for each dataset processed. Users can download the PREP pipeline as a freely available MATLAB library from http://eegstudy.org/prepcode.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9GGI9P24\\Bigdely-Shamlo et al. - 2015 - The PREP pipeline standardized preprocessing for large-scale EEG analysis.pdf},
  journal = {Frontiers in Neuroinformatics},
  keywords = {artifact,bcilab,BCILAB,big data,eeg,eeglab,EEGLAB,mach,machine learning,preprocessing},
  number = {June},
  pmid = {26150785}
}

@article{bing_huang_2020,
  title = {Indirect and Direct Training of Spiking Neural Networks for End-to-End Control of a Lane-Keeping Vehicle},
  author = {Bing, Zhenshan and Meschede, Claus and Chen, Guang and Knoll, Alois and Huang, Kai},
  year = {2020},
  month = jan,
  volume = {121},
  pages = {21--36},
  issn = {08936080},
  doi = {10.1016/j.neunet.2019.05.019},
  abstract = {Building spiking neural networks (SNNs) based on biological synaptic plasticities holds a promising potential for accomplishing fast and energy-efficient computing, which is beneficial to mobile robotic applications. However, the implementations of SNNs in robotic fields are limited due to the lack of practical training methods. In this paper, we therefore introduce both indirect and direct end-to-end training methods of SNNs for a lane-keeping vehicle. First, we adopt a policy learned using the Deep Q-Learning (DQN) algorithm and then subsequently transfer it to an SNN using supervised learning. Second, we adopt the reward-modulated spike-timing-dependent plasticity (R-STDP) for training SNNs directly, since it combines the advantages of both reinforcement learning and the well-known spiketiming-dependent plasticity (STDP). We examine the proposed approaches in three scenarios in which a robot is controlled to keep within lane markings by using an event-based neuromorphic vision sensor. We further demonstrate the advantages of the R-STDP approach in terms of the lateral localization accuracy and training time steps by comparing them with other three algorithms presented in this paper.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SYK73MVG\\Bing et al. - 2020 - Indirect and direct training of spiking neural net.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\VVQII58B\\Bing et al. - 2020 - Indirect and direct training of spiking neural net.pdf},
  journal = {Neural Networks},
  language = {en}
}

@article{biology_biology_1983,
  title = {Units {{Estimated By Oblique Masking}} *},
  author = {Biology, Theoretical},
  year = {1983},
  volume = {23},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MFMANE6P\\Biology - 1983 - Units Estimated By Oblique Masking.pdf}
}

@book{bishop_bishop_2013,
  title = {Pattern {{Recognition}} and {{Machine Learning}}},
  author = {Bishop, Christopher M},
  year = {2013},
  volume = {53},
  doi = {10.1117/1.2819119},
  abstract = {The dramatic growth in practical applications for machine learning over the last ten years has been accompanied by many important developments in the underlying algorithms and techniques. For example, Bayesian methods have grown from a specialist niche to become mainstream, while graphical models have emerged as a general framework for describing and applying probabilistic techniques. The practical applicability of Bayesian methods has been greatly enhanced by the development of a range of approximate inference algorithms such as variational Bayes and expectation propagation, while new models based on kernels have had a significant impact on both algorithms and applications. This completely new textbook reflects these recent developments while providing a comprehensive introduction to the fields of pattern recognition and machine learning. It is aimed at advanced undergraduates or first-year PhD students, as well as researchers and practitioners. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory. The book is suitable for courses on machine learning, statistics, computer science, signal processing, computer vision, data mining, and bioinformatics. Extensive support is provided for course instructors, including more than 400 exercises, graded according to difficulty. Example solutions for a subset of the exercises are available from the book web site, while solutions for the remainder can be obtained by instructors from the publisher. The book is supported by a great deal of additional material, and the reader is encouraged to visit the book web site for the latest information. Christopher M. Bishop is Deputy Director of Microsoft Research Cambridge, and holds a Chair in Computer Science at the University of Edinburgh. He is a Fellow of Darwin College Cambridge, a Fellow of the Royal Academy of Engineering, and a Fellow of the Royal Society of Edinburgh. His previous textbook "Neural Networks for Pattern Recognition" has been widely adopted.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HJ7LQ5Q7\\Bishop - 2013 - Pattern Recognition and Machine Learning.pdf},
  isbn = {978-0-387-31073-2},
  pmid = {25246403}
}

@article{bittner_magee_2015,
  title = {Conjunctive Input Processing Drives Feature Selectivity in Hippocampal {{CA1}} Neurons},
  author = {Bittner, Katie C and Grienberger, Christine and Vaidya, Sachin P and Milstein, Aaron D and Macklin, John J and Suh, Junghyup and Tonegawa, Susumu and Magee, Jeffrey C},
  year = {2015},
  volume = {18},
  pages = {1--13},
  issn = {1097-6256},
  doi = {10.1038/nn.4062},
  abstract = {Feature-selective firing allows networks to produce representations of the external and internal environments. Despite its importance, the mechanisms generating neuronal feature selectivity are incompletely understood. In many cortical microcircuits the integration of two functionally distinct inputs occurs nonlinearly through generation of active dendritic signals that drive burst firing and robust plasticity. To examine the role of this processing in feature selectivity, we recorded CA1 pyramidal neuron membrane potential and local field potential in mice running on a linear treadmill. We found that dendritic plateau potentials were produced by an interaction between properly timed input from entorhinal cortex and hippocampal CA3. These conjunctive signals positively modulated the firing of previously established place fields and rapidly induced new place field formation to produce feature selectivity in CA1 that is a function of both entorhinal cortex and CA3 input. Such selectivity could allow mixed network level representations that support context-dependent spatial maps.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3HH43WW8\\Bittner et al. - 2015 - Conjunctive input processing drives feature select.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\LQ772QI9\\Bittner et al. - 2015 - Conjunctive input processing drives feature selectivity in hippocampal CA1 neurons.pdf},
  journal = {Nature Neuroscience},
  number = {July},
  pmid = {26167906}
}

@article{bittner_magee_2017,
  title = {Behavioral Time Scale Synaptic Plasticity Underlies {{CA1}} Place Fields},
  author = {Bittner, Katie C. and Milstein, Aaron D. and Grienberger, Christine and Romani, Sandro and Magee, Jeffrey C.},
  year = {2017},
  month = sep,
  volume = {357},
  pages = {1033--1036},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aan3846},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\92KUIB8A\\Bittner et al. - 2017 - Behavioral time scale synaptic plasticity underlie.pdf},
  journal = {Science},
  language = {en},
  number = {6355}
}

@article{blair_cong_2014,
  title = {Oscillatory Neurocomputing with Ring Attractors: A Network Architecture for Mapping Locations in Space onto Patterns of Neural Synchrony},
  author = {Blair, HT and Wu, Allan and Cong, Jason},
  year = {2014},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7ZUHN7Z7\\Blair, Wu, Cong - 2014 - Oscillatory neurocomputing with ring attractors a network architecture for mapping locations in space onto patt.pdf},
  journal = {Transactions of the Royal Society B:},
  keywords = {computational biology,neuroscience}
}

@article{blakemore_campbell_1969,
  title = {By {{C}}. {{BLAKEMORE AND F}}. {{W}}. {{CAMPBELL From}} The},
  author = {Blakemore, By C and Campbell, F W},
  year = {1969},
  pages = {237--260},
  issn = {00223751},
  doi = {10.1113/jphysiol.1969.sp008862},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DXWPS5UH\\Blakemore, Campbell - 1969 - By C. BLAKEMORE AND F. W. CAMPBELL From the.pdf},
  journal = {October}
}

@article{blanchard_hayden_2017,
  title = {Robust Mixture Modeling Reveals Category-Free Selectivity in Reward Region Neuronal Ensembles},
  author = {Blanchard, Tommy C and Piantadosi, Steve and Hayden, Benjamin Y},
  year = {2017},
  volume = {119},
  pages = {jn.00808.2017},
  issn = {0022-3077},
  doi = {10.1152/jn.00808.2017},
  abstract = {Classification of neurons into clusters based on their response properties is an important tool for gaining insight into neural computations. However, it remains unclear to what extent neurons fall naturally into discrete functional categories. We developed a Bayesian method that models the tuning properties of neural populations as a mixture of multiple types of task-relevant response patterns. We applied this method to data from several cortical and striatal regions in economic choice tasks. In all cases, neurons fell into only two clusters: one multiple selectivity cluster containing all cells driven by task variables of interest and another of no selectivity for those variables. The single cluster of task-sensitive cells argues against robust categorical tuning in these areas. The no selectivity cluster was unanticipated and raises important questions about what distinguishes these neurons and what role they play. Moreover, the ability to formally identify these non-selective cells allows for more accurate measurement of ensemble effects by excluding or appropriately down-weighting them in analysis. Our findings provide a valuable tool for analysis of neural data, challenge simple categorization schemes previously proposed for these regions, and place useful constraints on neurocomputational models of economic choice and control.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UCCC3LIA\\Blanchard, Piantadosi, Hayden - 2018 - Robust mixture modeling reveals category-free selectivity in reward region neuronal ensembles.pdf},
  journal = {Journal of Neurophysiology},
  pmid = {29212924}
}

@article{blanchard_scheirer_2018,
  title = {A {{Neurobiological Cross}}-Domain {{Evaluation Metric}} for {{Predictive Coding Networks}}},
  author = {Blanchard, Nathaniel and Kinnison, Jeffery and Richardwebster, Brandon and Bashivan, Pouya and Scheirer, Walter J},
  year = {2018},
  abstract = {Achieving a good measure of model generalization remains a challenge within ma-chine learning. One of the highest-performing learning models is the biological brain, which has unparalleled generalization capabilities. In this work, we propose and evaluate a human-model similarity metric for determining model correspon-dence to the human brain, as inspired by representational similarity analysis. We evaluate this metric on unsupervised predictive coding networks. These models are designed to mimic the phenomenon of residual error propagation in the visual cortex, implying their potential for biological fidelity. The human-model similar-ity metric is calculated by measuring the similarity between human brain fMRI activations and predictive coding network activations over a shared set of stimuli. In order to study our metric in relation to standard performance evaluations on cross-domain tasks, we train a multitude of predictive coding models across var-ious conditions. Each unsupervised model is trained on next frame prediction in video and evaluated using three metrics: 1) mean squared error of next frame pre-diction, 2) object matching accuracy, and 3) our human-model similarity metric. Through this evaluation, we show that models with higher human-model similarity are more likely to generalize to cross-domain tasks. We also show that our metric facilitates a substantial decrease in model search time because the similarity met-ric stabilizes quickly \textemdash{} in as few as 10 epochs. We propose that this metric could be deployed in model search to quickly identify and eliminate weaker models.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DBLSEC7G\\Blanchard et al. - 2018 - A Neurobiological Cross-domain Evaluation Metric for Predictive Coding Networks.pdf}
}

@article{blinowska_janiszewska_2010,
  title = {Transmission of {{Brain Activity During Cognitive Task}}},
  author = {Blinowska, Katarzyna and Kus, Rafal and Kaminski, Maciej and Janiszewska, Joanna},
  year = {2010},
  month = jun,
  volume = {23},
  pages = {205--213},
  issn = {0896-0267, 1573-6792},
  doi = {10.1007/s10548-010-0137-y},
  abstract = {The transmission of brain activity during constant attention test was estimated by means of the shorttime directed transfer function (SDTF). SDTF is an estimator based on a multivariate autoregressive model. It determines the propagation as a function of time and frequency. For nine healthy subjects the transmission of EEG activity was determined for target and non-target conditions corresponding to pressing of a switch in case of appearance of two identical images or withholding the reaction in case of different images. The involvement of prefrontal and frontal cortex manifested by the propagation from these structures was observed, especially in the early stages of the task. For the target condition there was a burst of propagation from C3 after pressing the switch, which can be interpreted as beta rebound upon completion of motor action. In case of non-target condition the propagation from F8 or Fz to C3 was observed, which can be connected with the active inhibition of motor cortex by right inferior frontal cortex or presupplementary motor area.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\N8P7EV3U\\Blinowska et al. - 2010 - Transmission of Brain Activity During Cognitive Ta.pdf},
  journal = {Brain Topography},
  language = {en},
  number = {2}
}

@article{blinowska_kaminski_2013,
  title = {Application of Directed Transfer Function and Network Formalism for the Assessment of Functional Connectivity in Working Memory Task.},
  author = {Blinowska, Katarzyna J and Kami{\'n}ski, Maciej and Brzezicka, Aneta and Kami{\'n}ski, Jan},
  year = {2013},
  volume = {371},
  pages = {20110614},
  issn = {1364-503X},
  doi = {10.1098/rsta.2011.0614},
  abstract = {The dynamic pattern of functional connectivity during a working memory task was investigated by means of the short-time directed transfer function. A clear-cut picture of transmissions was observed with the main centres of propagation located in the frontal and parietal regions, in agreement with imaging studies and neurophysiological hypotheses concerning the mechanisms of working memory. The study of the time evolution revealed that most of the time short-range interactions prevailed, whereas the communication between the main centres of activity occurred more sparsely and changed dynamically in time. The patterns of connectivity were quantified by means of a network formalism based on assortative mixing\textendash an approach novel in the field of brain networks study. By means of application of the above method, we have demonstrated the existence of a modular structure of brain networks. The strength of interaction inside the modules was higher than between modules. The obtained results are compatible with theories concerning metabolic energy saving and efficient wiring in the brain, which showed that preferred organization includes modular structure with dense connectivity inside the modules and more sparse connections between the modules. The presented detailed temporal and spatial patterns of propagation are in line with the neurophysiological hypotheses concerning the role of gamma and theta activity in information processing during a working memory task.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8FMBDF6I\\Blinowska et al. - 2013 - Application of directed transfer function and netw.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\AVVQD6JW\\Blinowska et al. - 2013 - Application of directed transfer function and network formalism for the assessment of functional connectivity.pdf},
  journal = {Philosophical transactions. Series A, Mathematical, physical, and engineering sciences},
  keywords = {Animals,Brain,Brain Mapping,Brain Mapping: methods,Brain: physiology,Computer Simulation,Connectome,Connectome: methods,Electroencephalography,Electroencephalography: methods,Humans,Memory,Models,Nerve Net,Nerve Net: physiology,Neurological,Short-Term,Short-Term: physiology,Synaptic Transmission,Synaptic Transmission: physiology},
  pmid = {23858482}
}

@article{blouw_eliasmith_1905,
  title = {A Neurally Plausible Encoding of Word Order Information into a Semantic Vector Space},
  author = {Blouw, Peter and Eliasmith, Chris},
  year = {1905},
  pages = {1905--1910},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YEKG2YTK\\Blouw, Eliasmith - 1905 - A neurally plausible encoding of word order information into a semantic vector space.pdf},
  journal = {35th Annual Conference of the Cognitive \textbackslash ldots},
  keywords = {convolution,distributional semantics,permutation,random,semantic memory,vector space models}
}

@article{blouw_eliasmith_2015,
  title = {Concepts as {{Semantic Pointers}}: {{A Framework}} and {{Computational Model}}},
  author = {Blouw, Peter and Solodkin, Eugene and Thagard, Paul and Eliasmith, Chris},
  year = {2015},
  pages = {n/a--n/a},
  issn = {03640213},
  doi = {10.1111/cogs.12265},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GPI2XZAS\\Blouw et al. - 2015 - Concepts as Semantic Pointers A Framework and Computational Model.pdf},
  journal = {Cognitive Science},
  keywords = {categorization,computational modeling,concepts,mental representation,neural computation,semantics}
}

@article{blumenfeld_desposito_2014,
  title = {The Effects of Lateral Prefrontal Transcranial Magnetic Stimulation on Item Memory Encoding},
  author = {Blumenfeld, Robert S. and Lee, Taraz G. and D'Esposito, Mark},
  year = {2014},
  volume = {53},
  pages = {197--202},
  issn = {00283932},
  doi = {10.1016/j.neuropsychologia.2013.11.021},
  abstract = {Previous neuroimaging research has established that the left ventrolateral prefrontal cortex (VLPFC) is involved in long-term memory (LTM) encoding for individual items. Dorsolateral prefrontal cortex (DLPFC) is implicated less frequently, and one theory that has gained support to explain this discrepancy is that DLPFC is involved in forming item-item relational but not item LTM. Given that neuroimaging results are correlational, complimentary methods such as repetitive transcranial magnetic stimulation (TMS) have been used to test causal hypotheses generated from imaging data. Most TMS studies of LTM encoding have found that disruption of lateral PFC activity impairs subsequent memory. However these studies have lacked methods to precisely localize and directly compare TMS effects from frontal subregions implicated by the neuroimaging literature. Here, we target specific subregions of lateral PFC with TMS to test the prediction from the item/relational framework that temporary disruption of VLPFC during encoding will impair subsequent memory whereas TMS to DLPFC during item encoding will not. Frontal TMS was administered prior to a LTM encoding task in which participants were presented with a list of individual nouns and asked to judge whether each noun was concrete or abstract. After a 40. min delay period, item recognition memory was tested. Results indicate that VLPFC and DLPFC TMS have differential effects on subsequent item memory. VLPFC TMS reliably disrupted subsequent item memory whereas DLPFC TMS led to numerical enhancement in item memory, relative to TMS to a control region. \textcopyright{} 2013 Elsevier Ltd.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PT4ZVHQG\\Blumenfeld, Lee, D'Esposito - 2014 - The effects of lateral prefrontal transcranial magnetic stimulation on item memory encoding.pdf},
  journal = {Neuropsychologia},
  keywords = {Brain stimulation,Cognitive control,DLPFC,Memory,TMS,VLPFC},
  number = {1},
  pmid = {24316198}
}

@article{blumenfeld_ranganath_2011,
  title = {Putting the {{Pieces Together}}: {{The Role}} of {{Dorsolateral Prefrontal Cortex}} in {{Relational Memory Encoding}}},
  shorttitle = {Putting the {{Pieces Together}}},
  author = {Blumenfeld, Robert S. and Parks, Colleen M. and Yonelinas, Andrew P. and Ranganath, Charan},
  year = {2011},
  month = jan,
  volume = {23},
  pages = {257--265},
  issn = {0898-929X, 1530-8898},
  doi = {10.1162/jocn.2010.21459},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6UBC6A5Q\\Blumenfeld et al. - 2011 - Putting the Pieces Together The Role of Dorsolate.pdf},
  journal = {Journal of Cognitive Neuroscience},
  language = {en},
  number = {1}
}

@article{bobadilla-suarez_love_2019,
  title = {Measures of {{Neural Similarity}}},
  author = {{Bobadilla-Suarez}, S. and Ahlheim, C. and Mehrotra, A. and Panos, A. and Love, B. C.},
  year = {2019},
  month = dec,
  issn = {2522-0861, 2522-087X},
  doi = {10.1007/s42113-019-00068-5},
  abstract = {One fundamental question is what makes two brain states similar. For example, what makes the activity in visual cortex elicited from viewing a robin similar to a sparrow? One common assumption in fMRI analysis is that neural similarity is described by Pearson correlation. However, there are a host of other possibilities, including Minkowski and Mahalanobis measures, with each differing in its mathematical, theoretical, and neural computational assumptions. Moreover, the operable measures may vary across brain regions and tasks. Here, we evaluated which of several competing similarity measures best captured neural similarity. Our technique uses a decoding approach to assess the information present in a brain region, and the similarity measures that best correspond to the classifier's confusion matrix are preferred. Across two published fMRI datasets, we found the preferred neural similarity measures were common across brain regions but differed across tasks. Moreover, Pearson correlation was consistently surpassed by alternatives.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2IH7UW8B\\Bobadilla-Suarez et al. - 2019 - Measures of Neural Similarity.pdf},
  journal = {Computational Brain \& Behavior},
  language = {en}
}

@article{bobadilla-suarez_love_2019a,
  title = {Measures of Neural Similarity},
  author = {{Bobadilla-Suarez}, Sebastian and Ahlheim, Christiane and Mehrotra, Abhinav and Panos, Aristeidis and Love, Bradley C.},
  year = {2019},
  month = feb,
  doi = {10.1101/439893},
  abstract = {One fundamental question is what makes two brain states similar. For example, what makes the activity in visual cortex elicited from viewing a robin similar to a sparrow? One common assumption in fMRI analysis is that neural similarity is described by Pearson correlation. However, there are a host of other possibilities, including Minkowski and Mahalanobis measures, with each differing in its mathematical, theoretical, neural computational assumptions. Moreover, the operable measures may vary across brain regions and tasks. Here, we evaluated which of several competing similarity measures best captured neural similarity. Our technique uses a decoding approach to assess the information present in a brain region and the similarity measures that best correspond to the classifier's confusion matrix are preferred. Across two published fMRI datasets, we found the preferred neural similarity measures were common across brain regions, but differed across tasks. Moreover, Pearson correlation was consistently surpassed by alternatives.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4LK9C7PI\\Bobadilla-Suarez et al. - 2019 - Measures of neural similarity.pdf},
  journal = {bioRxiv},
  language = {en}
}

@phdthesis{bocincova_bocincova_2019,
  title = {Assessing the {{Neural Correlates}}, {{Sources}} and {{Consequences}} of the {{Attentional Rhythm}}},
  author = {Bocincova, Andrea},
  year = {2019},
  address = {{United States -- North Dakota}},
  abstract = {Evidence suggests that even when sustained at a single location, spatial attention waxes and wanes over time. These fluctuations are cyclic, lasting about 125-200 ms (i.e., \textasciitilde 4-8 Hz), and are characterized by alternating periods of focused attention to a single location together with exploratory periods during which attention is prone to switching to a new source of stimulation. Despite an increasing interest in this temporal property of spatial attention, multiple aspects of rhythmic attentional sampling remain to be explored. In this dissertation, I introduce and examine three unexplored areas related to this topic. The first area, addressed in Experiment 1, concerns the potential neural oscillatory signatures of attentional rhythmicity. Precisely, it assesses the role of a well-established oscillatory correlate of selective attention, alpha band power, in rhythmic switching of attention over time. The second area focuses on the neural sources controlling rhythmic attentional sampling. More specifically, the goal of Experiment 2 is to establish causal evidence for the involvement of an important attentional hub in generating the attentional rhythm using transcranial magnetic stimulation. Finally, the last area examines the consequences of attentional rhythmicity on the encoding and storage of information in working memory. In particular, Experiment 3 provides evidence that rhythmic changes in spatial attention affect the quality with which information is encoded into working memory. Finally, Experiment 4 assesses whether attention rhythmically cycles between items stored in WM in a manner similar to the cycling observed when attention is directed to the external world. In summary, the work included in this dissertation makes an important contribution to extending our understating of the attentional rhythm and introduces multiple avenues for further research necessary in this area.},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\84F7N382\\bocincova_2019_assessing_the_neural_correlates,_sources_and_consequences_of_the_attentional.pdf},
  language = {English},
  school = {North Dakota State University},
  type = {Ph.{{D}}.}
}

@article{boergers_kopell_2008,
  title = {Gamma Oscillations and Stimulus Selection},
  author = {Boergers, Christoph and Kopell, Nancy J},
  year = {2008},
  volume = {20},
  pages = {383--414},
  issn = {0899-7667},
  doi = {10.1162/neco.2007.07-06-289},
  abstract = {More coherent excitatory stimuli are known to have a competitive advantage over less coherent ones. We show here that this advantage is amplified greatly when the target includes inhibitory interneurons acting via GABA(A)-receptor-mediated synapses and the coherent input oscillates at gamma frequency. We hypothesize that therein lies, at least in part, the functional significance of the experimentally observed link between attentional biasing of stimulus competition and gamma frequency rhythmicity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LNSQ3DVE\\Boergers, Kopell - 2008 - Gamma oscillations and stimulus selection.pdf},
  journal = {Neural Computation},
  number = {2},
  pmid = {18047409}
}

@article{boerlin_deneve_2013,
  title = {Predictive {{Coding}} of {{Dynamical Variables}} in {{Balanced Spiking Networks}}},
  author = {Boerlin, Martin and Machens, Christian K. and Den{\`e}ve, Sophie},
  editor = {Sporns, Olaf},
  year = {2013},
  month = nov,
  volume = {9},
  pages = {e1003258},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1003258},
  abstract = {Two observations about the cortex have puzzled neuroscientists for a long time. First, neural responses are highly variable. Second, the level of excitation and inhibition received by each neuron is tightly balanced at all times. Here, we demonstrate that both properties are necessary consequences of neural networks that represent information efficiently in their spikes. We illustrate this insight with spiking networks that represent dynamical variables. Our approach is based on two assumptions: We assume that information about dynamical variables can be read out linearly from neural spike trains, and we assume that neurons only fire a spike if that improves the representation of the dynamical variables. Based on these assumptions, we derive a network of leaky integrate-and-fire neurons that is able to implement arbitrary linear dynamical systems. We show that the membrane voltage of the neurons is equivalent to a prediction error about a common population-level signal. Among other things, our approach allows us to construct an integrator network of spiking neurons that is robust against many perturbations. Most importantly, neural variability in our networks cannot be equated to noise. Despite exhibiting the same single unit properties as widely used population code models (e.g. tuning curves, Poisson distributed spike trains), balanced networks are orders of magnitudes more reliable. Our approach suggests that spikes do matter when considering how the brain computes, and that the reliability of cortical representations could have been strongly underestimated.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MBXWQWK8\\Boerlin et al. - 2013 - Predictive Coding of Dynamical Variables in Balanc.PDF},
  journal = {PLoS Computational Biology},
  language = {en},
  number = {11}
}

@article{bogaard_booth_2009,
  title = {Interaction of Cellular and Network Mechanisms in Spatiotemporal Pattern Formation in Neuronal Networks.},
  author = {Bogaard, Andrew and Parent, Jack and Zochowski, Michal and Booth, Victoria},
  year = {2009},
  month = feb,
  volume = {29},
  pages = {1677--87},
  issn = {1529-2401},
  doi = {10.1523/JNEUROSCI.5218-08.2009},
  abstract = {Spatiotemporal patterning of neuronal activity is considered to be an important feature of cognitive processing in the brain as well as pathological brain states, such as seizures. Here, we investigate complex interactions between intrinsic properties of neurons and network structure in the generation of network spatiotemporal patterning in the context of seizure-like synchrony. We show that membrane excitability properties have differential effects on network activity patterning for different network topologies. We consider excitatory networks consisting of neurons with excitability properties varying between type I and type II that exhibit significantly different spike frequency responses to external current stimulation, especially at firing threshold. We find that networks with type II-like neurons show higher synchronization and bursting capacity across a range of network topologies than corresponding networks with type I-like neurons. These differences in activity patterning are persistent across different network sizes, connectivity strengths, magnitudes of random external input, and the addition of inhibitory interneurons to the network, making them highly likely to be relevant to brain function. Furthermore, we show that heterogeneous networks of mixed cell types show emergent dynamical patterns even for very low mixing ratios. Specifically, the addition of a small percentage of type II-like cells into a network of type I-like cells can markedly change the patterning of network activity. These findings suggest that cellular as well as network mechanisms can go hand in hand, leading to the generation of seizure-like discharges, suggesting that a single ictogenic mechanism alone may not be responsible for seizure generation.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LUVE7FVF\\Bogaard et al. - 2009 - Interaction of cellular and network mechanisms in spatiotemporal pattern formation in neuronal networks.pdf},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  keywords = {Animals,Interneurons,Interneurons: cytology,Interneurons: physiology,Models,Nerve Net,Nerve Net: cytology,Nerve Net: physiology,Neurological,Neurons,Neurons: cytology,Neurons: physiology,Time Factors},
  number = {6},
  pmid = {19211875}
}

@article{bogacz_bogacz_2017,
  title = {Theory of Reinforcement Learning and Motivation in the Basal Ganglia},
  author = {Bogacz, Rafal},
  year = {2017},
  month = aug,
  doi = {10.1101/174524},
  abstract = {This paper proposes how the neural circuits in vertebrates select actions on the basis of past experience and the current motivational state. According to the presented theory, the basal ganglia evaluate the utility of considered actions by combining the positive consequences (e.g. nutrition) scaled by the motivational state (e.g. hunger) with the negative consequences (e.g. effort). The theory suggests how the basal ganglia compute utility by combining the positive and negative consequences encoded in the synaptic weights of striatal Go and No-Go neurons, and the motivational state carried by neuromodulators including dopamine. Furthermore, the theory suggests how the striatal neurons to learn separately about consequences of actions, and how the dopaminergic neurons themselves learn what level of activity they need to produce to optimize behaviour. The theory accounts for the effects of dopaminergic modulation on behaviour, patterns of synaptic plasticity in striatum, and responses of dopaminergic neurons in diverse situations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BLPLS6VX\\Bogacz - 2017 - Theory of reinforcement learning and motivation in.pdf},
  journal = {bioRxiv},
  language = {en}
}

@article{bogacz_bogacz_2017a,
  title = {A Tutorial on the Free-Energy Framework for Modelling Perception and Learning},
  author = {Bogacz, Rafal},
  year = {2017},
  volume = {76},
  pages = {198--211},
  issn = {10960880},
  doi = {10.1016/j.jmp.2015.11.003},
  abstract = {This paper provides an easy to follow tutorial on the free-energy framework for modelling perception developed by Friston, which extends the predictive coding model of Rao and Ballard. These models assume that the sensory cortex infers the most likely values of attributes or features of sensory stimuli from the noisy inputs encoding the stimuli. Remarkably, these models describe how this inference could be implemented in a network of very simple computational elements, suggesting that this inference could be performed by biological networks of neurons. Furthermore, learning about the parameters describing the features and their uncertainty is implemented in these models by simple rules of synaptic plasticity based on Hebbian learning. This tutorial introduces the free-energy framework using very simple examples, and provides step-by-step derivations of the model. It also discusses in more detail how the model could be implemented in biological neural circuits. In particular, it presents an extended version of the model in which the neurons only sum their inputs, and synaptic plasticity only depends on activity of pre-synaptic and post-synaptic neurons.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RF9AK2NU\\Bogacz - 2017 - A tutorial on the free-energy framework for modelling perception and learning.pdf},
  journal = {Journal of Mathematical Psychology},
  pmid = {28298703}
}

@article{bogacz_cohen_2006,
  title = {The Physics of Optimal Decision Making: {{A}} Formal Analysis of Models of Performance in Two-Alternative Forced-Choice Tasks.},
  author = {Bogacz, Rafal and Brown, Eric and Moehlis, Jeff and Holmes, Philip and Cohen, Jonathan D},
  year = {2006},
  volume = {113},
  pages = {700--765},
  issn = {1939-1471},
  doi = {10.1037/0033-295X.113.4.700},
  abstract = {In this article, the authors consider optimal decision making in two-alternative forced-choice (TAFC) tasks. They begin by analyzing 6 models of TAFC decision making and show that all but one can be reduced to the drift diffusion model, implementing the statistically optimal algorithm (most accurate for a given speed or fastest for a given accuracy). They prove further that there is always an optimal trade-off between speed and accuracy that maximizes various reward functions, including reward rate (percentage of correct responses per unit time), as well as several other objective functions, including ones weighted for accuracy. They use these findings to address empirical data and make novel predictions about performance under optimality.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QPB6WP2G\\Bogacz et al. - 2006 - The physics of optimal decision making A formal analysis of models of performance in two-alternative forced-choic.pdf},
  journal = {Psychological Review},
  keywords = {drift diffusion model,optimal performance,perceptual choice,reward rate,speed–accuracy trade-off},
  number = {4},
  pmid = {17014301}
}

@article{bonnefond_jensen_2015,
  title = {Gamma Activity Coupled to Alpha Phase as a Mechanism for Top-down Controlled Gating},
  author = {Bonnefond, Mathilde and Jensen, Ole},
  year = {2015},
  volume = {10},
  pages = {1--11},
  issn = {19326203},
  doi = {10.1371/journal.pone.0128667},
  abstract = {Coupling between neural oscillations in different frequency bands has been proposed to co- ordinate neural processing. In particular, gamma power coupled to alpha phase is proposed to reflect gating of information in the visual system but the existence of such a mechanism remains untested. Here, we recorded ongoing brain activity using magnetoencephalogra- phy in subjects who performed a modified Sternberg working memory task in which distrac- tors were presented in the retention interval. During the anticipatory pre-distractor period, we show that the phase of alpha oscillations was coupled with the power of high (80-120Hz) gamma band activity, i.e. gamma power consistently was lower at the trough than at the peak of the alpha cycle (9-12Hz). We further show that high alpha power was associated with weaker gamma power at the trough of the alpha cycle. This result is in line with alpha activity in sensory region implementing a mechanism of pulsed inhibition silencing neuronal firing every {$\sim$}100 ms.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\M8G3I58V\\Bonnefond, Jensen - 2015 - Gamma activity coupled to alpha phase as a mechanism for top-down controlled gating.pdf},
  journal = {PLoS ONE},
  number = {6},
  pmid = {26039691}
}

@article{bonnefond_jensen_2017,
  title = {Communication between {{Brain Areas Based}} on {{Nested Oscillations}}},
  author = {Bonnefond, Mathilde and Kastner, Sabine and Jensen, Ole},
  year = {2017},
  doi = {10.1523/ENEURO.0153-16.2017},
  abstract = {Unraveling how brain regions communicate is crucial for understanding how the brain processes external and internal information. Neuronal oscillations within and across brain regions have been proposed to play a crucial role in this process. Two main hypotheses have been suggested for routing of information based on oscillations, namely communication through coherence and gating by inhibition. Here, we propose a framework unifying these two hypotheses that is based on recent empirical findings. We discuss a theory in which communication between two regions is established by phase synchronization of oscillations at lower frequencies (Ͻ25 Hz), which serve as temporal reference frame for information carried by high-frequency activity (Ͼ40 Hz). Our framework, consistent with numerous recent empirical findings, posits that cross-frequency interactions are essential for understanding how large-scale cognitive and perceptual networks operate.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JQ4DJ66S\\Bonnefond, Kastner, Jensen - Unknown - Communication between Brain Areas Based on Nested Oscillations.pdf},
  keywords = {alpha,brain communication,cross-frequency coupling,gamma,slow oscillations,theta}
}

@article{bonner_epstein_2018,
  title = {Computational Mechanisms Underlying Cortical Responses to the Affordance Properties of Visual Scenes},
  author = {Bonner, Michael F and Epstein, Russell A},
  year = {2018},
  pages = {doi: https://doi.org/10.1101/177329},
  issn = {1553-7358},
  doi = {10.1101/177329},
  abstract = {Biologically inspired deep convolutional neural networks (CNNs), trained for computer vision tasks, have been found to predict cortical responses with remarkable accuracy. However, the complex internal operations of these models remain poorly understood, and the factors that account for their success are unknown. Here we developed a set of techniques for using CNNs to gain insights into the computational mechanisms underlying cortical responses. We focused on responses in the occipital place area (OPA), a scene-selective region of dorsal occipitoparietal cortex. In a previous study, we showed that fMRI activation patterns in the OPA contain information about the navigational affordances of scenes: that is, information about where one can and cannot move within the immediate environment. We hypothesized that this affordance information could be extracted using a set of purely feedforward computations. To test this idea, we examined a deep CNN with a feedforward architecture that had been previously trained for scene classification. We found that the CNN was highly predictive of OPA representations, and, importantly, that it accounted for the portion of OPA variance that reflected the navigational affordances of scenes. The CNN could thus serve as an image-computable candidate model of affordance-related responses in the OPA. We then ran a series of in silico experiments on this model to gain insights into its internal computations. These analyses showed that the computation of affordance-related features relied heavily on visual information at high-spatial frequencies and cardinal orientations, both of which have previously been identified as low-level stimulus preferences of scene-selective visual cortex. These computations also exhibited a strong preference for information in the lower visual field, which is consistent with known retinotopic biases in the OPA. Visualizations of feature selectivity within the CNN suggested that affordance-based responses encoded features that define the layout of the spatial environment, such as boundary-defining junctions and large extended surfaces. Together, these results map the sensory functions of the OPA onto a fully quantitative model that provides insights into its visual computations. More broadly, they advance integrative techniques for understanding visual cortex across multiple level of analysis: from the identification of cortical sensory functions to the modeling of their underlying algorithmic implementations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7S2IDSUX\\Bonner, Epstein - 2018 - Computational mechanisms underlying cortical responses to the affordance properties of visual scenes.pdf},
  journal = {PLoS Computational Biology},
  keywords = {visual computation of scene}
}

@article{bonnevie_moser_2013,
  title = {Grid Cells Require Excitatory Drive from the Hippocampus.},
  author = {Bonnevie, Tora and Dunn, Benjamin and Fyhn, Marianne and Hafting, Torkel and Derdikman, Dori and Kubie, John L and Roudi, Yasser and Moser, Edvard I and Moser, May-Britt},
  year = {2013},
  month = mar,
  volume = {16},
  pages = {309--17},
  issn = {1546-1726},
  doi = {10.1038/nn.3311},
  abstract = {To determine how hippocampal backprojections influence spatially periodic firing in grid cells, we recorded neural activity in the medial entorhinal cortex (MEC) of rats after temporary inactivation of the hippocampus. We report two major changes in entorhinal grid cells. First, hippocampal inactivation gradually and selectively extinguished the grid pattern. Second, the same grid cells that lost their grid fields acquired substantial tuning to the direction of the rat's head. This transition in firing properties was contingent on a drop in the average firing rate of the grid cells and could be replicated by the removal of an external excitatory drive in an attractor network model in which grid structure emerges by velocity-dependent translation of activity across a network with inhibitory connections. These results point to excitatory drive from the hippocampus, and possibly other regions, as one prerequisite for the formation and translocation of grid patterns in the MEC.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\V2S84KES\\Bonnevie et al. - 2013 - Grid cells require excitatory drive from the hippocampus.pdf},
  journal = {Nature neuroscience},
  keywords = {Animals,Computer Simulation,GABA-A Receptor Antagonists,GABA-A Receptor Antagonists: pharmacology,Hippocampus,Hippocampus: cytology,Hippocampus: drug effects,Hippocampus: physiology,Long-Evans,Male,Models,muscimol,Nerve Net,Nerve Net: cytology,Nerve Net: drug effects,Nerve Net: physiology,Neurological,Neurons,Neurons: cytology,Neurons: drug effects,Neurons: physiology,Rats},
  number = {3},
  pmid = {23334581}
}

@article{bono_clopath_2017,
  title = {Modeling Somatic and Dendritic Spike Mediated Plasticity at the Single Neuron and Network Level},
  author = {Bono, Jacopo and Clopath, Claudia},
  year = {2017},
  month = dec,
  volume = {8},
  pages = {706},
  issn = {2041-1723},
  doi = {10.1038/s41467-017-00740-z},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7G5TR5TX\\Bono and Clopath - 2017 - Modeling somatic and dendritic spike mediated plas.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\UUZIDUA8\\41467_2017_740_MOESM1_ESM.pdf},
  journal = {Nature Communications},
  language = {en},
  number = {1}
}

@article{borel_paulsen_2013,
  title = {Frequency Dependence of {{CA3}} Spike Phase Response Arising from H-Current Properties.},
  author = {Borel, Melodie and Guadagna, Simone and Jang, Hyun Jae and Kwag, Jeehyun and Paulsen, Ole},
  year = {2013},
  month = jan,
  volume = {7},
  pages = {263},
  issn = {1662-5102},
  doi = {10.3389/fncel.2013.00263},
  abstract = {The phase of firing of hippocampal neurons during theta oscillations encodes spatial information. Moreover, the spike phase response to synaptic inputs in individual cells depends on the expression of the hyperpolarization-activated mixed cation current (I h ), which differs between CA3 and CA1 pyramidal neurons. Here, we compared the phase response of these two cell types, as well as their intrinsic membrane properties. We found that both CA3 and CA1 pyramidal neurons show a voltage sag in response to negative current steps but that this voltage sag is significantly smaller in CA3 cells. Moreover, CA3 pyramidal neurons have less prominent resonance properties compared to CA1 pyramidal neurons. This is consistent with differential expression of I h by the two cell types. Despite their distinct intrinsic membrane properties, both CA3 and CA1 pyramidal neurons displayed bidirectional spike phase control by excitatory conductance inputs during theta oscillations. In particular, excitatory inputs delivered at the descending phase of a dynamic clamp-induced membrane potential oscillation delayed the subsequent spike by nearly 50 mrad. The effect was shown to be mediated by I h and was counteracted by increasing inhibitory conductance driving the membrane potential oscillation. Using our experimental data to feed a computational model, we showed that differences in I h between CA3 and CA1 pyramidal neurons could predict frequency-dependent differences in phase response properties between these cell types. We confirmed experimentally such frequency-dependent spike phase control in CA3 neurons. Therefore, a decrease in theta frequency, which is observed in intact animals during novelty, might switch the CA3 spike phase response from unidirectional to bidirectional and thereby promote encoding of the new context.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Q6KUB27B\\Borel et al. - 2013 - Frequency dependence of CA3 spike phase response arising from h-current properties.pdf},
  journal = {Frontiers in cellular neuroscience},
  pmid = {24399930}
}

@article{born_bradley_2005,
  title = {{{STRUCTURE AND FUNCTION OF VISUAL AREA MT}}},
  author = {Born, Richard T. and Bradley, David C.},
  year = {2005},
  month = jul,
  volume = {28},
  pages = {157--189},
  issn = {0147-006X, 1545-4126},
  doi = {10.1146/annurev.neuro.26.041002.131052},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\A3M2B33M\\Born and Bradley - 2005 - STRUCTURE AND FUNCTION OF VISUAL AREA MT.pdf},
  journal = {Annual Review of Neuroscience},
  language = {en},
  number = {1}
}

@article{borst_anderson_2017,
  title = {A Step-by-Step Tutorial on Using the Cognitive Architecture {{ACT}}-{{R}} in Combination with {{fMRI}} Data},
  author = {Borst, Jelmer P. and Anderson, John R.},
  year = {2017},
  volume = {76},
  pages = {94--103},
  issn = {10960880},
  doi = {10.1016/j.jmp.2016.05.005},
  abstract = {The cognitive architecture ACT-R is at the same time a psychological theory and a modeling framework for constructing cognitive models that adhere to the principles of the theory. ACT-R can be used in combination with fMRI data in two different ways: (1) fMRI data can be used to evaluate and constrain models in ACT-R by means of predefined Region-of-Interest (ROI) analysis, and (2) predictions from ACT-R models can be used to locate neural correlates of model processes and representations by means of model-based fMRI analysis. In this paper we provide a step-by-step tutorial on both approaches. Note that this tutorial neither teaches the ACT-R theory in any detail, nor fMRI analysis, but explains how ACT-R can be used in combination with fMRI data. To this end, we provide all data and computer code necessary to run the ACT-R model, carry out the analyses, and recreate the figures in the paper. As an example dataset we use a relatively simple algebra task. In the first section, we develop an ACT-R model of this task and fit it to behavioral data. In the second section, we apply a predefined ROI-analysis to evaluate the model using fMRI data. In the third section, we use model-based fMRI analysis to locate the following processes in the brain: retrieval of mathematical facts from memory, working memory updates, motor responses, and visually encoding the problems. After working through this tutorial, the reader will have learned what can be achieved with the two different analysis methods and how they are conducted; the example code can then be adapted to a new dataset.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9S37DEZD\\Borst, Anderson - 2017 - A step-by-step tutorial on using the cognitive architecture ACT-R in combination with fMRI data.pdf},
  journal = {Journal of Mathematical Psychology},
  keywords = {Cognitive architecture,fmri,Model-based analysis,Tutorial},
  pmid = {25246403}
}

@article{bourdoukan_deneve_2017,
  title = {Enforcing Balance Allows Local Supervised Learning in Spiking Recurrent Networks},
  author = {Bourdoukan, Ralph and Den{\`e}ve, Sophie},
  year = {2017},
  pages = {9},
  abstract = {To predict sensory inputs or control motor trajectories, the brain must constantly learn temporal dynamics based on error feedback. However, it remains unclear how such supervised learning is implemented in biological neural networks. Learning in recurrent spiking networks is notoriously difficult because local changes in connectivity may have an unpredictable effect on the global dynamics. The most commonly used learning rules, such as temporal back-propagation, are not local and thus not biologically plausible. Furthermore, reproducing the Poisson-like statistics of neural responses requires the use of networks with balanced excitation and inhibition. Such balance is easily destroyed during learning. Using a top-down approach, we show how networks of integrate-and-fire neurons can learn arbitrary linear dynamical systems by feeding back their error as a feed-forward input. The network uses two types of recurrent connections: fast and slow. The fast connections learn to balance excitation and inhibition using a voltage-based plasticity rule. The slow connections are trained to minimize the error feedback using a current-based Hebbian learning rule. Importantly, the balance maintained by fast connections is crucial to ensure that global error signals are available locally in each neuron, in turn resulting in a local learning rule for the slow connections. This demonstrates that spiking networks can learn complex dynamics using purely local learning rules, using E/I balance as the key rather than an additional constraint. The resulting network implements a given function within the predictive coding scheme, with minimal dimensions and activity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RPVWYWWW\\Bourdoukan and Denève - Enforcing balance allows local supervised learning.pdf},
  language = {en}
}

@article{bouteiller_berger_2012,
  title = {Modeling of the Nervous System: From Modulation of Glutamatergic and Gabaergic Molecular Dynamics to Neuron Spiking Activity.},
  author = {Bouteiller, Jean-Marie C and Legendre, Arnaud and Allam, Sushmita L and Ambert, Nicolas and Hu, Eric Y and Greget, Renaud and Keller, Anne F and Pernot, Fabien and Bischoff, Serge and Baudry, Michel and Berger, Theodore W},
  year = {2012},
  month = jan,
  volume = {2012},
  pages = {6612--5},
  issn = {1557-170X},
  doi = {10.1109/EMBC.2012.6347510},
  abstract = {One of the fundamental characteristics of the brain is its hierarchical and temporal organization: scales in both space and time must be considered to fully grasp the system's underlying mechanisms and their impact on brain function. Complex interactions taking place at the molecular level regulate neuronal activity that further modifies the function of millions of neurons connected by trillions of synapses, ultimately giving rise to complex function and behavior at the system level. Likewise, the spatial complexity is accompanied by a complex temporal integration of events taking place at the microsecond scale leading to slower changes occurring at the second, minute and hour scales. These integrations across hierarchies of the nervous system are sufficiently complex to have impeded the development of routine multi-level modeling methodologies. The present study describes an example of our multiscale efforts to rise from the biomolecular level to the neuron level. We more specifically describe how we integrate biomolecular mechanisms taking place at glutamatergic and gabaergic synapses and integrate them to study the impact of these modifications on spiking activity of a CA1 pyramidal cell in the hippocampus.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VVUNIRLQ\\Bouteiller et al. - 2012 - Modeling of the nervous system from modulation of glutamatergic and gabaergic molecular dynamics to neuron sp.pdf},
  journal = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual Conference},
  keywords = {Algorithms,Animals,Computer Simulation,GABAergic Neurons,GABAergic Neurons: pathology,gamma-Aminobutyric Acid,gamma-Aminobutyric Acid: metabolism,Glutamine,Glutamine: metabolism,Hippocampus,Hippocampus: metabolism,Humans,Kinetics,Models,Neurological,Neurons,Neurons: metabolism,Neurons: pathology,Neurons: physiology,nmda,Pyramidal Cells,Pyramidal Cells: cytology,Receptors,Systems Biology},
  pmid = {23367445}
}

@article{bowling_hopfinger_2019,
  title = {Top-down versus Bottom-up Attention Differentially Modulate Frontal\textendash Parietal Connectivity},
  author = {Bowling, Jake T. and Friston, Karl J. and Hopfinger, Joseph B.},
  year = {2019},
  month = nov,
  pages = {hbm.24850},
  issn = {1065-9471, 1097-0193},
  doi = {10.1002/hbm.24850},
  abstract = {The moment-to-moment focus of our mind's eye results from a complex interplay of voluntary and involuntary influences on attention. Previous neuroimaging studies suggest that the brain networks of voluntary versus involuntary attention can be segregated into a frontal-versus-parietal or a dorsal-versus-ventral partition\textemdash although recent work suggests that the dorsal network may be involved in both bottom-up and top-down attention. Research with nonhuman primates has provided evidence that a key distinction between top-down and bottom-up attention may be the direction of connectivity between frontal and parietal areas. Whereas typical fMRI connectivity analyses cannot disambiguate the direction of connections, dynamic causal modeling (DCM) can model directionality. Using DCM, we provide new evidence that directed connections within the dorsal attention network are differentially modulated for voluntary versus involuntary attention. These results suggest that the intraparietal sulcus exerts a baseline inhibitory effect on the frontal eye fields that is strengthened during exogenous orienting and attenuated during endogenous orienting. Furthermore, the attenuation from endogenous attention occurs even with salient peripheral cues when those cues are known to be counter predictive. Thus, directed connectivity between frontal and parietal regions of the dorsal attention network is highly influenced by the type of attention that is engaged.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5SFHPB67\\Bowling, Friston, Hopfinger - 2019 - Top-down versus bottom-up attention differentially modulate frontal-parietal connectivity.pdf},
  journal = {Human Brain Mapping},
  language = {en}
}

@article{bowman_zeithamova_1523,
  title = {Abstract Memory Representations in the Ventromedial Prefrontal Cortex and Hippocampus Support Concept Generalization},
  author = {Bowman, Caitlin R and Zeithamova, Dagmar},
  year = {1523},
  volume = {10},
  pages = {2811--17},
  doi = {10.1523/JNEUROSCI.2811-17.2018},
  abstract = {memory representations in the ventromedial prefrontal cortex and hippocampus 5 support concept generalization Abstract: 242 words 15 Introduction: 649 words},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\46ETEMXT\\Bowman, Zeithamova - 1523 - Abstract memory representations in the ventromedial prefrontal cortex and hippocampus support concept genera.pdf},
  journal = {J. Neurosci}
}

@article{bradley_goyal_2008,
  title = {Velocity Computation in the Primate Visual System},
  author = {Bradley, David C. and Goyal, Manu S.},
  year = {2008},
  month = sep,
  volume = {9},
  pages = {686--695},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn2472},
  abstract = {Computational neuroscience combines theory and experiment to shed light on the principles and mechanisms of neural computation. This approach has been highly fruitful in the ongoing effort to understand velocity computation by the primate visual system. This Review describes the success of spatiotemporal-energy models in representing local-velocity detection. It shows why local-velocity measurements tend to differ from the velocity of the object as a whole. Certain cells in the middle temporal area are thought to solve this problem by combining local-velocity estimates to compute the overall pattern velocity. The Review discusses different models for how this might occur and experiments that test these models. Although no model is yet firmly established, evidence suggests that computing pattern velocity from local-velocity estimates involves simple operations in the spatiotemporal frequency domain.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XL87Y9FN\\Bradley and Goyal - 2008 - Velocity computation in the primate visual system.pdf},
  journal = {Nature Reviews Neuroscience},
  language = {en},
  number = {9}
}

@article{braithwaite_goldstone_2015,
  title = {Effects of {{Variation}} and {{Prior Knowledge}} on {{Abstract Concept Learning}}},
  author = {Braithwaite, David W. and Goldstone, Robert L.},
  year = {2015},
  volume = {33},
  pages = {226--256},
  issn = {0737-0008},
  doi = {10.1080/07370008.2015.1067215},
  abstract = {Learning abstract concepts through concrete examples may promote learning at the cost of inhibiting transfer. The present study investigated one approach to solving this problem: systematically varying superficial features of the examples. Participants learned to solve problems involving amathematical concept by studying either superficially similar or varied examples. In Experiment 1, less knowledge- able participants learned better from similar examples,while more knowledgeable participants learned better from varied examples. In Experiment 2, prior to learning how to solve the problems, some participants received a pretraining aimed at increasing attention to the structural relations underlying the target concept. These participants, like the more knowledgeable participants in Experiment 1, learned better from varied examples. Thus, the utility of varied examples depends on prior knowledge and, in particular, ability to attend to relevant structure. Increasing this ability can prepare learners to learn more effectively from varied examples.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2T6QGQDW\\Braithwaite, Goldstone - 2015 - Effects of Variation and Prior Knowledge on Abstract Concept Learning.pdf},
  journal = {Cognition and Instruction},
  number = {3}
}

@article{brandon_hasselmo_2013,
  title = {Segregation of Cortical Head Direction Cell Assemblies on Alternating Theta Cycles},
  author = {Brandon, Mark P and Bogaard, Andrew R and Schultheiss, Nathan W and Hasselmo, Michael E},
  year = {2013},
  month = jun,
  volume = {16},
  pages = {739--748},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn.3383},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\S69FCJWB\\Brandon et al. - 2013 - Segregation of cortical head direction cell assemb.pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {6}
}

@article{braun_bassett_2015,
  title = {Dynamic Reconfiguration of Frontal Brain Networks during Executive Cognition in Humans},
  author = {Braun, Urs and Sch{\"a}fer, Axel and Walter, Henrik and Erk, Susanne and {Romanczuk-Seiferth}, Nina and Haddad, Leila and Schweiger, Janina I. and Grimm, Oliver and Heinz, Andreas and Tost, Heike and {Meyer-Lindenberg}, Andreas and Bassett, Danielle S.},
  year = {2015},
  month = sep,
  volume = {112},
  pages = {11678--11683},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1422487112},
  abstract = {The brain is an inherently dynamic system, and executive cognition requires dynamically reconfiguring, highly evolving networks of brain regions that interact in complex and transient communication patterns. However, a precise characterization of these reconfiguration processes during cognitive function in humans remains elusive. Here, we use a series of techniques developed in the field of ``dynamic network neuroscience'' to investigate the dynamics of functional brain networks in 344 healthy subjects during a working-memory challenge (the ``n-back'' task). In contrast to a control condition, in which dynamic changes in cortical networks were spread evenly across systems, the effortful working-memory condition was characterized by a reconfiguration of frontoparietal and frontotemporal networks. This reconfiguration, which characterizes ``network flexibility,'' employs transient and heterogeneous connectivity between frontal systems, which we refer to as ``integration.'' Frontal integration predicted neuropsychological measures requiring working memory and executive cognition, suggesting that dynamic network reconfiguration between frontal systems supports those functions. Our results characterize dynamic reconfiguration of large-scale distributed neural circuits during executive cognition in humans and have implications for understanding impaired cognitive function in disorders affecting connectivity, such as schizophrenia or dementia.},
  copyright = {\textcopyright{}  . Freely available online through the PNAS open access option.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9MPR9IUN\\Braun et al. - 2015 - Dynamic reconfiguration of frontal brain networks .pdf;C\:\\Users\\wchapman\\Zotero\\storage\\L9AH3UMU\\11678.html},
  journal = {Proceedings of the National Academy of Sciences},
  keywords = {working-memory},
  language = {en},
  number = {37},
  pmid = {26324898}
}

@article{brea_pfister_2013,
  title = {Matching Recall and Storage in Sequence Learning with Spiking Neural Networks.},
  author = {Brea, Johanni and Senn, Walter and Pfister, Jean-Pascal},
  year = {2013},
  month = jun,
  volume = {33},
  pages = {9565--75},
  issn = {1529-2401},
  doi = {10.1523/JNEUROSCI.4098-12.2013},
  abstract = {Storing and recalling spiking sequences is a general problem the brain needs to solve. It is, however, unclear what type of biologically plausible learning rule is suited to learn a wide class of spatiotemporal activity patterns in a robust way. Here we consider a recurrent network of stochastic spiking neurons composed of both visible and hidden neurons. We derive a generic learning rule that is matched to the neural dynamics by minimizing an upper bound on the Kullback-Leibler divergence from the target distribution to the model distribution. The derived learning rule is consistent with spike-timing dependent plasticity in that a presynaptic spike preceding a postsynaptic spike elicits potentiation while otherwise depression emerges. Furthermore, the learning rule for synapses that target visible neurons can be matched to the recently proposed voltage-triplet rule. The learning rule for synapses that target hidden neurons is modulated by a global factor, which shares properties with astrocytes and gives rise to testable predictions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KU3EJQSK\\Brea, Senn, Pfister - 2013 - Matching recall and storage in sequence learning with spiking neural networks.pdf},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  keywords = {Learning,Learning: physiology,Mental Recall,Mental Recall: physiology,Models,Neural Networks (Computer),Neurological,Synapses,Synapses: physiology},
  number = {23},
  pmid = {23739954}
}

@article{brecht_naumann_2014,
  title = {An Isomorphic Mapping Hypothesis of the Grid Representation.},
  author = {Brecht, Michael and Ray, Saikat and Burgalossi, Andrea and Tang, Qiusong and Schmidt, Helene and Naumann, Robert},
  year = {2014},
  volume = {369},
  pages = {20120521},
  issn = {1471-2970},
  doi = {10.1098/rstb.2012.0521},
  abstract = {We introduce a grid cell microcircuit hypothesis. We propose the 'grid in the world' (evident in grid cell discharges) is generated by a 'grid in the cortex'. This cortical grid is formed by patches of calbindin-positive pyramidal neurons in layer 2 of medial entorhinal cortex (MEC). Our isomorphic mapping hypothesis assumes three types of isomorphism: (i) metric correspondence of neural space (the two-dimensional cortical sheet) and the external two-dimensional space within patches; (ii) isomorphism between cellular connectivity matrix and firing field; (iii) isomorphism between single cell and population activity. Each patch is a grid cell lattice arranged in a two-dimensional map of space with a neural : external scale of approximately 1 : 2000 in the dorsal part of rat MEC. The lattice behaves like an excitable medium with neighbouring grid cells exciting each other. Spatial scale is implemented as an intrinsic scaling factor for neural propagation speed. This factor varies along the dorsoventral cortical axis. A connectivity scheme of the grid system is described. Head direction input specifies the direction of activity propagation. We extend the theory to neurons between grid patches and predict a rare discharge pattern (inverted grid cells) and the relative location and proportion of grid cells and spatial band cells.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KFMMIS6M\\Brecht et al. - 2014 - An isomorphic mapping hypothesis of the grid representation.pdf},
  journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
  keywords = {cognition,computational biology,neuroscience,theoretical biology},
  number = {1635},
  pmid = {24366133}
}

@techreport{bredenberg_savin_2020,
  title = {Learning Efficient Task-Dependent Representations with Synaptic Plasticity},
  author = {Bredenberg, Colin and Simoncelli, Eero P. and Savin, Cristina},
  year = {2020},
  month = jun,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.06.19.162172},
  abstract = {Abstract           Neural populations do not perfectly encode the sensory world: their capacity is limited by the number of neurons, metabolic and other biophysical resources, and intrinsic noise. The brain is presumably shaped by these limitations, improving efficiency by discarding some aspects of incoming sensory streams, while prefer-entially preserving commonly occurring, behaviorally-relevant information. Here we construct a stochastic recurrent neural circuit model that can learn efficient, task-specific sensory codes using a novel form of reward-modulated Hebbian synaptic plasticity. We illustrate the flexibility of the model by training an initially unstructured neural network to solve two different tasks: stimulus estimation, and stimulus discrimination. The network achieves high performance in both tasks by appropriately allocating resources and using its recurrent circuitry to best compensate for different levels of noise. We also show how the interaction between stimulus priors and task structure dictates the emergent network representations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3PKHQ982\\Bredenberg et al. - 2020 - Learning efficient task-dependent representations .pdf},
  language = {en},
  type = {Preprint}
}

@article{brem_sensi_2018,
  title = {Towards {{Combinatorial Approaches}} for {{Preserving Cognitive Fitness}} in {{Aging}}},
  author = {Brem, Anna-Katharine and Sensi, Stefano L.},
  year = {2018},
  month = dec,
  volume = {41},
  pages = {885--897},
  issn = {01662236},
  doi = {10.1016/j.tins.2018.09.009},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZA5VPKLC\\Brem and Sensi - 2018 - Towards Combinatorial Approaches for Preserving Co.pdf},
  journal = {Trends in Neurosciences},
  language = {en},
  number = {12}
}

@article{brendel_deneve_2017,
  title = {Learning to Represent Signals Spike by Spike},
  author = {Brendel, Wieland and Bourdoukan, Ralph and Vertechi, Pietro and Machens, Christian K. and Den{\'e}ve, Sophie},
  year = {2017},
  month = mar,
  abstract = {A key question in neuroscience is at which level functional meaning emerges from biophysical phenomena. In most vertebrate systems, precise functions are assigned at the level of neural populations, while single-neurons are deemed unreliable and redundant. Here we challenge this view and show that many single-neuron quantities, including voltages, firing thresholds, excitation, inhibition, and spikes, acquire precise functional meaning whenever a network learns to transmit information parsimoniously and precisely to the next layer. Based on the hypothesis that neural circuits generate precise population codes under severe constraints on metabolic costs, we derive synaptic plasticity rules that allow a network to represent its time-varying inputs with maximal accuracy. We provide exact solutions to the learnt optimal states, and we predict the properties of an entire network from its input distribution and the cost of activity. Single-neuron variability and tuning curves as typically observed in cortex emerge over the course of learning, but paradoxically coincide with a precise, non-redundant spike-based population code. Our work suggests that neural circuits operate far more accurately than previously thought, and that no spike is fired in vain.},
  archivePrefix = {arXiv},
  eprint = {1703.03777},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AA48XHRV\\Brendel et al. - 2017 - Learning to represent signals spike by spike.pdf},
  journal = {arXiv:1703.03777 [q-bio]},
  language = {en},
  primaryClass = {q-bio}
}

@article{brennan_ahmed_2020,
  title = {Hyperexcitable {{Neurons Enable Precise}} and {{Persistent Information Encoding}} in the {{Superficial Retrosplenial Cortex}}},
  author = {Brennan, Ellen K W and Ahmed, Omar},
  year = {2020},
  pages = {24},
  abstract = {The retrosplenial cortex (RSC) is essential for memory and navigation, but the neural codes underlying these functions remain largely unknown. Here, we show that the most prominent cell type in layers 2/3 (L2/3) of the mouse granular RSC is a hyperexcitable, small pyramidal cell. These cells have a low rheobase (LR), high input resistance, lack of spike frequency adaptation, and spike widths intermediate to those of neighboring fast-spiking (FS) inhibitory neurons and regular-spiking (RS) excitatory neurons. LR cells are excitatory but rarely synapse onto neighboring neurons. Instead, L2/3 is a feedforward, not feedback, inhibition-dominated network with dense connectivity between FS cells and from FS to LR neurons. Biophysical models of LR but not RS cells precisely and continuously encode sustained input from afferent postsubicular head-direction cells. Thus, the distinct intrinsic properties of LR neurons can support both the precision and persistence necessary to encode information over multiple timescales in the RSC.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KSHBUEP4\\Brennan - Hyperexcitable Neurons Enable Precise and Persiste.pdf},
  language = {en}
}

@article{brette_brette_2018,
  title = {Is Coding a Relevant Metaphor for the Brain?},
  author = {Brette, Romain},
  year = {2018},
  month = jul,
  doi = {10.1101/168237},
  abstract = {"Neural coding" is a popular metaphor in neuroscience, where objective properties of the world are communicated to the brain in the form of spikes. Here I argue that this metaphor is often inappropriate and misleading. First, when neurons are said to encode experimental parameters, the neural code depends on experimental details that are not carried by the coding variable. Thus, the representational power of neural codes is much more limited than generally implied. Second, neural codes carry information only by reference to things with known meaning. In contrast, perceptual systems must build information from relations between sensory signals and actions, forming a structured internal model. Neural codes are inadequate for this purpose because they are unstructured. Third, coding variables are observables tied to the temporality of experiments, while spikes are timed actions that mediate coupling in a distributed dynamical system. The coding metaphor tries to fit the dynamic, circular and distributed causal structure of the brain into a linear chain of transformations between observables, but the two causal structures are incongruent. I conclude that the neural coding metaphor cannot provide a basis for theories of brain function, because it is incompatible with both the causal structure of the brain and the informational requirements of cognition.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\M5H9P83Z\\Brette - 2018 - Is coding a relevant metaphor for the brain.pdf},
  journal = {bioRxiv},
  language = {en}
}

@article{brette_destexhe_2007,
  title = {Simulation of Networks of Spiking Neurons: {{A}} Review of Tools and Strategies},
  author = {Brette, Romain and Rudolph, Michelle and Carnevale, Ted and Hines, Michael and Beeman, David and Bower, James M. and Diesmann, Markus and Morrison, Abigail and Goodman, Philip H. and Harris, Frederick C. and Zirpe, Milind and Natschl??ger, Thomas and Pecevski, Dejan and Ermentrout, Bard and Djurfeldt, Mikael and Lansner, Anders and Rochel, Olivier and Vieville, Thierry and Muller, Eilif and Davison, Andrew P. and El Boustani, Sami and Destexhe, Alain},
  year = {2007},
  volume = {23},
  pages = {349--398},
  issn = {09295313},
  doi = {10.1007/s10827-007-0038-6},
  abstract = {We review different aspects of the simulation of spiking neural networks. We start by reviewing the different types of simulation strategies and algorithms that are currently implemented. We next review the precision of those simulation strategies, in particular in cases where plasticity depends on the exact timing of the spikes. We overview different simulators and simulation environments presently available (restricted to those freely available, open source and documented). For each simulation tool, its advantages and pitfalls are reviewed, with an aim to allow the reader to identify which simulator is appropriate for a given task. Finally, we provide a series of benchmark simulations of different types of networks of spiking neurons, including Hodgkin-Huxley type, integrate-and-fire models, interacting with current-based or conductance-based synapses, using clock-driven or event-driven integration strategies. The same set of models are implemented on the different simulators, and the codes are made available. The ultimate goal of this review is to provide a resource to facilitate identifying the appropriate integration strategy and simulation tool to use for a given modeling problem related to spiking neural networks.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2Q9XZMI6\\Brette et al. - 2007 - Simulation of networks of spiking neurons A review of tools and strategies(2).pdf},
  journal = {Journal of Computational Neuroscience},
  keywords = {Clock-driven,Event-driven,Integration strategies,Simulation tools,Spiking neural networks},
  number = {3},
  pmid = {17629781}
}

@article{brincat_miller_2016,
  title = {Prefrontal {{Cortex Networks Shift}} from {{External}} to {{Internal Modes}} during {{Learning}}},
  author = {Brincat, Scott L and Earl, X and Miller, K},
  year = {2016},
  doi = {10.1523/JNEUROSCI.0274-16.2016},
  abstract = {As we learn about items in our environment, their neural representations become increasingly enriched with our acquired knowledge. But there is little understanding of how network dynamics and neural processing related to external information changes as it becomes laden with "internal" memories. We sampled spiking and local field potential activity simultaneously from multiple sites in the lateral prefrontal cortex (PFC) and the hippocampus (HPC)-regions critical for sensory associations-of monkeys performing an object paired-associate learning task. We found that in the PFC, evoked potentials to, and neural information about, external sensory stimulation decreased while induced beta-band (11-27 Hz) oscillatory power and synchrony associated with "top-down" or internal processing increased. By contrast, the HPC showed little evidence of learning-related changes in either spiking activity or network dynamics. The results suggest that during associative learning, PFC networks shift their resources from external to internal processing.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HW9NHGVG\\Brincat, Earl, Miller - 2016 - Prefrontal Cortex Networks Shift from External to Internal Modes during Learning.pdf},
  keywords = {bottom-up,hippocampus,learning,memory,prefrontal cortex,top-down}
}

@article{brincat_miller_2017,
  title = {Gradual Progression from Sensory to Task-Related Processing in Cerebral Cortex},
  author = {Brincat, Scott L and Siegel, Markus and Nicolai, Constantin Von and Miller, Earl K},
  year = {2017},
  doi = {10.1101/195602},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6E82EGX4\\Brincat et al. - 2017 - Gradual progression from sensory to task-related processing in cerebral cortex.pdf}
}

@article{brojde_colunga_2011,
  title = {Words Can Slow down Category Learning.},
  author = {Brojde, Chandra L and Porter, Chelsea and Colunga, Eliana},
  year = {2011},
  volume = {18},
  pages = {798--804},
  issn = {1531-5320},
  doi = {10.3758/s13423-011-0103-z},
  abstract = {Words have been shown to influence many cognitive tasks, including category learning. Most demonstrations of these effects have focused on instances in which words facilitate performance. One possibility is that words augment representations, predicting an across the-board benefit of words during category learning. We propose that words shift attention to dimensions that have been historically predictive in similar contexts. Under this account, there should be cases in which words are detrimental to performance. The results from two experiments show that words impair learning of object categories under some conditions. Experiment 1 shows that words hurt performance when learning to categorize by texture. Experiment 2 shows that words also hurt when learning to categorize by brightness, leading to selectively attending to shape when both shape and hue could be used to correctly categorize stimuli. We suggest that both the positive and negative effects of words have developmental origins in the history of word usage while learning categories. [corrected]},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IV8H9X4J\\Brojde, Porter, Colunga - 2011 - Words can slow down category learning.pdf},
  journal = {Psychonomic bulletin \& review},
  keywords = {associative learning,Concept Formation,Humans,Language,Photic Stimulation,Psycholinguistics},
  number = {4},
  pmid = {21557027}
}

@article{broschard_freeman_2019,
  title = {Selective Attention in Rat Visual Category Learning},
  author = {Broschard, Matthew B. and Kim, Jangjin and Love, Bradley C. and Wasserman, Edward A. and Freeman, John H.},
  year = {2019},
  month = mar,
  volume = {26},
  pages = {84--92},
  issn = {1549-5485},
  doi = {10.1101/lm.048942.118},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HGFRS2MQ\\Broschard et al. - 2019 - Selective attention in rat visual category learnin.pdf},
  journal = {Learning \& Memory},
  language = {en},
  number = {3}
}

@article{brotchie_goodman_1995,
  title = {Head Position Signals Used by Parietal Neurons to Encode Locations of Visual Stimuli},
  author = {Brotchie, Peter R. and Andersen, Richard A. and Snyder, Lawrence H. and Goodman, Sabrina J.},
  year = {1995},
  month = may,
  volume = {375},
  pages = {232--235},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/375232a0},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\F3EHN4AG\\Brotchie et al. - 1995 - Head position signals used by parietal neurons to .pdf},
  journal = {Nature},
  language = {en},
  number = {6528}
}

@article{brown_liotti_2011,
  title = {Naturalizing Aesthetics: {{Brain}} Areas for Aesthetic Appraisal across Sensory Modalities},
  author = {Brown, Steven and Gao, Xiaoqing and Tisdelle, Loren and Eickhoff, Simon B and Liotti, Mario},
  year = {2011},
  volume = {58},
  pages = {250--258},
  doi = {10.1016/j.neuroimage.2011.06.012},
  abstract = {a b s t r a c t We present here the most comprehensive analysis to date of neuroaesthetic processing by reporting the results of voxel-based meta-analyses of 93 neuroimaging studies of positive-valence aesthetic appraisal across four sensory modalities. The results demonstrate that the most concordant area of activation across all four modalities is the right anterior insula, an area typically associated with visceral perception, especially of negative valence (disgust, pain, etc.). We argue that aesthetic processing is, at its core, the appraisal of the valence of perceived objects. This appraisal is in no way limited to artworks but is instead applicable to all types of perceived objects. Therefore, one way to naturalize aesthetics is to argue that such a system evolved first for the appraisal of objects of survival advantage, such as food sources, and was later co-opted in humans for the experience of artworks for the satisfaction of social needs.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\88PX3NIC\\Brown et al. - 2011 - Naturalizing aesthetics Brain areas for aesthetic appraisal across sensory modalities.pdf},
  journal = {NeuroImage},
  keywords = {ALE,anterior cingulate,Anterior insula,Arts,Brain,Exteroceptive,fmri,Hedonics,Interoceptive,Meta-analysis,Music,Neuroaesthetics,Orbitofrontal,Pleasantness,Pleasure,Preference,Valence,Visceral}
}

@article{brown_mitra_2004,
  title = {Multiple Neural Spike Train Data Analysis: State-of-the-Art and Future Challenges},
  author = {Brown, Emery N and Kass, Robert E and Mitra, Partha P},
  year = {2004},
  volume = {7},
  pages = {456--461},
  issn = {1097-6256},
  doi = {10.1038/nn1228},
  abstract = {Multiple electrodes are now a standard tool in neuroscience research that make it possible to study the simultaneous activity of several neurons in a given brain region or across different regions. The data from multi-electrode studies present important analysis challenges that must be resolved for optimal use of these neurophysiological measurements to answer questions about how the brain works. Here we review statistical methods for the analysis of multiple neural spike-train data and discuss future challenges for methodology research.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\H4DKRWH3\\Brown, Kass, Mitra - 2004 - Multiple neural spike train data analysis state-of-the-art and future challenges.pdf},
  journal = {Nature Neuroscience},
  number = {5},
  pmid = {15114358}
}

@article{brown_solo_2001,
  title = {An Analysis of Neural Receptive Field Plasticity by Point Process Adaptive Filtering},
  author = {Brown, Emery N and Nguyen, David P and Frank, Loren M and Wilson, Matthew A and Solo, Victor},
  year = {2001},
  volume = {98},
  pages = {12261--12266},
  issn = {0027-8424},
  doi = {10.1073/pnas.201409398},
  abstract = {Neural receptive fields are plastic: with experience, neurons in many brain regions change their spiking responses to relevant stimuli. Analysis of receptive field plasticity from experimental measurements is crucial for understanding how neural systems adapt their representations of relevant biological information. Current analysis methods using histogram estimates of spike rate functions in nonoverlapping temporal windows do not track the evolution of receptive field plasticity on a fine time scale. Adaptive signal processing is an established engineering paradigm for estimating time-varying system parameters from experimental measurements. We present an adaptive filter algorithm for tracking neural receptive field plasticity based on point process models of spike train activity. We derive an instantaneous steepest descent algorithm by using as the criterion function the instantaneous log likelihood of a point process spike train model. We apply the point process adaptive filter algorithm in a study of spatial (place) receptive field properties of simulated and actual spike train data from rat CA1 hippocampal neurons. A stability analysis of the algorithm is sketched in the. The adaptive algorithm can update the place field parameter estimates on a millisecond time scale. It reliably tracked the migration, changes in scale, and changes in maximum firing rate characteristic of hippocampal place fields in a rat running on a linear track. Point process adaptive filtering offers an analytic method for studying the dynamics of neural receptive fields.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BG6N9J3I\\Brown et al. - 2001 - An analysis of neural receptive field plasticity by point process adaptive filtering.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  number = {21},
  pmid = {11593043}
}

@article{brun_moser_2008,
  title = {Progressive Increase in Grid Scale from Dorsal to Ventral Medial Entorhinal Cortex.},
  author = {Brun, Vegard Heimly and Solstad, Trygve and Kjelstrup, Kirsten Brun and Fyhn, Marianne and Witter, Menno P and Moser, Edvard I and Moser, May-Britt},
  year = {2008},
  month = jan,
  volume = {18},
  pages = {1200--12},
  issn = {1098-1063},
  doi = {10.1002/hipo.20504},
  abstract = {Grid cells are topographically organized in the sense that, within the dorsal part of the medial entorhinal cortex, the scale of the grid increases systematically with anatomical distance from the dorsal border of this brain area. The ventral limit of the spatial map is currently not known. To determine if the grid map extends into the intermediate and ventral parts of the medial entorhinal cortex, we recorded activity from entorhinal principal cells at multiple dorsoventral levels while rats shuttled back and forth on an 18 m long linear track. The recordings spanned a range of more than 3 mm, covering approximately three quarters of the dorsoventral extent of the medial entorhinal cortex. Distinct periodic firing fields were observed at all recording levels. The average interpeak distance between the fields increased from approximately 50 cm in the most dorsal part to approximately 3 m at the most ventral recording positions. The increase in grid scale was accompanied by a decrease in the frequency of theta modulation and the rate of phase precession. The increase in average spacing and field size was approximately linear but this relationship coincided with a substantial increase in the variability of each measure. Taken together, the observations suggest that the spatial scale of the grid representation increases progressively along most of the dorsoventral axis of the medial entorhinal cortex, mirroring the topographical scale expansion observed in place cells in the hippocampus.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VRHWB5D7\\Brun et al. - 2008 - Progressive increase in grid scale from dorsal to ventral medial entorhinal cortex.pdf},
  journal = {Hippocampus},
  keywords = {Animals,Brain Mapping,Computer Simulation,Entorhinal Cortex,Entorhinal Cortex: cytology,Entorhinal Cortex: physiology,Long-Evans,Male,Nerve Net,Nerve Net: cytology,Nerve Net: physiology,Neurons,Neurons: physiology,Orientation,Orientation: physiology,Rats,Space Perception,Space Perception: physiology,Theta Rhythm},
  number = {12},
  pmid = {19021257}
}

@article{brunner_makeig_2016,
  title = {Volume {{Conduction Influences Scalp}}-{{Based Connectivity Estimates}}},
  author = {Brunner, Clemens and Billinger, Martin and Seeber, Martin and Mullen, Timothy R. and Makeig, Scott},
  year = {2016},
  volume = {10},
  pages = {1--4},
  issn = {1662-5188},
  doi = {10.3389/fncom.2016.00121},
  abstract = {Authors find that for DTF the original Kaliminiska 2014 article argued wrongly that DTF is not affected by volume conduction. They didn't mix the noise frequencies properly according to volume conduction and when done correctly, volume conduction needs to be taken into account, AKA, you should perform DTF on sourcelevel.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UXTBF3QG\\Brunner et al. - 2016 - Volume Conduction Influences Scalp-Based Connectivity Estimates.pdf},
  journal = {Frontiers in Computational Neuroscience},
  keywords = {conduction,connectivity,directed transfer function,electroencephalographic,Electroencephalographic,inverse pro,inverse problem,source analysis},
  number = {November},
  pmid = {27920674}
}

@article{brzosko_paulsen_2017,
  title = {Sequential Neuromodulation of Hebbian Plasticity Offers Mechanism for Effective Reward-Based Navigation},
  author = {Brzosko, Zuzanna and Zannone, Sara and Schultz, Wolfram and Clopath, Claudia and Paulsen, Ole},
  year = {2017},
  volume = {6},
  pages = {1--18},
  issn = {2050084X},
  doi = {10.7554/eLife.27756},
  abstract = {\textbackslash textlessp\textbackslash textgreaterSpike timing-dependent plasticity (STDP) is under neuromodulatory control, which is correlated with distinct behavioral states. Previously, we reported that dopamine, a reward signal, broadens the time window for synaptic potentiation and modulates the outcome of hippocampal STDP even when applied after the plasticity induction protocol (Brzosko et al., 2015). Here, we demonstrate that sequential neuromodulation of STDP by acetylcholine and dopamine offers an efficacious model of reward-based navigation. Specifically, our experimental data in mouse hippocampal slices show that acetylcholine biases STDP toward synaptic depression, whilst subsequent application of dopamine converts this depression into potentiation. Incorporating this bidirectional neuromodulation-enabled correlational synaptic learning rule into a computational model yields effective navigation toward changing reward locations, as in natural foraging behavior. Thus, temporally sequenced neuromodulation of STDP enables associations to be made between actions and outcomes and also provides a possible mechanism for aligning the time scales of cellular and behavioral learning.\textbackslash textless/p\textbackslash textgreater},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\V5QBDQXB\\Brzosko et al. - 2017 - Sequential neuromodulation of hebbian plasticity offers mechanism for effective reward-based navigation.pdf},
  journal = {eLife},
  pmid = {28691903}
}

@article{bufacchi_iannetti_2018,
  title = {An {{Action Field Theory}} of {{Peripersonal Space}}},
  author = {Bufacchi, Rory J and Iannetti, Gian Domenico},
  year = {2018},
  volume = {xx},
  issn = {13646613},
  doi = {10.1016/j.tics.2018.09.004},
  abstract = {Predominant conceptual frameworks often describe peripersonal space (PPS) as a single, distance-based, in-or-out zone within which stimuli elicit enhanced neural and behavioural responses. Here we argue that this intuitive framework is contradicted by neurophysiological and behavioural data. First, PPS-related measures are not binary, but graded with proximity. Second, they are strongly influenced by factors other than proximity, such as walking, tool use, stimulus valence, and social cues. Third, many different PPS-related responses exist, and each can be used to describe a different space. Here, we reconceptualise PPS as a set of graded fields describing behavioural relevance of actions aiming to create or avoid contact between objects and the body. This reconceptualisation incorporates PPS into mainstream theories of action selection and behaviour.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZVWNFRNL\\Bufacchi, Iannetti - 2018 - An Action Field Theory of Peripersonal Space.pdf},
  journal = {Trends in Cognitive Sciences},
  keywords = {defence,egocentric coding,goal-oriented actions,motor system,perception and action}
}

@article{bullock_bullock_2004,
  title = {Adaptive Neural Models of Queuing and Timing in Fluent Action.},
  author = {Bullock, Daniel},
  year = {2004},
  month = sep,
  volume = {8},
  pages = {426--433},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2004.07.003},
  abstract = {In biological cognition, specialized representations and associated control processes solve the temporal problems inherent in skilled action. Recent data and neural circuit models highlight three distinct levels of temporal structure: sequence preparation, velocity scaling, and state-sensitive timing. Short sequences of actions are prepared collectively in prefrontal cortex, then queued for performance by a cyclic competitive process that operates on a parallel analog representation. Successful acts like ball-catching depend on coordinated scaling of effector velocities, and velocity scaling, mediated by the basal ganglia, may be coupled to perceived time-to-contact. Making acts accurate at high speeds requires state-sensitive and precisely timed activations of muscle forces in patterns that accelerate and decelerate the effectors. The cerebellum may provide a maximally efficient representational basis for learning to generate such timed activation patterns.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7YEZFLY5\\Bullock - 2004 - Adaptive neural models of queuing and timing in fluent action.pdf},
  journal = {Trends in cognitive sciences},
  keywords = {Cerebellum,Cerebellum: physiology,Cognition,Cognition: physiology,Humans,Nerve Net,Nerve Net: physiology,Neurophysiology,Neurophysiology: instrumentation,Physiological,Physiological: physiology,Prefrontal Cortex,Prefrontal Cortex: physiology,Psychomotor Performance,Psychomotor Performance: physiology,Time Factors},
  number = {9},
  pmid = {15350244}
}

@article{burgess_burgess_2006,
  title = {Spatial Memory: How Egocentric and Allocentric Combine},
  author = {Burgess, Neil},
  year = {2006},
  volume = {10},
  pages = {551--557},
  issn = {13646613},
  doi = {10.1016/j.tics.2006.10.005},
  abstract = {Recent experiments indicate the need for revision of a model of spatial memory consisting of viewpoint-specific representations, egocentric spatial updating and a geometric module for reorientation. Instead, it appears that both egocentric and allocentric representations exist in parallel, and combine to support behavior according to the task. Current research indicates complementary roles for these representations, with increasing dependence on allocentric representations with the amount of movement between presentation and retrieval, the number of objects remembered, and the size, familiarity and intrinsic structure of the environment. Identifying the neuronal mechanisms and functional roles of each type of representation, and of their interactions, promises to provide a framework for investigation of the organization of human memory more generally. ?? 2006 Elsevier Ltd. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KL6H4V7I\\Burgess - 2006 - Spatial memory how egocentric and allocentric combine.pdf},
  journal = {Trends in Cognitive Sciences},
  number = {12},
  pmid = {17071127}
}

@article{burgess_okeefe_2007,
  title = {An Oscillatory Interference Model of Grid Cell Firing},
  author = {Burgess, Neil and Barry, Caswell and Keefe, John O and Al, Burgess E T and O'Keefe, J},
  year = {2007},
  volume = {000},
  pages = {1--3},
  issn = {1050-9631},
  doi = {10.1002/hipo},
  abstract = {We expand upon our proposal that the oscillatory interference mechanism proposed for the phase precession effect in place cells underlies the grid-like firing pattern of dorsomedial entorhinal grid cells (O'Keefe and Burgess (2005) Hippocampus 15:853-866). The original one-dimensional interference model is generalized to an appropriate two-dimensional mechanism. Specifically, dendritic subunits of layer II medial entorhinal stellate cells provide multiple linear interference patterns along different directions, with their product determining the firing of the cell. Connection of appropriate speed- and direction- dependent inputs onto dendritic subunits could result from an unsupervised learning rule which maximizes postsynaptic firing (e.g. competitive learning). These inputs cause the intrinsic oscillation of subunit membrane potential to increase above theta frequency by an amount proportional to the animal's speed of running in the "preferred" direction. The phase difference between this oscillation and a somatic input at theta-frequency essentially integrates velocity so that the interference of the two oscillations reflects distance traveled in the preferred direction. The overall grid pattern is maintained in environmental location by phase reset of the grid cell by place cells receiving sensory input from the environment, and environmental boundaries in particular. We also outline possible variations on the basic model, including the generation of grid-like firing via the interaction of multiple cells rather than via multiple dendritic subunits. Predictions of the interference model are given for the frequency composition of EEG power spectra and temporal autocorrelograms of grid cell firing as functions of the speed and direction of running and the novelty of the environment. (c) 2007 Wiley-Liss, Inc.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6LZFW7W2\\Burgess et al. - 2007 - An oscillatory interference model of grid cell firing.pdf},
  journal = {Hippocampus},
  keywords = {campus,dendrites,entorhinal cortex,hippo-,place cells,stellate cells,theta rhythm},
  pmid = {17598147}
}

@article{burgos-robles_tye_2017,
  title = {Amygdala Inputs to Prefrontal Cortex Guide Behavior amid Conflicting Cues of Reward and Punishment},
  author = {{Burgos-Robles}, Anthony and Kimchi, Eyal Y and Izadmehr, Ehsan M and Porzenheim, Mary Jane and {Ramos-Guasp}, William A and Nieh, Edward H and {Felix-Ortiz}, Ada C and Namburi, Praneeth and Leppla, Christopher A and Presbrey, Kara N and Anandalingam, Kavitha K and {Pagan-Rivera}, Pablo A and Anahtar, Melodi and Beyeler, Anna and Tye, Kay M},
  year = {2017},
  volume = {20},
  issn = {1097-6256},
  doi = {10.1038/nn.4553},
  abstract = {Orchestrating appropriate behavioral responses in the face of competing signals that predict either rewards or threats in the environment is crucial for survival. The basolateral nucleus of the amygdala (BLA) and prelimbic (PL) medial prefrontal cortex have been implicated in reward-seeking and fear-related responses, but how information flows between these reciprocally connected structures to coordinate behavior is unknown. We recorded neuronal activity from the BLA and PL while rats performed a task wherein competing shock- and sucrose-predictive cues were simultaneously presented. The correlated firing primarily displayed a BLA[rarr]PL directionality during the shock-associated cue. Furthermore, BLA neurons optogenetically identified as projecting to PL more accurately predicted behavioral responses during competition than unidentified BLA neurons. Finally photostimulation of the BLA[rarr]PL projection increased freezing, whereas both chemogenetic and optogenetic inhibition reduced freezing. Therefore, the BLA[rarr]PL circuit is critical in governing the selection of behavioral responses in the face of competing signals.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QM72EY4I\\Burgos-Robles et al. - 2017 - Amygdala inputs to prefrontal cortex guide behavior amid conflicting cues of reward and punishment.pdf},
  journal = {Nature Neuroscience},
  number = {6},
  pmid = {28436980}
}

@article{burms_dambre_2015,
  title = {Reward-{{Modulated Hebbian Plasticity}} as {{Leverage}} for {{Partially Embodied Control}} in {{Compliant Robotics}}},
  author = {Burms, Jeroen and Caluwaerts, Ken and Dambre, Joni},
  year = {2015},
  month = aug,
  volume = {9},
  issn = {1662-5218},
  doi = {10.3389/fnbot.2015.00009},
  abstract = {In embodied computation (or morphological computation), part of the complexity of motor control is offloaded to the body dynamics. We demonstrate that a simple Hebbianlike learning rule can be used to train systems with (partial) embodiment, and can be extended outside of the scope of traditional neural networks. To this end, we apply the learning rule to optimize the connection weights of recurrent neural networks with different topologies and for various tasks. We then apply this learning rule to a simulated compliant tensegrity robot by optimizing static feedback controllers that directly exploit the dynamics of the robot body. This leads to partially embodied controllers, i.e., hybrid controllers that naturally integrate the computations that are performed by the robot body into a neural network architecture. Our results demonstrate the universal applicability of reward-modulated Hebbian learning. Furthermore, they demonstrate the robustness of systems trained with the learning rule. This study strengthens our belief that compliant robots should or can be seen as computational units, instead of dumb hardware that needs a complex controller. This link between compliant robotics and neural networks is also the main reason for our search for simple universal learning rules for both neural networks and robotics.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\88F695ZP\\Burms et al. - 2015 - Reward-Modulated Hebbian Plasticity as Leverage fo.pdf},
  journal = {Frontiers in Neurorobotics},
  language = {en}
}

@article{burton_burton_1963,
  title = {Psychological Review},
  author = {Burton, Roger V},
  year = {1963},
  volume = {70},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QV38VXQR\\Burton - 1963 - Psychological review.pdf},
  number = {6}
}

@article{burton_white_2008,
  title = {Development of Theta Rhythmicity in Entorhinal Stellate Cells of the Juvenile Rat.},
  author = {Burton, Brian G and Economo, Michael N and Lee, G Jenny and a White, John},
  year = {2008},
  volume = {100},
  pages = {3144--3157},
  issn = {0022-3077},
  doi = {10.1152/jn.90424.2008},
  abstract = {Mature stellate cells of the rat medial entorhinal cortex (EC), layer II, exhibit subthreshold membrane potential oscillations (MPOs) at theta frequencies (4-12 Hz) in vitro. We find that MPOs appear between postnatal days 14 (P14) and 18 (P18) but show little further change by day 28+ (P28-P32). To identify the factors responsible, we examined the electrical responses of developing stellate cells, paying attention to two currents thought necessary for mature oscillation: the h current I(h), which provides the slow rectification required for resonance; and a persistent sodium current I(NaP), which provides amplification of resonance. Responses to injected current revealed that P14 cells were often nonresonant with a relatively high resistance. Densities of I(h) and I(NaP) both rose by about 50\% from P14 to P18. However, I(h) levels fell to intermediate values by P28+. Given the nonrobust trend in I(h) expression and a previously demonstrated potency of even low levels of I(h) to sustain oscillation, we propose that resonance and MPOs are limited at P14 more by low levels of I(NaP) than of I(h). The relative importance of I(NaP) for the development of MPOs is supported by simulations of a conductance-based model, which also suggest that general shunt conductance may influence the precise age when MPOs appear. In addition to our physiological study, we analyzed spine densities at P14, P18, and P28+ and found a vigorous synaptogenesis across the whole period. Our data predict that functions that rely on theta rhythmicity in the hippocampal network are limited until at least P18.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\R3DV54H4\\Burton et al. - 2008 - Development of theta rhythmicity in entorhinal stellate cells of the juvenile rat.pdf},
  journal = {Journal of neurophysiology},
  number = {6},
  pmid = {18829850}
}

@article{buschman_kastner_2015,
  title = {From {{Behavior}} to {{Neural Dynamics}}: {{An Integrated Theory}} of {{Attention}}},
  author = {Buschman, Timothy J. and Kastner, Sabine},
  year = {2015},
  issn = {10974199},
  doi = {10.1016/j.neuron.2015.09.017},
  abstract = {The brain has a limited capacity and therefore needs mechanisms to selectively enhance the information most relevant to one's current behavior. We refer to these mechanisms as "attention." Attention acts by increasing the strength of selected neural representations and preferentially routing them through the brain's large-scale network. This is a critical component of cognition and therefore has been a central topic in cognitive neuroscience. Here we review a diverse literature that has studied attention at the level of behavior, networks, circuits, and neurons. We then integrate these disparate results into a unified theory of attention.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9C4RMJAP\\Buschman and Kastner - 2015 - From Behavior to Neural Dynamics An Integrated Th.pdf},
  journal = {Neuron},
  pmid = {26447577}
}

@article{buschman_miller_2007,
  title = {Top-down versus Bottom-up Control of Attention in the Prefrontal and Posterior Parietal Cortices},
  author = {Buschman, Timothy J and Miller, Earl K},
  year = {2007},
  volume = {315},
  pages = {1860--1864},
  issn = {00368075},
  doi = {10.1126/science.1138071},
  abstract = {Attention can be focused volitionally by "top-down" signals derived from task demands and automatically by "bottom-up" signals from salient stimuli. The frontal and parietal cortices are involved, but their neural activity has not been directly compared. Therefore, we recorded from them simultaneously in monkeys. Prefrontal neurons reflected the target location first during top-down attention, whereas parietal neurons signaled it earlier during bottom-up attention. Synchrony between frontal and parietal areas was stronger in lower frequencies during top-down attention and in higher frequencies during bottom-up attention. This result indicates that top-down and bottom-up signals arise from the frontal and sensory cortex, respectively, and different modes of attention may emphasize synchrony at different frequencies.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TGTFZSL9\\Buschman, Miller - 2007 - Top-down versus bottom-up control of attention in the prefrontal and posterior parietal cortices.pdf},
  journal = {Science},
  number = {5820},
  pmid = {17395832}
}

@article{buschman_miller_2009,
  title = {Serial, {{Covert Shifts}} of {{Attention}} during {{Visual Search Are Reflected}} by the {{Frontal Eye Fields}} and {{Correlated}} with {{Population Oscillations}}},
  author = {Buschman, Timothy J and Miller, Earl K},
  year = {2009},
  volume = {63},
  pages = {386--396},
  issn = {08966273},
  doi = {10.1016/j.neuron.2009.06.020},
  abstract = {Attention regulates the flood of sensory information into a manageable stream, and so understanding how attention is controlled is central to understanding cognition. Competing theories suggest visual search involves serial and/or parallel allocation of attention, but there is little direct, neural evidence for either mechanism. Two monkeys were trained to covertly search an array for a target stimulus under visual search (endogenous) and pop-out (exogenous) conditions. Here, we present neural evidence in the frontal eye fields (FEF) for serial, covert shifts of attention during search but not pop-out. Furthermore, attention shifts reflected in FEF spiking activity were correlated with 18-34 Hz oscillations in the local field potential, suggesting a "clocking" signal. This provides direct neural evidence that primates can spontaneously adopt a serial search strategy and that these serial covert shifts of attention are directed by the FEF. It also suggests that neuron population oscillations may regulate the timing of cognitive processing. ?? 2009 Elsevier Inc. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9E46JSVQ\\Buschman, Miller - Unknown - Article Serial, Covert Shifts of Attention during Visual Search Are Reflected by the Frontal Eye Fields and.pdf},
  journal = {Neuron},
  keywords = {SYSNEURO},
  number = {3},
  pmid = {19679077}
}

@article{buschman_miller_2010,
  title = {Shifting the {{Spotlight}} of {{Attention}}: {{Evidence}} for {{Discrete Computations}} in {{Cognition}}},
  author = {Buschman, Timothy J. and Miller, Earl K.},
  year = {2010},
  volume = {4},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2010.00194},
  abstract = {Our thoughts have a limited bandwidth; we can only fully process a few items in mind simultaneously. To compensate, the brain developed attention, the ability to select information relevant to the current task, while filtering out the rest. Therefore, by understanding the neural mechanisms of attention we hope to understand a core component of cognition. Here, we review our recent investigations of the neural mechanisms underlying the control of visual attention in frontal and parietal cortex. This includes the observation that the neural mechanisms that shift attention were synchronized to 25 Hz oscillatory brain rhythms, with each shift in attention falling within a single cycle of the oscillation. We generalize these findings to present a hypothesis that cognition relies on neural mechanisms that operate in discrete, periodic computations, as reflected in ongoing oscillations. We discuss the advantages of the model, experimental support, and make several testable hypotheses.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\45UNMF54\\Buschman, Miller - 2010 - Shifting the spotlight of attention evidence for discrete computations in cognition.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\8AGPTCK5\\Article - 2010 - Shifting the spotlight of attention evidence for discrete computations in cognition.pdf},
  journal = {Frontiers in Human Neuroscience},
  keywords = {attention,cognition,oscillations,synchrony},
  number = {1},
  pmid = {21119775}
}

@article{buschman_miller_2011,
  title = {Neural Substrates of Cognitive Capacity Limitations},
  author = {Buschman, Timothy J and Siegel, Markus and Roy, Jefferson E and Miller, Earl K},
  year = {2011},
  volume = {108},
  pages = {1--4},
  issn = {1091-6490},
  doi = {10.1073/pnas.1104666108/-/DCSupplemental.www.pnas.org/cgi/doi/10.1073/pnas.1104666108},
  abstract = {Cognition has a severely limited capacity: Adult humans can retain only about four items ``in mind''. This limitation is fundamental to human brain function: Individual capacity is highly correlated with intelligence measures and capacity is reduced in neuropsychiatric diseases. Although human capacity limitations are well studied, their mechanisms have not been investigated at the single-neuron level. Simultaneous recordings from monkey parietal and frontal cortex revealed that visual capacity limitations occurred immedi- ately upon stimulus encoding and in a bottom-up manner. Capacity limitations were found to reflect a dual model of working memory. The left and right halves of visual space had independent capacities and thus are discrete resources. However, within each hemifield, neural information about successfully remembered objects was re- ducedbyaddingfurtherobjects, indicatingthat resources are shared. Together, these results suggest visual capacity limitation is due to discrete, slot-like, resources, each containing limited pools of neural information that can be divided among objects},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7RFLLF3K\\Buschman et al. - 2011 - Neural substrates of cognitive capacity limitations.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  number = {27},
  pmid = {21690375}
}

@article{buschman_miller_2012,
  title = {Synchronous Oscillatory Neural Ensembles for Rules in the Prefrontal Cortex.},
  author = {Buschman, Timothy J and Denovellis, Eric L and Diogo, Cinira and Bullock, Daniel and Miller, Earl K},
  year = {2012},
  month = nov,
  volume = {76},
  pages = {838--46},
  issn = {1097-4199},
  doi = {10.1016/j.neuron.2012.09.029},
  abstract = {Intelligent behavior requires acquiring and following rules. Rules define how our behavior should fit different situations. To understand its neural mechanisms, we simultaneously recorded from multiple electrodes in dorsolateral prefrontal cortex (PFC) while monkeys switched between two rules (respond to color versus orientation). We found evidence that oscillatory synchronization of local field potentials (LFPs) formed neural ensembles representing the rules: there were rule-specific increases in synchrony at "beta" (19-40 Hz) frequencies between electrodes. In addition, individual PFC neurons synchronized to the LFP ensemble corresponding to the current rule (color versus orientation). Furthermore, the ensemble encoding the behaviorally dominant orientation rule showed increased "alpha" (6-16 Hz) synchrony when preparing to apply the alternative (weaker) color rule. This suggests that beta-frequency synchrony selects the relevant rule ensemble, while alpha-frequency synchrony deselects a stronger, but currently irrelevant, ensemble. Synchrony may act to dynamically shape task-relevant neural ensembles out of larger, overlapping circuits.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PHTQS7FI\\Buschman et al. - 2012 - Synchronous oscillatory neural ensembles for rules in the prefrontal cortex.pdf},
  journal = {Neuron},
  keywords = {Animals,Attention,Color Perception,Cortical Synchronization,Cortical Synchronization: physiology,Female,Linear Models,Macaca fascicularis,Macaca mulatta,Male,Neurons,Neurons: physiology,Orientation,Orientation: physiology,Periodicity,Photic Stimulation,Prefrontal Cortex,Prefrontal Cortex: cytology,Prefrontal Cortex: physiology,Reaction Time,Reaction Time: physiology,ROC Curve,Spectrum Analysis,Time Factors},
  number = {4},
  pmid = {23177967}
}

@article{buschman_miller_2014,
  title = {Goal-Direction and Top-down Control},
  author = {Buschman, Timothy J and Miller, Earl K and B, Phil Trans R Soc and Buschman, Timothy J and Miller, Earl K and Miller, Earl K},
  year = {2014},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XQPT3Z3P\\Buschman et al. - 2014 - Goal-direction and top-down control.pdf},
  journal = {Philosophical Transactions of the Royal Society B},
  number = {September}
}

@article{busemeyer_turner_2019,
  title = {Cognitive and {{Neural Bases}} of {{Multi}}-{{Attribute}}, {{Multi}}-{{Alternative}}, {{Value}}-Based {{Decisions}}},
  author = {Busemeyer, Jerome R. and Gluth, Sebastian and Rieskamp, J{\"o}rg and Turner, Brandon M.},
  year = {2019},
  month = mar,
  volume = {23},
  pages = {251--263},
  issn = {13646613},
  doi = {10.1016/j.tics.2018.12.003},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XZDJ22VM\\Busemeyer et al. - 2019 - Cognitive and Neural Bases of Multi-Attribute, Mul.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {3}
}

@article{bush_burgess_2014,
  title = {A Hybrid Oscillatory Interference/Continuous Attractor Network Model of Grid Cell Firing.},
  author = {Bush, Daniel and Burgess, Neil},
  year = {2014},
  month = apr,
  volume = {34},
  pages = {5065--79},
  issn = {1529-2401},
  doi = {10.1523/JNEUROSCI.4017-13.2014},
  abstract = {Grid cells in the rodent medial entorhinal cortex exhibit remarkably regular spatial firing patterns that tessellate all environments visited by the animal. Two theoretical mechanisms that could generate this spatially periodic activity pattern have been proposed: oscillatory interference and continuous attractor dynamics. Although a variety of evidence has been cited in support of each, some aspects of the two mechanisms are complementary, suggesting that a combined model may best account for experimental data. The oscillatory interference model proposes that the grid pattern is formed from linear interference patterns or "periodic bands" in which velocity-controlled oscillators integrate self-motion to code displacement along preferred directions. However, it also allows the use of symmetric recurrent connectivity between grid cells to provide relative stability and continuous attractor dynamics. Here, we present simulations of this type of hybrid model, demonstrate that it generates intracellular membrane potential profiles that closely match those observed in vivo, addresses several criticisms aimed at pure oscillatory interference and continuous attractor models, and provides testable predictions for future empirical studies.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UBMY387T\\Bush, Burgess - 2014 - A hybrid oscillatory interferencecontinuous attractor network model of grid cell firing.pdf},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  keywords = {Animals,Biological Clocks,Biological Clocks: physiology,Computer Simulation,Entorhinal Cortex,Entorhinal Cortex: cytology,Environment,Models,Nerve Net,Nerve Net: physiology,Neurological,Neurons,Neurons: physiology,Nonlinear Dynamics,Space Perception,Space Perception: physiology},
  number = {14},
  pmid = {24695724}
}

@article{bush_burgess_2014a,
  title = {What Do Grid Cells Contribute to Place Cell Firing?},
  author = {Bush, Daniel and Barry, Caswell and Burgess, Neil},
  year = {2014},
  volume = {37},
  pages = {136--145},
  issn = {01662236},
  doi = {10.1016/j.tins.2013.12.003},
  abstract = {The unitary firing fields of hippocampal place cells are commonly assumed to be generated by input from entorhinal grid cell modules with differing spatial scales. Here, we review recent research that brings this assumption into doubt. Instead, we propose that place cell spatial firing patterns are determined by environmental sensory inputs, including those representing the distance and direction to environmental boundaries, while grid cells provide a complementary self-motion related input that contributes to maintaining place cell firing. In this view, grid and place cell firing patterns are not successive stages of a processing hierarchy, but complementary and interacting representations that work in combination to support the reliable coding of large-scale space. \textcopyright{} 2014 Elsevier Ltd.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TCEP87FT\\Bush, Barry, Burgess - 2014 - What do grid cells contribute to place cell firing.pdf},
  journal = {Trends in Neurosciences},
  keywords = {Border cells,Boundary vector cells,Grid cells,Hippocampus,Place cells},
  number = {3},
  pmid = {24485517}
}

@article{bush_burgess_2015,
  title = {Using {{Grid Cells}} for {{Navigation}}},
  author = {Bush, Daniel and Barry, Caswell and Manson, Daniel and Burgess, Neil},
  year = {2015},
  volume = {87},
  pages = {507--520},
  issn = {08966273},
  doi = {10.1016/j.neuron.2015.07.006},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6PYWZLLU\\Bush et al. - 2015 - Using Grid Cells for Navigation.pdf},
  journal = {Neuron},
  number = {3}
}

@article{buzsaki_tingley_2018,
  title = {Space and {{Time}}: {{The Hippocampus}} as a {{Sequence Generator}}},
  shorttitle = {Space and {{Time}}},
  author = {Buzs{\'a}ki, Gy{\"o}rgy and Tingley, David},
  year = {2018},
  month = oct,
  volume = {22},
  pages = {853--869},
  issn = {13646613},
  doi = {10.1016/j.tics.2018.07.006},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Q5GMAP4U\\Buzsáki and Tingley - 2018 - Space and Time The Hippocampus as a Sequence Gene.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {10}
}

@book{buzsaki_wise_2015,
  title = {Tools for Probing Local Circuits: {{High}}-Density Silicon Probes Combined with Optogenetics},
  author = {Buzsaki, Gyorgy and Stark, Eran and Berenyi, Antal and Khodagholy, Dion and Kipke, Daryl R and Yoon, Euisik and Wise, Kensall D},
  year = {2015},
  volume = {86},
  doi = {10.1016/j.neuron.2015.01.028},
  abstract = {To understand how function arises from the interactions between neurons, it is necessary to use methods that allow the monitoring of brain activity at the single-neuron, single-spike level and the targeted manipulation of the diverse neuron types selectively in a closed-loop manner. Large-scale recordings of neuronal spiking combined with optogenetic perturbation of identified individual neurons has emerged as a suitable method for such tasks in behaving animals. To fully exploit the potential power of these methods, multiple steps of technical innovation are needed. We highlight the current state of the art in electrophysiological recording methods, combined with optogenetics, and discuss directions for progress. In addition, we point to areas where rapid development is in progress and discuss topics where near-term improvements are possible and needed.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AXTHCT9M\\Buzsaki et al. - 2015 - Tools for probing local circuits High-density silicon probes combined with optogenetics.pdf},
  isbn = {doi:10.1016/j.neuron.2015.01.028},
  pmid = {25856489}
}

@book{cabeza_moscovitch_2018,
  title = {Process-{{Specific Alliances}} ({{PSAs}}) in {{Cognitive Neuroscience}}},
  author = {Cabeza, Roberto and Stanley, Matthew L and Moscovitch, Morris},
  year = {2018},
  doi = {10.1016/j.tics.2018.08.005},
  abstract = {Most cognitive neuroscience theories have focused on the functions of individual brain regions, but cognitive abilities depend also on functional interactions among multiple regions. Many recent studies on these interactions have examined large-scale, resting-state networks, but these networks are difficult to link to theories about specific cognitive processes. Cognitive theories are easier to link to the mini-networks we call process specific alliances (PSAs). A PSA is a small team of brain regions that rapidly assemble to mediate a cognitive process in response to task demands but quickly disassemble when the process is no longer needed. We compare PSAs to resting-state networks and to other connectivity-based, task-related networks, and we characterize the advantages and disadvantages of each type of network.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\THYUVR37\\Cabeza, Stanley, Moscovitch - 2018 - Process-Specific Alliances (PSAs) in Cognitive Neuroscience.pdf},
  keywords = {cognition,fmri,function,networks,process}
}

@article{cacucci_okeefe_2007,
  title = {Experience-Dependent Increase in {{CA1}} Place Cell Spatial Information, but Not Spatial Reproducibility, Is Dependent on the Autophosphorylation of the Alpha-Isoform of the Calcium/Calmodulin-Dependent Protein Kinase {{II}}.},
  author = {Cacucci, Francesca and Wills, Thomas J and Lever, Colin and Giese, Karl Peter and O'Keefe, John},
  year = {2007},
  volume = {27},
  pages = {7854--7859},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.1704-07.2007},
  abstract = {Place cells in hippocampal area CA1 are essential for spatial learning and memory. Here, we examine whether daily exposure to a previously unexplored environment can alter place cell properties. We demonstrate two previously unreported slowly developing plasticities in mouse place fields: both the spatial tuning and the trial-to-trial reproducibility of CA1 place fields improve over days. We asked whether these two components of improved spatial coding rely on the alpha-isoform of the calcium/calmodulin-dependent protein kinase II (alphaCaMKII) autophosphorylation, an effector mechanism of NMDA receptor-dependent long-term potentiation and an essential molecular process for spatial memory formation. We show that, in mice with deficient autophosphorylation of alphaCaMKII, the spatial tuning of place fields is initially similar to that of wild-type mice, but completely fails to show the experience-dependent increase over days. In contrast, place field reproducibility in the mutants, although impaired, does show the experience-dependent increase over days. Consequently, the progressive improvement in spatial coding in new hippocampal place cell maps depends on the existence of two molecularly dissociable, experience-dependent processes.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HRSLJS4M\\Cacucci et al. - 2007 - Experience-dependent increase in CA1 place cell spatial information, but not spatial reproducibility, is depende.pdf},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  keywords = {camkii,hippocampus,ltp,place cells,plasticity,spatial memory},
  number = {29},
  pmid = {17634379}
}

@article{cakan_obermayer_2020,
  title = {Biophysically Grounded Mean-Field Models of Neural Populations under Electrical Stimulation},
  author = {Cakan, Caglar and Obermayer, Klaus},
  editor = {Morrison, Abigail},
  year = {2020},
  month = apr,
  volume = {16},
  pages = {e1007822},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1007822},
  abstract = {Electrical stimulation of neural systems is a key tool for understanding neural dynamics and ultimately for developing clinical treatments. Many applications of electrical stimulation affect large populations of neurons. However, computational models of large networks of spiking neurons are inherently hard to simulate and analyze. We evaluate a reduced meanfield model of excitatory and inhibitory adaptive exponential integrate-and-fire (AdEx) neurons which can be used to efficiently study the effects of electrical stimulation on large neural populations. The rich dynamical properties of this basic cortical model are described in detail and validated using large network simulations. Bifurcation diagrams reflecting the network's state reveal asynchronous up- and down-states, bistable regimes, and oscillatory regions corresponding to fast excitation-inhibition and slow excitation-adaptation feedback loops. The biophysical parameters of the AdEx neuron can be coupled to an electric field with realistic field strengths which then can be propagated up to the population description. We show how on the edge of bifurcation, direct electrical inputs cause network state transitions, such as turning on and off oscillations of the population rate. Oscillatory input can frequencyentrain and phase-lock endogenous oscillations. Relatively weak electric field strengths on the order of 1 V/m are able to produce these effects, indicating that field effects are strongly amplified in the network. The effects of time-varying external stimulation are well-predicted by the mean-field model, further underpinning the utility of low-dimensional neural mass models.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EWN9FRKX\\Cakan and Obermayer - 2020 - Biophysically grounded mean-field models of neural.pdf},
  journal = {PLOS Computational Biology},
  language = {en},
  number = {4}
}

@article{calabrese_woolley_2011,
  title = {A Generalized Linear Model for Estimating Spectrotemporal Receptive Fields from Responses to Natural Sounds},
  author = {Calabrese, Ana and Schumacher, Joseph W and Schneider, David M and Paninski, Liam and Woolley, Sarah M.N.},
  year = {2011},
  volume = {6},
  pages = {16104},
  issn = {19326203},
  doi = {10.1371/journal.pone.0016104},
  abstract = {In the auditory system, the stimulus-response properties of single neurons are often described in terms of the spectrotemporal receptive field (STRF), a linear kernel relating the spectrogram of the sound stimulus to the instantaneous firing rate of the neuron. Several algorithms have been used to estimate STRFs from responses to natural stimuli; these algorithms differ in their functional models, cost functions, and regularization methods. Here, we characterize the stimulus-response function of auditory neurons using a generalized linear model (GLM). In this model, each cell's input is described by: 1) a stimulus filter (STRF); and 2) a post-spike filter, which captures dependencies on the neuron's spiking history. The output of the model is given by a series of spike trains rather than instantaneous firing rate, allowing the prediction of spike train responses to novel stimuli. We fit the model by maximum penalized likelihood to the spiking activity of zebra finch auditory midbrain neurons in response to conspecific vocalizations (songs) and modulation limited (ml) noise. We compare this model to normalized reverse correlation (NRC), the traditional method for STRF estimation, in terms of predictive power and the basic tuning properties of the estimated STRFs. We find that a GLM with a sparse prior predicts novel responses to both stimulus classes significantly better than NRC. Importantly, we find that STRFs from the two models derived from the same responses can differ substantially and that GLM STRFs are more consistent between stimulus classes than NRC STRFs. These results suggest that a GLM with a sparse prior provides a more accurate characterization of spectrotemporal tuning than does the NRC method when responses to complex sounds are studied in these neurons.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\I57AESUP\\Calabrese et al. - 2011 - A generalized linear model for estimating spectrotemporal receptive fields from responses to natural sounds.pdf},
  journal = {PLoS ONE},
  number = {1},
  pmid = {21264310}
}

@article{caligiore_baldassarre_2019,
  title = {The Super-Learning Hypothesis: {{Integrating}} Learning Processes across Cortex, Cerebellum and Basal Ganglia},
  shorttitle = {The Super-Learning Hypothesis},
  author = {Caligiore, Daniele and Arbib, Michael A. and Miall, R. Chris and Baldassarre, Gianluca},
  year = {2019},
  month = may,
  volume = {100},
  pages = {19--34},
  issn = {01497634},
  doi = {10.1016/j.neubiorev.2019.02.008},
  abstract = {Despite wide evidence suggesting anatomical and functional interactions between cortex, cerebellum and basal ganglia, the learning processes operating within them \textendash often viewed as respectively unsupervised, supervised and reinforcement learning\textendash{} are studied in isolation, neglecting their strong interdependence. We discuss how those brain areas form a highly integrated system combining different learning mechanisms into an effective super-learning process supporting the acquisition of flexible motor behaviour. The term ``super-learning'' does not indicate a new learning paradigm. Rather, it refers to the fact that different learning mechanisms act in synergy as they: (a) affect neural structures often relying on the widespread action of neuromodulators; (b) act within various stages of cortical/subcortical pathways that are organised in pipeline to support multiple sensation-toaction mappings operating at different levels of abstraction; (c) interact through the reciprocal influence of the output compartments of different brain structures, most notably in the cerebello-cortical and basal gangliacortical loops. Here we articulate this new hypothesis and discuss empirical evidence supporting it by specifically referring to motor adaptation and sequence learning.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\C6GG7LG2\\Caligiore et al. - 2019 - The super-learning hypothesis Integrating learnin.pdf},
  journal = {Neuroscience \& Biobehavioral Reviews},
  language = {en}
}

@article{campbell_giocomo_2018,
  title = {{{REVIEW Where Are You Going}}? {{The Neurobiology}} of {{Navigation}}},
  author = {Campbell, Malcolm G and Giocomo, Lisa M},
  year = {2018},
  volume = {120},
  pages = {2091--2106},
  doi = {10.1152/jn.00686},
  abstract = {Campbell MG, Giocomo LM. Self-motion processing in visual and entorhinal cortices: inputs, integration, and implications for position coding.The sensory signals generated by self-motion are complex and multimodal, but the ability to integrate these signals into a unified self-motion percept to guide navigation is essential for animal survival. Here, we summarize classic and recent work on self-motion coding in the visual and entorhinal cortices of the rodent brain. We compare motion processing in rodent and primate visual cortices, highlighting the strengths of classic primate work in establishing causal links between neural activity and perception, and discuss the integration of motor and visual signals in rodent visual cortex. We then turn to the medial entorhinal cortex (MEC), where calculations using self-motion to update position estimates are thought to occur. We focus on several key sources of self-motion information to MEC: the medial septum, which provides locomotor speed information; visual cortex, whose input has been increasingly recognized as essential to both position and speed-tuned MEC cells; and the head direction system, which is a major source of directional information for self-motion estimates. These inputs create a large and diverse group of self-motion codes in MEC, and great interest remains in how these self-motion codes might be integrated by MEC grid cells to estimate position. However, which signals are used in these calculations and the mechanisms by which they are integrated remain controversial. We end by proposing future experiments that could further our understanding of the interactions between MEC cells that code for self-motion and position and clarify the relationship between the activity of these cells and spatial perception.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EFW2CNQK\\Campbell, Giocomo - 2018 - REVIEW Where Are You Going The Neurobiology of Navigation.pdf},
  journal = {J Neurophysiol}
}

@article{campbell_robson_1968,
  title = {{{GRATINGS BY F}}. {{W}}. {{CAMPBELL AND J}}. {{G}}. {{ROBSON From}} the {{Physiological Laboratory}}, {{University}} of {{Cambridge}} ({{Received}} 10 {{November}} 1967)},
  author = {Campbell, B Y F W and Robson, J G},
  year = {1968},
  pages = {551--566},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JBPW7ZY2\\Campbell, Robson - 1968 - GRATINGS BY F. W. CAMPBELL AND J. G. ROBSON From the Physiological Laboratory, University of Cambridge (Receiv.pdf},
  journal = {October}
}

@article{canolty_knight_2010,
  title = {The Functional Role of Cross-Frequency Coupling},
  author = {Canolty, Ryan T. and Knight, Robert T.},
  year = {2010},
  volume = {14},
  pages = {506--515},
  issn = {13646613},
  doi = {10.1016/j.tics.2010.09.001},
  abstract = {Recent studies suggest that cross-frequency coupling (CFC) might play a functional role in neuronal computation, communication and learning. In particular, the strength of phase-amplitude CFC differs across brain areas in a task-relevant manner, changes quickly in response to sensory, motor and cognitive events, and correlates with performance in learning tasks. Importantly, whereas high-frequency brain activity reflects local domains of cortical processing, low-frequency brain rhythms are dynamically entrained across distributed brain regions by both external sensory input and internal cognitive events. CFC might thus serve as a mechanism to transfer information from large-scale brain networks operating at behavioral timescales to the fast, local cortical processing required for effective computation and synaptic modification, thus integrating functional systems across multiple spatiotemporal scales. ?? 2010 Elsevier Ltd.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UUGGK65F\\Canolty, Knight - 2010 - The functional role of cross-frequency coupling.pdf},
  journal = {Trends in Cognitive Sciences},
  number = {11},
  pmid = {20932795}
}

@article{capotosto_corbetta_2009,
  title = {Frontoparietal {{Cortex Controls Spatial Attention}} through {{Modulation}} of {{Anticipatory Alpha Rhythms}}},
  author = {Capotosto, P. and Babiloni, C. and Romani, G. L. and Corbetta, M.},
  year = {2009},
  month = may,
  volume = {29},
  pages = {5863--5872},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0539-09.2009},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EYIIR8KT\\Capotosto et al. - 2009 - Frontoparietal Cortex Controls Spatial Attention t.pdf},
  journal = {Journal of Neuroscience},
  language = {en},
  number = {18}
}

@article{carandini_carandini_2012,
  title = {From Circuits to Behavior: A Bridge Too Far?},
  shorttitle = {From Circuits to Behavior},
  author = {Carandini, Matteo},
  year = {2012},
  month = apr,
  volume = {15},
  pages = {507--509},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn.3043},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9RYF4BFJ\\Carandini - 2012 - From circuits to behavior a bridge too far.pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {4}
}

@article{carhart-harris_hopkins_2014,
  title = {The Entropic Brain: A Theory of Conscious States Informed by Neuroimaging Research with Psychedelic Drugs},
  author = {{Carhart-Harris}, Robin L and Leech, Robert and Hellyer, Peter J and Shanahan, Murray and Feilding, Amanda and Tagliazucchi, Enzo and Chialvo, Dante R and Nutt, David and Axmacher, Nikolai and Brooks, Samantha J and Maclean, Katherine and Hopkins, Johns},
  year = {2014},
  doi = {10.3389/fnhum.2014.00020},
  abstract = {Entropy is a dimensionless quantity that is used for measuring uncertainty about the state of a system but it can also imply physical qualities, where high entropy is synonymous with high disorder. Entropy is applied here in the context of states of consciousness and their associated neurodynamics, with a particular focus on the psychedelic state. The psychedelic state is considered an exemplar of a primitive or primary state of consciousness that preceded the development of modern, adult, human, normal waking consciousness. Based on neuroimaging data with psilocybin, a classic psychedelic drug, it is argued that the defining feature of "primary states" is elevated entropy in certain aspects of brain function, such as the repertoire of functional connectivity motifs that form and fragment across time. Indeed, since there is a greater repertoire of connectivity motifs in the psychedelic state than in normal waking consciousness, this implies that primary states may exhibit "criticality," i.e., the property of being poised at a "critical" point in a transition zone between order and disorder where certain phenomena such as power-law scaling appear. Moreover, if primary states are critical, then this suggests that entropy is suppressed in normal waking consciousness, meaning that the brain operates just below criticality. It is argued that this entropy suppression furnishes normal waking consciousness with a constrained quality and associated metacognitive functions, including reality-testing and self-awareness. It is also proposed that entry into primary states depends on a collapse of the normally highly organized activity within the default-mode network (DMN) and a decoupling between the DMN and the medial temporal lobes (which are normally significantly coupled). These hypotheses can be tested by examining brain activity and associated cognition in other candidate primary states such as rapid eye movement (REM) sleep and early psychosis and comparing these with non-primary states such as normal waking consciousness and the anaesthetized state.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PG9P8E3D\\Carhart-Harris et al. - 2014 - The entropic brain a theory of conscious states informed by neuroimaging research with psychedelic drugs.pdf}
}

@article{carpenter_grossberg_1987,
  title = {A Massively Parallel Architecture for a Self-Organizing Neural Pattern Recognition Machine},
  author = {Carpenter, Gail and Grossberg, Stephen},
  year = {1987},
  volume = {37},
  pages = {54--115},
  issn = {0734189X},
  doi = {10.1016/S0734-189X(87)80014-2},
  abstract = {A class of adaptive resonance theory (ART) models for learning, recognition, and prediction with arbitrarily distributed code representations is introduced. Distributed ART neural networks combine the stable fast learning capabilities of winner-take-all ART systems with the noise tolerance and code compression capabilities of multilayer perceptrons. With a winner-take-all code, the unsupervised model dART reduces to fuzzy ART and the supervised model dARTMAP reduces to fuzzy ARTMAP. With a distributed code, these networks automatically apportion learned changes according to the degree of activation of each coding node, which permits fast as well as slow learning without catastrophic forgetting. Distributed ART models replace the traditional neural network path weight with a dynamic weight equal to the rectified difference between coding node activation and an adaptive threshold. Thresholds increase monotonically during learning according to a principle of atrophy due to disuse. However, monotonic change at the synaptic level manifests itself as bidirectional change at the dynamic level, where the result of adaptation resembles long-term potentiation (LTP) for single-pulse or low frequency test inputs but can resemble long-term depression (LTD) for higher frequency test inputs. This paradoxical behavior is traced to dual computational properties of phasic and tonic coding signal components. A parallel distributed match-reset-search process also helps stabilize memory. Without the match-reset-search system, dART becomes a type of distributed competitive learning network.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TVKUJ5LX\\Carpenter, Grossberg - 1987 - A massively parallel architecture for a self-organizing neural pattern recognition machine.pdf},
  journal = {Computer Vision, Graphics, and Image Processing},
  pmid = {17439963}
}

@article{carreiras_barber_2005,
  title = {Early Event-Related Potential Effects of Syllabic Processing during Visual Word Recognition},
  author = {Carreiras, Manuel and Vergara, Marta and Barber, Horacio},
  year = {2005},
  volume = {17},
  pages = {1803--1817},
  issn = {0898-929X},
  doi = {10.1162/089892905774589217},
  abstract = {A number of behavioral studies have suggested that syllables might play an important role in visual word recognition in some languages. We report two event-related potential (ERP) experiments using a new paradigm showing that syllabic units modulate early ERP components. In Experiment 1, words and pseudowords were presented visually and colored so that there was a match or a mismatch between the syllable boundaries and the color boundaries. The results showed color-syllable congruency effects in the time window of the P200. Lexicality modulated the N400 amplitude, but no effects of this variable were obtained at the P200 window. In Experiment 2, high- and low-frequency words and pseudowords were presented in the congruent and incongruent conditions. The results again showed congruency effects at the P200 for low-frequency words and pseudowords, but not for high-frequency words. Lexicality and lexical frequency effects showed up at the N400 component. The results suggest a dissociation between syllabic and lexical effects with important consequences for models of visual word recognition.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NPB6TY7W\\Carreiras, Vergara, Barber - 2005 - Early event-related potential effects of syllabic processing during visual word recognition.pdf},
  journal = {Journal of Cognitive Neuroscience},
  keywords = {Brain Mapping,Data Interpretation,Electroencephalography,Electroencephalography: methods,Evoked Potentials,Female,Humans,Male,Photic Stimulation,Photic Stimulation: methods,Reaction Time,Reaction Time: physiology,Recognition (Psychology),Recognition (Psychology): physiology,Statistical,Time Factors,Verbal Learning,Verbal Learning: physiology,Visual,Visual Perception,Visual Perception: physiology,Visual: physiology},
  number = {11},
  pmid = {16269115}
}

@article{carrere_alexandre_2015,
  title = {A Pavlovian Model of the Amygdala and Its Influence within the Medial Temporal Lobe.},
  author = {Carrere, Maxime and Alexandre, Fr{\'e}d{\'e}ric},
  year = {2015},
  volume = {9},
  pages = {41},
  issn = {1662-5137},
  doi = {10.3389/fnsys.2015.00041},
  abstract = {Recent advances in neuroscience give us a better view of the inner structure of the amygdala, of its relations with other regions in the Medial Temporal Lobe (MTL) and of the prominent role of neuromodulation. They have particularly shed light on two kinds of neurons in the basal nucleus of the amygdala, the so-called fear neurons and extinction neurons. Fear neurons mediate context-dependent fear by receiving contextual information from the hippocampus, whereas extinction neurons are linked with the medial prefrontal cortex (mPFC) and involved in fear extinction. The computational model of the amygdala that we describe in this paper is primarily a model of pavlovian conditioning, but its architecture also emphasizes the central role of the amygdala in the MTL memory processes through three main information flows. (i) Thalamic and higher order sensory cortical inputs including from the perirhinal cortex are received in the lateral amygdalar nucleus, where CS-US associations can be acquired. (ii) These associations are subsequently modulated, in the basal nucleus of the amygdala, by contextual inputs coming from the hippocampus and the mPFC. Basal fear and extinction neurons indicate the currently valid association to their main targets including in the MTL and the mPFC. (iii) The competition for the choice of the pavlovian response is ultimately performed by projection of these amygdalar neurons in the central nucleus of the amygdala where, beyond motor responding, a hormonal response, including cholinergic modulation, is also triggered via the basal forebrain. In turn, acetylcholine modulates activation in the basal nucleus and facilitates learning in the hippocampus. Based on biologically founded arguments, our model replicates a number of biological experiments, proposes some predictions about the role of amygdalar regions and describes pavlovian conditioning as a distributed systemic learning, binding memory processes in the MTL.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IBZHILWV\\Carrere, Alexandre - 2015 - A pavlovian model of the amygdala and its influence within the medial temporal lobe.pdf},
  journal = {Frontiers in systems neuroscience},
  keywords = {amygdala,hippocampus,pavlovian conditioning,per},
  pmid = {25852499}
}

@article{caruso_groh_2018,
  title = {Single Neurons May Encode Simultaneous Stimuli by Switching between Activity Patterns},
  author = {Caruso, Valeria C. and Mohl, Jeff T. and Glynn, Christopher and Lee, Jungah and Willett, Shawn M. and Zaman, Azeem and Ebihara, Akinori F. and Estrada, Rolando and Freiwald, Winrich A. and Tokdar, Surya T. and Groh, Jennifer M.},
  year = {2018},
  month = dec,
  volume = {9},
  issn = {2041-1723},
  doi = {10.1038/s41467-018-05121-8},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\K6ANGAJI\\Caruso et al. - 2018 - Single neurons may encode simultaneous stimuli by .pdf},
  journal = {Nature Communications},
  language = {en},
  number = {1}
}

@article{casanova_espeland_2013,
  title = {Alzheimer's {{Disease Risk Assessment Using Large}}-{{Scale Machine Learning Methods}}},
  author = {Casanova, Ramon and Hsu, Fang-Chi and Sink, Kaycee M. and Rapp, Stephen R. and Williamson, Jeff D. and Resnick, Susan M. and a. Espeland, Mark},
  year = {2013},
  volume = {8},
  pages = {e77949},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0077949},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YBKXG5Z5\\Casanova et al. - 2013 - Alzheimer's Disease Risk Assessment Using Large-Scale Machine Learning Methods.pdf},
  journal = {PLoS ONE},
  number = {11}
}

@book{cassel_pereiradevasconcelos_2015,
  title = {Importance of the Ventral Midline Thalamus in Driving Hippocampal Functions},
  author = {Cassel, Jean-Christophe and {Pereira de Vasconcelos}, Anne},
  year = {2015},
  edition = {First},
  volume = {219},
  publisher = {{Elsevier B.V.}},
  doi = {10.1016/bs.pbr.2015.03.005},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\M5IQNHYX\\Cassel, Pereira de Vasconcelos - 2015 - Importance of the ventral midline thalamus in driving hippocampal functions.pdf},
  keywords = {hippocampus,Hippocampus,medial prefrontal cortex,Medial prefrontal cortex,memory consolidation,Memory consolidation,memory generalization,Memory generalization,reuniens nucleus,Reuniens nucleus,rhomboid nucleus,Rhomboid nucleus,spatial memory,Spatial memory,theta rhythm,Theta rhythm,ventral midline thal-,Ventral midline thalamus,working-memory}
}

@article{castellani_cooper_1999,
  title = {Solutions of the {{BCM}} Learning Rule in a Network of Lateral Interacting Nonlinear Neurons},
  author = {Castellani, G C and Intrator, N and Shouval, H and Cooper, L N},
  year = {1999},
  volume = {10},
  pages = {111--121},
  issn = {0954-898X},
  doi = {10.1088/0954-898X/10/2/001},
  abstract = {We introduce a new method for obtaining the fixed points for neurons that follow the BCM learning rule. The new formalism, which is based on the objective function formulation, permits analysis of a laterally connected network of nonlinear neurons and allows explicit calculation of the fixed points under various network conditions. We show that the stable fixed points, in terms of the postsynaptic activity, are not altered by the lateral connectivity or nonlinearity. We show that the lateral connectivity alters the probability of attaining different states in a network of interacting neurons. We further show the exact alteration in presynaptic weights as a result of the neuronal nonlinearity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\P7ND6ML7\\Castellani - 1999 - Solutions of the BCM learning rule in a network of lateral interacting nonlinear neurons.pdf},
  journal = {Network},
  pmid = {10378187}
}

@article{castro_aguiar_2014,
  title = {A Feedforward Model for the Formation of a Grid Field Where Spatial Information Is Provided Solely from Place Cells},
  author = {Castro, Lu{\'i}sa and Aguiar, Paulo},
  year = {2014},
  volume = {108},
  pages = {133--143},
  issn = {14320770},
  doi = {10.1007/s00422-013-0581-3},
  abstract = {Grid cells (GCs) in the medial entorhinal cortex (mEC) have the property of having their firing activity spatially tuned to a regular triangular lattice. Several theoretical models for grid field formation have been proposed, but most assume that place cells (PCs) are a product of the grid cell system. There is, however, an alternative possibility that is supported by various strands of experimental data. Here we present a novel model for the emergence of gridlike firing patterns that stands on two key hypotheses: (1) spatial information in GCs is provided from PC activity and (2) grid fields result from a combined synaptic plasticity mechanism involving inhibitory and excitatory neurons mediating the connections between PCs and GCs. Depending on the spatial location, each PC can contribute with excitatory or inhibitory inputs to GC activity. The nature and magnitude of the PC input is a function of the distance to the place field center, which is inferred from rate decoding. A biologically plausible learning rule drives the evolution of the connection strengths from PCs to a GC. In this model, PCs compete for GC activation, and the plasticity rule favors efficient packing of the space representation. This leads to gridlike firing patterns. In a new environment, GCs continuously recruit new PCs to cover the entire space. The model described here makes important predictions and can represent the feedforward connections from hippocampus CA1 to deeper mEC layers.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EVV4NCKY\\Castro, Aguiar - 2014 - A feedforward model for the formation of a grid field where spatial information is provided solely from place ce.pdf},
  journal = {Biological Cybernetics},
  keywords = {Combined plasticity rule,Competition,Efficient packing,Grid cells,Inhibitory neurons plasticity,Place cells},
  number = {2},
  pmid = {24577877}
}

@article{catrambone_nersessian_2006,
  title = {The Role of Perceptually Represented Structure in Analogical Problem Solving.},
  author = {Catrambone, Richard and Craig, David L and Nersessian, Nancy J},
  year = {2006},
  volume = {34},
  pages = {1126--1132},
  issn = {0090-502X},
  doi = {10.3758/BF03193258},
  abstract = {Current models of analogical reasoning assume that representations of source examples and target problems occur in an amodal format\textendash that is, a representation whose construction and processing are independent of activity in the perceptual and motor cortices of the brain. We examined the possible use of kinesthetic information\textendash perceptual structures associated with the sensation of space and force\textendash in the representation of source examples and target problems. Participants who recreated a source story while acting out the key elements were more likely to access the story when later working on the target problem than were participants who only verbally recreated the story or who verbally recreated it as well as sketched it. We argue that enactment made kinesthetic and spatial features more salient in participants' source story representations and that this aided performance. These results suggest that current models of analogical reasoning might be improved by including perceptual information as part of their representational schemes.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4S7WA8XG\\Catrambone, Craig, Nersessian - 2006 - The role of perceptually represented structure in analogical problem solving.pdf},
  journal = {Memory \& cognition},
  number = {5},
  pmid = {17128610}
}

@article{cavdar_aker_2008,
  title = {The Pathways Connecting the Hippocampal Formation, the Thalamic Reuniens Nucleus and the Thalamic Reticular Nucleus in the Rat.},
  author = {Cavdar, Safiye and Onat, Filiz Y and Cakmak, Yusuf Ozg{\"u}r and Yananli, Hasan R and G{\"u}l{\c c}ebi, Medine and Aker, Rezzan},
  year = {2008},
  month = mar,
  volume = {212},
  pages = {249--256},
  issn = {1469-7580},
  doi = {10.1111/j.1469-7580.2008.00858.x},
  abstract = {Most dorsal thalamic nuclei send axons to specific areas of the neocortex and to specific sectors of the thalamic reticular nucleus; the neocortex then sends reciprocal connections back to the same thalamic nucleus, directly as well indirectly through a relay in the thalamic reticular nucleus. This can be regarded as a 'canonical' circuit of the sensory thalamus. For the pathways that link the thalamus and the hippocampal formation, only a few comparable connections have been described. The reuniens nucleus of the thalamus sends some of its major cortical efferents to the hippocampal formation. The present study shows that cells of the hippocampal formation as well as cells in the reuniens nucleus are retrogradely labelled following injections of horseradish peroxidase or fluoro-gold into the rostral part of the thalamic reticular nucleus in the rat. Within the hippocampal formation, labelled neurons were localized in the subiculum, predominantly on the ipsilateral side, with fewer neurons labelled contralaterally. Labelled neurons were seen in the hippocampal formation and nucleus reuniens only after injections made in the rostral thalamic reticular nucleus (1.6-1.8 mm caudal to bregma). In addition, the present study confirmed the presence of afferent connections to the rostral thalamic reticular nucleus from cortical (cingulate, orbital and infralimbic, retrosplenial and frontal), midline thalamic (paraventricular, anteromedial, centromedial and mediodorsal thalamic nuclei) and brainstem structures (substantia nigra pars reticularis, ventral tegmental area, periaqueductal grey, superior vestibular and pontine reticular nuclei). These results demonstrate a potential for the thalamo-hippocampal circuitry to influence the functional roles of the thalamic reticular nucleus, and show that thalamo-hippocampal connections resemble the circuitry that links the sensory thalamus and neocortex.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JPHX8AP3\\Cavdar et al. - 2008 - The pathways connecting the hippocampal formation, the thalamic reuniens nucleus and the thalamic reticular nucle.pdf},
  journal = {Journal of anatomy},
  keywords = {Animals,Brain Stem,Brain Stem: anatomy {\&} histology,Brain Stem: anatomy \& histology,Cell Count,Coloring Agents,Fluorescence,Hippocampus,Hippocampus: anatomy {\&} histology,Hippocampus: anatomy \& histology,Horseradish Peroxidase,Microscopy,Midline Thalamic Nuclei,Midline Thalamic Nuclei: anatomy {\&} histology,Midline Thalamic Nuclei: anatomy \& histology,Neurons,Neurons: cytology,Rats,Staining and Labeling,Stilbamidines,Ventral Thalamic Nuclei,Ventral Thalamic Nuclei: anatomy {\&} histology,Ventral Thalamic Nuclei: anatomy \& histology},
  number = {3},
  pmid = {18221482}
}

@article{cayco-gajic_silver_2019,
  title = {Re-Evaluating {{Circuit Mechanisms Underlying Pattern Separation}}},
  author = {{Cayco-Gajic}, N. Alex and Silver, R. Angus},
  year = {2019},
  month = feb,
  volume = {101},
  pages = {584--602},
  issn = {08966273},
  doi = {10.1016/j.neuron.2019.01.044},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BUU8VVJA\\Cayco-Gajic and Silver - 2019 - Re-evaluating Circuit Mechanisms Underlying Patter.pdf},
  journal = {Neuron},
  language = {en},
  number = {4}
}

@article{cer_oreilly_2012,
  title = {Neural Mechanisms of Binding in the Hippocampus and Neocortex: {{Insights}} from Computational Models},
  author = {Cer, Daniel M. and O'Reilly, Randall C},
  year = {2012},
  pages = {1--19},
  doi = {10.1093/acprof:oso/9780198529675.003.0008},
  abstract = {An account of the neurological mechanisms that underlie binding is given which is characterized by the decomposition of the binding problem into three distinct subproblems. Each subproblem is then supported by anatomically specialized brain regions. The posterior cortex employs coarse-coded dis-tributed representations of low-order conjunctions to resolve binding ambiguities, while also supporting systematic generalization to novel stimuli and situations. These representations are slowly acquired over experience. The hippocampus can more rapidly bind higher-order conjunctions of information such as episodes or locations. Finally, the prefrontal cortex supports transient, actively maintained bindings that are used in the service of working memory. We argue that this approach to the binding problem compares favorably with those based on temporal synchrony binding.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TUZTX5Z3\\Cer, O'Reilly - 2012 - Neural mechanisms of binding in the hippocampus and neocortex Insights from computational models.pdf},
  journal = {Handbook of Binding and Memory: Perspectives from Cognitive Neuroscience},
  keywords = {Binding,Hippocampus,Neural mechanisms,Posterior cortex,Prefrontal cortex}
}

@article{chakravarthy_balasubramani_2011,
  title = {Nest},
  author = {Chakravarthy, Srinivasa and Balasubramani, Pragathi Priyadharsini},
  year = {2011},
  volume = {525},
  pages = {40--45},
  issn = {12282472},
  doi = {10.1007/978-1-4614-6675-8},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ISK5KPUN\\Chakravarthy, Balasubramani - 2011 - Nest.pdf},
  journal = {Space},
  number = {March}
}

@article{chalk_deneve_2016,
  title = {Neural Oscillations as a Signature of Efficient Coding in the Presence of Synaptic Delays},
  author = {Chalk, Matthew and Gutkin, Boris and Deneve, Sophie},
  year = {2016},
  pages = {23},
  abstract = {Cortical networks exhibit 'global oscillations', in which neural spike times are entrained to an underlying oscillatory rhythm, but where individual neurons fire irregularly, on only a fraction of cycles. While the network dynamics underlying global oscillations have been well characterised, their function is debated. Here, we show that such global oscillations are a direct consequence of optimal efficient coding in spiking networks with synaptic delays and noise. To avoid firing unnecessary spikes, neurons need to share information about the network state. Ideally, membrane potentials should be strongly correlated and reflect a 'prediction error' while the spikes themselves are uncorrelated and occur rarely. We show that the most efficient representation is when: (i) spike times are entrained to a global Gamma rhythm (implying a consistent representation of the error); but (ii) few neurons fire on each cycle (implying high efficiency), while (iii) excitation and inhibition are tightly balanced. This suggests that cortical networks exhibiting such dynamics are tuned to achieve a maximally efficient population code.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LZ85F47Z\\Chalk and Gutkin - Neural oscillations as a signature of efficient co.pdf},
  journal = {ELife},
  language = {en}
}

@article{chalk_tkacik_2018,
  title = {Toward a Unified Theory of Efficient, Predictive, and Sparse Coding},
  author = {Chalk, Matthew and Marre, Olivier and Tka{\v c}ik, Ga{\v s}per},
  year = {2018},
  month = jan,
  volume = {115},
  pages = {186--191},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1711114115},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CPU82L6P\\Chalk et al. - 2018 - Toward a unified theory of efficient, predictive, .pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {1}
}

@article{chang_griffiths_2018,
  title = {Automatically {{Composing Representation Transformations}} as a {{Means}} for {{Generalization}}},
  author = {Chang, Michael B. and Gupta, Abhishek and Levine, Sergey and Griffiths, Thomas L},
  year = {2018},
  abstract = {How can we build a learner that can capture the essence of what makes a hard problem more complex than a simple one, break the hard problem along characteristic lines into smaller problems it knows how to solve, and sequentially solve the smaller problems until the larger one is solved? To work towards this goal, we focus on learning to generalize in a particular family of problems that exhibit compositional and recursive structure: their solutions can be found by composing in sequence a set of reusable partial solutions. Our key idea is to recast the problem of generalization as a problem of learning algorithmic procedures: we can formulate a solution to this family as a sequential decision-making process over transformations between representations. Our formulation enables the learner to learn the structure and parameters of its own computation graph with sparse supervision, make analogies between problems by transforming one problem representation to another, and exploit modularity and reuse to scale to problems of varying complexity. Experiments on solving a variety of multilingual arithmetic problems demonstrate that our method discovers the hierarchical decomposition of a problem into its subproblems, generalizes out of distribution to unseen problem classes, and extrapolates to harder versions of the same problem, yielding a 10-fold reduction in sample complexity compared to a monolithic recurrent neural network.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5JGGRPH2\\Chang et al. - 2018 - Automatically Composing Representation Transformations as a Means for Generalization.pdf}
}

@article{chang_juan_2016,
  title = {Theta {{Oscillation Reveals}} the {{Temporal Involvement}} of {{Different Attentional Networks}} in {{Contingent Reorienting}}},
  author = {Chang, Chi-Fu and Liang, Wei-Kuang and Lai, Chiou-Lian and Hung, Daisy L and Juan, Chi-Hung},
  year = {2016},
  volume = {10},
  pages = {1--11},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2016.00264},
  abstract = {In the visual world, rapidly reorienting to relevant objects outside the focus of attention is vital for survival. This ability from the interaction between goal-directed and stimulus- driven attentional control is termed contingent reorienting. Neuroimaging studies have demonstrated activations of the ventral and dorsal attentional networks (DANs) which exhibit right hemisphere dominance, but the temporal dynamics of the attentional networks still remain unclear. The present study used event-related potential (ERP) to index the locus of spatial attention and Hilbert-Huang transform (HHT) to acquire the time-frequency information during contingent reorienting. The ERP results showed contingent reorienting induced significant N2pc on both hemispheres. In contrast, our time-frequency analysis found further that, unlike the N2pc, theta oscillation during contingent reorienting differed between hemispheres and experimental sessions. The inter-trial coherence (ITC) of the theta oscillation demonstrated that the two sides of the attentional networks became phase-locked to contingent reorienting at different stages. The left attentional networks were associated with contingent reorienting in the first experimental session whereas the bilateral attentional networks play a more important role in this process in the subsequent session. This phase-locked information suggests a dynamic temporal evolution of the involvement of different attentional networks in contingent reorienting and a potential role of the left ventral network in the first session.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\V9L4JEWD\\Chang et al. - 2016 - Theta Oscillation Reveals the Temporal Involvement of Different Attentional Networks in Contingent Reorienting.pdf},
  journal = {Frontiers in Human Neuroscience},
  keywords = {attentional networks,contingent reorienting,inter-trial coherence,n2pc,thet,theta oscillation},
  number = {June}
}

@article{chang_metcalfe_2018,
  title = {Fronto-Insular-Parietal Network Engagement Underlying Arithmetic Word Problem Solving},
  author = {Chang, Ting-Ting and Lung, Tzu-Chen and Ng, Chan-Tat and Metcalfe, Arron W. S.},
  year = {2018},
  month = dec,
  issn = {10659471},
  doi = {10.1002/hbm.24502},
  abstract = {Mathematical word problems are ubiquitous and standard for teaching and evaluating generalization of mathematical knowledge for real-world contexts. It is therefore concerning that the neural mechanisms of word problem solving are not well understood, as these insights represent strong potential for improving education and remediating deficits in this domain. Here, we investigate neural response to word problems via functional magnetic resonance imaging (fMRI). Healthy adults performed sentence judgment tasks on word problems that either contained one-step mathematical operations, or nonarithmetic judgments on parallel narratives without any numerical information. Behavioral results suggested that the composite efficiency measurement of combining accuracy and RT did not differ between the two problem types. Arithmetic sentence judgments elicited greater activation in the fronto-insular-parietal network including intraparietal sulcus (IPS), dorsolateral prefrontal cortex (PFC), and anterior insula (AI) than narrative sentence judgment. Narrative sentence judgments, conversely, resulted in greater activation predominantly in the left ventral PFC, angular gyrus and perisylvian cortex compared with reading arithmetic sentences. Moreover, task-dependent functional connectivity analyses showed the AI circuits were more strongly coupled with IPS during arithmetic sentence judgments than nonarithmetic sentences. Finally, activations in the IPS during arithmetic were highly correlated with out-of-scanner performance on a distinct set of problems with the same characteristics. These results show arithmetic word problem performance differences may rely more heavily on fronto-insular-parietal circuits for mathematical model building than narrative text comprehension of similar difficulty. More broadly, our study suggests that quantitative measurements of brain mechanisms can provide pivotal role for uncovering crucial arithmetic skills. K E Y W O R D S brain connectivity, fMRI, individual difference, mathematical learning, posterior parietal cortex, problem solving, word problem},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\48ZZ6BZA\\Chang et al. - 2018 - Fronto-insular-parietal network engagement underlying arithmetic word problem solving.pdf},
  journal = {Human Brain Mapping}
}

@article{chao_dehaene_2018,
  title = {Large-{{Scale Cortical Networks}} for {{Hierarchical Prediction}} and {{Prediction Error}} in the {{Primate Brain}}},
  author = {Chao, Zenas C and Takaura, Kana and Wang, Liping and Fujii, Naotaka and Dehaene, Stanislas},
  year = {2018},
  volume = {100},
  pages = {1252--1266.e3},
  doi = {10.1016/j.neuron.2018.10.004},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\44I3QVJD\\Chao et al. - 2018 - Large-Scale Cortical Networks for Hierarchical Prediction and Prediction Error in the Primate Brain(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\5NDS72FK\\Chao et al. - 2018 - Large-Scale Cortical Networks for Hierarchical Prediction and Prediction Error in the Primate Brain.pdf},
  journal = {Neuron}
}

@phdthesis{chapman_chapman_2018,
  title = {A {{Model}} of {{Relational Reasoning Through Selective Attention}}},
  author = {Chapman, G William},
  year = {2018},
  abstract = {Understanding the relationship between sets of objects is a fundamental requirement of cog- nitive skills, such as learning from example or generalization. For example, recognizing that planets revolve around stars, and not the other way around, is essential for understanding astronomical systems. However, the method by which we recognize and apply such relations is not clearly under- stood. In particular, how a set of neurons is able to represent which object fulfills which role (role binding), presented difficulty in past studies. Here, we propose a systems-level model, which utilizes selective attention and working memory, to address issues of role binding. In our model, selective attention is used to perceive visual stimuli such that all relations can be reframed as an operation from one object unto another, and so binding becomes an issue only in the initial recognition of the direction of the relation. We test and refine this model, utilizing EEG during a second-order relational reasoning task. Epoched EEG was projected to the cortical surface, providing source- space estimates of event-related potentials. Permutation testing revealed 8 cortical clusters which responded differentially based on the specifics of a trial. Dynamic connectivity between these clus- ters was estimated with the directed transfer function, to reveal the dynamic causality between regions. Our results support the model, identifying a distinct bottom-up network that identifies relations between single pairs of objects, along with a top-down biasing network that may reorient attention to sequential pairs of objects. Taken together, our results show that relational reasoning can be performed by a distributed network, utilizing selective attention.},
  copyright = {All rights reserved},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4IZJMP5U\\William, Iv - 2018 - A Model of Relational Reasoning Through Selective Attention.pdf},
  school = {University of Colorado Boulder},
  type = {{{PhD Thesis}}}
}

@article{chariker_young_2018,
  ids = {chariker\_young\_2018a},
  title = {Rhythm and Synchrony in a Cortical Network Model},
  author = {Chariker, Logan and Shapley, Robert and Young, Lai-Sang},
  year = {2018},
  month = oct,
  volume = {38},
  pages = {8621--8634},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0675-18.2018},
  abstract = {We studied mechanisms for cortical gamma-band activity in the cerebral cortex and identified neurobiological factors that affect such activity. This was done by analyzing the behavior of a previously developed, data-driven, large-scale network model that simulated many visual functions of monkey V1 cortex (Chariker et al., 2016). Gamma activity was an emergent property of the model. The model's gamma activity, like that of the real cortex, was (1) episodic, (2) variable in frequency and phase, and (3) graded in power with stimulus variables like orientation. The spike firing of the model's neuronal population was only partially synchronous during multiple firing events (MFEs) that occurred at gamma rates. Detailed analysis of the model's MFEs showed that gamma-band activity was multidimensional in its sources. Most spikes were evoked by excitatory inputs. A large fraction of these inputs came from recurrent excitation within the local circuit, but feedforward and feedback excitation also contributed, either through direct pulsing or by raising the overall baseline. Inhibition was responsible for ending MFEs, but disinhibition led directly to only a small minority of the synchronized spikes. As a potential explanation for the wide range of gamma characteristics observed in different parts of cortex, we found that the relative rise times of AMPA and GABA synaptic conductances have a strong effect on the degree of synchrony in gamma. SIGNIFICANCE STATEMENT Canonical computations used throughout the cerebral cortex are performed in primary visual cortex (V1). Providing theoretical mechanisms for these computations will advance understanding of computation throughout cortex. We studied one dynamical feature, gamma-band rhythms, in a large-scale, data-driven, computational model of monkey V1. Our most significant conclusion is that the sources of gamma band activity are multidimensional. A second major finding is that the relative rise times of excitatory and inhibitory synaptic potentials have strong effects on spike synchrony and peak gamma band power. Insight gained from studying our V1 model can shed light on the functions of other cortical regions.},
  copyright = {Copyright \textcopyright{} 2018 the authors 0270-6474/18/388621-14\$15.00/0},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WARTIXDR\\Chariker et al. - 2018 - Rhythm and Synchrony in a Cortical Network Model.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\FR9J8NT9\\8621.html},
  journal = {Journal of Neuroscience},
  language = {en},
  number = {40},
  pmid = {30120205}
}

@article{chartove_kopell_2020,
  title = {A Biophysical Model of Striatal Microcircuits Suggests Delta/Theta-Rhythmically Interleaved Gamma and Beta Oscillations Mediate Periodicity in Motor Control},
  author = {Chartove, Julia A. K. and McCarthy, Michelle M. and {Pittman-Polletta}, Benjamin R. and Kopell, Nancy J.},
  editor = {Migliore, Michele},
  year = {2020},
  month = feb,
  volume = {16},
  pages = {e1007300},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1007300},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KBLPT6L4\\Chartove et al. - 2020 - A biophysical model of striatal microcircuits sugg.pdf},
  journal = {PLOS Computational Biology},
  language = {en},
  number = {2}
}

@article{chase_simon_1973,
  title = {Perception in Chess},
  author = {Chase, William G and Simon, Herbert A},
  year = {1973},
  volume = {4},
  pages = {55--81},
  issn = {00100285},
  doi = {10.1016/0010-0285(73)90004-2},
  abstract = {This paper develops a technique for isolating and studying the perceptual structures that chess players perceive. Three chess players of varying strength - from master to novice - were confronted with two tasks: (1) A perception task, where the player reproduces a chess position in plain view, and (2) de Groot's (1965) short-term recall task, where the player reproduces a chess position after viewing it for 5 sec. The successive glances at the position in the perceptual task and long pauses in the memory task were used to segment the structures in the reconstruction protocol. The size and nature of these structures were then analyzed as a function of chess skill. ?? 1973.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5ZSFL4IN\\Chase, Simon - 1973 - Perception in chess.pdf},
  journal = {Cognitive Psychology},
  number = {1},
  pmid = {22081213}
}

@article{chatham_badre_2014,
  title = {Corticostriatal Output Gating during Selection from Working Memory},
  author = {Chatham, Christopher H and Frank, Michael J and Badre, David},
  year = {2014},
  volume = {81},
  pages = {930--942},
  issn = {08966273},
  doi = {10.1016/j.neuron.2014.01.002},
  abstract = {Convergent evidence suggests that corticostriatal interactions act as a gate to select the input to working memory (WM). However, not all information in WM is relevant for behavior simultaneously. For this reason, a second "output gate" might advantageously govern which contents of WM influence behavior. Here, we test whether frontostriatal circuits previously implicated in input gating also support output gating during selection from WM. fMRI of ahierarchical rule task with dissociable input and output gating demands demonstrated greater lateral prefrontal cortex (PFC) recruitment and frontostriatal connectivity during output gating. Moreover, PFC and striatum correlated with distinct behavioral profiles. Whereas PFC recruitment correlated with mean efficiency of selection from WM, striatal recruitment and frontostriatal interactions correlated with its reliability, as though such dynamics stochastically gate WM's output. These results support the output gating hypothesis, suggesting that contextual representations in PFC influence striatum to select which information in WM drives responding. \textcopyright{} 2014 Elsevier Inc.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TI8EXBZZ\\Chatham, Frank, Badre - 2014 - Article Corticostriatal Output Gating during Selection from Working Memory.pdf},
  journal = {Neuron},
  number = {4},
  pmid = {24559680}
}

@article{chatham_badre_2015,
  title = {Multiple Gates on Working Memory},
  author = {Chatham, Christopher H and Badre, David},
  year = {2015},
  month = feb,
  volume = {1},
  pages = {23--31},
  issn = {23521546},
  doi = {10.1016/j.cobeha.2014.08.001},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UB5EQN6R\\Chatham and Badre - 2015 - Multiple gates on working memory.pdf},
  journal = {Current Opinion in Behavioral Sciences},
  language = {en}
}

@article{chatham_munakata_2012,
  title = {Cognitive {{Control Reflects Context Monitoring}}, {{Not Motoric Stopping}}, in {{Response Inhibition}}},
  author = {Chatham, Christopher H and Claus, Eric D and Kim, Albert and Curran, Tim and Banich, Marie T and Munakata, Yuko},
  year = {2012},
  volume = {7},
  pages = {e31546},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0031546},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SUEN2ELD\\Chatham et al. - 2012 - Cognitive Control Reflects Context Monitoring, Not Motoric Stopping, in Response Inhibition.pdf},
  journal = {PLoS ONE},
  number = {2}
}

@article{chaudhuri_fiete_2016,
  title = {Computational Principles of Memory},
  author = {Chaudhuri, Rishidev and Fiete, Ila},
  year = {2016},
  volume = {19},
  pages = {394--403},
  issn = {1097-6256},
  doi = {10.1038/nn.4237},
  abstract = {The ability to store and later use information is essential for a variety of adaptive behaviors, including integration, learning, generalization, prediction and inference. In this Review, we survey theoretical principles that can allow the brain to construct persistent states for memory. We identify requirements that a memory system must satisfy and analyze existing models and hypothesized biological substrates in light of these requirements. We also highlight open questions, theoretical puzzles and problems shared with computer science and information theory.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HVR7WKAS\\Chaudhuri and Fiete - 2016 - Computational principles of memory.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\L593B5AC\\Chaudhuri, Fiete - 2016 - Computational principles of memory.pdf},
  journal = {Nature Neuroscience},
  number = {3},
  pmid = {26906506}
}

@article{chaudhuri_fiete_2019,
  title = {The Intrinsic Attractor Manifold and Population Dynamics of a Canonical Cognitive Circuit across Waking and Sleep},
  author = {Chaudhuri, Rishidev and Ger{\c c}ek, Berk and Pandey, Biraj and Peyrache, Adrien and Fiete, Ila},
  year = {2019},
  month = sep,
  volume = {22},
  pages = {1512--1520},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-019-0460-x},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\94GA6ZPB\\Chaudhuri et al. - 2019 - The intrinsic attractor manifold and population dy.pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {9}
}

@article{chen_ding_2011,
  title = {Electrophysiological {{Recording Techniques}}},
  author = {Chen, Yonghong and Dhamala, Mukesh and Bollimunta, Anil and Schroeder, Charles E and Ding, Mingzhou},
  editor = {Vertes, Robert P and Stackman, Robert W},
  year = {2011},
  volume = {54},
  pages = {27--41},
  doi = {10.1007/978-1-60327-202-5},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4PSMNSY7\\Chen et al. - 2011 - Electrophysiological Recording Techniques.pdf},
  keywords = {alpha oscillations,cortical,current source density analysis,local field potential},
  series = {Neuromethods}
}

@article{chen_duvenaud_2019,
  title = {Neural {{Ordinary Differential Equations}}},
  author = {Chen, Ricky T. Q. and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David},
  year = {2019},
  month = dec,
  abstract = {We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a blackbox differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.},
  archivePrefix = {arXiv},
  eprint = {1806.07366},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YQKVFNHA\\Chen et al. - 2019 - Neural Ordinary Differential Equations.pdf},
  journal = {arXiv:1806.07366 [cs, stat]},
  language = {en},
  primaryClass = {cs, stat}
}

@article{chen_griffiths_2017,
  title = {Evaluating Vector-Space Models of Analogy},
  author = {Chen, Dawn and Peterson, Joshua C and Griffiths, Thomas L},
  year = {2017},
  abstract = {Vector-space representations provide geometric tools for reasoning about the similarity of a set of objects and their relationships. Recent machine learning methods for deriving vector-space embeddings of words (e.g., word2vec) have achieved considerable success in natural language processing. These vector spaces have also been shown to exhibit a surprising capacity to capture verbal analogies, with similar results for natural images, giving new life to a classic model of analogies as parallelograms that was first proposed by cognitive scientists. We evaluate the parallelogram model of analogy as applied to modern word embeddings, providing a detailed analysis of the extent to which this approach captures human relational similarity judgments in a large benchmark dataset. We find that that some semantic relationships are better captured than others. We then provide evidence for deeper limitations of the parallelogram model based on the intrinsic geometric constraints of vector spaces, paralleling classic results for first-order similarity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HBGDEM77\\Chen, Peterson, Griffiths - 2017 - Evaluating vector-space models of analogy.pdf},
  journal = {arXiv},
  keywords = {analogy}
}

@article{chen_jacobson_2014,
  title = {Multi-Scale Bio-Inspired Place Recognition},
  author = {Chen, Zetao and Jacobson, Adam},
  year = {2014},
  pages = {1895--1901},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KMTIU72F\\Chen, Jacobson - 2014 - Multi-scale bio-inspired place recognition.pdf},
  journal = {\{\textbackslash ldots\} (ICRA), 2014 IEEE \{\textbackslash ldots\}}
}

@article{chen_liu_2016,
  title = {Lifelong {{Machine Learning}}},
  author = {Chen, Zhiyuan and Liu, Bing},
  year = {2016},
  volume = {10},
  pages = {1--145},
  issn = {1939-4608},
  doi = {10.2200/S00737ED1V01Y201610AIM033},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EVKBY23Z\\Chen, Liu - 2016 - Lifelong Machine Learning.pdf},
  journal = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
  number = {3}
}

@article{chen_milford_2015,
  title = {Bio-Inspired Homogenous Multi-Scale Place Recognition},
  author = {Chen, Zetao and Lowry, Stephanie and Jacobson, Adam and Hasselmo, Michael E and Milford, Michael},
  year = {2015},
  issn = {08936080},
  doi = {10.1016/j.neunet.2015.10.002},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5W2UMG28\\Chen et al. - 2015 - Bio-inspired homogenous multi-scale place recognition(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\BFY9AKAU\\Chen et al. - 2015 - Bio-inspired homogenous multi-scale place recognition.pdf},
  journal = {Neural Networks}
}

@article{chen_olshausen_2018,
  title = {The {{Sparse Manifold Transform}}},
  author = {Chen, Yubei and Paiton, Dylan M. and Olshausen, Bruno A.},
  year = {2018},
  month = jun,
  abstract = {We present a signal representation framework called the sparse manifold transform that combines key ideas from sparse coding, manifold learning, and slow feature analysis. It turns non-linear transformations in the primary sensory signal space into linear interpolations in a representational embedding space while maintaining approximate invertibility. The sparse manifold transform is an unsupervised and generative framework that explicitly and simultaneously models the sparse discreteness and low-dimensional manifold structure found in natural scenes. When stacked, it also models hierarchical composition. We provide a theoretical description of the transform and demonstrate properties of the learned representation on both synthetic data and natural videos.},
  archivePrefix = {arXiv},
  eprint = {1806.08887},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\G5N3KYFU\\Chen et al. - 2018 - The Sparse Manifold Transform.pdf},
  journal = {arXiv:1806.08887 [cs, eess, stat]},
  language = {en},
  primaryClass = {cs, eess, stat}
}

@article{cheng_frank_2008,
  title = {New {{Experiences Enhance Coordinated Neural Activity}} in the {{Hippocampus}}},
  author = {Cheng, Sen and Frank, Loren M.},
  year = {2008},
  month = jan,
  volume = {57},
  pages = {303--313},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2007.11.035},
  abstract = {Summary The acquisition of new memories for places and events requires synaptic plasticity in the hippocampus, and plasticity depends on temporal coordination among neurons. Spatial activity in the hippocampus is relatively disorganized during the initial exploration of a novel environment, however, and it is unclear how~neural activity during the initial stages of learning drives synaptic plasticity. Here we show that pairs of CA1 cells that represent overlapping novel locations are initially more coactive and more precisely coordinated than are cells representing overlapping familiar locations. This increased coordination occurrs specifically during brief, high-frequency events (HFEs) in~the local field potential that are similar to ripples and is not associated with better coordination of~place-specific neural activity outside of HFEs. As novel locations become more familiar, correlations between cell pairs decrease. Thus, hippocampal neural activity during learning has a unique structure that is well suited to induce synaptic plasticity and to allow for rapid storage of new memories.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CEIHGTKX\\Cheng and Frank - 2008 - New Experiences Enhance Coordinated Neural Activit.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\A53NBAPF\\S0896627307010306.html},
  journal = {Neuron},
  number = {2}
}

@article{chiang_wallis_2018,
  title = {Neuronal Encoding in Prefrontal Cortex during Hierarchical Reinforcement Learning},
  author = {Chiang, Feng-Kuei and Wallis, Joni D},
  year = {2018},
  pages = {1--12},
  issn = {1530-8898},
  doi = {10.1162/jocn_a_01272},
  abstract = {Reinforcement learning models have proven highly effective for understanding learning in both artificial and biological systems. However, these models have difficulty in scaling up to the complexity of real-life environments. One solution is to incorporate the hierarchical structure of behavior. In hierarchical reinforcement learning, primitive actions are chunked together into more temporally abstract actions, called "options," that are reinforced by attaining a subgoal. These subgoals are capable of generating pseudoreward prediction errors, which are distinct from reward prediction errors that are associated with the final goal of the behavior. Studies in humans have shown that pseudoreward prediction errors positively correlate with activation of ACC. To determine how pseudoreward prediction errors are encoded at the single neuron level, we trained two animals to perform a primate version of the task used to generate these errors in humans. We recorded the electrical activity of neurons in ACC during performance of this task, as well as neurons in lateral prefrontal cortex and OFC. We found that the firing rate of a small population of neurons encoded pseudoreward prediction errors, and these neurons were restricted to ACC. Our results provide support for the idea that ACC may play an important role in encoding subgoals and pseudoreward prediction errors to support hierarchical reinforcement learning. One caveat is that neurons encoding pseudoreward prediction errors were relatively few in number, especially in comparison to neurons that encoded information about the main goal of the task.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\74FVJ5YC\\Chiang, Wallis - 2018 - Neuronal Encoding in Prefrontal Cortex during Hierarchical Reinforcement Learning.pdf},
  journal = {Journal of cognitive neuroscience},
  pmid = {29694261}
}

@techreport{chindemi_muller_2020,
  title = {A Calcium-Based Plasticity Model Predicts Long-Term Potentiation and Depression in the Neocortex},
  author = {Chindemi, Giuseppe and Abdellah, Marwan and Amsalem, Oren and {Benavides-Piccione}, Ruth and Delattre, Vincent and Doron, Michael and Ecker, Andras and King, James and Kumbhar, Pramod and Monney, Caitlin and Perin, Rodrigo and R{\"o}ssert, Christian and Van Geit, Werner and DeFelipe, Javier and Graupner, Michael and Segev, Idan and Markram, Henry and Muller, Eilif},
  year = {2020},
  month = apr,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.04.19.043117},
  abstract = {Long-term potentiation (LTP) and long-term depression (LTD) of pyramidal cell connections are among the key mechanisms underlying learning and memory in the brain. Despite their important role, only a few of these connections have been characterized in terms of LTP/LTD dynamics, such as the one between layer 5 thick-tufted pyramidal cells (L5-TTPCs). Comparing the available evidence on different pyramidal connection types reveals a large variability of experimental outcomes, possibly indicating the presence of connection-type-specific mechanisms. Here, we show that a calcium-based plasticity rule regulating L5-TTPC synapses holds also for several other pyramidal-to-pyramidal connections in a digital model of neocortical tissue. In particular, we show that synaptic physiology, cell morphology and innervation patterns jointly determine LTP/LTD dynamics without requiring a different model or parameter set for each connection type. We therefore propose that a similar set of plasticity mechanisms is shared by seemingly very different neocortical connections and that only a small number of targeted experiments is required for generating a complete map of synaptic plasticity dynamics in the neocortex.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7LDRETEB\\Chindemi et al. - 2020 - A calcium-based plasticity model predicts long-ter.pdf},
  language = {en},
  type = {Preprint}
}

@article{cho_holyoak_2010,
  title = {Common and Dissociable Prefrontal Loci Associated with Component Mechanisms of Analogical Reasoning},
  author = {Cho, Soohyun and Moody, Teena D and Fernandino, Leonardo and Mumford, Jeanette A and Poldrack, Russell A and Cannon, Tyrone D and Knowlton, Barbara J and Holyoak, Keith J},
  year = {2010},
  volume = {20},
  pages = {524--533},
  issn = {10473211},
  doi = {10.1093/cercor/bhp121},
  abstract = {The ability to draw analogies requires 2 key cognitive processes, relational integration and resolution of interference. The present study aimed to identify the neural correlates of both component processes of analogical reasoning within a single, nonverbal analogy task using event-related functional magnetic resonance imaging. Participants verified whether a visual analogy was true by considering either 1 or 3 relational dimensions. On half of the trials, there was an additional need to resolve interference in order to make a correct judgment. Increase in the number of dimensions to integrate was associated with increased activation in the lateral prefrontal cortex as well as lateral frontal pole in both hemispheres. When there was a need to resolve interference during reasoning, activation increased in the lateral prefrontal cortex but not in the frontal pole. We identified regions in the middle and inferior frontal gyri which were exclusively sensitive to demands on each component process, in addition to a partial overlap between these neural correlates of each component process. These results indicate that analogical reasoning is mediated by the coordination of multiple regions of the prefrontal cortex, of which some are sensitive to demands on only one of these 2 component processes, whereas others are sensitive to both.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DT7RK9E6\\Cho et al. - 2010 - Common and dissociable prefrontal loci associated with component mechanisms of analogical reasoning.pdf},
  journal = {Cerebral Cortex},
  keywords = {analogy,Executive control,Inhibition,Interference resolution,Relational integration,working-memory},
  number = {3},
  pmid = {19549622}
}

@article{choi_badre_2018,
  title = {Evidence for a {{Functional Hierarchy}} of {{Association Networks}}},
  author = {Choi, Eun Young and Drayna, Garrett K. and Badre, David},
  year = {2018},
  month = may,
  volume = {30},
  pages = {722--736},
  issn = {0898-929X, 1530-8898},
  doi = {10.1162/jocn_a_01229},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TK5BS9BL\\Choi et al. - 2018 - Evidence for a Functional Hierarchy of Association.pdf},
  journal = {Journal of Cognitive Neuroscience},
  language = {en},
  number = {5}
}

@article{choi_shea-brown_2018,
  title = {Predictive {{Coding}} in {{Area V4}}: {{Dynamic Shape Discrimination}} under {{Partial Occlusion}}},
  shorttitle = {Predictive {{Coding}} in {{Area V4}}},
  author = {Choi, Hannah and Pasupathy, Anitha and {Shea-Brown}, Eric},
  year = {2018},
  month = may,
  volume = {30},
  pages = {1209--1257},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/neco_a_01072},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WH3QKWZG\\Choi et al. - 2018 - Predictive Coding in Area V4 Dynamic Shape Discri.pdf},
  journal = {Neural Computation},
  language = {en},
  number = {5}
}

@article{choi_tani_2018,
  title = {Predictive {{Coding}} for {{Dynamic Visual Processing}}: {{Development}} of {{Functional Hierarchy}} in a {{Multiple Spatiotemporal Scales RNN Model}}},
  shorttitle = {Predictive {{Coding}} for {{Dynamic Visual Processing}}},
  author = {Choi, Minkyu and Tani, Jun},
  year = {2018},
  month = jan,
  volume = {30},
  pages = {237--270},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/neco_a_01026},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6768RQ5F\\Choi and Tani - 2018 - Predictive Coding for Dynamic Visual Processing D.pdf},
  journal = {Neural Computation},
  language = {en},
  number = {1}
}

@article{choo_eliasmith_2013,
  title = {General {{Instruction Following}} in a {{Large}}-{{Scale Biologically Plausible Brain Model}}},
  author = {Choo, Xuan and Eliasmith, Chris},
  year = {2013},
  pages = {322--327},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ED4NDYDR\\Choo, Eliasmith - 2013 - General Instruction Following in a Large-Scale Biologically Plausible Brain Model.pdf},
  journal = {Proc. 35th Annu. Conf. Cogn. Sci. \{\textbackslash ldots\}},
  keywords = {apart from motor and,cognitive architectures,cognitive con-,in-,instruction processing,neural engineering,spiking neuron model,struction following,trol,value in wm area},
  number = {X}
}

@article{choquet_choquet_2018,
  title = {Linking {{Nanoscale Dynamics}} of {{AMPA Receptor Organization}} to {{Plasticity}} of {{Excitatory Synapses}} and {{Learning}}},
  author = {Choquet, Daniel},
  year = {2018},
  doi = {10.1523/JNEUROSCI.2119-18.2018},
  abstract = {The spatiotemporal organization of neurotransmitter receptors in the postsynaptic membrane is a fundamental determinant of synaptic transmission and thus of information processing by the brain. The ionotropic AMPA subtype of glutamate receptors (AMPARs) mediate fast excitatory synaptic transmission in the CNS. The number of AMPARs located en face presynaptic glutamate release sites sets the efficacy of synaptic transmission. Understanding how this number is set and regulated has been the topic of intense research in the last two decades. We showed that AMPARs are not stable in the synapse as initially thought. They continuously enter and exit the postsynaptic density by lateral diffusion, and they exchange between the neuronal surface and intracellular compartments by endocytosis and exocy-tosis at extrasynaptic sites. Regulation of these various trafficking pathways has emerged as a key mechanism for activity-dependent plasticity of synaptic transmission, a process important for learning and memory. I here present my view of these findings. In particular, the advent of super-resolution microscopy and single-molecule tracking has helped to uncover the intricacy of AMPARs' dynamic organization at the nanoscale. In addition, AMPAR surface diffusion is highly regulated by a variety of factors, including neuronal activity, stress hormones, and neurodegeneration, suggesting that AMPAR diffusion-trapping may play a central role in synapse function. Using innovative tools to understand further the link between receptor dynamics and synapse plasticity is now unveiling new molecular mechanisms of learning. Modifying AMPAR dynamics may emerge as a new target to correct synapse dysfunction in the diseased brain.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8MJFCE56\\Choquet - 2018 - Linking Nanoscale Dynamics of AMPA Receptor Organization to Plasticity of Excitatory Synapses and Learning.pdf},
  keywords = {ampa,Long Term Potentiation,neurodegen-erative diseases,receptor trafficking,super resolution imaging,Synaptic plasticity}
}

@article{chow_kopell_1998,
  title = {Frequency Control in Synchronized Networks of Inhibitory Neurons.},
  author = {Chow, C C and a White, J and Ritt, J and Kopell, Nancy},
  year = {1998},
  month = dec,
  volume = {5},
  pages = {407--420},
  issn = {0929-5313},
  abstract = {We analyze the control of frequency for a synchronized inhibitory neuronal network. The analysis is done for a reduced membrane model with a biophysically based synaptic influence. We argue that such a reduced model can quantitatively capture the frequency behavior of a larger class of neuronal models. We show that in different parameter regimes, the network frequency depends in different ways on the intrinsic and synaptic time constants. Only in one portion of the parameter space, called phasic, is the network period proportional to the synaptic decay time. These results are discussed in connection with previous work of the authors, which showed that for mildly heterogeneous networks, the synchrony breaks down, but coherence is preserved much more for systems in the phasic regime than in the other regimes. These results imply that for mildly heterogeneous networks, the existence of a coherent rhythm implies a linear dependence of the network period on synaptic decay time and a much weaker dependence on the drive to the cells. We give experimental evidence for this conclusion.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WK5RLFB7\\Chow et al. - 1998 - Frequency control in synchronized networks of inhibitory neurons.pdf},
  journal = {Journal of computational neuroscience},
  keywords = {Hippocampus,Hippocampus: cytology,Hippocampus: physiology,Interneurons,Interneurons: physiology,Neural Inhibition,Neural Inhibition: physiology,Neural Networks (Computer),Neural Pathways,Periodicity,Synapses,Synapses: physiology},
  number = {4},
  pmid = {9877022}
}

@article{chrastil_stern_2015,
  title = {There and {{Back Again}}: {{Hippocampus}} and {{Retrosplenial Cortex Track Homing Distance}} during {{Human Path Integration}}},
  author = {Chrastil, Elizabeth R and Sherrill, K R and Hasselmo, Michael E and Stern, C E},
  year = {2015},
  volume = {35},
  pages = {15442--15452},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.1209-15.2015},
  abstract = {UNLABELLED: Path integration, the updating of position and orientation during movement, often involves tracking a home location. Here, we examine processes that could contribute to successful location tracking in humans. In particular, we investigate a homing vector model of path integration, whereby a navigator continuously tracks a trajectory back to the home location. To examine this model, we developed a loop task for fMRI, in which participants viewed movement that circled back to a home location in a sparse virtual environment. In support of a homing vector system, hippocampus, retrosplenial cortex, and parahippocampal cortex were responsive to Euclidean distance from home. These results provide the first evidence of a constantly maintained homing signal in the human brain. In addition, hippocampus, retrosplenial cortex, and parahippocampal cortex, as well as medial prefrontal cortex, were recruited during successful path integration. These findings suggest that dynamic processes recruit hippocampus, retrosplenial cortex, and parahippocampal cortex in support of path integration, including a homing vector system that tracks movement relative to home.\$\textbackslash backslash\$n\$\textbackslash backslash\$nSIGNIFICANCE STATEMENT: Path integration is the continual updating of position and orientation during navigation. Animal studies have identified place cells and grid cells as important for path integration, but underlying models of path integration in humans have rarely been studied. The results of our novel loop closure task are the first to suggest that a homing vector tracks Euclidean distance from the home location, supported by the hippocampus, retrosplenial cortex, and parahippocampal cortex. These findings suggest a potential homing vector mechanism supporting path integration, which recruits hippocampus and retrosplenial cortex to track movement relative to home. These results provide new avenues for computational and animal models by directing attention to homing vector models of path integration, which differ from current movement-tracking models.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SE5DZQBP\\Chrastil et al. - 2015 - There and Back Again Hippocampus and Retrosplenial Cortex Track Homing Distance during Human Path Integration.pdf},
  journal = {Journal of Neuroscience},
  keywords = {angular gyrus,animal studies have identified,but underlying models of,continual updating of position,fmri,have rarely been studied,important for path integration,medial prefrontal cortex,navigation,parahippocampal cortex,path integration in humans,path integration is the,place cells,precuneus,significance statement},
  number = {46},
  pmid = {26586830}
}

@article{chrastil_stern_2017,
  title = {Individual {{Differences}} in {{Human Path Integration Abilities Correlate}} with {{Gray Matter Volume}} in {{Retrosplenial Cortex}}, {{Hippocampus}}, and {{Medial Prefrontal Cortex}}},
  author = {Chrastil, Elizabeth R and Sherrill, Katherine R and Aselcioglu, Irem and Hasselmo, Michael E and Stern, Chantal E},
  year = {2017},
  volume = {i},
  pages = {ENEURO.0346----16.2017},
  issn = {2373-2822},
  doi = {10.1523/ENEURO.0346-16.2017},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6KQ2NYH4\\Chrastil et al. - 2017 - Individual Differences in Human Path Integration Abilities Correlate with Gray Matter Volume in Retrosplenial C.pdf},
  journal = {Eneuro},
  keywords = {between good and,brain systems used for,cerebellum,critical insight into the,differences in brain structure,distance,humans vary considerably in,navigation,poor navigators could provide,rotation,significance statement,successful navigation in,their navigational abilities,vbm},
  number = {April}
}

@article{chung_bengio_2017,
  title = {Hierarchical {{Multiscale Recurrent Neural Networks}}},
  author = {Chung, Junyoung and Ahn, Sungjin and Bengio, Yoshua},
  year = {2017},
  month = mar,
  abstract = {Learning both hierarchical and temporal representation has been among the longstanding challenges of recurrent neural networks. Multiscale recurrent neural networks have been considered as a promising approach to resolve this issue, yet there has been a lack of empirical evidence showing that this type of models can actually capture the temporal dependencies by discovering the latent hierarchical structure of the sequence. In this paper, we propose a novel multiscale approach, called the hierarchical multiscale recurrent neural network, that can capture the latent hierarchical structure in the sequence by encoding the temporal dependencies with different timescales using a novel update mechanism. We show some evidence that the proposed model can discover underlying hierarchical structure in the sequences without using explicit boundary information. We evaluate our proposed model on character-level language modelling and handwriting sequence generation.},
  archivePrefix = {arXiv},
  eprint = {1609.01704},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JKQZNBKZ\\Chung et al. - 2017 - Hierarchical Multiscale Recurrent Neural Networks.pdf},
  journal = {arXiv:1609.01704 [cs]},
  language = {en},
  primaryClass = {cs}
}

@article{chung_greengard_2017,
  title = {A {{Fully Automated Approach}} to {{Spike Sorting}}},
  author = {Chung, Jason E. and Magland, Jeremy F. and Barnett, Alex H. and Tolosa, Vanessa M. and Tooker, Angela C. and Lee, Kye Y. and Shah, Kedar G. and Felix, Sarah H. and Frank, Loren M. and Greengard, Leslie F.},
  year = {2017},
  volume = {95},
  pages = {1381--1394.e6},
  issn = {08966273},
  doi = {10.1016/j.neuron.2017.08.030},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KNFZFVQF\\Chung et al. - 2017 - A Fully Automated Approach to Spike Sorting.pdf},
  journal = {Neuron},
  number = {6}
}

@article{churchland_shenoy_2007,
  title = {Techniques for Extracting Single-Trial Activity Patterns from Large-Scale Neural Recordings},
  author = {Churchland, Mark M and Yu, Byron M and Sahani, Maneesh and Shenoy, Krishna V},
  year = {2007},
  month = oct,
  volume = {17},
  pages = {609--618},
  issn = {09594388},
  doi = {10.1016/j.conb.2007.11.001},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SHTHHBXD\\Churchland et al. - 2007 - Techniques for extracting single-trial activity pa.pdf},
  journal = {Current Opinion in Neurobiology},
  language = {en},
  number = {5}
}

@book{ciaramelli_moscovitch_2008,
  title = {Top-down and Bottom-up Attention to Memory: {{A}} Hypothesis ({{AtoM}}) on the Role of the Posterior Parietal Cortex in Memory Retrieval},
  author = {Ciaramelli, Elisa and Grady, Cheryl L and Moscovitch, Morris},
  year = {2008},
  volume = {46},
  doi = {10.1016/j.neuropsychologia.2008.03.022},
  abstract = {Recent neuroimaging studies have implicated the posterior parietal cortex in episodic memory retrieval, but there is uncertainty about its specific role. Research in the attentional domain has shown that superior parietal lobe (SPL) regions along the intraparietal sulcus are implicated in the voluntary orienting of attention to relevant aspects of the environment, whereas inferior parietal lobe (IPL) regions at the temporo-parietal junction mediate the automatic allocation of attention to task-relevant information. Here we propose that the SPL and the IPL play conceptually similar roles in episodic memory retrieval. We hypothesize that the SPL allocates top-down attention to memory retrieval, whereas the IPL mediates the automatic, bottom-up attentional capture by retrieved memory contents. By reviewing the existing fMRI literature, we show that the posterior intraparietal sulcus of SPL is consistently active when the need for top-down assistance to memory retrieval is supposedly maximal, e.g., for memories retrieved with low vs. high confidence, for familiar vs. recollected memories, for recognition of high vs. low frequency words. On the other hand, the supramarginal gyrus of IPL is consistently active when the attentional capture by memory contents is supposedly maximal, i.e., for strong vs. weak memories, for vividly recollected vs. familiar memories, for memories retrieved with high vs. low confidence. We introduce a model of episodic memory retrieval that characterizes contributions of posterior parietal cortex. \textcopyright{} 2008 Elsevier Ltd. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\B3X7BLBJ\\Ciaramelli, Grady, Moscovitch - 2008 - Top-down and bottom-up attention to memory A hypothesis (AtoM) on the role of the posterior parie.pdf},
  isbn = {0027-8424 (Print)\$\textbackslash backslash\$r0027-8424 (Linking)},
  keywords = {Episodic memory,Intraparietal sulcus,Parietal cortex,Retrieval,Temporo-parietal junction},
  pmid = {18471837}
}

@article{clark_clark_2006,
  title = {Language, Embodiment, and the Cognitive Niche},
  author = {Clark, Andy},
  year = {2006},
  volume = {10},
  pages = {370--374},
  issn = {13646613},
  doi = {10.1016/j.tics.2006.06.012},
  abstract = {Embodied agents use bodily actions and environmental interventions to make the world a better place to think in. Where does language fit into this emerging picture of the embodied, ecologically efficient agent? One useful way to approach this question is to consider language itself as a cognition-enhancing animal-built structure. To take this perspective is to view language as a kind of self-constructed cognitive niche: a persisting but never stationary material scaffolding whose crucial role in promoting thought and reason remains surprisingly poorly understood. It is the very materiality of this linguistic scaffolding, I suggest, that gives it some key benefits. By materializing thought in words, we create structures that are themselves proper objects of perception, manipulation, and (further) thought. \textcopyright{} 2006 Elsevier Ltd. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BIYI4MSY\\Clark - 2006 - Language, embodiment, and the cognitive niche.pdf},
  journal = {Trends in Cognitive Sciences},
  number = {8},
  pmid = {16843701}
}

@article{clark_clark_2013,
  title = {Whatever next? {{Predictive}} Brains, Situated Agents, and the Future of Cognitive Science},
  author = {Clark, Andy},
  year = {2013},
  volume = {36},
  pages = {181--204},
  issn = {0140-525X},
  doi = {10.1017/S0140525X12000477},
  abstract = {\textbackslash textlessp\textbackslash textgreaterBrains, it has recently been argued, are essentially prediction machines. They are bundles of cells that support perception and action by constantly attempting to match incoming sensory inputs with top-down expectations or predictions. This is achieved using a hierarchical generative model that aims to minimize prediction error within a bidirectional cascade of cortical processing. Such accounts offer a unifying model of perception and action, illuminate the functional role of attention, and may neatly capture the special contribution of cortical processing to adaptive success. This target article critically examines this ``hierarchical prediction machine'' approach, concluding that it offers the best clue yet to the shape of a unified science of mind and action. Sections 1 and 2 lay out the key elements and implications of the approach. Section 3 explores a variety of pitfalls and challenges, spanning the evidential, the methodological, and the more properly conceptual. The paper ends (sections 4 and 5) by asking how such approaches might impact our more general vision of mind, experience, and agency.\textbackslash textless/p\textbackslash textgreater},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4HSUI7VR\\Clark - 2013 - Whatever next Predictive brains, situated agents, and the future of cognitive science.pdf},
  journal = {Behavioral and Brain Sciences},
  keywords = {attention,bayesian brain,expectation,from helmholtz to action-oriented,generative model,hierarchy,introduction,perception,precision,prediction,prediction error,prediction machines,predictive,predictive coding,top-down processing},
  number = {03},
  pmid = {23663408}
}

@article{clark_clark_2017,
  title = {Spatial {{Navigation}}: {{Retrosplenial Cortex Encodes}} the {{Spatial Structure}} of {{Complex Routes}}},
  author = {Clark, Benjamin J},
  year = {2017},
  volume = {27},
  pages = {R649----R651},
  issn = {09609822},
  doi = {10.1016/j.cub.2017.05.019},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\P973RKJV\\Clark - 2017 - Spatial Navigation Retrosplenial Cortex Encodes the Spatial Structure of Complex Routes.pdf},
  journal = {Current Biology},
  number = {13}
}

@article{clark_wilber_2018,
  title = {The Retrosplenial-Parietal Network and Reference Frame Coordination for Spatial Navigation.},
  author = {Clark, Benjamin J. and Simmons, Christine M. and Berkowitz, Laura E. and Wilber, Aaron A.},
  year = {2018},
  month = oct,
  volume = {132},
  pages = {416--429},
  issn = {1939-0084, 0735-7044},
  doi = {10.1037/bne0000260},
  abstract = {The retrosplenial cortex is anatomically positioned to integrate sensory, motor, and visual information and is thought to have an important role in processing spatial information and guiding behavior through complex environments. Anatomical and theoretical work has argued that the retrosplenial cortex participates in spatial behavior in concert with input from the parietal cortex. Although the nature of these interactions is unknown, a central position is that the functional connectivity is hierarchical with egocentric spatial information processed in the parietal cortex and higher-level allocentric mappings generated in the retrosplenial cortex. Here, we review the evidence supporting this proposal. We begin by summarizing the key anatomical features of the retrosplenial-parietal network, and then review studies investigating the neural correlates of these regions during spatial behavior. Our summary of this literature suggests that the retrosplenial-parietal circuitry does not represent a strict hierarchical parcellation of function between the two regions but instead a heterogeneous mixture of egocentric-allocentric coding and integration across frames of reference. We also suggest that this circuitry should be represented as a gradient of egocentric-to-allocentric information processing from parietal to retrosplenial cortices, with more specialized encoding of global allocentric frameworks within the retrosplenial cortex and more specialized egocentric and local allocentric representations in parietal cortex. We conclude by identifying the major gaps in this literature and suggest new avenues of research.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GE4MBSPP\\Clark et al. - 2018 - The retrosplenial-parietal network and reference f.pdf},
  journal = {Behavioral Neuroscience},
  language = {en},
  number = {5}
}

@article{clayton_cohenkadosh_2018,
  title = {The Many Characters of Visual Alpha Oscillations},
  author = {Clayton, Michael S. and Yeung, Nick and Cohen Kadosh, Roi},
  year = {2018},
  month = oct,
  volume = {48},
  pages = {2498--2508},
  issn = {0953816X},
  doi = {10.1111/ejn.13747},
  abstract = {A central feature of human brain activity is the alpha rhythm: a 7\textendash 13 Hz oscillation observed most notably over occipitoparietal brain regions during periods of eyes-closed rest. Alpha oscillations covary with changes in visual processing and have been associated with a broad range of neurocognitive functions. In this article, we review these associations and suggest that alpha oscillations can be thought to exhibit at least five distinct `characters': those of the inhibitor, perceiver, predictor, communicator and stabiliser. In short, while alpha oscillations are strongly associated with reductions in visual attention, they also appear to play important roles in regulating the timing and temporal resolution of perception. Furthermore, alpha oscillations are strongly associated with top-down control and may facilitate transmission of predictions to visual cortex. This is in addition to promoting communication between frontal and posterior brain regions more generally, as well as maintaining ongoing perceptual states. We discuss why alpha oscillations might associate with such a broad range of cognitive functions and suggest ways in which these diverse associations can be studied experimentally.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TTQD93LC\\Clayton et al. - 2018 - The many characters of visual alpha oscillations.pdf},
  journal = {European Journal of Neuroscience},
  language = {en},
  number = {7}
}

@article{climer_eden_2015,
  title = {Examination of Rhythmicity of Extracellularly Recorded Neurons in the Entorhinal Cortex},
  author = {Climer, Jason R and DiTullio, Ronald and Newman, Ehren L and Hasselmo, Michael E and Eden, Uri T},
  year = {2015},
  volume = {25},
  pages = {460--473},
  issn = {10509631},
  doi = {10.1002/hipo.22383},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PC8WSS6W\\Climer et al. - 2015 - Examination of rhythmicity of extracellularly reco.pdf},
  journal = {Hippocampus},
  keywords = {bat,grid cell,maximum likelihood estimation,rat,theta},
  number = {4}
}

@article{climer_hasselmo_2013,
  title = {Phase Coding by Grid Cells in Unconstrained Environments: Two-Dimensional Phase Precession.},
  author = {Climer, Jason R and Newman, Ehren L and Hasselmo, Michael E},
  year = {2013},
  month = aug,
  volume = {38},
  pages = {2526--2541},
  issn = {1460-9568},
  doi = {10.1111/ejn.12256},
  abstract = {Action potential timing is thought to play a critical role in neural representation. For example, theta phase precession is a robust phenomenon exhibited by spatial cells of the rat entorhinal-hippocampal circuit. In phase precession, the time a neuron fires relative to the phase of theta rhythm (6-10 Hz) oscillations in the local field potential reduces uncertainty about the position of the animal. This relationship between neural firing and behavior has made precession an important constraint for hypothetical mechanisms of temporal coding. However, challenges exist in identifying what regulates the spike timing of these cells. We have developed novel analytical techniques for mapping between behavior and neural firing that provide sufficient sensitivity to examine features of grid cell phase coding in open environments. Here, we show robust, omnidirectional phase precession by entorhinal grid cells in openfield enclosures. We present evidence that full phase precession persists regardless of how close the animal comes to the center of a firing field. Many conjunctive grid cells, previously thought to be phase locked, also exhibited phase coding. However, we were unable to detect directional- or field-specific phase coding predicted by some variants of models. Finally, we present data that suggest bursting of layer II grid cells contributes to the bimodality of phase precession. We discuss implications of these observations for models of temporal coding and propose the utility of these techniques in other domains where behavior is aligned to neural spiking.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EH54WSQ7\\Climer, Newman, Hasselmo - 2013 - Phase coding by grid cells in unconstrained environments two-dimensional phase precession.pdf},
  journal = {The European journal of neuroscience},
  keywords = {Animal,Animal: physiology,Animals,Behavior,Data Interpretation,Entorhinal Cortex,Entorhinal Cortex: physiology,Long-Evans,Male,Neurons,Neurons: physiology,Rats,Statistical,Theta Rhythm},
  number = {4},
  pmid = {23718553}
}

@article{clopath_clopath_2012,
  title = {Synaptic Consolidation: An Approach to Long-Term Learning},
  author = {Clopath, Claudia and Clopath, C},
  year = {2012},
  volume = {6},
  pages = {251--257},
  doi = {10.1007/s11571-011-9177-6},
  abstract = {Synaptic plasticity is thought to be the basis of learning and memory, but it is mostly studied on the time-scale of mere minutes. This review discusses synaptic con-solidation, a process that enables synapses to retain their strength for a much longer time (days to years), instead of returning to their original value. The process involves specific plasticity-related proteins, and depends on the dopamine D1/D5 receptors. Here, we review the research on synaptic consolidation, describing electrophysiology experiments, recent modeling work, as well as behavioral correlates. Memories are stored for different amounts of time. For example, people remember for a whole day where they parked their car, without being able to remember where they parked it a month ago. On the other hand, they per-fectly remember where they parked at their wedding. Thus, selected memories are stored for a very long time, a pro-cess that is called memory consolidation. Memories are thought to be stored in the connections between neurons called synapses, whose strength can be changed by learning. Every new memory changes the syn-apse strengths, which in turn alters previously stored mem-ories. This phenomenon is puzzling, because some memories appear to be stored for an entire life-time. One explanatory hypothesis is relying on the fact that memories can be stored (in synaptic strengths) in different parts of the brain: it is plausible that important memories are transfered from one brain area to a different one that is better protected from changes induced by new incoming memories. There is some biological evidence that memories are stored in the medial temporal lobe. In particular, during consolidation, memories that are first stored in the hippocampus are transfered to other areas of the cortex (Kirwan et al. 2008; Smith and Squire 2009). This transfer can happen during replay events while resting and sleeping (Wilson and McNaughton 1994; Diba et al. 2007). The hypothesis is reinforced by the famous patient HM (Scoville and Milner 1957) whose hippocampus was removed following epilepsy in the medial temporal lobe. HM retained old memories from before his surgery, but he could barely acquire any new long-term memories. This review will describe an additional, less-known mechanism of memory consolidation, which happens at the synapse level. Synapses can be plastic, which means that their strength can vary. A change in synaptic strength can last for different lengths of time: we speak about short-term plasticity when the change lasts up to a few minutes, early-long-term plasticity when it lasts up to a few hours and late-long-term plasticity when it lasts beyond the experi-ment's duration (which is often about 10 h) but is thought to last much longer even, possibly a life-time. This last type of plasticity is also called synaptic consolidation or main-tenance. This process allows relevant memories to be consolidated within a single synapse, so that new memories can no longer alter previously consolidated ones. The remainder of this article will describe the mecha-nism of synaptic consolidation, as shown by synaptic tag-ging experiments. First, the phenomenology will be described, together with the key slice experiments. Then the two existing models of synaptic consolidation will be presented and compared. Finally, the link to behavior will be discussed, followed by a link to reinforcement learning and open computational questions. Background on synaptic plasticity},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UHZXP3GC\\Clopath, Clopath - 2012 - Synaptic consolidation an approach to long-term learning.pdf},
  journal = {Cogn Neurodyn},
  keywords = {Behavior Á,Electrophysiology Á,Memory consolidation,Model Á,Review,Synaptic consolidation Á,Synaptic plasticity Á,Synaptic tagging Á}
}

@article{clopath_gerstner_2010,
  title = {Connectivity Reflects Coding: A Model of Voltage-Based {{STDP}} with Homeostasis},
  shorttitle = {Connectivity Reflects Coding},
  author = {Clopath, Claudia and B{\"u}sing, Lars and Vasilaki, Eleni and Gerstner, Wulfram},
  year = {2010},
  month = mar,
  volume = {13},
  pages = {344--352},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn.2479},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9SFZADMV\\Clopath et al. - 2010 - Connectivity reflects coding a model of voltage-b.pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {3}
}

@article{clopath_gerstner_2010a,
  title = {Voltage and Spike Timing Interact in {{STDP}} - a Unified Model},
  author = {Clopath, Claudia and Gerstner, Wulfram},
  year = {2010},
  volume = {2},
  pages = {1--11},
  issn = {16633563},
  doi = {10.3389/fnsyn.2010.00025},
  abstract = {A phenomenological model of synaptic plasticity is able to account for a large body of experimental data on spike-timing-dependent plasticity (STDP). The basic ingredient of the model is the correlation of presynaptic spike arrival with postsynaptic voltage. The local membrane voltage is used twice: a first term accounts for the instantaneous voltage and the second one for a low-pass filtered voltage trace. Spike-timing effects emerge as a special case. We hypothesize that the voltage dependence can explain differential effects of STDP in dendrites, since the amplitude and time course of backpropagating action potentials or dendritic spikes influences the plasticity results in the model. The dendritic effects are simulated by variable choices of voltage time course at the site of the synapse, i.e., without an explicit model of the spatial structure of the neuron.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3YW3U72Z\\Clopath, Gerstner - 2010 - Voltage and spike timing interact in STDP - a unified model.pdf},
  journal = {Frontiers in Synaptic Neuroscience},
  keywords = {Computational neuroscience,Frequency,LTD,LTP,Model,STDP,Synaptic plasticity},
  number = {JUL},
  pmid = {21423511}
}

@article{clopath_rose_2017,
  title = {Variance and Invariance of Neuronal Long-Term Representations},
  author = {Clopath, Claudia and Bonhoeffer, Tobias and H{\"u}bener, Mark and Rose, Tobias},
  year = {2017},
  month = mar,
  volume = {372},
  pages = {20160161},
  issn = {0962-8436, 1471-2970},
  doi = {10.1098/rstb.2016.0161},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CI92MX43\\Clopath et al. - 2017 - Variance and invariance of neuronal long-term repr.pdf},
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  language = {en},
  number = {1715}
}

@article{clower_strick_2005,
  title = {Basal Ganglia and Cerebellar Inputs to '{{AIP}}'},
  author = {Clower, Dottie M. and Dum, Richard P. and Strick, Peter L.},
  year = {2005},
  volume = {15},
  pages = {913--920},
  issn = {10473211},
  doi = {10.1093/cercor/bhh190},
  abstract = {The anterior intraparietal area (AIP) is a subregion of area 7b in posterior parietal cortex. AIP neurons respond to the sight of objects, as well as to the act of grasping them. We used retrograde transneuronal transport of rabies virus to examine subcortical inputs to AIP in the monkey. Virus transport labeled substantial numbers of neurons in the substantia nigra pars reticulata (SNpr), as well as in the dentate nucleus of the cerebellum. The hotspots of labeled neurons in SNpr and in dentate after AIP injections were separate from those created by virus injections into several other parietal or frontal regions. These observations provide the first evidence that a major output nucleus of the basal ganglia, the SNpr, projects to a region of posterior parietal cortex. In addition, our findings provide further support for the concept that posterior parietal cortex is a target of cerebellar output.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\83V6RCPK\\Clower, Dum, Strick - 2005 - Basal ganglia and cerebellar inputs to 'AIP'.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\QLM5PLNA\\Clower, Dum, Strick - 2005 - Basal ganglia and cerebellar inputs to 'AIP'(2).pdf},
  journal = {Cerebral Cortex},
  keywords = {Basal ganglia,Cerebellum,Dentate nucleus,Posterior parietal cortex,Rabies virus,Substantia nigra,Transneuronal tracing},
  number = {7},
  pmid = {15459083}
}

@article{cohen_andersen_2002,
  title = {A Common Reference Frame for Movement Plans in the Posterior Parietal Cortex},
  author = {Cohen, Yale E. and Andersen, Richard A.},
  year = {2002},
  month = jul,
  volume = {3},
  pages = {553--562},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn873},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NMEPRD4J\\Cohen and Andersen - 2002 - A common reference frame for movement plans in the.pdf},
  journal = {Nature Reviews Neuroscience},
  keywords = {gain field,transformation},
  language = {en},
  number = {7}
}

@book{cohen_oreilly_1996,
  title = {A Preliminary Theory of the Interactions between Prefrontal Cortex and Hippocampus That Contribute to Planning and Prospective Memory},
  author = {Cohen, Jd and O'Reilly, Randall C},
  year = {1996},
  abstract = {This chapter addresses the neurobiological mechanisms that may underlie prospective memory. In our work, we have exploited the use of computational modeling techniques to help identify the role that specific brain structures play in cognition. In particular, we have used such techniques to characterize the function of prefrontal cortex and hippocampus in terms of specific processing mechanisms. This work suggests that an important function of prefrontal cortex is the representation and maintenance of contextual information \textendash{} information that must be held in mind in such a form that it can be used to mediate an appropriate behavioral response. At the same time, our work supports the idea that an important function of the hippocampus is to rapidly establish novel associations, that can also be used to guide behavior. In our view, prospective memory reflects the interaction between these two systems, allowing established sequences of behavior to be associated with new conditions \textendash{} in effect, providing a mechanism for planning.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\F2BP9H94\\Cohen, O'Reilly - 1996 - A preliminary theory of the interactions between prefrontal cortex and hippocampus that contribute to planning.pdf},
  isbn = {0-8058-1536-8}
}

@article{cole_deary_2018,
  title = {Brain Age Predicts Mortality},
  author = {Cole, J. H. and Ritchie, S. J. and Bastin, M. E. and Vald{\'e}s Hern{\'a}ndez, M. C. and Mu{\~n}oz Maniega, S and Royle, N and Corley, J and Pattie, A and Harris, S. E. and Zhang, Q and Wray, N. R. and Redmond, P and Marioni, R. E. and Starr, J. M. and Cox, S. R. and Wardlaw, J. M. and Sharp, D. J. and Deary, I. J.},
  year = {2018},
  volume = {23},
  pages = {1385--1392},
  issn = {14765578},
  doi = {10.1038/mp.2017.62},
  abstract = {Brain age predicts mortality},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VPST32KN\\Cole et al. - 2017 - Brain age predicts mortality.pdf},
  journal = {Molecular Psychiatry},
  number = {5},
  pmid = {28439103}
}

@article{colgin_moser_2009,
  title = {Frequency of Gamma Oscillations Routes Flow of Information in the Hippocampus},
  author = {Colgin, Laura Lee and Denninger, Tobias and Fyhn, Marianne and Hafting, Torkel and Bonnevie, Tora and Jensen, Ole and Moser, May-Britt and Moser, Edvard I.},
  year = {2009},
  month = nov,
  volume = {462},
  pages = {353--357},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature08573},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RC74UB65\\Colgin et al. - 2009 - Frequency of gamma oscillations routes flow of inf.pdf},
  journal = {Nature},
  language = {en},
  number = {7271}
}

@article{collins_collins_2018,
  title = {Chapter 5 - {{Learning Structures Through Reinforcement}}},
  author = {Collins, Anne G E},
  year = {2018},
  doi = {10.1016/B978-0-12-812098-9.00005-X},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\A7WB5G4E\\Collins - 2098 - Chapter 5 - Learning Structures Through Reinforcement.pdf},
  keywords = {Exploration,Generalization,Hierarchical reinforcement learning,Reinforcement learning,Representation learning,Rule learning,Structure learning}
}

@article{collins_frank_2016,
  title = {Neural Signature of Hierarchically Structured Expectations Predicts Clustering and Transfer of Rule Sets in Reinforcement Learning},
  author = {Collins, Anne Gabrielle Eva and Frank, Michael Joshua},
  year = {2016},
  volume = {152},
  pages = {160--169},
  issn = {18737838},
  doi = {10.1016/j.cognition.2016.04.002},
  abstract = {Often the world is structured such that distinct sensory contexts signify the same abstract rule set. Learning from feedback thus informs us not only about the value of stimulus-action associations but also about which rule set applies. Hierarchical clustering models suggest that learners discover structure in the environment, clustering distinct sensory events into a single latent rule set. Such structure enables a learner to transfer any newly acquired information to other contexts linked to the same rule set, and facilitates re-use of learned knowledge in novel contexts. Here, we show that humans exhibit this transfer, generalization and clustering during learning. Trial-by-trial model-based analysis of EEG signals revealed that subjects' reward expectations incorporated this hierarchical structure; these structured neural signals were predictive of behavioral transfer and clustering. These results further our understanding of how humans learn and generalize flexibly by building abstract, behaviorally relevant representations of the complex, high-dimensional sensory environment.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\67FLKV8M\\Collins, Frank - 2016 - Neural signature of hierarchically structured expectations predicts clustering and transfer of rule sets in rein.pdf},
  journal = {Cognition},
  keywords = {Clustering,eeg,Prefrontal cortex,Structure-learning,Transfer},
  pmid = {27082659}
}

@article{compte_wang_2000,
  title = {Synaptic Mechanisms and Network Dynamics Underlying Spatial Working Memory in a Cortical Network Model.},
  author = {Compte, Albert and Brunel, Nicolas and {Goldman-Rakic}, Patricia S and Wang, Xiao-Jing},
  year = {2000},
  volume = {10},
  pages = {910--923},
  issn = {1047-3211},
  doi = {10.1093/cercor/10.9.910},
  abstract = {Single-neuron recordings from behaving primates have established a link between working memory processes and information-specific neuronal persistent activity in the prefrontal cortex. Using a network model endowed with a columnar architecture and based on the physiological properties of cortical neurons and synapses, we have examined the synaptic mechanisms of selective persistent activity underlying spatial working memory in the prefrontal cortex. Our model reproduces the phenomenology of the oculomotor delayed-response experiment of Funahashi et al. (S. Funahashi, C.J. Bruce and P.S. Goldman-Rakic, Mnemonic coding of visual space in the monkey's dorsolateral prefrontal cortex. J Neurophysiol 61:331-349, 1989). To observe stable spontaneous and persistent activity, we find that recurrent synaptic excitation should be primarily mediated by NMDA receptors, and that overall recurrent synaptic interactions should be dominated by inhibition. Isodirectional tuning of adjacent pyramidal cells and interneurons can be accounted for by a structured pyramid-to-interneuron connectivity. Robust memory storage against random drift of the tuned persistent activity and against distractors (intervening stimuli during the delay period) may be enhanced by neuromodulation of recurrent synapses. Experimentally testable predictions concerning the neural basis of working memory are discussed.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RKJTL4HF\\Compte et al. - 2000 - Synaptic mechanisms and network dynamics underlying spatial working memory in a cortical network model.pdf},
  journal = {Cerebral Cortex},
  keywords = {ampa,Animal,Animal: physiology,Animals,Attention,Attention: physiology,Behavior,Haplorhini,Interneurons,Interneurons: physiology,Memory,Models,Neural Inhibition,Neural Inhibition: physiology,Neurological,nmda,Prefrontal Cortex,Prefrontal Cortex: chemistry,Prefrontal Cortex: cytology,Prefrontal Cortex: physiology,Pyramidal Cells,Pyramidal Cells: physiology,Receptors,Short-Term,Short-Term: physiology,Synapses,Synapses: physiology},
  number = {9},
  pmid = {10982751}
}

@techreport{cone_shouval_2020,
  title = {Learning Precise Spatiotemporal Sequences via Biophysically Realistic Circuits with Modular Structure},
  author = {Cone, I. and Shouval, H. Z.},
  year = {2020},
  month = apr,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.04.17.046862},
  abstract = {The ability to express and learn temporal sequences is an essential part of learning and memory. Learned temporal sequences are expressed in multiple brain regions and as such there may be common design in the circuits that mediate it. This work proposes a substrate for such representations, via a biophysically realistic network model that can robustly learn and recall discrete sequences of variable order and duration. The model consists of a network of spiking leaky-integrate-and-fire model neurons placed in a modular architecture designed to resemble cortical microcolumns. Learning is performed via a learning rule with ``eligibility traces'', which hold a history of synaptic activity before being converted into changes in synaptic strength upon neuromodulator activation. Before training, the network responds to incoming stimuli, and contains no memory of any particular sequence. After training, presentation of only the first element in that sequence is sufficient for the network to recall an entire learned representation of the sequence. An extended version of the model also demonstrates the ability to successfully learn and recall non-Markovian sequences. This model provides a possible framework for biologically realistic sequence learning and memory, and is in agreement with recent experimental results, which have shown sequence dependent plasticity in sensory cortex.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DKJASXDS\\Cone and Shouval - 2020 - Learning precise spatiotemporal sequences via biop.pdf},
  language = {en},
  type = {Preprint}
}

@article{conen_padoa-schioppa_2016,
  title = {The Dynamic Nature of Value-Based Decisions},
  author = {Conen, Katherine E and {Padoa-Schioppa}, Camillo},
  year = {2016},
  volume = {19},
  pages = {866--867},
  issn = {1097-6256},
  doi = {10.1038/nn.4329},
  abstract = {Nature Neuroscience 19, 866 (2016). doi:10.1038/nn.4329},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FF5VMIAI\\Conen, Padoa-Schioppa - 2016 - The dynamic nature of value-based decisions.pdf},
  journal = {Nature Neuroscience},
  number = {7},
  pmid = {27351171}
}

@article{conner_tandon_2019,
  ids = {conner.tandon.2019a},
  title = {Network Dynamics of {{Broca}}'s Area during Word Selection},
  author = {Conner, Christopher R. and Kadipasaoglu, Cihan M. and Shouval, Harel Z. and Hickok, Gregory and Tandon, Nitin},
  editor = {Hinojosa, Jos{\'e} A.},
  year = {2019},
  month = dec,
  volume = {14},
  pages = {e0225756},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0225756},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6FQFULWL\\Conner et al. - 2019 - Network dynamics of Broca’s area during word selec.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\Y78YYY5M\\Conner et al. - 2019 - Network dynamics of Broca’s area during word selec.pdf},
  journal = {PLOS ONE},
  language = {en},
  number = {12}
}

@article{constantinou_montemurro_2016,
  title = {Bursting {{Neurons}} in the {{Hippocampal Formation Encode Features}} of {{LFP Rhythms}}},
  author = {Constantinou, Maria and Gonzalo Cogno, Soledad and Elijah, Daniel H and Kropff, Emilio and Gigg, John and Samengo, In{\'e}s and Montemurro, Marcelo A},
  year = {2016},
  volume = {10},
  pages = {1--18},
  issn = {1662-5188},
  doi = {10.3389/fncom.2016.00133},
  abstract = {Burst spike patterns are common in regions of the hippocampal formation such as the subiculum and medial entorhinal cortex (MEC). Neurons in these areas are immersed in extracellular electrical potential fluctuations often recorded as the local field potential (LFP). LFP rhythms within different frequency bands are linked to different behavioral states. For example, delta rhythms are often associated with slow-wave sleep, inactivity and anesthesia; whereas theta rhythms are prominent during awake exploratory behavior and REM sleep. Recent evidence suggests that bursting neurons in the hippocampal formation can encode LFP features. We explored this hypothesis using a two-compartment model of a bursting pyramidal neuron driven by time-varying input signals containing spectral peaks at either delta or theta rhythms. The model predicted a neural code in which bursts represented the instantaneous value, phase, slope and amplitude of the driving signal both in their timing and size (spike number). To verify whether this code is employed in vivo, we examined electrophysiological recordings from the subiculum of anesthetized rats and the MEC of a behaving rat containing prevalent delta or theta rhythms, respectively. In both areas, we found bursting cells that encoded information about the instantaneous voltage, phase, slope and/or amplitude of the dominant LFP rhythm with essentially the same neural code as the simulated neurons. A fraction of the cells encoded part of the information in burst size, in agreement with model predictions. These results provide in-vivo evidence that the output of bursting neurons in the mammalian brain is tuned to features of the LFP.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\C5CGPIC9\\Constantinou et al. - 2016 - Bursting Neurons in the Hippocampal Formation Encode Features of LFP Rhythms.pdf},
  journal = {Frontiers in Computational Neuroscience},
  keywords = {bursting,entorh,entorhinal cortex,information theory,local field potential,neural coding,subiculum},
  number = {December},
  pmid = {28082890}
}

@article{corbitt_horwitz_2018,
  title = {Simulating Laminar Neuroimaging Data for a Visual Delayed Match-to-Sample Task},
  author = {Corbitt, Paul T. and Ulloa, Antonio and Horwitz, Barry},
  year = {2018},
  month = jun,
  volume = {173},
  pages = {199--222},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2018.02.037},
  abstract = {Invasive electrophysiological and neuroanatomical studies in nonhuman mammalian experimental preparations have helped elucidate the lamina (layer) dependence of neural computations and interregional connections. Noninvasive functional neuroimaging can, in principle, resolve cortical laminae (layers), and thus provide insight into human neural computations and interregional connections. However human neuroimaging data are noisy and difficult to interpret; biologically realistic simulations can aid experimental interpretation by relating the neuroimaging data to simulated neural activity. We illustrate the potential of laminar neuroimaging by upgrading an existing large-scale, multiregion neural model that simulates a visual delayed match-to-sample (DMS) task. The new laminar-based neural unit incorporates spiny stellate, pyramidal, and inhibitory neural populations which are divided among supragranular, granular, and infragranular laminae (layers). We simulated neural activity which is translated into local field potential-like data used to simulate conventional and laminar fMRI activity. We implemented the laminar connectivity schemes proposed by Felleman and Van Essen (Cerebral Cortex, 1991) for interregional connections. The hemodynamic model that we employ is a modified version of one due to Heinzle et al. (Neuroimage, 2016) that incorporates the effects of draining veins. We show that the laminar version of the model replicates the findings of the existing model. The laminar model shows the finer structure in fMRI activity and functional connectivity. Laminar differences in the magnitude of neural activities are a prominent finding; these are also visible in the simulated fMRI. We illustrate differences between task and control conditions in the fMRI signal, and demonstrate differences in interregional laminar functional connectivity that reflect the underlying connectivity scheme. These results indicate that multi-layer computational models can aid in interpreting layer-specific fMRI, and suggest that increased use of laminar fMRI could provide unique and fundamental insights to human neuroscience.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EHGMBXXI\\Corbitt et al. - 2018 - Simulating laminar neuroimaging data for a visual .pdf},
  journal = {NeuroImage},
  language = {en}
}

@article{cordova_aly_2019,
  title = {Focusing on What Matters: {{Modulation}} of the Human Hippocampus by Relational Attention},
  shorttitle = {Focusing on What Matters},
  author = {C{\'o}rdova, Natalia I. and {Turk-Browne}, Nicholas B. and Aly, Mariam},
  year = {2019},
  month = feb,
  issn = {10509631},
  doi = {10.1002/hipo.23082},
  abstract = {Hippocampal episodic memory is fundamentally relational, comprising links between events and the spatiotemporal contexts in which they occurred. Such relations are also important over shorter timescales, during online perception. For example, how do we assess the relative spatial positions of objects, their temporal order, or the relationship between their features? Here, we investigate the role of the hippocampus in online relational processing by manipulating attention to different kinds of relations. While undergoing fMRI, participants viewed two images in rapid succession on each trial and performed one of three relational tasks, judging the images' relative: spatial positions, temporal onsets, or sizes. Additionally, they sometimes judged whether one image was tilted, irrespective of the other. This served as a baseline item task with no demands on relational processing. The hippocampus showed reliable deactivation when participants attended to relational vs. item information. Attention to temporal relations was associated with the most robust deactivation. One interpretation of such deactivation is that it reflects hippocampal disengagement. If true, there should be reduced information content and noisier activity patterns for the temporal vs. other tasks. Instead, multivariate pattern analysis revealed more stable hippocampal representations in the temporal task. This increased pattern similarity was not simply a reflection of lower univariate activity. Thus, the hippocampus differentiates between relational and item processing even during online perception, and its representations of temporal relations are particularly robust. These findings suggest that the relational computations of the hippocampus extend beyond long-term memory, enabling rapid extraction of relational information in perception.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MLK3IMID\\Córdova et al. - 2019 - Focusing on what matters Modulation of the human .pdf},
  journal = {Hippocampus},
  language = {en}
}

@article{corkin_corkin_2002,
  title = {What's New with the Amnesic Patient {{H}}.{{M}}.?},
  author = {Corkin, Suzanne},
  year = {2002},
  month = feb,
  volume = {3},
  pages = {153--160},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn726},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YFK843D9\\Corkin - 2002 - What's new with the amnesic patient H.M..pdf},
  journal = {Nature Reviews Neuroscience},
  language = {en},
  number = {2}
}

@article{corral_corral_2013,
  title = {Building {{Conceptual Filters}}: {{Forming Clean Representations Through Early Categorization}}},
  author = {Corral, Daniel},
  year = {2013},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MGVEI7UV\\Corral - 2013 - Building Conceptual Filters Forming Clean Representations Through Early Categorization.pdf}
}

@phdthesis{corral_corral_2017,
  title = {A {{Dual Model}} of {{Relational Concept Representation}}},
  author = {Corral, Daniel},
  year = {2017},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RHMDNBKU\\Corral - 2017 - A Dual Model of Relational Concept Representation.pdf},
  school = {University of Colorado Boulder},
  type = {{{PhD}}}
}

@article{corral_jones_2014,
  title = {The Effects of Relational Structure on Analogical Learning},
  author = {Corral, Daniel and Jones, Matt},
  year = {2014},
  volume = {132},
  pages = {280--300},
  issn = {18737838},
  doi = {10.1016/j.cognition.2014.04.007},
  abstract = {Relational structure is important for various cognitive tasks, such as analogical transfer, but its role in learning of new relational concepts is poorly understood. This article reports two experiments testing people's ability to learn new relational categories as a function of their relational structure. In Experiment 1, each stimulus consisted of 4 objects varying on 2 dimensions. Each category was defined by two binary relations between pairs of objects. The manner in which the relations were linked (i.e., by operating on shared objects) varied between subjects, producing 3 logically different conditions. In Experiment 2, each stimulus consisted of 4 objects varying on 3 dimensions. Categories were defined by three binary relations, leading to six logically different conditions. Various learning models were compared to the behavioral data, based on the theory of schema refinement. The results highlight several shortcomings of schema refinement as a model of relational learning: (1) it can make unreasonable demands on working memory, (2) it does not allow schemas to grow in complexity, and (3) it incorrectly predicts learning is insensitive to relational structure. We propose schema elaboration as an additional mechanism that provides a more complete account, and we relate this mechanism to previous proposals regarding interactions between analogy and representation construction. The current findings may advance understanding of the cognitive mechanisms involved in learning and representing relational concepts. \textcopyright{} 2014 Elsevier B.V.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XAMS4MEK\\Corral, Jones - 2014 - The effects of relational structure on analogical learning.pdf},
  journal = {Cognition},
  keywords = {analogy,Relational category learning,Relational structure,Schema elaboration,Schema refinement,Structured representation},
  number = {3},
  pmid = {24858106}
}

@article{costa_vanrossum_2013,
  title = {Probabilistic Inference of Short-Term Synaptic Plasticity in Neocortical Microcircuits},
  author = {Costa, Rui P. and Sj{\"o}str{\"o}m, P. Jesper and {van Rossum}, Mark C. W.},
  year = {2013},
  volume = {7},
  issn = {1662-5188},
  doi = {10.3389/fncom.2013.00075},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HX2YBMEZ\\Costa et al. - 2013 - Probabilistic inference of short-term synaptic pla.pdf},
  journal = {Frontiers in Computational Neuroscience},
  language = {en}
}

@article{couey_witter_2013,
  title = {Recurrent Inhibitory Circuitry as a Mechanism for Grid Formation.},
  author = {Couey, Jonathan J and Witoelar, Aree and Zhang, Sheng-Jia and Zheng, Kang and Ye, Jing and Dunn, Benjamin and Czajkowski, Rafal and Moser, May-Britt and Moser, Edvard I and Roudi, Yasser and Witter, Menno P},
  year = {2013},
  month = mar,
  volume = {16},
  pages = {318--324},
  issn = {1546-1726},
  doi = {10.1038/nn.3310},
  abstract = {Grid cells in layer II of the medial entorhinal cortex form a principal component of the mammalian neural representation of space. The firing pattern of a single grid cell has been hypothesized to be generated through attractor dynamics in a network with a specific local connectivity including both excitatory and inhibitory connections. However, experimental evidence supporting the presence of such connectivity among grid cells in layer II is limited. Here we report recordings from more than 600 neuron pairs in rat entorhinal slices, demonstrating that stellate cells, the principal cell type in the layer II grid network, are mainly interconnected via inhibitory interneurons. Using a model attractor network, we demonstrate that stable grid firing can emerge from a simple recurrent inhibitory network. Our findings thus suggest that the observed inhibitory microcircuitry between stellate cells is sufficient to generate grid-cell firing patterns in layer II of the medial entorhinal cortex.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HBRBGE4U\\Couey et al. - 2013 - Recurrent inhibitory circuitry as a mechanism for grid formation.pdf},
  journal = {Nature neuroscience},
  keywords = {Animals,Entorhinal Cortex,Entorhinal Cortex: cytology,Entorhinal Cortex: physiology,Female,Interneurons,Interneurons: physiology,Long-Evans,Nerve Net,Nerve Net: cytology,Nerve Net: physiology,Neural Inhibition,Neural Inhibition: physiology,Neurons,Neurons: cytology,Neurons: physiology,Patch-Clamp Techniques,Rats,Synaptic Transmission,Synaptic Transmission: physiology},
  number = {3},
  pmid = {23334580}
}

@article{coulter_coulter_2018,
  title = {Inferring Single-Trial Neural Population Dynamics Using Sequential Auto-Encoders},
  author = {Coulter, Wallace H},
  year = {2018},
  doi = {10.1038/s41592-018-0109-9},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SJ4ZYA9J\\Coulter - Unknown - Inferring single-trial neural population dynamics using sequential auto-encoders.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\VW9LJ34X\\Pandarinath et al. - 2018 - Inferring single-trial neural population dynamics .pdf},
  journal = {Nature Methods}
}

@article{courellis_iversen_2017,
  title = {{{EEG}}-Based Quantification of Cortical Current Density and Dynamic Causal Connectivity Generalized across Subjects Performing {{BCI}}-Monitored Cognitive Tasks},
  author = {Courellis, Hristos and Mullen, Tim and Poizner, Howard and Cauwenberghs, Gert and Iversen, John R.},
  year = {2017},
  volume = {11},
  pages = {1--17},
  issn = {1662453X},
  doi = {10.3389/fnins.2017.00180},
  abstract = {Quantification of dynamic causal interactions among brain regions constitutes an important component of conducting research and developing applications in experimental and translational neuroscience. Furthermore, cortical networks with dynamic causal connectivity in brain-computer interface (BCI) applications offer a more comprehensive view of brain states implicated in behavior than do individual brain regions. However, models of cortical network dynamics are difficult to generalize across subjects because current electroencephalography (EEG) signal analysis techniques are limited in their ability to reliably localize sources across subjects. We propose an algorithmic and computational framework for identifying cortical networks across subjects in which dynamic causal connectivity is modeled among user-selected cortical regions of interest (ROIs). We demonstrate the strength of the proposed framework using a "reach/saccade to spatial target" cognitive task performed by 10 right-handed individuals. Modeling of causal cortical interactions was accomplished through measurement of cortical activity using (EEG), application of independent component clustering to identify cortical ROIs as network nodes, estimation of cortical current density using cortically constrained low resolution electromagnetic brain tomography (cLORETA), multivariate autoregressive (MVAR) modeling of representative cortical activity signals from each ROI, and quantification of the dynamic causal interaction among the identified ROIs using the Short-time direct Directed Transfer function (SdDTF). The resulting cortical network and the computed causal dynamics among its nodes exhibited physiologically plausible behavior, consistent with past results reported in the literature. This physiological plausibility of the results strengthens the framework's applicability in reliably capturing complex brain functionality, which is required by applications, such as diagnostics and BCI.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TNMZQVXY\\Courellis et al. - 2017 - EEG-based quantification of cortical current density and dynamic causal connectivity generalized across subjec.pdf},
  journal = {Frontiers in Neuroscience},
  keywords = {Brain-computer interface (BCI),Causality analysis,Electroencephalography (EEG),Independent component analysis,LORETA,Motor activity,Source localization,Spatial reach and saccade},
  number = {MAY},
  pmid = {28566997}
}

@article{courrieu_courrieu_2004,
  title = {Solving {{Time}} of {{Least Square Systems}} in {{Sigma}}-{{Pi Unit Networks}}},
  author = {Courrieu, Pierre},
  year = {2004},
  volume = {4},
  pages = {39--45},
  abstract = {The solving of least square systems is a useful operation in neurocomputational modeling of learning, pattern matching, and pattern recognition. In these last two cases, the solution must be obtained on-line, thus the time required to solve a system in a plausible neural architecture is critical. This paper presents a recurrent network of Sigma-Pi neurons, whose solving time increases at most like the logarithm of the system size, and of its condition number, which provides plausible computation times for biological systems.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6CNCTJFH\\Courrieu - 2004 - Solving Time of Least Square Systems in Sigma-Pi Unit Networks.pdf},
  journal = {Neural Information Processing},
  keywords = {least square systems,neurons,on-line pattern matching,rbfn learning,recurrent neural network,sigma-pi},
  number = {3}
}

@article{cox_witten_2019,
  title = {Striatal Circuits for Reward Learning and Decision-Making},
  author = {Cox, Julia and Witten, Ilana B.},
  year = {2019},
  month = jun,
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/s41583-019-0189-2},
  abstract = {The striatum is essential for learning which actions lead to reward and for implementing those actions. Decades of experimental and theoretical work have led to several influential theories and hypotheses about how the striatal circuit mediates these functions. However, owing to technical limitations, testing these hypotheses rigorously has been difficult. In this Review{$\mkern1mu$}, we briefly describe some of the classic ideas of striatal function. We then review recent studies in rodents that take advantage of optical and genetic methods to test these classic ideas by recording and manipulating identified cell types within the circuit. This new body of work has provided experimental support of some longstanding ideas about the striatal circuit and has uncovered critical aspects of the classic view that are incorrect or incomplete.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VTWVMXKA\\Cox and Witten - 2019 - Striatal circuits for reward learning and decision.pdf},
  journal = {Nature Reviews Neuroscience},
  language = {en}
}

@book{craig_mcbain_2015,
  title = {Navigating the Circuitry of the Brain's {{GPS}} System: {{Future}} Challenges for Neurophysiologists},
  author = {Craig, Michael T and Mcbain, Chris J},
  year = {2015},
  volume = {25},
  doi = {10.1002/hipo.22456},
  abstract = {The discovery of the brain's navigation system creates a compelling challenge for neurophysiologists: how do we map the circuitry of a system that can only be definitively identified in awake, behaving animals? Do grid and border cells in the entorhinal cortex correspond to the two classes of principal cell found there, stellate and pyramidal cells? In the hippocampus, does the diversity seen in pyramidal cell subtypes have functional correlates in the place cell system? How do interneurons regulate the activity of spatially tuned principal cells in the hippocampal and entorhinal circuits? Here, we discuss recent literature relating the cellular circuitry of these circuits to in vivo studies of the brain's navigation system, and the role that interneurons have in regulating the activity of principal cells in these circuits. We propose that studying in vitro models of neuronal oscillations in the entorhinal cortex and hippocampus can provide useful insights for bridging the gap in understanding that exists in relating in vivo and behavioral studies to circuit function at the cellular level. \{\textcopyright\} 2015 Wiley Periodicals, Inc.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MH6P6ZFB\\Craig, Mcbain - 2015 - Navigating the circuitry of the brain's GPS system Future challenges for neurophysiologists.pdf},
  isbn = {1098-1063 (Electronic)\$\textbackslash backslash\$r1050-9631 (Linking)},
  keywords = {Hippocampus,Interneurons,Oscillations},
  pmid = {25786788}
}

@article{crochet_petersen_2019,
  title = {Neural {{Circuits}} for {{Goal}}-{{Directed Sensorimotor Transformations}}},
  author = {Crochet, Sylvain and Lee, Seung-Hee and Petersen, Carl C.H.},
  year = {2019},
  month = jan,
  volume = {42},
  pages = {66--77},
  issn = {01662236},
  doi = {10.1016/j.tins.2018.08.011},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JB49H98U\\Crochet et al. - 2019 - Neural Circuits for Goal-Directed Sensorimotor Tra.pdf},
  journal = {Trends in Neurosciences},
  language = {en},
  number = {1}
}

@article{csicsvari_kenneth_2003,
  title = {Massively Parallel Recording of Unit and Local Field Potentials with Silicon-Based Electrodes.},
  author = {Csicsvari, Jozsef and Henze, Darrell A and Jamieson, Brian and Harris, Kenneth D and Sirota, Anton and Kenneth, D},
  year = {2003},
  month = aug,
  volume = {90},
  pages = {1314--1323},
  issn = {0022-3077},
  doi = {10.1152/jn.00116.2003},
  abstract = {Parallel recording of neuronal activity in the behaving animal is a prerequisite for our understanding of neuronal representation and storage of information. Here we describe the development of micro-machined silicon microelectrode arrays for unit and local field recordings. The two-dimensional probes with 96 or 64 recording sites provided high-density recording of unit and field activity with minimal tissue displacement or damage. The on-chip active circuit eliminated movement and other artifacts and greatly reduced the weight of the headgear. The precise geometry of the recording tips allowed for the estimation of the spatial location of the recorded neurons and for high-resolution estimation of extracellular current source density. Action potentials could be simultaneously recorded from the soma and dendrites of the same neurons. Silicon technology is a promising approach for high-density, high-resolution sampling of neuronal activity in both basic research and prosthetic devices.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\I3DPUMXM\\Csicsvari et al. - 2003 - Massively parallel recording of unit and local field potentials with silicon-based electrodes.pdf},
  journal = {Journal of neurophysiology},
  keywords = {Animals,Brain,Brain: physiology,Electrophysiology,Electrophysiology: methods,Microelectrodes,Rats,Silicon,Sprague-Dawley},
  number = {2},
  pmid = {12904510}
}

@article{cueva_wei_2018,
  title = {Emergence of Grid-like Representations by Training Recurrent Neural Networks to Perform Spatial Localization},
  author = {Cueva, Christopher J. and Wei, Xue-Xin},
  year = {2018},
  month = mar,
  abstract = {Decades of research on the neural code underlying spatial navigation have revealed a diverse set of neural response properties. The Entorhinal Cortex (EC) of the mammalian brain contains a rich set of spatial correlates, including grid cells which encode space using tessellating patterns. However, the mechanisms and functional significance of these spatial representations remain largely mysterious. As a new way to understand these neural representations, we trained recurrent neural networks (RNNs) to perform navigation tasks in 2D arenas based on velocity inputs. Surprisingly, we find that grid-like spatial response patterns emerge in trained networks, along with units that exhibit other spatial correlates, including border cells and band-like cells. All these different functional types of neurons have been observed experimentally. The order of the emergence of grid-like and border cells is also consistent with observations from developmental studies. Together, our results suggest that grid cells, border cells and others as observed in EC may be a natural solution for representing space efficiently given the predominant recurrent connections in the neural circuits.},
  archivePrefix = {arXiv},
  eprint = {1803.07770},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9NSCMC6V\\Cueva_Wei_2018_Emergence of grid-like representations by training recurrent neural networks to.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\T3HW2UVN\\1803.html},
  journal = {arXiv:1803.07770 [cs, q-bio, stat]},
  primaryClass = {cs, q-bio, stat}
}

@techreport{cui_chen_2016,
  title = {Multi-{{Scale Convolutional Neural Networks}} for {{Time Series Classification General Terms}}},
  author = {Cui, Zhicheng and Chen, Wenlin and Chen, Yixin},
  year = {2016},
  abstract = {Time series classification (TSC), the problem of predicting class labels of time series, has been around for decades within the community of data mining and machine learning, and found many important applications such as biomedical engineering and clinical prediction. However, it still remains challenging and falls short of classification accuracy and efficiency. Traditional approaches typically involve extracting discriminative features from the original time series using dynamic time warping (DTW) or shapelet transformation, based on which an off-the-shelf classifier can be applied. These methods are ad-hoc and separate the feature extraction part with the classification part, which limits their accuracy performance. Plus, most existing methods fail to take into account the fact that time series often have features at different time scales. To address these problems, we propose a novel end-to-end neural network model, Multi-scale Convolutional Neural Network (MCNN), which incorporates feature extraction and classification in a single framework. Leveraging a novel multi-branch layer and learnable con-volutional layers, MCNN automatically extracts features at different scales and frequencies, leading to superior feature representation. MCNN is also computationally efficient, as it naturally leverages GPU computing. We conduct comprehensive empirical evaluation with various existing methods on a large number of benchmark datasets, and show that MCNN advances the state-of-the-art by achieving superior accuracy performance than other leading methods.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KDDBJ738\\Cui, Chen, Chen - Unknown - Multi-Scale Convolutional Neural Networks for Time Series Classification General Terms.pdf},
  keywords = {convolutional neu-ral network,deep learning,H28 [Database Management]: Database Applications-Keywords Time series classification}
}

@article{culpepper_olshausen_2009,
  title = {Learning Transport Operators for Image Manifolds},
  author = {Culpepper, Benjamin J and Olshausen, Bruno A},
  year = {2009},
  pages = {9},
  abstract = {We describe an unsupervised manifold learning algorithm that represents a surface through a compact description of operators that traverse it. The operators are based on matrix exponentials, which are the solution to a system of first-order linear differential equations. The matrix exponents are represented by a basis that is adapted to the statistics of the data so that the infinitesimal generator for a trajectory along the underlying manifold can be produced by linearly composing a few elements. The method is applied to recover topological structure from low dimensional synthetic data, and to model local structure in how natural images change over time and scale.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QUNCVHD3\\Culpepper and Olshausen - Learning transport operators for image manifolds.pdf},
  language = {en}
}

@techreport{cunningham_sahani_2007,
  title = {Inferring {{Neural Firing Rates}} from {{Spike Trains Using Gaussian Processes}}},
  author = {Cunningham, John P and Yu, Byron M and Shenoy, Krishna V and Sahani, Maneesh},
  year = {2007},
  abstract = {Neural spike trains present challenges to analytical efforts due to their noisy, spiking nature. Many studies of neuroscientific and neural prosthetic importance rely on a smoothed, denoised estimate of the spike train's underlying firing rate. Current techniques to find time-varying firing rates require ad hoc choices of parameters, offer no confidence intervals on their estimates, and can obscure potentially important single trial variability. We present a new method, based on a Gaussian Process prior, for inferring probabilistically optimal estimates of firing rate functions underlying single or multiple neural spike trains. We test the performance of the method on simulated data and experimentally gathered neural spike trains, and we demonstrate improvements over conventional estimators.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BM6FUZ7W\\Cunningham et al. - Unknown - Inferring Neural Firing Rates from Spike Trains Using Gaussian Processes.pdf}
}

@article{cunningham_yu_2014,
  title = {Dimensionality Reduction for Large-Scale Neural Recordings},
  author = {Cunningham, John P and Yu, Byron M},
  year = {2014},
  month = nov,
  volume = {17},
  pages = {1500--1509},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn.3776},
  abstract = {Most sensory, cognitive and motor functions depend on the interactions of many neurons. In recent years, there has been rapid development and increasing use of technologies for recording from large numbers of neurons, either sequentially or simultaneously. A key question is what scientific insight can be gained by studying a population of recorded neurons beyond studying each neuron individually. Here, we examine three important motivations for population studies: single-trial hypotheses requiring statistical power, hypotheses of population response structure and exploratory analyses of large data sets. Many recent studies have adopted dimensionality reduction to analyze these populations and to find features that are not apparent at the level of individual neurons. We describe the dimensionality reduction methods commonly applied to population activity and offer practical advice about selecting methods and interpreting their outputs. This review is intended for experimental and computational researchers who seek to understand the role dimensionality reduction has had and can have in systems neuroscience, and who seek to apply these methods to their own data.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JWSSC5RJ\\Cunningham and Yu - 2014 - Dimensionality reduction for large-scale neural re.pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {11}
}

@book{cutsuridis_vida_2018,
  title = {Hippocampal {{Microcircuits}}: {{A Computational Modeler}}'s {{Resource Book}}},
  shorttitle = {Hippocampal {{Microcircuits}}},
  editor = {Cutsuridis, Vassilis and Graham, Bruce P. and Cobb, Stuart and Vida, Imre},
  year = {2018},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-99103-0},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AHJL8LEA\\Cutsuridis et al. - 2018 - Hippocampal Microcircuits A Computational Modeler.pdf},
  isbn = {978-3-319-99102-3 978-3-319-99103-0},
  keywords = {PING},
  language = {en},
  series = {Springer {{Series}} in {{Computational Neuroscience}}}
}

@article{dabney_botvinick_2020,
  title = {A Distributional Code for Value in Dopamine-Based Reinforcement Learning},
  author = {Dabney, Will and {Kurth-Nelson}, Zeb and Uchida, Naoshige and Starkweather, Clara Kwon and Hassabis, Demis and Munos, R{\'e}mi and Botvinick, Matthew},
  year = {2020},
  month = jan,
  volume = {577},
  pages = {671--675},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/s41586-019-1924-6},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3XXMWDYX\\Dabney et al. - 2020 - A distributional code for value in dopamine-based .pdf},
  journal = {Nature},
  language = {en},
  number = {7792}
}

@article{daffner_holcomb_2012,
  title = {The Influence of Executive Capacity on Selective Attention and Subsequent Processing},
  author = {Daffner, Kirk R and Tarbi, Elise C and Haring, Anna E and Zhuravleva, Tatyana Y and Sun, Xue and Rentz, Dorene M and Holcomb, Phillip J},
  year = {2012},
  volume = {6},
  pages = {1--19},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2012.00167},
  abstract = {Recent investigations that suggest selective attention (SA) is dependent on top-down control mechanisms lead to the expectation that individuals with high executive capacity (EC) would exhibit more robust neural indices of SA. This prediction was tested by using event-related potentials (ERPs) to examine differences in markers of information processing across 25 subjects divided into two groups based on high vs. average EC, as defined by neuropsychological test scores. Subjects performed an experimental task requiring SA to a specified color. In contrast to expectation, individuals with high and average EC did not differ in the size of ERP indices of SA: the anterior Selection Positivity (SP) and posterior Selection Negativity (SN). However, there were substantial differences between groups in markers of subsequent processing, including the anterior N2 (a measure of attentional control) and the P3a (an index of the orienting of attention). EC predicted speed of processing at both early and late attentional stages. Individuals with lower EC exhibited prolonged SN, P3a, and P3b latencies. However, the delays in carrying out SA operations did not account for subsequent delays in decision making, or explain excessive orienting and reduced attentional control mechanisms in response to stimuli that should have been ignored. SN latency, P3 latency, and the size of the anterior N2 made independent contributions to the variance of EC. In summary, our findings suggest that current views regarding the relationship between top-down control mechanisms and SA may need refinement.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\A52IN8DI\\Daffner et al. - 2012 - The influence of executive capacity on selective attention and subsequent processing.pdf},
  journal = {Frontiers in Human Neuroscience},
  keywords = {event-re,event-related potentials,executive functions,selective attention,top-down control},
  number = {June},
  pmid = {22701415}
}

@article{dahl_adachi_2013,
  title = {Conceptual Metaphorical Mapping in Chimpanzees ({{Pan}} Troglodytes)},
  author = {Dahl, Christoph D. and Adachi, Ikuma},
  year = {2013},
  volume = {2013},
  pages = {1--7},
  issn = {2050084X},
  doi = {10.7554/eLife.00932},
  abstract = {Conceptual metaphors are linguistic constructions. Such a metaphor is humans' mental representation of social rank as a pyramidal-like structure. High-ranked individuals are represented in higher positions than low-ranked individuals. We show that conceptual metaphorical mapping between social rank and the representational domain exists in our closest evolutionary relatives, the chimpanzees. Chimpanzee participants were requested to discriminate face identities in a vertical arrangement. We found a modulation of response latencies by the rank of the presented individual and the position on the display: a high-ranked individual presented in the higher and a low-ranked individual in the lower position led to quicker identity discrimination than a high-ranked individual in the lower and a low-ranked individual in the higher position. Such a spatial representation of dominance hierarchy in chimpanzees suggests that a natural tendency to systematically map an abstract dimension exists in the common ancestor of humans and chimpanzees. DOI:http://dx.doi.org/10.7554/eLife.00932.001.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9QXPYPD5\\Dahl, Adachi - 2013 - Conceptual metaphorical mapping in chimpanzees (Pan troglodytes).pdf},
  journal = {eLife},
  number = {2},
  pmid = {24151544}
}

@techreport{dai_arkhipov_2020,
  title = {Brain {{Modeling ToolKit}}: An {{Open Source Software Suite}} for {{Multiscale Modeling}} of {{Brain Circuits}}},
  shorttitle = {Brain {{Modeling ToolKit}}},
  author = {Dai, Kael and Gratiy, Sergey L. and Billeh, Yazan N. and Xu, Richard and Cai, Binghuang and Cain, Nicholas and Rimehaug, Atle E. and Stasik, Alexander J. and Einevoll, Gaute T. and Mihalas, Stefan and Koch, Christof and Arkhipov, Anton},
  year = {2020},
  month = may,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.05.08.084947},
  abstract = {Abstract           Experimental studies in neuroscience are producing data at a rapidly increasing rate, providing exciting opportunities and formidable challenges to existing theoretical and modeling approaches. To turn massive datasets into predictive quantitative frameworks, the field needs software solutions for systematic integration of data into realistic, multiscale models. Here we describe the Brain Modeling ToolKit (BMTK), a software suite for building models and performing simulations at multiple levels of resolution, from biophysically detailed multi-compartmental, to point-neuron, to population-statistical approaches. Leveraging the SONATA file format and existing software such as NEURON, NEST, and others, BMTK offers consistent user experience across multiple levels of resolution. It permits highly sophisticated simulations to be set up with little coding required, thus lowering entry barriers to new users. We illustrate successful applications of BMTK to large-scale simulations of a cortical area. BMTK is an open-source package provided as a resource supporting modeling-based discovery in the community.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L2WZLI29\\Dai et al. - 2020 - Brain Modeling ToolKit an Open Source Software Su.pdf},
  language = {en},
  type = {Preprint}
}

@book{dang-vu_courtemanche_2020,
  title = {Neuronal {{Oscillations}} of {{Wakefulness}} and {{Sleep}}: {{Windows}} on {{Spontaneous Activity}} of the {{Brain}}},
  shorttitle = {Neuronal {{Oscillations}} of {{Wakefulness}} and {{Sleep}}},
  editor = {{Dang-Vu}, Thien Thanh and Courtemanche, Richard},
  year = {2020},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-0716-0653-7},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Y545R6KD\\Dang-Vu and Courtemanche - 2020 - Neuronal Oscillations of Wakefulness and Sleep Wi.pdf},
  isbn = {978-1-07-160651-3 978-1-07-160653-7},
  language = {en}
}

@article{danker_davachi_2016,
  title = {Trial-by-{{Trial Hippocampal Encoding Activation Predicts}} the {{Fidelity}} of {{Cortical Reinstatement During Subsequent Retrieval}}},
  author = {Danker, Jared F and Tompary, Alexa and Davachi, Lila},
  year = {2016},
  pages = {bhw146},
  issn = {1047-3211},
  doi = {10.1093/cercor/bhw146},
  abstract = {According to current models of episodic memory, the hippocampus binds together the neural representation of an experience during encoding such that it can be reinstated in cortex during subsequent retrieval. However, direct evidence linking hippocampal engagement during encoding with subsequent cortical reinstatement during retrieval is lacking. In this study, we aim to directly test the relationship between hippocampal activation during encoding and cortical reinstatement during retrieval. During a scanned encoding session, human participants studied Noun\textendash Sound and Noun\textendash Picture pairs. One day later, during a scanned retrieval session, participants retrieved the sounds and pictures when given the nouns as cues. First, we found that trial-by-trial hippocampal encoding activation was related to trial-by-trial reactivation during retrieval as measured by the univariate BOLD response in several modality-specific cortical regions. Second, using multivariate measures, we found a correlation between encoding-retrieval pattern similarity computed for each trial and hippocampal encoding activation on the corresponding encoding event, suggesting that the magnitude of hippocampal activation during an experience is related to the fidelity of subsequent reinstatement of cortical activity patterns during retrieval. Consistent with current theories of episodic memory, our findings demonstrate a critical link between initial hippocampal activation during an experience and subsequent cortical reinstatement.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PW4MJHD4\\Danker, Tompary, Davachi - 2016 - Trial-by-Trial Hippocampal Encoding Activation Predicts the Fidelity of Cortical Reinstatement During.pdf},
  journal = {Cerebral Cortex},
  keywords = {binding,episodic memory,fmri,hippocampus,reactivation},
  pmid = {27288317}
}

@article{dannenberg_hasselmo_2019,
  title = {The {{Role}} of {{Hierarchical Dynamical Functions}} in {{Coding}} for {{Episodic Memory}} and {{Cognition}}},
  author = {Dannenberg, Holger and Alexander, Andrew S. and Robinson, Jennifer C. and Hasselmo, Michael E.},
  year = {2019},
  month = jun,
  pages = {1--19},
  issn = {0898-929X, 1530-8898},
  doi = {10.1162/jocn_a_01439},
  abstract = {Behavioral research in human verbal memory function led to the initial definition of episodic memory and semantic memory. A complete model of the neural mechanisms of episodic memory must include the capacity to encode and mentally reconstruct everything that humans can recall from their experience. This article proposes new model features necessary to address the complexity of episodic memory encoding and recall in the context of broader cognition and the functional properties of neurons that could contribute to this broader scope of memory. Many episodic memory models represent individual snapshots of the world with a sequence of vectors, but a full model must represent complex functions encoding and retrieving the relations between multiple stimulus features across space and time on multiple hierarchical scales. Episodic memory involves not only the space and time of an agent experiencing events within an episode but also features shown in neurophysiological data such as coding of speed, direction, boundaries, and objects. Episodic memory includes not only a spatio-temporal trajectory of a single agent but also segments of spatio-temporal trajectories for other agents and objects encountered in the environment consistent with data on encoding the position and angle of sensory features of objects and boundaries. We will discuss potential interactions of episodic memory circuits in the hippocampus and entorhinal cortex with distributed neocortical circuits that must represent all features of human cognition.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7SX4LSXW\\Dannenberg et al. - 2019 - The Role of Hierarchical Dynamical Functions in Co.pdf},
  journal = {Journal of Cognitive Neuroscience},
  language = {en}
}

@article{dardenne_cohen_2012,
  title = {Role of Prefrontal Cortex and the Midbrain Dopamine System in Working Memory Updating},
  author = {D'Ardenne, K and Eshel, Neir and Luka, J and Lenartowicz, A and Nystrom, Leigh E and Cohen, J D},
  year = {2012},
  volume = {109},
  pages = {19900--19909},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1116727109/-/DCSupplemental.www.pnas.org/cgi/doi/10.1073/pnas.1116727109},
  abstract = {Humans are adept at switching between goal-directed behaviors quickly and effectively. The prefrontal cortex (PFC) is thought to play a critical role by encoding, updating, and maintaining internal representations of task context in working memory. It has also been hypothesized that the encoding of context representations in PFC is regulated by phasic dopamine gating signals. Here we use multimodal methods to test these hypotheses. First we used functional MRI (fMRI) to identify regions of PFC associated with the representation of context in a working memory task. Next we used single-pulse transcranial magnetic stimulation (TMS), guided spatially by our fMRI findings and temporally by previous eventrelated EEG recordings, to disrupt context encoding while participants performed the same working memory task. We found that TMS pulses to the right dorsolateral PFC (DLPFC) immediately after context presentation, and well in advance of the response, adversely impacted context-dependent relative to context-independent responses. This finding causally implicates right DLPFC function in context encoding. Finally, using the same paradigm, we conducted high-resolution fMRI measurements in brainstem dopaminergic nuclei (ventral tegmental area and substantia nigra) and found phasic responses after presentation of context stimuli relative to other stimuli, consistent with the timing of a gating signal that regulates the encoding of representations in PFC. Furthermore, these responses were positively correlated with behavior, as well as with responses in the same region of right DLPFC targeted in the TMS experiment, lending support to the hypothesis that dopamine phasic signals regulate encoding, and thereby the updating, of context representations in PFC.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GA9DQUD9\\D'Ardenne et al. - 2012 - Role of prefrontal cortex and the midbrain dopamine system in working memory updating.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  pmid = {23086162}
}

@article{dautan_mena-segovia_2016,
  title = {Segregated Cholinergic Transmission Modulates Dopamine Neurons Integrated in Distinct Functional Circuits},
  author = {Dautan, Daniel and Souza, Albert S and {Huerta-ocampo}, Icnelia and Valencia, Miguel and Assous, Maxime and Witten, Ilana B and Deisseroth, Karl and Tepper, James M and Bolam, J Paul and Gerdjikov, Todor V and {Mena-segovia}, Juan},
  year = {2016},
  pages = {1--14},
  issn = {1097-6256},
  doi = {10.1038/nn.4335},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QXESRW6M\\Dautan et al. - 2016 - Segregated cholinergic transmission modulates dopamine neurons integrated in distinct functional circuits.pdf},
  journal = {Nature Neuroscience},
  number = {June},
  pmid = {27348215}
}

@book{davis_zhong_2017,
  title = {The {{Biology}} of {{Forgetting}}\textemdash{{A Perspective}}},
  author = {Davis, Ronald L. and Zhong, Yi},
  year = {2017},
  volume = {95},
  doi = {10.1016/j.neuron.2017.05.039},
  abstract = {Pioneering research studies, beginning with those using Drosophila, have identified several molecular and cellular mechanisms for active forgetting. The currently known mechanisms for active forgetting include neurogenesis-based forgetting, interference-based forgetting, and intrinsic forgetting, the latter term describing the brain's chronic signaling systems that function to slowly degrade molecular and cellular memory traces. The best-characterized pathway for intrinsic forgetting includes ``forgetting cells'' that release dopamine onto engram cells, mobilizing a signaling pathway that terminates in the activation of Rac1/Cofilin to effect changes in the actin cytoskeleton and neuron/synapse structure. Intrinsic forgetting may be the default state of the brain, constantly promoting memory erasure and competing with processes that promote memory stability like consolidation. A better understanding of active forgetting will provide insights into the brain's memory management system and human brain disorders that alter active forgetting mechanisms. Davis and Zhong review the neuroscience mechanisms for active forgetting, embedding these within types of forgetting established from experimental psychology. Intrinsic forgetting, one type of active forgetting that chronically erodes memory traces, may be the default state of the brain.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QCUXEYUK\\Davis, Zhong - 2017 - The Biology of Forgetting—A Perspective.pdf},
  isbn = {0896-6273},
  keywords = {consolidation,dopamine,hippocampal neurogenesis,intrinsic forgetting,memory,Rac1},
  pmid = {28772119}
}

@article{daw_dayan_2005,
  title = {Uncertainty-Based Competition between Prefrontal and Dorsolateral Striatal Systems for Behavioral Control},
  author = {Daw, Nathaniel D and Niv, Yael and Dayan, Peter},
  year = {2005},
  volume = {8},
  pages = {1704--1711},
  issn = {1097-6256},
  doi = {10.1038/nn1560},
  abstract = {A broad range of neural and behavioral data suggests that the brain contains multiple systems for behavioral choice, including one associated with prefrontal cortex and another with dorsolateral striatum. However, such a surfeit of control raises an additional choice problem: how to arbitrate between the systems when they disagree. Here, we consider dual-action choice systems from a normative perspective, using the computational theory of reinforcement learning. We identify a key trade-off pitting computational simplicity against the flexible and statistically efficient use of experience. The trade-off is realized in a competition between the dorsolateral striatal and prefrontal systems. We suggest a Bayesian principle of arbitration between them according to uncertainty, so each controller is deployed when it should be most accurate. This provides a unifying account of a wealth of experimental evidence about the factors favoring dominance by either system.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QYJYZ2T3\\Daw, Niv, Dayan - 2005 - Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control.pdf},
  journal = {Nature Neuroscience},
  number = {12},
  pmid = {16286932}
}

@book{dayan_abbott_2003,
  title = {Theoretical Neuroscience: {{Computational}} and {{Mathematical Modeling}} of {{Neural Systems}}},
  author = {Dayan, Peter and Abbott, L F},
  year = {2003},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LF5RBTBA\\Dayan, Abbott - 2003 - Theoretical neuroscience Computational and Mathematical Modeling of Neural Systems.pdf}
}

@article{dayan_daw_2008,
  title = {Decision Theory, Reinforcement Learning, and the Brain},
  author = {Dayan, P. and Daw, N. D.},
  year = {2008},
  month = dec,
  volume = {8},
  pages = {429--453},
  issn = {1530-7026, 1531-135X},
  doi = {10.3758/CABN.8.4.429},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BKL5GCCC\\Dayan and Daw - 2008 - Decision theory, reinforcement learning, and the b.pdf},
  journal = {Cognitive, Affective, \& Behavioral Neuroscience},
  language = {en},
  number = {4}
}

@article{dayan_dayan_1993,
  title = {Improving {{Generalization}} for {{Temporal Difference Learning}}: {{The Successor Representation}}},
  author = {Dayan, Peter},
  year = {1993},
  volume = {5},
  pages = {613--624},
  issn = {0899-7667},
  doi = {10.1162/neco.1993.5.4.613},
  abstract = {Estimation of returns over time, the focus of temporal difference (TD) algorithms, imposes particular constraints on good function approximators or representations. Appropriate generalization between states is determined by how similar their successors are, and representations should follow suit. This paper shows how TD machinery can be used to learn such representations, and illustrates, using a navigation task, the appropriately distributed nature of the result.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\J85DYKMX\\Dayan - Unknown - Improving Generalisation for Temporal Difference Learning The Successor Representation.pdf},
  journal = {Neural Computation},
  number = {4}
}

@article{dean_datta_2013,
  title = {On the {{Technology Prospects}} and {{Investment Opportunities}} for {{Scalable Neuroscience}}},
  author = {Dean, Thomas and Ahanonu, Biafra and Chowdhury, Mainak and Datta, Anjali},
  year = {2013},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9PPTRQVC\\Dean et al. - 2013 - On the Technology Prospects and Investment Opportunities for Scalable Neuroscience.pdf},
  journal = {stanford.edu}
}

@article{deco_kringelbach_2017,
  title = {Perspective {{Hierarchy}} of {{Information Processing}} in the {{Brain}}: {{A Novel}} '{{Intrinsic Ignition}}' {{Framework}}},
  author = {Deco, Gustavo and Kringelbach, Morten L},
  year = {2017},
  doi = {10.1016/j.neuron.2017.03.028},
  abstract = {A general theory of brain function has to be able to explain local and non-local network computations over space and time. We propose a new framework to capture the key principles of how local activity influences global computation, i.e., describing the propagation of information and thus the broadness of communication driven by local activity. More specifically, we consider the diversity in space (nodes or brain regions) over time using the concept of intrinsic ignition, which are naturally occurring intrinsic perturbations reflecting the capability of a given brain area to propagate neuronal activity to other regions in a given brain state. Characterizing the profile of intrinsic ignition for a given brain state provides insight into the precise nature of hierarchical information processing. Combining this data-driven method with a causal whole-brain computational model can provide novel insights into the imbalance of brain states found in neuropsychiatric disorders.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\K2MYCJHR\\Deco, Kringelbach - 2017 - Perspective Hierarchy of Information Processing in the Brain A Novel 'Intrinsic Ignition' Framework.pdf},
  keywords = {binding,brain function,brain state,computational modeling,ignition,perturbation,whole-brain modeling}
}

@article{deco_rolls_2005,
  title = {Attention, Short-Term Memory, and Action Selection: {{A}} Unifying Theory},
  author = {Deco, Gustavo and Rolls, Edmund T.},
  year = {2005},
  volume = {76},
  pages = {236--256},
  issn = {03010082},
  doi = {10.1016/j.pneurobio.2005.08.004},
  abstract = {Cognitive behaviour requires complex context-dependent processing of information that emerges from the links between attentional perceptual processes, working memory and reward-based evaluation of the performed actions. We describe a computational neuroscience theoretical framework which shows how an attentional state held in a short term memory in the prefrontal cortex can by top-down processing influence ventral and dorsal stream cortical areas using biased competition to account for many aspects of visual attention. We also show how within the prefrontal cortex an attentional bias can influence the mapping of sensory inputs to motor outputs, and thus play an important role in decision making. We also show how the absence of expected rewards can switch an attentional bias signal, and thus rapidly and flexibly alter cognitive performance. This theoretical framework incorporates spiking and synaptic dynamics which enable single neuron responses, fMRI activations, psychophysical results, the effects of pharmacological agents, and the effects of damage to parts of the system to be explicitly simulated and predicted. This computational neuroscience framework provides an approach for integrating different levels of investigation of brain function, and for understanding the relations between them. The models also directly address how bottom-up and top-down processes interact in visual cognition, and show how some apparently serial processes reflect the operation of interacting parallel distributed systems. \textcopyright{} 2005 Elsevier Ltd. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VBPI8DGR\\Deco, Rolls - 2005 - Attention, short-term memory, and action selection A unifying theory.pdf},
  journal = {Progress in Neurobiology},
  keywords = {Attention,Biased competition,Decision-making,Executive function,Short-term memory,Task switching},
  number = {4},
  pmid = {16257103}
}

@article{dehaene_naccache_2001,
  title = {Towards a {{Cognitive Neuroscience}} of {{Consciousness}}: {{Basic Evidence}} and a {{Workspace Framework}}},
  author = {Dehaene, Stanislas and Naccache, Lionel},
  year = {2001},
  volume = {79},
  pages = {1--37},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6UD3M3ER\\Dehaene, Naccache - 2001 - Towards a Cognitive Neuroscience of Consciousness Basic Evidence and a Workspace Framework.pdf},
  journal = {Cognition}
}

@article{dejean_herry_2016,
  title = {Prefrontal Neuronal Assemblies Temporally Control Fear Behaviour},
  author = {Dejean, Cyril and Courtin, Julien and Karalis, Nikolaos and Chaudun, Fabrice and Wurtz, H{\'e}l{\`e}ne and Bienvenu, Thomas C M and Herry, Cyril},
  year = {2016},
  volume = {535},
  pages = {420--424},
  issn = {0028-0836},
  doi = {10.1038/nature18630},
  abstract = {Precise spike timing through the coordination and synchronization of neuronal assemblies is an efficient and flexible coding mechanism for sensory and cognitive processing1\textendash 6. In cortical and subcortical areas, the formation of cell assemblies critically depends on neuronal oscillations, which can precisely control the timing of spiking activity7,8. Whereas this form of coding has been described for sensory processing and spatial learning9\textendash 12, its role in encoding emotional behaviour remains unknown. Fear behaviour relies on the activation of distributed structures, among which the dorsal medial prefrontal cortex (dmPFC) is known to be critical for fear memory expression13\textendash 16. In the dmPFC, the phasic activation of neurons to threat-predicting cues, a spike-rate coding mechanism, correlates with conditioned fear responses and supports the discrimination between aversive and neutral stimuli14,17\textendash 19. However, this mechanism does not account for freezing observed outside stimuli presentations, and the contribution of a general spike-time coding mechanism for freezing in the dmPFC remains to be established. Here we use a combination of single-unit and local field potential recordings along with optogenetic manipulations to show that, in the dmPFC, expression of conditioned fear is causally related to the organization of neurons into functional assemblies. During fear behaviour, the development of 4 Hz oscillations coincides with the activation of assemblies nested in the ascending phase of the oscillation. The selective optogenetic inhibition of dmPFC neurons during the ascending or descending phases of this oscillation blocks and promotes conditioned fear responses, respectively. These results identify a novel phase-specific coding mechanism, which dynamically regulates the development of dmPFC assemblies to control the precise timing of fear responses.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TY6JNZUC\\Dejean - Unknown - Prefrontal neuronal assemblies temporally control fear behavior.pdf},
  journal = {Nature},
  number = {7612},
  pmid = {27409809}
}

@article{dekleva_miller_2018,
  title = {Single Reach Plans in Dorsal Premotor Cortex during a Two-Target Task},
  author = {Dekleva, Brian M. and Kording, Konrad P. and Miller, Lee E.},
  year = {2018},
  month = dec,
  volume = {9},
  issn = {2041-1723},
  doi = {10.1038/s41467-018-05959-y},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Y9IAPITI\\Dekleva et al. - Unknown - Single reach plans in dorsal premotor cortex during a two-target task-annotated.pdf},
  journal = {Nature Communications},
  language = {en},
  number = {1}
}

@article{dekock_sakmann_2007,
  title = {Layer- and Cell-Type-Specific Suprathreshold Stimulus Representation in Rat Primary Somatosensory Cortex},
  author = {De Kock, Christian P.J. and Bruno, R. M. and Spors, H. and Sakmann, B.},
  year = {2007},
  volume = {581},
  pages = {139--154},
  issn = {00223751},
  doi = {10.1113/jphysiol.2006.124321},
  abstract = {Sensory stimuli are encoded differently across cortical layers and it is unknown how response characteristics relate to the morphological identity of responding cells. We therefore juxtasomally recorded action potential (AP) patterns from excitatory cells in layer (L) 2/3, L4, L5 and L6 of rat barrel cortex in response to a standard stimulus (e.g. repeated deflection of single whiskers in the caudal direction). Subsequent single-cell filling with biocytin allowed for post hoc identification of recorded cells. We report three major conclusions. First, sensory-evoked responses were layer- and cell-type-specific but always \textbackslash textless 1 AP per stimulus, indicating low AP rates for the entire cortical column. Second, response latencies from L4, L5B and L6 were comparable and thus a whisker deflection is initially represented simultaneously in these layers. Finally, L5 thick-tufted cells dominated the cortical AP output following sensory stimulation, suggesting that these cells could direct sensory guided behaviours.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XJ3IR2JH\\De Kock et al. - 2007 - Layer- and cell-type-specific suprathreshold stimulus representation in rat primary somatosensory cortex.pdf},
  journal = {Journal of Physiology},
  number = {1},
  pmid = {17317752}
}

@article{delbeke_prodanov_2017,
  title = {And {{Then There Was Light}}: {{Perspectives}} of {{Optogenetics}} for {{Deep Brain Stimulation}} and {{Neuromodulation}}},
  shorttitle = {And {{Then There Was Light}}},
  author = {Delbeke, Jean and Hoffman, Luis and Mols, Katrien and Braeken, Dries and Prodanov, Dimiter},
  year = {2017},
  month = dec,
  volume = {11},
  issn = {1662-453X},
  doi = {10.3389/fnins.2017.00663},
  abstract = {Deep Brain Stimulation (DBS) has evolved into a well-accepted add-on treatment for patients with severe Parkinsons disease as well as for other chronic neurological conditions. The focal action of electrical stimulation can yield better responses and it exposes the patient to fewer side effects compared to pharmaceuticals distributed throughout the body toward the brain. On the other hand, the current practice of DBS is hampered by the relatively coarse level of neuromodulation achieved. Optogenetics, in contrast, offers the perspective of much more selective actions on the various physiological structures, provided that the stimulated cells are rendered sensitive to the action of light. Optogenetics has experienced tremendous progress since its first in vivo applications about 10 years ago. Recent advancements of viral vector technology for gene transfer substantially reduce vector-associated cytotoxicity and immune responses. This brings about the possibility to transfer this technology into the clinic as a possible alternative to DBS and neuromodulation. New paths could be opened toward a rich panel of clinical applications. Some technical issues still limit the long term use in humans but realistic perspectives quickly emerge. Despite a rapid accumulation of observations about patho-physiological mechanisms, it is still mostly serendipity and empiric adjustments that dictate clinical practice while more efficient logically designed interventions remain rather exceptional. Interestingly, it is also very much the neuro technology developed around optogenetics that offers the most promising tools to fill in the existing knowledge gaps about brain function in health and disease. The present review examines Parkinson's disease and refractory epilepsy as use cases for possible optogenetic stimulation therapies.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WNLM6CB5\\Delbeke et al. - 2017 - And Then There Was Light Perspectives of Optogene.pdf},
  journal = {Frontiers in Neuroscience},
  language = {en}
}

@article{delbruck_hasler_2014,
  title = {Research Topic: Neuromorphic Engineering Systems and Applications. {{A}} Snapshot of Neuromorphic Systems Engineering},
  author = {Delbruck, Tobi and {van Schaik}, Andr{\~A}{\textcopyright} and Hasler, Jennifer},
  year = {2014},
  month = dec,
  volume = {8},
  pages = {1--2},
  issn = {1662-453X},
  doi = {10.3389/fnins.2014.00424},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4ERM759P\\Delbruck, van Schaik, Hasler - 2014 - Research topic neuromorphic engineering systems and applications. A snapshot of neuromorphic syste.pdf},
  journal = {Frontiers in Neuroscience},
  keywords = {dynamic vision sensor,event-b,event-based,floating gate,neural networks,neural simulation,neuromorphic engineering,spiking neural networks},
  number = {December}
}

@article{deloache_deloache_2004,
  title = {Becoming Symbol-Minded},
  author = {DeLoache, Judy S.},
  year = {2004},
  volume = {8},
  pages = {66--70},
  issn = {13646613},
  doi = {10.1016/j.tics.2003.12.004},
  abstract = {No facet of human development is more crucial than becoming symbol-minded. To participate fully in any society, children have to master the symbol systems that are important in that society. Children today must learn to use more varieties of symbolic media than ever before, so it is even more important to understand the processes involved in symbolic development. Recent research has greatly expanded what we know about early symbol use. We have learned, for example, that infants initially accept a wide range of entities as potential symbols and that young children are often confused about the nature of symbol-referent relations. During the first few years of life, however, children make rapid progress towards becoming competent symbol users.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\P9FIKFLC\\DeLoache - 2004 - Becoming symbol-minded.pdf},
  journal = {Trends in Cognitive Sciences},
  number = {2},
  pmid = {15588810}
}

@article{delorme_makeig_2011,
  title = {{{EEGLAB}}, {{SIFT}}, {{NFT}}, {{BCILAB}}, and {{ERICA}}: {{New}} Tools for Advanced {{EEG}} Processing},
  author = {Delorme, Arnaud and Mullen, Tim and Kothe, Christian and Akalin Acar, Zeynep and {Bigdely-Shamlo}, Nima and Vankov, Andrey and Makeig, Scott},
  year = {2011},
  volume = {2011},
  issn = {16875265},
  doi = {10.1155/2011/130714},
  abstract = {We describe a set of complementary EEG data collection and processing tools recently developed at the Swartz Center for Computational Neuroscience (SCCN) that connect to and extend the EEGLAB software environment, a freely available and readily extensible processing environment running under Matlab. The new tools include (1) a new and flexible EEGLAB STUDY design facility for framing and performing statistical analyses on data from multiple subjects; (2) a neuroelectromagnetic forward head modeling toolbox (NFT) for building realistic electrical head models from available data; (3) a source information flow toolbox (SIFT) for modeling ongoing or event-related effective connectivity between cortical areas; (4) a BCILAB toolbox for building online brain-computer interface (BCI) models from available data, and (5) an experimental real-time interactive control and analysis (ERICA) environment for real-time production and coordination of interactive, multimodal experiments.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RI7LCAPJ\\Delorme et al. - 2011 - EEGLAB, SIFT, NFT, BCILAB, and ERICA New tools for advanced EEG processing.pdf},
  journal = {Computational Intelligence and Neuroscience},
  pmid = {21687590}
}

@article{deneve_bourdoukan_2017,
  title = {The {{Brain}} as an {{Efficient}} and {{Robust Adaptive Learner}}},
  author = {Den{\`e}ve, Sophie and Alemi, Alireza and Bourdoukan, Ralph},
  year = {2017},
  month = jun,
  volume = {94},
  pages = {969--977},
  issn = {08966273},
  doi = {10.1016/j.neuron.2017.05.016},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L3SMS6DV\\Denève et al. - 2017 - The Brain as an Efficient and Robust Adaptive Lear.pdf},
  journal = {Neuron},
  language = {en},
  number = {5}
}

@article{deneve_machens_2016,
  title = {Efficient Codes and Balanced Networks},
  author = {Den{\`e}ve, Sophie and Machens, Christian K},
  year = {2016},
  month = mar,
  volume = {19},
  pages = {375--382},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn.4243},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MEIZ4LCM\\Denève and Machens - 2016 - Efficient codes and balanced networks.pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {3}
}

@article{deneve_pouget_2001,
  title = {Efficient Computation and Cue Integration with Noisy Population Codes},
  author = {Deneve, Sophie and Latham, P E and Pouget, A},
  year = {2001},
  volume = {4},
  pages = {826--831},
  issn = {10976256},
  doi = {10.1038/90541},
  abstract = {The brain represents sensory and motor variables through the activity of large populations of neurons. It is not understood how the nervous system computes with these population codes, given that individual neurons are noisy and thus unreliable. We focus here on two general types of computation, function approximation and cue integration, as these are powerful enough to handle a range of tasks, including sensorimotor transformations, feature extraction in sensory systems and multisensory integration. We demonstrate that a particular class of neural networks, basis function networks with multidimensional attractors, can perform both types of computation optimally with noisy neurons. Moreover, neurons in the intermediate layers of our model show response properties similar to those observed in several multimodal cortical areas. Thus, basis function networks with multidimensional attractors may be used by the brain to compute efficiently with population codes.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LDCWB7G4\\Deneve, Latham, Pouget - 2001 - Efficient Computation and Cue Integration With Noisy Population Code.pdf},
  journal = {Nature Neuroscience},
  number = {8},
  pmid = {11477429}
}

@article{deng_xie_2020,
  title = {Rethinking the Performance Comparison between {{SNNS}} and {{ANNS}}},
  author = {Deng, Lei and Wu, Yujie and Hu, Xing and Liang, Ling and Ding, Yufei and Li, Guoqi and Zhao, Guangshe and Li, Peng and Xie, Yuan},
  year = {2020},
  month = jan,
  volume = {121},
  pages = {294--307},
  issn = {08936080},
  doi = {10.1016/j.neunet.2019.09.005},
  abstract = {Artificial neural networks (ANNs), a popular path towards artificial intelligence, have experienced remarkable success via mature models, various benchmarks, open-source datasets, and powerful computing platforms. Spiking neural networks (SNNs), a category of promising models to mimic the neuronal dynamics of the brain, have gained much attention for brain inspired computing and been widely deployed on neuromorphic devices. However, for a long time, there are ongoing debates and skepticisms about the value of SNNs in practical applications. Except for the low power attribute benefit from the spike-driven processing, SNNs usually perform worse than ANNs especially in terms of the application accuracy. Recently, researchers attempt to address this issue by borrowing learning methodologies from ANNs, such as backpropagation, to train high-accuracy SNN models. The rapid progress in this domain continuously produces amazing results with ever-increasing network size, whose growing path seems similar to the development of deep learning. Although these ways endow SNNs the capability to approach the accuracy of ANNs, the natural superiorities of SNNs and the way to outperform ANNs are potentially lost due to the use of ANN-oriented workloads and simplistic evaluation metrics.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\C6U76PVI\\Deng et al. - 2020 - Rethinking the performance comparison between SNNS.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\IG7LXPEW\\Deng et al. - 2020 - Rethinking the performance comparison between SNNS.pdf},
  journal = {Neural Networks},
  language = {en}
}

@techreport{denison_heeger_2019,
  title = {A Dynamic Normalization Model of Temporal Attention},
  author = {Denison, Rachel N. and Carrasco, Marisa and Heeger, David J.},
  year = {2019},
  month = dec,
  institution = {{Neuroscience}},
  doi = {10.1101/2019.12.21.886051},
  abstract = {Vision is dynamic, handling a continuously changing stream of input, yet most models of visual attention are static. Here, we develop a dynamic normalization model of visual temporal attention and constrain it with new psychophysical human data. We manipulated temporal attention\textendash the prioritization of visual information at specific points in time\textendash to a sequence of two stimuli separated by a variable time interval. Voluntary temporal attention improved perceptual sensitivity only over a specific interval range. To explain these data, we modeled voluntary and involuntary attentional gain dynamics. Voluntary gain enhancement took the form of a limited resource over short time intervals, which recovered over time. Taken together, our theoretical and experimental results formalize and generalize the idea of limited attentional resources across space at a single moment to limited resources across time at a single location.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XUJ3M7ZS\\Denison et al. - 2019 - A dynamic normalization model of temporal attentio.pdf},
  language = {en},
  type = {Preprint}
}

@article{depannemaecker_dealmeida_2019,
  title = {Realistic Spiking Neural Network: {{Non}}-Synaptic Mechanisms Improve Convergence in Cell Assembly},
  shorttitle = {Realistic Spiking Neural Network},
  author = {Depannemaecker, Damien and Canton Santos, Luiz Eduardo and Rodrigues, Ant{\^o}nio M{\'a}rcio and Scorza, Carla Alessandra and Scorza, Fulvio Alexandre and {de Almeida}, Ant{\^o}nio-Carlos Guimar{\~a}es},
  year = {2019},
  month = oct,
  pages = {S089360801930320X},
  issn = {08936080},
  doi = {10.1016/j.neunet.2019.09.038},
  abstract = {Learning in neural networks inspired by brain tissue has been studied for machine learning applications. However, existing works primarily focused on the concept of synaptic weight modulation, and other aspects of neuronal interactions, such as non-synaptic mechanisms, have been neglected. Non-synaptic interaction mechanisms have been shown to play significant roles in the brain, and four classes of these mechanisms can be highlighted: i) electrotonic coupling; ii) ephaptic interactions; iii) electric field effects; and iv) extracellular ionic fluctuations. In this work, we proposed simple rules for learning inspired by recent findings in machine learning adapted to a realistic spiking neural network. We show that the inclusion of non-synaptic interaction mechanisms improves cell assembly convergence. By including extracellular ionic fluctuation represented by the extracellular electrodiffusion in the network, we showed the importance of these mechanisms to improve cell assembly convergence. Additionally, we observed a variety of electrophysiological patterns of neuronal activity, particularly bursting and synchronism when the convergence is improved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9FE6QPRG\\Depannemaecker et al. - 2019 - Realistic spiking neural network Non-synaptic mec.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\KGS8BW4C\\Depannemaecker et al. - 2019 - Realistic spiking neural network Non-synaptic mec.pdf},
  journal = {Neural Networks},
  language = {en}
}

@article{depasquale1$_abbott_2018,
  title = {Full-{{FORCE}}: {{A}} Target-Based Method for Training Recurrent Networks},
  author = {Depasquale 1{\textcurrency}, Brian and Cueva, Christopher J and Rajan, Kanaka and Escola, G Sean and Abbott, L F},
  year = {2018},
  doi = {10.1371/journal.pone.0191527},
  abstract = {Trained recurrent networks are powerful tools for modeling dynamic neural computations. We present a target-based method for modifying the full connectivity matrix of a recurrent network to train it to perform tasks involving temporally complex input/output transforma-tions. The method introduces a second network during training to provide suitable " target " dynamics useful for performing the task. Because it exploits the full recurrent connectivity, the method produces networks that perform tasks with fewer neurons and greater noise robustness than traditional least-squares (FORCE) approaches. In addition, we show how introducing additional input signals into the target-generating network, which act as task hints, greatly extends the range of tasks that can be learned and provides control over the complexity and nature of the dynamics of the trained, task-performing network.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\V3LWAETZ\\Depasquale 1¤ et al. - Unknown - full-FORCE A target-based method for training recurrent networks.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\XYU42B97\\DePasquale et al. - 2018 - full-FORCE A target-based method for training rec.pdf}
}

@article{depue_banich_2016,
  title = {The {{Organization}} of {{Right Prefrontal Networks Reveals Common Mechanisms}} of {{Inhibitory Regulation Across Cognitive}}, {{Emotional}}, and {{Motor Processes}}},
  author = {Depue, B E and Orr, J M and Smolker, H R and Naaz, F and Banich, M T},
  year = {2016},
  volume = {26},
  pages = {1634--1646},
  issn = {14602199},
  doi = {10.1093/cercor/bhu324},
  abstract = {Inhibitory control/regulation is critical to adapt behavior in accordance with changing environmental circumstances. Dysfunctional inhibitory regulation is ubiquitous in neurological and psychiatric populations. These populations exhibit dysfunction across psychological domains, including memory/thought, emotion/affect, and motor response. Although investigation examining inhibitory regulation within a single domain has begun outlining the basic neural mechanisms supporting regulation, it is unknown how the neural mechanisms of these domains interact. To investigate the organization of inhibitory neural networks within and across domains, we used neuroimaging to outline the functional and anatomical pathways that comprise inhibitory neural networks regulating cognitive, emotional, and motor processes. Networks were defined at the group level using an array of analyses to indicate their intrinsic pathway structure, which was subsequently assessed to determine how the pathways explained individual differences in behavior. Results reveal how neural networks underlying inhibitory regulation are organized both within and across domains, and indicate overlapping/common neural elements.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IKJKEUAC\\Depue et al. - 2016 - The Organization of Right Prefrontal Networks Reveals Common Mechanisms of Inhibitory Regulation Across Cognitive,.pdf},
  journal = {Cerebral Cortex},
  keywords = {cognition,inhibition,neuroimaging,prefrontal cortex},
  number = {4},
  pmid = {25601236}
}

@article{depue_curran_2013,
  title = {{{ERPs}} and {{Neural Oscillations}} during {{Volitional Suppression}} of {{Memory Retrieval}}},
  author = {Depue, Brendan Eliot and a Ketz, Nicholas and Mollison, Matthew V and Nyhus, Erika and Banich, Marie T and Curran, Tim},
  year = {2013},
  volume = {25},
  pages = {1624--1633},
  issn = {0898-929X},
  doi = {10.1162/jocn_a_00418},
  abstract = {Although investigations of memory and the dynamics of ERP components and neural oscillations as assessed through EEG have been well utilized, little research into the volitional nature of suppression over memory retrieval have used these methods. Oscillation analyses conducted on the Think/No-Think (TNT) task and volitional suppression of retrieval are of interest to broaden our knowledge of neural oscillations associated not only during successful memory retrieval but also when retrieval is unwanted or suppressed. In the current study, we measured EEG during a TNT task and performed ERP and EEG spectral power band analyses. ERP results replicated other researchers' observations of increases in 500\textendash 800 msec parietal effects for items where retrieval was instructed to be elaborated compared with being suppressed. Furthermore, EEG analyses indicated increased alpha (8\textendash 12 Hz) and theta (3\textendash 8 Hz) oscillations across parietal electrodes for items that were instructed to be suppressed versus those to be elaborat...},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TSHX2L2D\\Depue et al. - 2013 - ERPs and Neural Oscillations during Volitional Suppression of Memory Retrieval.pdf},
  journal = {Journal of Cognitive Neuroscience},
  number = {10},
  pmid = {23647519}
}

@book{derdikman_knierim_2014,
  title = {Space, Time and Memory in the Hippocampal Formation},
  editor = {Derdikman, Dori and Knierim, James J.},
  year = {2014},
  publisher = {{Springer Verlag Wien}},
  address = {{Wien}},
  annotation = {OCLC: ocn872989098},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TQ9ZXVNU\\Derdikman and Knierim - 2014 - Space, time and memory in the hippocampal formatio.pdf},
  isbn = {978-3-7091-1291-5},
  language = {en},
  lccn = {QP383.25 .S63 2014}
}

@article{desrochers_badre_2015,
  title = {The {{Necessity}} of {{Rostrolateral Prefrontal Cortex}} for {{Higher}}-{{Level Sequential Behavior}}},
  author = {Desrochers, Theresa M and Chatham, Christopher H and Badre, David},
  year = {2015},
  volume = {87},
  pages = {1357--1368},
  issn = {10974199},
  doi = {10.1016/j.neuron.2015.08.026},
  abstract = {Frontal neocortex is thought to support our highest intellectual abilities, including our ability to plan and enact a sequence of tasks toward a desired goal. In everyday life, such task sequences are abstract in that they do not require consistent movement sequences and are often assembled "on the fly." Yet, remarkably little is known about the necessity of frontal sub-regions for such control. Participants repeatedly completed sequences of simple tasks during fMRI scanning. Rostrolateral prefrontal cortex (RLPFC) activation ramped over sequence position and reset at the initiation of each new sequence. To establish the necessity and function of RLPFC in this task, participants performed the sequential task while undergoing transcranial magnetic stimulation (TMS) of the RLPFC versus two prefrontal control regions. Across two independent experiments, only RLPFC stimulation increasingly disrupted task performance as each sequence progressed. These data establish RLPFC as necessary for uncertainty resolution during sequence-level control. Sequences of tasks are ubiquitous in everyday life, but little is known about how they are controlled by the brain. Desrochers et al. show that rostrolateral prefrontal cortex provides a transient top-down signal to keep task sequences on track.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7UIZPZCY\\Desrochers, Chatham, Badre - 2015 - The Necessity of Rostrolateral Prefrontal Cortex for Higher-Level Sequential Behavior.pdf},
  journal = {Neuron},
  number = {6},
  pmid = {26402612}
}

@article{desrochers_sheinberg_2015,
  title = {The {{Monitoring}} and {{Control}} of {{Task Sequences}} in {{Human}} and {{Non}}-{{Human Primates}}.},
  author = {Desrochers, Theresa M and Burk, Diana C and Badre, David and Sheinberg, David L},
  year = {2015},
  volume = {9},
  pages = {185},
  issn = {1662-5137},
  doi = {10.3389/fnsys.2015.00185},
  abstract = {Our ability to plan and execute a series of tasks leading to a desired goal requires remarkable coordination between sensory, motor, and decision-related systems. Prefrontal cortex (PFC) is thought to play a central role in this coordination, especially when actions must be assembled extemporaneously and cannot be programmed as a rote series of movements. A central component of this flexible behavior is the moment-by-moment allocation of working memory and attention. The ubiquity of sequence planning in our everyday lives belies the neural complexity that supports this capacity, and little is known about how frontal cortical regions orchestrate the monitoring and control of sequential behaviors. For example, it remains unclear if and how sensory cortical areas, which provide essential driving inputs for behavior, are modulated by the frontal cortex during these tasks. Here, we review what is known about moment-to-moment monitoring as it relates to visually guided, rule-driven behaviors that change over time. We highlight recent human work that shows how the rostrolateral prefrontal cortex (RLPFC) participates in monitoring during task sequences. Neurophysiological data from monkeys suggests that monitoring may be accomplished by neurons that respond to items within the sequence and may in turn influence the tuning properties of neurons in posterior sensory areas. Understanding the interplay between proceduralized or habitual acts and supervised control of sequences is key to our understanding of sequential task execution. A crucial bridge will be the use of experimental protocols that allow for the examination of the functional homology between monkeys and humans. We illustrate how task sequences may be parceled into components and examined experimentally, thereby opening future avenues of investigation into the neural basis of sequential monitoring and control.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XWT3FBIX\\Desrochers et al. - 2015 - The Monitoring and Control of Task Sequences in Human and Non-Human Primates.pdf},
  journal = {Frontiers in systems neuroscience},
  keywords = {Attention,Electrophysiology,executive functions,frontal cortex,human imaging studies,Monitoring,Motor Sequences,non-human primates,review,Sequential control,Task sequences,TMS},
  number = {January},
  pmid = {26834581}
}

@article{destrebecqz_cleeremans_2001,
  title = {Can Sequence Learning Be Implicit? {{New}} Evidence with the Process Dissociation Procedure},
  author = {Destrebecqz, Arnaud and Cleeremans, Axel},
  year = {2001},
  volume = {8},
  pages = {343--350},
  issn = {10699384},
  doi = {10.3758/BF03196171},
  abstract = {Can we learn without awareness? Although this issue has been extensively explored through studies of implicit learning, there is currently no agreement about the extent to which knowledge can be acquired and projected onto performance in an unconscious way. The controversy, like that surrounding implicit memory, seems to be at least in part attributable to unquestioned acceptance of the unrealistic assumption that tasks are process-pure\textendash that is, that a given task exclusively involves either implicit or explicit knowledge. Methods such as the process dissociation procedure (PDP, Jacoby, 1991) have been developed to overcome the conceptual limitations of the process purity assumption but have seldom been used in the context of implicit learning research. In this paper, we show how the PDP can be applied to a free generation task so as to disentangle explicit and implicit sequence learning. Our results indicate that subjects who are denied preparation to the next stimulus nevertheless exhibit knowledge of the sequence through their reaction time performance despite remaining unable (1) to project this knowledge in a recognition task and (2) to refrain from expressing their knowledge when specifically instructed to do so. These findings provide strong evidence that sequence learning can be unconscious.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8DGEICYK\\Unknown - 2001 - Can sequence learning be implicit New evidence with the process dissociation procedure.pdf},
  journal = {Psychonomic Bulletin and Review},
  number = {2},
  pmid = {11495124}
}

@article{detorakis_neftci_2018,
  title = {Contrastive {{Hebbian Learning}} with {{Random Feedback Weights}}},
  author = {Detorakis, Georgios and Bartley, Travis and Neftci, Emre},
  year = {2018},
  month = jun,
  abstract = {Neural networks are commonly trained to make predictions through learning algorithms. Contrastive Hebbian learning, which is a powerful rule inspired by gradient backpropagation, is based on Hebb's rule and the contrastive divergence algorithm. It operates in two phases, the forward (or free) phase, where the data are fed to the network, and a backward (or clamped) phase, where the target signals are clamped to the output layer of the network and the feedback signals are transformed through the transpose synaptic weight matrices. This implies symmetries at the synaptic level, for which there is no evidence in the brain. In this work, we propose a new variant of the algorithm, called random contrastive Hebbian learning, which does not rely on any synaptic weights symmetries. Instead, it uses random matrices to transform the feedback signals during the clamped phase, and the neural dynamics are described by first order non-linear differential equations. The algorithm is experimentally verified by solving a Boolean logic task, classification tasks (handwritten digits and letters), and an autoencoding task. This article also shows how the parameters affect learning, especially the random matrices. We use the pseudospectra analysis to investigate further how random matrices impact the learning process. Finally, we discuss the biological plausibility of the proposed algorithm, and how it can give rise to better computational models for learning.},
  archivePrefix = {arXiv},
  eprint = {1806.07406},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KUFMZYJL\\Detorakis et al_2018_Contrastive Hebbian Learning with Random Feedback Weights.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\U8952NRS\\Detorakis et al. - 2019 - Contrastive Hebbian learning with random feedback .pdf;C\:\\Users\\wchapman\\Zotero\\storage\\NZVZEDPJ\\1806.html},
  journal = {arXiv:1806.07406 [cs, q-bio, stat]},
  primaryClass = {cs, q-bio, stat}
}

@article{devereux_tyler_2018,
  title = {Integrated Deep Visual and Semantic Attractor Neural Networks Predict {{fMRI}} Pattern-Information along the Ventral Object Processing Pathway},
  author = {Devereux, Barry J and Clarke, Alex and Tyler, Lorraine K},
  year = {2018},
  volume = {8},
  pages = {10636},
  issn = {20452322},
  doi = {10.1038/s41598-018-28865-1},
  abstract = {Recognising an object involves rapid visual processing and activation of semantic knowledge about the object, but how visual processing activates and interacts with semantic representations remains unclear. Cognitive neuroscience research has shown that while visual processing involves posterior regions along the ventral stream, object meaning involves more anterior regions, especially perirhinal cortex. Here we investigate visuo-semantic processing by combining a deep neural network model of vision with an attractor network model of semantics, such that visual information maps onto object meanings represented as activation patterns across features. In the combined model, concept activation is driven by visual input and co-occurrence of semantic features, consistent with neurocognitive accounts. We tested the model\{\$\textbackslash backslash\$textquoteright\}s ability to explain fMRI data where participants named objects. Visual layers explained activation patterns in early visual cortex, whereas pattern-information in perirhinal cortex was best explained by later stages of the attractor network, when detailed semantic representations are activated. Posterior ventral temporal cortex was best explained by intermediate stages corresponding to initial semantic processing, when visual information has the greatest influence on the emerging semantic representation. These results provide proof of principle of how a mechanistic model of combined visuo-semantic processing can account for pattern-information in the ventral stream.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6H8782GG\\Devereux, Clarke, Tyler - 2018 - Integrated deep visual and semantic attractor neural networks predict fMRI pattern-information along th.pdf},
  journal = {Scientific Reports},
  number = {1}
}

@article{devries_olivers_2018,
  title = {Priority {{Switches}} in {{Visual Working Memory}} Are {{Supported}} by {{Frontal Delta}} and {{Posterior Alpha Interactions}}},
  author = {De Vries, Ingmar E J and Van Driel, Joram and Karacaoglu, Merve and Olivers, Christian N L},
  year = {2018},
  volume = {28},
  pages = {4090--4104},
  doi = {10.1093/cercor/bhy223},
  abstract = {Visual working memory (VWM) distinguishes between representations relevant for imminent versus future perceptual goals. We investigated how the brain sequentially prioritizes visual working memory representations that serve consecutive tasks. Observers remembered two targets for a sequence of two visual search tasks, thus making one target currently relevant, and the other prospectively relevant. We show that during the retention interval prior to the first search, lateralized parieto-occipital EEG alpha (8-14 Hz) suppression is stronger for current compared with prospective search targets. Crucially, between the first and second search task, this difference in posterior alpha lateralization reverses, reflecting the change in priority states of the two target representations. Connectivity analyses indicate that this switch in posterior alpha lateralization is driven by frontal delta/low-theta (2-6 Hz) activity. Moreover, this frontal low-frequency signal also predicts task performance after the switch. We thus obtained evidence for large-scale network interactions underlying the flexible shifting between the priority states of multiple memory representations in VWM.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XBASDKVY\\De Vries et al. - 2018 - Priority Switches in Visual Working Memory are Supported by Frontal Delta and Posterior Alpha Interactions.pdf},
  journal = {Cerebral Cortex},
  keywords = {cognitive control,cross-frequency-coupling,eeg,neural oscillations,visual attention}
}

@article{devries_olivers_2020,
  title = {Oscillatory {{Control}} over {{Representational States}} in {{Working Memory}}},
  author = {{de Vries}, Ingmar E.J. and Slagter, Heleen A. and Olivers, Christian N.L.},
  year = {2020},
  month = feb,
  volume = {24},
  pages = {150--162},
  issn = {13646613},
  doi = {10.1016/j.tics.2019.11.006},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RU6STLZJ\\de Vries et al. - 2020 - Oscillatory Control over Representational States i.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {2}
}

@article{dewolf_eliasmith_2013,
  title = {A Neural Model of the Development of Expertise},
  author = {DeWolf, T and Eliasmith, Chris},
  year = {2013},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L7IPI9TH\\DeWolf, Eliasmith - 2013 - A neural model of the development of expertise.pdf},
  journal = {Trials},
  keywords = {au-,basal ganglia,building blocks to create,even more com-,expert actions,moves to envision,neural engineering framework,plex actions,stringing together series of,these new actions as,tomaticity}
}

@article{dezubicaray_dezubicaray_2001,
  title = {Brain {{Activity During}} the {{Encoding}}, {{Retention}}, and {{Retrieval}} of {{Stimulus Representations}}},
  author = {{de Zubicaray}, G. I.},
  year = {2001},
  month = sep,
  volume = {8},
  pages = {243--251},
  issn = {10720502},
  doi = {10.1101/lm.40301},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\82EQC2N7\\de Zubicaray - 2001 - Brain Activity During the Encoding, Retention, and.pdf},
  journal = {Learning \& Memory},
  language = {en},
  number = {5}
}

@article{dias-ferreira_costa_2012,
  title = {The Symphony of Choice},
  author = {{Dias-Ferreira}, Eduardo and Costa, Rui M.},
  year = {2012},
  month = apr,
  volume = {484},
  pages = {42--43},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/484042a},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YMBMLWWW\\Dias-Ferreira and Costa - 2012 - The symphony of choice.pdf},
  journal = {Nature},
  language = {en},
  number = {7392}
}

@article{diaz_zhang_2013,
  title = {Widespread Production of Extracellular Superoxide by Heterotrophic Bacteria},
  author = {Diaz, Julia M. and Hansel, Colleen M. and Voelker, Bettina M. and Mendes, Chantal M. and Andeer, Peter F. and Zhang, Tong},
  year = {2013},
  issn = {10959203},
  doi = {10.1126/science.1237331},
  abstract = {Superoxide and other reactive oxygen species (ROS) originate from several natural sources and profoundly influence numerous elemental cycles, including carbon and trace metals. In the deep ocean, the permanent absence of light precludes currently known ROS sources, yet ROS production mysteriously occurs. Here, we show that taxonomically and ecologically diverse heterotrophic bacteria from aquatic and terrestrial environments are a vast, unrecognized, and light-independent source of superoxide, and perhaps other ROS derived from superoxide. Superoxide production by a model bacterium within the ubiquitous Roseobacter clade involves an extracellular oxidoreductase that is stimulated by the reduced form of nicotinamide adenine dinucleotide (NADH), suggesting a surprising homology with eukaryotic organisms. The consequences of ROS cycling in immense aphotic zones representing key sites of nutrient regeneration and carbon export must now be considered, including potential control of carbon remineralization and metal bioavailability.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CMBIWFM2\\Diaz et al. - 2013 - Widespread production of extracellular superoxide by heterotrophic bacteria.pdf},
  journal = {Science},
  pmid = {23641059}
}

@article{diba_buzsaki_2007,
  title = {Forward and Reverse Hippocampal Place-Cell Sequences during Ripples},
  author = {Diba, Kamran and Buzs{\'a}ki, Gy{\"o}rgy},
  year = {2007},
  month = oct,
  volume = {10},
  pages = {1241--1242},
  issn = {1546-1726},
  doi = {10.1038/nn1961},
  abstract = {We report that temporal spike sequences from hippocampal place neurons of rats on an elevated track recurred in reverse order at the end of a run, but in forward order in anticipation of the run, coinciding with sharp waves. Vector distances between the place fields were reflected in the temporal structure of these sequences. This bidirectional re-enactment of temporal sequences may contribute to the establishment of higher-order associations in episodic memory.},
  copyright = {2007 Nature Publishing Group},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BAWTSUKW\\Diba and Buzsáki - 2007 - Forward and reverse hippocampal place-cell sequenc.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\2PSCQFEF\\nn1961.html},
  journal = {Nature Neuroscience},
  language = {en},
  number = {10}
}

@article{dicarlo_cox_2007,
  title = {Untangling Invariant Object Recognition},
  author = {DiCarlo, James J. and Cox, David D.},
  year = {2007},
  month = aug,
  volume = {11},
  pages = {333--341},
  issn = {13646613},
  doi = {10.1016/j.tics.2007.06.010},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RZY784AC\\DiCarlo and Cox - 2007 - Untangling invariant object recognition.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {8}
}

@article{dicke_thier_1999,
  title = {The Role of Cortical Area {{MST}} in a Model of Combined Smooth Eye-Head Pursuit},
  author = {Dicke, Peter W. and Thier, Peter},
  year = {1999},
  month = jan,
  volume = {80},
  pages = {71--84},
  issn = {0340-1200, 1432-0770},
  doi = {10.1007/s004220050505},
  abstract = {The cortical medial superior temporal area (MST) is essential for the normal execution of smooth pursuit eye movements. Many pursuit-related neurons (visual-tracking neurons  VT neurons) in the lateral part of area MST (MSTl) are responsive to retinal image slip (r) as well as to eye (e) and head velocity (h) with similar preferred directions (isodirectionality). We show, by running a connectionist network with VT neuron-like elements, that an assembly of MSTl-VT neurons is able to reconstruct target motion in world-centered coordinates (t\textcent ). When t\textcent{} is fed into a subsequent model stage, converting t\textcent{} into gaze velocity (g\textcent ) with varying contributions of e and h, the overall model is able to account for many of the salient properties of visually guided pursuit including the consequences of MSTl lesions. However, the analysis of the MSTl network also clearly indicates that isodirectionality is not a prerequisite for its performance. The investigation of a second model suggests that isodirectionality indeed does not result from functional but from developmental constraints. This second model is a connectionist network with hidden units, which similar to MSTl-VT neurons receive input from modality speci\textregistered c units encoding retinal slip, eye and head velocity. After training this network to oer t\textcent{} as output, two subsets of hidden units emerged, one exhibiting isodirectionality, but not the other. Since only isodirectional hidden units contributed to the \textasciimacron ow of information, the preponderance of isodirectional MSTl-VT neurons might be the result of developmental pruning, eliminating the second group.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IXXYBVTQ\\Dicke and Thier - 1999 - The role of cortical area MST in a model of combin.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\VNYV63L3\\Dicke and Thier - 1999 - The role of cortical area MST in a model of combin.pdf},
  journal = {Biological Cybernetics},
  language = {en},
  number = {1}
}

@article{diehl_cook_2015,
  title = {Unsupervised Learning of Digit Recognition Using Spike-Timing-Dependent Plasticity},
  author = {Diehl, Peter U and Cook, Matthew},
  year = {2015},
  volume = {1},
  pages = {99},
  doi = {10.3389/fncom.2015.00099},
  abstract = {In order to understand how the mammalian neocortex is performing computations, two things are necessary; we need to have a good understanding of the available neuronal processing units and mechanisms, and we need to gain a better understanding of how those mechanisms are combined to build functioning systems. Therefore, in recent years there is an increasing interest in how spiking neural networks (SNN) can be used to perform complex computations or solve pattern recognition tasks. However, it remains a challenging task to design SNNs which use biologically plausible mechanisms (especially for learning new patterns), since most such SNN architectures rely on training in a rate-based network and subsequent conversion to a SNN. We present a SNN for digit recognition which is based on mechanisms with increased biological plausibility, i.e., conductance-based instead of current-based synapses, spike-timing-dependent plasticity with time-dependent weight change, lateral inhibition, and an adaptive spiking threshold. Unlike most other systems, we do not use a teaching signal and do not present any class labels to the network. Using this unsupervised learning scheme, our architecture achieves 95\% accuracy on the MNIST benchmark, which is better than previous SNN implementations without supervision. The fact that we used no domain-specific knowledge points toward the general applicability of our network design. Also, the performance of our network scales well with the number of neurons used and shows similar performance for four different learning rules, indicating robustness of the full combination of mechanisms, which suggests applicability in heterogeneous biological neural networks.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NTYJSQ9F\\Mel et al. - 2015 - Unsupervised learning of digit recognition using spike-timing-dependent plasticity.pdf},
  journal = {Frontiers in Computational Neuroscience | www.frontiersin.org},
  keywords = {classification,digit recognition,spiking neural network,STDP,unsupervised learning}
}

@article{diesmann_gewaltig_2001,
  title = {{{NEST}}: {{An}} Environment for Neural Systems Simulations},
  author = {Diesmann, Markus and Gewaltig, M O},
  year = {2001},
  pages = {43--70},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IWAZ55ZR\\Diesmann, Gewaltig - 2001 - NEST An environment for neural systems simulations.pdf},
  journal = {\{\textbackslash ldots\} Rechnen, Beitr\{\"a\}ge zum Heinz-Billing-Preis}
}

@article{ding_burgalossi_2020,
  title = {Structural {{Correlates}} of {{CA2}} and {{CA3 Pyramidal Cell Activity}} in {{Freely}}-{{Moving Mice}}},
  author = {Ding, Lingjun and Chen, Hongbiao and Diamantaki, Maria and Coletta, Stefano and {Preston-Ferrer}, Patricia and Burgalossi, Andrea},
  year = {2020},
  month = jul,
  volume = {40},
  pages = {5797--5806},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0099-20.2020},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GLDIY3K9\\Ding et al. - 2020 - Structural Correlates of CA2 and CA3 Pyramidal Cel.pdf},
  journal = {The Journal of Neuroscience},
  language = {en},
  number = {30}
}

@article{doborjeh_gandomi_2019,
  title = {Personalised Modelling with Spiking Neural Networks Integrating Temporal and Static Information},
  author = {Doborjeh, Maryam and Kasabov, Nikola and Doborjeh, Zohreh and Enayatollahi, Reza and Tu, Enmei and Gandomi, Amir H.},
  year = {2019},
  month = nov,
  volume = {119},
  pages = {162--177},
  issn = {08936080},
  doi = {10.1016/j.neunet.2019.07.021},
  abstract = {This paper proposes a new personalised prognostic/diagnostic system that supports classification, prediction and pattern recognition when both static and dynamic/spatiotemporal features are presented in a dataset. The system is based on a proposed clustering method (named d2WKNN) for optimal selection of neighbouring samples to an individual with respect to the integration of both static (vector-based) and temporal individual data. The most relevant samples to an individual are selected to train a Personalised Spiking Neural Network (PSNN) that learns from sets of streaming data to capture the space and time association patterns. The generated time-dependant patterns resulted in a higher accuracy of classification/prediction (80\% to 93\%) when compared with global modelling and conventional methods. In addition, the PSNN models can support interpretability by creating personalised profiling of an individual. This contributes to a better understanding of the interactions between features. Therefore, an end-user can comprehend what interactions in the model have led to a certain decision (outcome). The proposed PSNN model is an analytical tool, applicable to several real-life health applications, where different data domains describe a person's health condition. The system was applied to two case studies: (1) classification of spatiotemporal neuroimaging data for the investigation of individual response to treatment and (2) prediction of risk of stroke with respect to temporal environmental data. For both datasets, besides the temporal data, static health data were also available. The hyper-parameters of the proposed system, including the PSNN models and the d2WKNN clustering parameters, are optimised for each individual.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IY7IYCN7\\Doborjeh et al. - 2019 - Personalised modelling with spiking neural network.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\Q9THQ62E\\Doborjeh et al. - 2019 - Personalised modelling with spiking neural network.pdf},
  journal = {Neural Networks},
  language = {en}
}

@article{dodel_geisel_2002,
  title = {Functional Connectivity by Cross-Correlation Clustering},
  author = {Dodel, Silke and Herrmann, J.Michael and Geisel, Theo},
  year = {2002},
  month = jun,
  volume = {44-46},
  pages = {1065--1070},
  issn = {09252312},
  doi = {10.1016/S0925-2312(02)00416-2},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7ALB2WJ3\\Dodel, Herrmann, Geisel - 2002 - Functional connectivity by cross-correlation clustering.pdf},
  journal = {Neurocomputing},
  keywords = {clique,cluster,connectivity component,cross-correlation,fmri,functional connectivity,graph}
}

@article{doersch_doersch_2016,
  title = {Tutorial on {{Variational Autoencoders}}},
  author = {Doersch, Carl},
  year = {2016},
  issn = {1664042X},
  doi = {10.3389/fphys.2016.00108},
  abstract = {In just three years, Variational Autoencoders (VAEs) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. VAEs are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. VAEs have already shown promise in generating many kinds of complicated data, including handwritten digits, faces, house numbers, CIFAR images, physical models of scenes, segmentation, and predicting the future from static images. This tutorial introduces the intuitions behind VAEs, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6M7G4XZ5\\Doersch - 2016 - Tutorial on Variational Autoencoders.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\U6Z9DNBT\\Doersch - 2016 - Tutorial on Variational Autoencoders.pdf},
  keywords = {neural networks,structured prediction,unsupervised learning,variational autoencoders},
  pmid = {27148061}
}

@article{dogge_aarts_2019,
  title = {Moving {{Forward}}: {{On}} the {{Limits}} of {{Motor}}-{{Based Forward Models}}},
  shorttitle = {Moving {{Forward}}},
  author = {Dogge, Myrthel and Custers, Ruud and Aarts, Henk},
  year = {2019},
  month = jul,
  pages = {S1364661319301603},
  issn = {13646613},
  doi = {10.1016/j.tics.2019.06.008},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RASBLHF7\\Dogge et al. - 2019 - Moving Forward On the Limits of Motor-Based Forwa.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en}
}

@article{doiron_josic_2016,
  title = {The Mechanics of State-Dependent Neural Correlations},
  author = {Doiron, Brent and {Litwin-Kumar}, Ashok and Rosenbaum, Robert and Ocker, Gabriel K and Josi{\'c}, Kre{\v s}imir},
  year = {2016},
  month = mar,
  volume = {19},
  pages = {383--393},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn.4242},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\II7P9KE9\\Doiron et al. - 2016 - The mechanics of state-dependent neural correlatio.pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {3}
}

@article{dold_senn_2017,
  title = {Lagrangian Dynamics of Dendritic Microcircuits Enables Real-Time Backpropagation of Errors},
  author = {Dold, Dominik and Kungl, Akos F and Sacramento, Jo{\~a}o and Petrovici, Mihai A and Schindler, Kaspar and Binas, Jonathan and Bengio, Yoshua and Senn, Walter},
  year = {2017},
  pages = {2},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\77WM9WMS\\Dold et al. - Lagrangian dynamics of dendritic microcircuits ena.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\XN26LT7J\\Dold et al. - Lagrangian dynamics of dendritic microcircuits ena.pdf},
  language = {en}
}

@article{domingo_domingo_2018,
  title = {Evidence for a Reversal of the Neural Information Flow between Object Perception and Object Reconstruction from Memory},
  author = {Domingo, Juan Linde},
  year = {2018},
  pages = {1--28},
  doi = {10.1101/300913},
  abstract = {8 Remembering is a reconstructive process. Surprisingly little is known about how the reconstruction 9 of a memory unfolds in time in the human brain. We used reaction times and EEG time-series 10 decoding to test the hypothesis that the information flow is reversed when an event is reconstructed 11 from memory, compared to when the same event is initially being perceived. Across three 12 experiments, we found highly consistent evidence supporting such a reversed stream. When seeing 13 an object, low-level perceptual features were discriminated faster behaviourally, and could be 14 decoded from brain activity earlier, than high-level conceptual features. This pattern reversed during 15 associative memory recall, with reaction times and brain activity patterns now indicating that 16 conceptual information was reconstructed more rapidly than perceptual details. Our findings 17 support a neurobiologically plausible model of human memory, suggesting that memory retrieval is 18 a hierarchical, multi-layered process that prioritizes semantically meaningful information over 19 perceptual detail. 20 21},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2MUIFB5T\\Domingo - 2018 - Evidence for a reversal of the neural information flow between object perception and object reconstruction from memory.pdf},
  journal = {bioRxiv}
}

@article{dominiak_sachdev_2019,
  title = {Whisking Signals Motor Preparation and the Behavioral State of Mice},
  author = {Dominiak, Sina E. and Nashaat, Mostafa A. and Sehara, Keisuke and Oraby, Hatem and Larkum, Matthew E. and Sachdev, Robert N.S.},
  year = {2019},
  month = mar,
  doi = {10.1101/568030},
  abstract = {A central function of the brain is to plan, predict and imagine the effect of movement in a dynamically changing environment. Here we show that the position of the vibrissae, sets of mobile tactile sensors on each side of the face, reflects the behavioral state and predicts the movement of mice, head-fixed in a plus-maze floating on air. Whisker position and whisking as well as nose position signal whether the animal is moving backward or forward, turning right or left, standing still or moving, expecting reward or licking. Surprisingly, the relationship between bilateral whisker position and behavioral state has little to do with tactile input from the whiskers. Thus, in addition to a tactile exploratory function, these mobile sensors on the face of a mouse signal the behavioral and motor preparation state of the animal.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XMTMIJN3\\Dominiak et al. - 2019 - Whisking signals motor preparation and the behavio.pdf},
  journal = {bioRxiv},
  language = {en}
}

@article{dora_bohtesmbohte_2018,
  title = {A {{Deep Predictive Coding Network}} for {{Learning Latent Representations}}},
  author = {Dora, Shirin and Pennartz, Cyriel and Bohte SMBohte, Sander},
  year = {2018},
  doi = {10.1101/278218},
  abstract = {It has been argued that the brain is a prediction machine that continuously learns how to make better predictions about the stimuli received from the external environment. It builds a model of the world around us and uses this model to infer the external stimulus. Predictive coding has been proposed as a mechanism through which the brain might be able to build such a model of the external environment. However, it is not clear how predictive coding can be used to build deep neural network models of the brain while complying with the architectural constraints imposed by the brain. In this paper, we describe an algorithm to build a deep generative model using predictive coding that can be used to infer latent representations about the stimuli received from external environment. Specifically, we used predictive coding to train a deep neural network on real-world images in a unsupervised learning paradigm. To understand the capacity of the network with regards to modeling the external environment , we studied the latent representations generated by the model on images of objects that are never presented to the model during training. Despite the novel features of these objects the model is able to infer the latent representations for them. Furthermore, the reconstructions of the original images obtained from these latent representations preserve the important details of these objects.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Y9Z796JP\\Dora, Pennartz, Bohte SMBohte - Unknown - A Deep Predictive Coding Network for Learning Latent Representations.pdf}
}

@article{dorman_blackwell_2018,
  title = {Inhibition Enhances Spatially-Specific Calcium Encoding of Synaptic Input Patterns in a Biologically Constrained Model},
  author = {Dorman, Daniel B and Je, Joanna and Blackwell, Kim T},
  year = {2018},
  doi = {10.7554/eLife.38588.001},
  abstract = {Synaptic plasticity, which underlies learning and memory, depends on calcium elevation in neurons, but the precise relationship between calcium and spatiotemporal patterns of synaptic inputs is unclear. Here, we develop a biologically realistic computational model of striatal spiny projection neurons with sophisticated calcium dynamics, based on data from rodents of both sexes, to investigate how spatiotemporally clustered and distributed excitatory and inhibitory inputs affect spine calcium. We demonstrate that coordinated excitatory synaptic inputs evoke enhanced calcium elevation specific to stimulated spines, with lower but physiologically relevant calcium elevation in nearby non-stimulated spines. Results further show a novel and important function of inhibition-to enhance the difference in calcium between stimulated and non-stimulated spines. These findings suggest that spine calcium dynamics encode synaptic input patterns and may serve as a signal for both stimulus-specific potentiation and heterosynaptic depression, maintaining balanced activity in a dendritic branch while inducing pattern-specific plasticity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LQYJ8M79\\Dorman, Je, Blackwell - 2018 - Inhibition enhances spatially-specific calcium encoding of synaptic input patterns in a biologically cons.pdf}
}

@article{dosenbach_petersen_2008,
  title = {A Dual-Networks Architecture of Top-down Control},
  author = {Dosenbach, Nico U F and Fair, Damien A and Cohen, Alexander L and Schlaggar, Bradley L and Petersen, Steven E},
  year = {2008},
  volume = {12},
  pages = {99--105},
  issn = {13646613},
  doi = {10.1016/j.tics.2008.01.001},
  abstract = {Complex systems ensure resilience through multiple controllers acting at rapid and slower timescales. The need for efficient information flow through complex systems encourages small-world network structures. On the basis of these principles, a group of regions associated with top-down control was examined. Functional magnetic resonance imaging showed that each region had a specific combination of control signals; resting-state functional connectivity grouped the regions into distinct 'fronto-parietal' and 'cingulo-opercular' components. The fronto-parietal component seems to initiate and adjust control; the cingulo-opercular component provides stable 'set-maintenance' over entire task epochs. Graph analysis showed dense local connections within components and weaker 'long-range' connections between components, suggesting a small-world architecture. The control systems of the brain seem to embody the principles of complex systems, encouraging resilient performance. ?? 2008 Elsevier Ltd. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L254ECNJ\\Dosenbach et al. - 2008 - A dual-networks architecture of top-down control.pdf},
  journal = {Trends in Cognitive Sciences},
  number = {3},
  pmid = {18262825}
}

@article{dotson_gray_2018,
  title = {Feature-{{Based Visual Short}}-{{Term Memory Is Widely Distributed}} and {{Hierarchically Organized}}},
  author = {Dotson, Nicholas M. and Hoffman, Steven J. and Goodell, Baldwin and Gray, Charles M.},
  year = {2018},
  volume = {99},
  pages = {215--226.e4},
  issn = {10974199},
  doi = {10.1016/j.neuron.2018.05.026},
  abstract = {Dotson et al. recorded from 42 cortical areas in monkeys performing a feature-based memory task. They find that task-dependent differences in firing rates are widely distributed, while stimulus-specific changes in firing rates are more restricted and hierarchically organized.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7CPICWWL\\Dotson et al. - 2018 - Feature-Based Visual Short-Term Memory Is Widely Distributed and Hierarchically Organized.pdf},
  journal = {Neuron},
  number = {1},
  pmid = {29909999}
}

@article{doumas_sandhofer_2008,
  title = {A Theory of the Discovery and Predication of Relational Concepts.},
  author = {Doumas, Leonidas A A and Hummel, John E and Sandhofer, Catherine M},
  year = {2008},
  volume = {115},
  pages = {1--43},
  issn = {1939-1471},
  doi = {10.1037/0033-295X.115.1.1},
  abstract = {Relational thinking plays a central role in human cognition. However, it is not known how children and adults acquire relational concepts and come to represent them in a form that is useful for the purposes of relational thinking (i.e., as structures that can be dynamically bound to arguments). The authors present a theory of how a psychologically and neurally plausible cognitive architecture can discover relational concepts from examples and represent them as explicit structures (predicates) that can take arguments (i.e., predicate them). The theory is instantiated as a computer program called DORA (Discovery Of Relations by Analogy). DORA is used to simulate the discovery of novel properties and relations, as well as a body of empirical phenomena from the domain of relational learning and the development of relational representations in children and adults.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IXQCN5JI\\Doumas, Hummel, Sandhofer - 2008 - A theory of the discovery and predication of relational concepts.pdf},
  journal = {Psychological Review},
  keywords = {analogy,cognitive develop-ment,learning relations,learning structured representations,relation discovery},
  number = {1},
  pmid = {18211183}
}

@book{downing_downing_2015,
  title = {Intelligence {{Emerging}}},
  author = {Downing, Keith L},
  year = {2015},
  volume = {53},
  doi = {10.1017/CBO9781107415324.004},
  abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein-protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-\$\textbackslash alpha\$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD {$\leq$} 2.0 \{\textbackslash AA\} for the interface backbone atoms) increased from 21\{\%\} with default Glide SP settings to 58\{\%\} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63\{\%\} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40\{\%\} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TAGNTNDY\\Fallis - 2013 - Fluent Python.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\UUBGVLPU\\Downing - 2015 - Intelligence Emerging.pdf},
  isbn = {978-85-7811-079-6},
  keywords = {icle},
  pmid = {25246403}
}

@article{dranias_bullock_2008,
  title = {Dopaminergic and Non-Dopaminergic Value Systems in Conditioning and Outcome-Specific Revaluation.},
  author = {Dranias, Mark R and Grossberg, Stephen and Bullock, Daniel},
  year = {2008},
  month = oct,
  volume = {1238},
  pages = {239--287},
  issn = {1872-6240},
  doi = {10.1016/j.brainres.2008.07.013},
  abstract = {Animals are motivated to choose environmental options that can best satisfy current needs. To explain such choices, this paper introduces the MOTIVATOR (Matching Objects To Internal VAlues Triggers Option Revaluations) neural model. MOTIVATOR describes cognitive-emotional interactions between higher-order sensory cortices and an evaluative neuraxis composed of the hypothalamus, amygdala, and orbitofrontal cortex. Given a conditioned stimulus (CS), the model amygdala and lateral hypothalamus interact to calculate the expected current value of the subjective outcome that the CS predicts, constrained by the current state of deprivation or satiation. The amygdala relays the expected value information to orbitofrontal cells that receive inputs from anterior inferotemporal cells, and medial orbitofrontal cells that receive inputs from rhinal cortex. The activations of these orbitofrontal cells code the subjective values of objects. These values guide behavioral choices. The model basal ganglia detect errors in CS-specific predictions of the value and timing of rewards. Excitatory inputs from the pedunculopontine nucleus interact with timed inhibitory inputs from model striosomes in the ventral striatum to regulate dopamine burst and dip responses from cells in the substantia nigra pars compacta and ventral tegmental area. Learning in cortical and striatal regions is strongly modulated by dopamine. The model is used to address tasks that examine food-specific satiety, Pavlovian conditioning, reinforcer devaluation, and simultaneous visual discrimination. Model simulations successfully reproduce discharge dynamics of known cell types, including signals that predict saccadic reaction times and CS-dependent changes in systolic blood pressure.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DRRZ2A52\\Dranias, Grossberg, Bullock - 2008 - Dopaminergic and non-dopaminergic value systems in conditioning and outcome-specific revaluation.pdf},
  journal = {Brain research},
  keywords = {Animals,Brain,Brain: physiology,Cognition,Cognition: physiology,Conditioning (Psychology),Conditioning (Psychology): physiology,Dopamine,Dopamine: metabolism,Emotions,Emotions: physiology,Models,Neurological,Neurons,Neurons: physiology},
  pmid = {18674518}
}

@article{du_masmanidis_2011,
  title = {Multiplexed, High Density Electrophysiology with Nanofabricated Neural Probes.},
  author = {Du, Jiangang and Blanche, Timothy J and Harrison, Reid R and a Lester, Henry and Masmanidis, Sotiris C},
  year = {2011},
  month = jan,
  volume = {6},
  pages = {e26204},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0026204},
  abstract = {Extracellular electrode arrays can reveal the neuronal network correlates of behavior with single-cell, single-spike, and sub-millisecond resolution. However, implantable electrodes are inherently invasive, and efforts to scale up the number and density of recording sites must compromise on device size in order to connect the electrodes. Here, we report on silicon-based neural probes employing nanofabricated, high-density electrical leads. Furthermore, we address the challenge of reading out multichannel data with an application-specific integrated circuit (ASIC) performing signal amplification, band-pass filtering, and multiplexing functions. We demonstrate high spatial resolution extracellular measurements with a fully integrated, low noise 64-channel system weighing just 330 mg. The on-chip multiplexers make possible recordings with substantially fewer external wires than the number of input channels. By combining nanofabricated probes with ASICs we have implemented a system for performing large-scale, high-density electrophysiology in small, freely behaving animals that is both minimally invasive and highly scalable.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PM3J73MY\\Du et al. - 2011 - Multiplexed, high density electrophysiology with nanofabricated neural probes.pdf},
  journal = {PloS one},
  keywords = {Animal,Animals,Behavior,Computer-Assisted,Electrodes,Electrophysiological Phenomena,Inbred C57BL,Male,Mice,Molecular Probes,Molecular Probes: chemistry,Nanostructures,Nanostructures: ultrastructure,Nanotechnology,Nanotechnology: instrumentation,Nanotechnology: methods,Neurons,Neurons: metabolism,Signal Processing,Silicon,Silicon: chemistry,Temperature},
  number = {10},
  pmid = {22022568}
}

@article{duan_wang_2018,
  title = {State {{Aggregation Learning}} from {{Markov Transition Data}}},
  author = {Duan, Yaqi and Ke, Zheng Tracy and Wang, Mengdi},
  year = {2018},
  month = nov,
  abstract = {State aggregation is a model reduction method rooted in control theory and reinforcement learning. It reduces the complexity of engineering systems by mapping the system's states into a small number of meta-states. In this paper, we study the unsupervised estimation of unknown state aggregation structures based on Markov trajectories. We formulate the state aggregation of Markov processes into a nonnegative factorization model, where left and right factor matrices correspond to aggregation and disaggregation distributions respectively. By leveraging techniques developed in the context of topic modeling, we propose an efficient polynomial-time algorithm for computing the estimated state aggregation model. Under some "anchor state" assumption, we show that one can reliably recover the state aggregation structure from sample transitions with high probability. Sharp divergence error bounds are proved for the estimated aggregation and disaggregation distributions, and experiments with Manhattan traffic data are provided.},
  archivePrefix = {arXiv},
  eprint = {1811.02619},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TX5I59F2\\Duan_et_al_2018_State_Aggregation_Learning_from_Markov_Transition_Data.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\WDFS7TQE\\1811.html},
  journal = {arXiv:1811.02619 [cs, stat]},
  primaryClass = {cs, stat}
}

@article{dudchenko_wood_2015,
  title = {Place Fields and the Cognitive Map},
  author = {a. Dudchenko, Paul and Wood, Emma R},
  year = {2015},
  pages = {n/a----n/a},
  issn = {10509631},
  doi = {10.1002/hipo.22450},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\D6YJZBBP\\Dudchenko, Wood - 2015 - Place fields and the cognitive map.pdf},
  journal = {Hippocampus},
  keywords = {for sharing his,place cells,spatial cognition,the authors would like,to thank roddy grieves,tolman}
}

@article{dudek_farris_2016,
  title = {Rediscovering Area {{CA2}}: Unique Properties and Functions},
  author = {Dudek, Serena M and Alexander, Georgia M and Farris, Shannon},
  year = {2016},
  volume = {17},
  pages = {89--102},
  issn = {1471-003X},
  doi = {10.1038/nrn.2015.22},
  abstract = {Hippocampal area CA2 has several features that distinguish it from CA1 and CA3, including a unique gene expression profile, failure to display long-term potentiation and relative resistance to cell death. A recent increase in interest in the CA2 region, combined with the development of new methods to define and manipulate its neurons, has led to some exciting new discoveries on the properties of CA2 neurons and their role in behaviour. Here, we review these findings and call attention to the idea that the definition of area CA2 ought to be revised in light of gene expression data.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZV6ADJU9\\Dudek, Alexander, Farris - 2016 - Rediscovering area CA2 unique properties and functions.pdf},
  journal = {Nature Reviews Neuroscience},
  number = {2},
  pmid = {26806628}
}

@book{dumont_taube_2015,
  title = {The Neural Correlates of Navigation beyond the Hippocampus},
  author = {Dumont, Julie R and Taube, Jeffrey S},
  year = {2015},
  edition = {First},
  volume = {219},
  publisher = {{Elsevier B.V.}},
  doi = {10.1016/bs.pbr.2015.03.004},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\E53KUC6T\\Dumont, Taube - 2015 - The neural correlates of navigation beyond the hippocampus.pdf},
  keywords = {angular head,Angular head velocity,grid cell,Grid cell,head direction cell,Head direction cell,navigation,Navigation,place cell,Place cell,spatial orientation,Spatial orientation}
}

@book{duncan_duncan_2010,
  title = {The Multiple-Demand ({{MD}}) System of the Primate Brain: Mental Programs for Intelligent Behaviour},
  author = {Duncan, John},
  year = {2010},
  volume = {14},
  doi = {10.1016/j.tics.2010.01.004},
  abstract = {A common or multiple-demand (MD) pattern of frontal and parietal activity is associated with diverse cognitive demands, and with standard tests of fluid intelligence. In intelligent behaviour, goals are achieved by assembling a series of sub-tasks, creating structured mental programs. Single cell and functional magnetic resonance imaging (fMRI) data indicate a key role for MD cortex in defining and controlling the parts of such programs, with focus on the specific content of a current cognitive operation, rapid reorganization as mental focus is changed, and robust separation of successive task steps. Resembling the structured problem-solving of symbolic artificial intelligence, the mental programs of MD cortex appear central to intelligent thought and action. ?? 2010 Elsevier Ltd. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4XEK2NA5\\Duncan - 2010 - The multiple-demand (MD) system of the primate brain mental programs for intelligent behaviour.pdf},
  isbn = {1364-6613},
  pmid = {20171926}
}

@article{duncan_emslie_2000,
  title = {A {{Neural Basis}} for {{General Intelligence}}},
  author = {Duncan, John and Seitz, Rudiger J and Kolodny, Jonathan and Bor, Daniel and Herzog, Hans and Ahmed, Ayesha and Newell, Fiona N and Emslie, Hazel},
  year = {2000},
  volume = {289},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Y7S2XWVY\\Duncan et al. - 2000 - A Neural Basis for General Intelligence.pdf},
  journal = {Science}
}

@article{dupret_csicsvari_2013,
  title = {Dynamic {{Reconfiguration}} of {{Hippocampal Interneuron Circuits}} during {{Spatial Learning}}},
  author = {Dupret, David and O'Neill, Joseph and Csicsvari, Jozsef},
  year = {2013},
  volume = {78},
  pages = {166--180},
  issn = {08966273},
  doi = {10.1016/j.neuron.2013.01.033},
  abstract = {In the hippocampus, cell assemblies forming mnemonic representations of space are thought to arise as a result of changes in functional connections of pyramidal cells. We have found that CA1 interneuron circuits are also reconfigured during goal-oriented spatial learning through modification of inputs from pyramidal cells. As learning progressed, new pyramidal assemblies expressed in theta cycles alternated with previously established ones, and eventually overtook them. The firing patterns of interneurons developed a relationship to new, learning-related assemblies: some interneurons associated their activity with new pyramidal assemblies while some others dissociated from them. These firing associations were explained by changes in the weight of monosynaptic inputs received by interneurons from new pyramidal assemblies, as these predicted the associational changes. Spatial learning thus engages circuit modifications in the hippocampus that incorporate a redistribution of inhibitory activity that might assist in the segregation of competing pyramidal cell assembly patterns in space and time},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KBBW5MZD\\Dupret, O'Neill, Csicsvari - 2013 - Dynamic Reconfiguration of Hippocampal Interneuron Circuits during Spatial Learning.pdf},
  journal = {Neuron},
  number = {1},
  pmid = {23523593}
}

@techreport{dupuy_dupuy_2018,
  title = {A Neurocomputational Model for Learning, Memory Consolidation and Schemas},
  author = {Dupuy, Nathalie},
  year = {2018},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AGKZASH5\\Dupuy - 2018 - A neurocomputational model for learning, memory consolidation and schemas.pdf}
}

@article{durbin_rumelhart_1989,
  title = {Product {{Units}}: {{A Computationally Powerful}} and {{Biologically Plausible Extension}} to {{Backpropagation Networks}}},
  author = {Durbin, Richard and Rumelhart, David E},
  year = {1989},
  volume = {1},
  pages = {133--142},
  issn = {0899-7667},
  doi = {10.1162/neco.1989.1.1.133},
  abstract = {Introduces a computational unit for feedforward learning networks of the backpropagation type, which calculates a weighted product in which each input is raised to a power determined by a variable weight. The unit can learn to represent generalized polynomial terms in the inputs and can form a better representation of data in cases where higher order combinations of inputs are significant without increasing the number of free parameters. Product units can be trained using gradient descent, allow simpler solutions to standard learning problems, have a higher empirical learning capacity than summing units, and act to create a hidden layer representation for an output summing unit. A neurobiological interpretation is presented for this combination of product and summing units in terms of a single neuron.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\X6SXYTUV\\Durbin, Rumelhart - 1989 - Product Units A Computationally Powerful and Biologically Plausible Extension to Backpropagation Networks.pdf},
  journal = {Neural Computation}
}

@article{durrant-whyte_bailey_2006,
  title = {Simultaneous Localization and Mapping: Part {{I}}},
  author = {{Durrant-Whyte}, H and Bailey, Tim},
  year = {2006},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BLDZIV79\\Durrant-Whyte, Bailey - 2006 - Simultaneous localization and mapping part I.pdf},
  journal = {Robotics \{\&\} Automation Magazine, \{\textbackslash ldots\}}
}

@article{duvarci_pare_2014,
  title = {Amygdala Microcircuits Controlling Learned Fear},
  author = {Duvarci, Sevil and Pare, Denis},
  year = {2014},
  volume = {82},
  pages = {966--980},
  issn = {10974199},
  doi = {10.1016/j.neuron.2014.04.042},
  abstract = {We review recent work on the role of intrinsic amygdala networks in the regulation of classically conditioned defensive behaviors, commonly known as conditioned fear. These new developments highlight how conditioned fear depends on far more complex networks than initially envisioned. Indeed, multiple parallel inhibitory and excitatory circuits are differentially recruited during the expression versus extinction of conditioned fear. Moreover, shifts between expression and extinction circuits involve coordinated interactions with different regions of the medial prefrontal cortex. However, key areas of uncertainty remain, particularly with respect to the connectivity of the different cell types. Filling these gaps in our knowledge is important because much evidence indicates that human anxiety disorders results from an abnormal regulation of the networks supporting fear learning. Duvarci and Pare review recent work on the role of intrinsic amygdala networks in regulating conditioned fear, revealing that it depends on multiple parallel inhibitory and excitatory circuits that are differentially recruited during the expression versus extinction of conditioned fear. ?? 2014 Elsevier Inc.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\93M7P43W\\Duvarci, Pare - 2014 - Amygdala microcircuits controlling learned fear.pdf},
  journal = {Neuron},
  number = {5},
  pmid = {24908482}
}

@article{dvorak_fenton_2017,
  title = {Control of Recollection by Slow Gamma Dominating Medium Gamma in Hippocampus {{CA1}}},
  author = {Dvorak, Dino and Radwan, Basma and Sparks, Fraser Todd and Talbot, Zoe Nicole and Fenton, Andre Antonio},
  year = {2017},
  pages = {1--35},
  doi = {10.1101/152488},
  abstract = {Behavior is used to assess memory and cognitive deficits in animals like Fmr1-null mice that model Fragile-X Syndrome, but behavior is a proxy for unknown neural events that define cognitive variables like recollection. We identified an electrophysiological signature of recollection in mouse dorsal CA1 hippocampus. During a shocked-place avoidance task, slow-gamma (SG: 30-60 Hz) dominates medium-gamma (MG: 60-90 Hz) oscillations 2-3 seconds before successful avoidance, but not failures. Wild-type but not Fmr1-null mice adapt to relocating the shock; concurrently, SG/MG maxima (SG-dominance) decrease in wild-type but not in cognitively inflexible Fmr1-null mice. During SG-dominance events, place cell ensembles represent distant locations; during place avoidance, these are avoided places. During shock relocation, wild-type ensembles represent distant locations near the currently-correct shock zone but Fmr1-null ensembles represent the formerly-correct zone. These findings indicate that recollection occurs when CA1 slow gamma dominates medium gamma, and that accurate recollection of inappropriate memories explains Fmr1-null cognitive inflexibility.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BWE3GRBV\\Dvorak et al. - 2017 - Control of recollection by slow gamma dominating medium gamma in hippocampus CA1.pdf},
  journal = {bioRxiv}
}

@article{ebbesen_brecht_2016,
  title = {Cell {{Type}}-{{Specific Differences}} in {{Spike Timing}} and {{Spike Shape}} in the {{Rat Parasubiculum}} and {{Superficial Medial Entorhinal Cortex}}},
  author = {Ebbesen, Christian Laut and Reifenstein, Eric Torsten and Tang, Qiusong and Burgalossi, Andrea and Ray, Saikat and Schreiber, Susanne and Kempter, Richard and Brecht, Michael},
  year = {2016},
  volume = {16},
  pages = {1005--1015},
  issn = {22111247},
  doi = {10.1016/j.celrep.2016.06.057},
  abstract = {The medial entorhinal cortex (MEC) and the adjacent parasubiculum are known for their elaborate spatial discharges (grid cells, border cells, etc.) and the precessing of spikes relative to the local field potential. We know little, however, about how spatio-temporal firing patterns map onto cell types. We find that cell type is a major determinant of spatio-temporal discharge properties. Parasubicular neurons and MEC layer 2 (L2) pyramids have shorter spikes, discharge spikes in bursts, and are theta-modulated (rhythmic, locking, skipping), but spikes phase-precess only weakly. MEC L2 stellates and layer 3 (L3) neurons have longer spikes, do not discharge in bursts, and are weakly theta-modulated (non-rhythmic, weakly locking, rarely skipping), but spikes steeply phase-precess. The similarities between MEC L3 neurons and MEC L2 stellates on one hand and parasubicular neurons and MEC L2 pyramids on the other hand suggest two distinct streams of temporal coding in the parahippocampal cortex.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MXA5TWYQ\\Ebbesen et al. - 2016 - Cell Type-Specific Differences in Spike Timing and Spike Shape in the Rat Parasubiculum and Superficial Medial E.pdf},
  journal = {Cell Reports},
  number = {4},
  pmid = {27425616}
}

@article{ebitz_hayden_2016,
  title = {Dorsal Anterior Cingulate: A {{Rorschach}} Test for Cognitive Neuroscience},
  author = {Ebitz, R Becket and Hayden, Benjamin Yost},
  year = {2016},
  volume = {19},
  pages = {1278--1279},
  issn = {1097-6256},
  doi = {10.1038/nn.4387},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8NA8Y99N\\Ebitz, Hayden - 2016 - Dorsal anterior cingulate a Rorschach test for cognitive neuroscience.pdf},
  journal = {Nature Neuroscience},
  number = {10},
  pmid = {27669987}
}

@article{ebner_cuntz_2019,
  title = {Unifying {{Long}}-{{Term Plasticity Rules}} for {{Excitatory Synapses}} by {{Modeling Dendrites}} of {{Cortical Pyramidal Neurons}}},
  author = {Ebner, Christian and Clopath, Claudia and Jedlicka, Peter and Cuntz, Hermann},
  year = {2019},
  month = dec,
  volume = {29},
  pages = {4295-4307.e6},
  issn = {22111247},
  doi = {10.1016/j.celrep.2019.11.068},
  abstract = {A large number of experiments have indicated that precise spike times, firing rates, and synapse locations crucially determine the dynamics of long-term plasticity induction in excitatory synapses. However, it remains unknown how plasticity mechanisms of synapses distributed along dendritic trees cooperate to produce the wide spectrum of outcomes for various plasticity protocols. Here, we propose a four-pathway plasticity framework that is well grounded in experimental evidence and apply it to a biophysically realistic cortical pyramidal neuron model. We show in computer simulations that several seemingly contradictory experimental landmark studies are consistent with one unifying set of mechanisms when considering the effects of signal propagation in dendritic trees with respect to synapse location. Our model identifies specific spatiotemporal contributions of dendritic and axo-somatic spikes as well as of subthreshold activation of synaptic clusters, providing a unified parsimonious explanation not only for rate and timing dependence but also for location dependence of synaptic changes.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BWKFAVFK\\Ebner et al. - 2019 - Unifying Long-Term Plasticity Rules for Excitatory.pdf},
  journal = {Cell Reports},
  language = {en},
  number = {13}
}

@article{eckstein_bunge_2019,
  title = {How the Inference of Hierarchical Rules Unfolds over Time},
  author = {Eckstein, Maria K. and Starr, Ariel and Bunge, Silvia A.},
  year = {2019},
  month = apr,
  volume = {185},
  pages = {151--162},
  issn = {00100277},
  doi = {10.1016/j.cognition.2019.01.009},
  abstract = {Inductive reasoning, which entails reaching conclusions that are based on but go beyond available evidence, has long been of interest in cognitive science. Nevertheless, knowledge is still lacking as to the specific cognitive processes that underlie inductive reasoning. Here, we shed light on these processes in two ways. First, we characterized the timecourse of inductive reasoning in a rule induction task, using pupil dilation as a momentby-moment measure of cognitive load. Participants' patterns of behavior and pupillary responses indicated that they engaged in rule inference on-line, and were surprised when additional evidence violated their inferred rules. Second, we sought to gain insight into how participants represented rules on this task \textendash{} specifically, whether they would structure the rules hierarchically when possible. We predicted the cognitive load imposed by hierarchical representations, as well as by non-hierarchical, flat ones. We used task-evoked pupil dilation as a metric of cognitive load to infer, based on these predictions, which participants represented rules with flat or hierarchical structures. Participants categorized as representing the rules hierarchically or flat differed in task performance and self-reports of strategy. Hierarchical rule representation was associated with more efficient performance and more pronounced pupillary responses to rule violations on trials that afford a higher-order regularity, but with less efficient performance on trials that do not. Thus, differences in rule representation can be inferred from a physiological measure of cognitive load, and are associated with differences in performance. These results illustrate how pupillometry can provide a window into reasoning as it unfolds over time.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\N3HKCKZC\\Eckstein et al. - 2019 - How the inference of hierarchical rules unfolds ov.pdf},
  journal = {Cognition},
  language = {en}
}

@book{eden_eden_2010,
  title = {Chapter 2: {{Introduction}} to {{Point Processes}}},
  author = {Eden, Uri T},
  year = {2010},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5ZC7GD8L\\Eden - 2010 - Chapter 2 Introduction to Point Processes.pdf}
}

@article{edvardsen_burgess_2019,
  title = {Navigating with Grid and Place Cells in Cluttered Environments},
  author = {Edvardsen, Vegard and Bicanski, Andrej and Burgess, Neil},
  year = {2019},
  month = aug,
  pages = {hipo.23147},
  issn = {1050-9631, 1098-1063},
  doi = {10.1002/hipo.23147},
  abstract = {Hippocampal formation contains several classes of neurons thought to be involved in navigational processes, in particular place cells and grid cells. Place cells have been associated with a topological strategy for navigation, while grid cells have been suggested to support metric vector navigation. Grid cell-based vector navigation can support novel shortcuts across unexplored territory by providing the direction toward the goal. However, this strategy is insufficient in natural environments cluttered with obstacles. Here, we show how navigation in complex environments can be supported by integrating a grid cell-based vector navigation mechanism with local obstacle avoidance mediated by border cells and place cells whose interconnections form an experience-dependent topological graph of the environment. When vector navigation and object avoidance fail (i.e., the agent gets stuck), place cell replay events set closer subgoals for vector navigation. We demonstrate that this combined navigation model can successfully traverse environments cluttered by obstacles and is particularly useful where the environment is underexplored. Finally, we show that the model enables the simulated agent to successfully navigate experimental maze environments from the animal literature on cognitive mapping. The proposed model is sufficiently flexible to support navigation in different environments, and may inform the design of experiments to relate different navigational abilities to place, grid, and border cell firing.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6RVJC8SX\\Edvardsen et al. - 2019 - Navigating with grid and place cells in cluttered .pdf},
  journal = {Hippocampus},
  language = {en}
}

@article{egger_oberlaender_2020,
  title = {Cortical {{Output Is Gated}} by {{Horizontally Projecting Neurons}} in the {{Deep Layers}}},
  author = {Egger, Robert and Narayanan, Rajeevan T. and Guest, Jason M. and Bast, Arco and Udvary, Daniel and Messore, Luis F. and Das, Suman and {de Kock}, Christiaan P.J. and Oberlaender, Marcel},
  year = {2020},
  month = jan,
  volume = {105},
  pages = {122-137.e8},
  issn = {08966273},
  doi = {10.1016/j.neuron.2019.10.011},
  abstract = {Pyramidal tract neurons (PTs) represent the major output cell type of the mammalian neocortex. Here, we report the origins of the PTs' ability to respond to a broad range of stimuli with onset latencies that rival or even precede those of their intracortical input neurons. We find that neurons with extensive horizontally projecting axons cluster around the deeplayer terminal fields of primary thalamocortical axons. The strategic location of these corticocortical neurons results in high convergence of thalamocortical inputs, which drive reliable sensory-evoked responses that precede those in other excitatory cell types. The resultant fast and horizontal stream of excitation provides PTs throughout the cortical area with input that acts to amplify additional inputs from thalamocortical and other intracortical populations. The fast onsets and broadly tuned characteristics of PT responses hence reflect a gating mechanism in the deep layers, which assures that sensory-evoked input can be reliably transformed into cortical output.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\T9FM8C9I\\Egger et al. - 2020 - Cortical Output Is Gated by Horizontally Projectin.pdf},
  journal = {Neuron},
  language = {en},
  number = {1}
}

@article{eichenbaum_eichenbaum_2014,
  title = {Time Cells in the Hippocampus: A New Dimension for Mapping Memories.},
  author = {Eichenbaum, Howard B},
  year = {2014},
  volume = {15},
  pages = {732--744},
  issn = {1471-0048},
  doi = {10.1038/nrn3827},
  abstract = {Recent studies have revealed the existence of hippocampal neurons that fire at successive moments in temporally structured experiences. Several studies have shown that such temporal coding is not attributable to external events, specific behaviours or spatial dimensions of an experience. Instead, these cells represent the flow of time in specific memories and have therefore been dubbed 'time cells'. The firing properties of time cells parallel those of hippocampal place cells; time cells thus provide an additional dimension that is integrated with spatial mapping. The robust representation of both time and space in the hippocampus suggests a fundamental mechanism for organizing the elements of experience into coherent memories.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GVKV2PMQ\\Eichenbaum - 2014 - Time cells in the hippocampus a new dimension for mapping memories.pdf},
  journal = {Nature reviews. Neuroscience},
  number = {11},
  pmid = {25269553}
}

@article{eimas_corbit_1973,
  title = {Selective {{Adaptation}} of {{Linguistic Feature Coverging}} Evidence from Electrophysiological Studies of Single Neurons {{The}} Perception of Series of Synthetic Speech Varying Continuously in t 10 Msec t 100 Msec},
  author = {Eimas, Peter D and Corbit, John D},
  year = {1973},
  volume = {4},
  pages = {99--109},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3YAVUP5N\\Eimas, Corbit - 1973 - Selective Adaptation of Linguistic Feature Coverging evidence from electrophysiological studies of single neurons.pdf},
  journal = {Cognitive psychology}
}

@article{eleore_delgado-garcia_2011,
  title = {Role of Reuniens Nucleus Projections to the Medial Prefrontal Cortex and to the Hippocampal Pyramidal {{CA1}} Area in Associative Learning},
  author = {Eleore, Lyndell and {L{\'o}pez-Ramos}, Juan Carlos and {Guerra-Narbona}, Rafael and {Delgado-Garc{\'i}a}, Jos{\'e} M},
  year = {2011},
  volume = {6},
  issn = {19326203},
  doi = {10.1371/journal.pone.0023538},
  abstract = {We studied the interactions between short- and long-term plastic changes taking place during the acquisition of a classical eyeblink conditioning and following high-frequency stimulation (HFS) of the reuniens nucleus in behaving mice. Synaptic changes in strength were studied at the reuniens-medial prefrontal cortex (mPFC) and the reuniens-CA1 synapses. Input/output curves and a paired-pulse study enabled determining the functional capabilities of the two synapses and the optimal intensities to be applied at the reuniens nucleus during classical eyeblink conditioning and for HFS applied to the reuniens nucleus. Animals were conditioned using a trace paradigm, with a tone as conditioned stimulus (CS) and an electric shock to the trigeminal nerve as unconditioned stimulus (US). A single pulse was presented to the reuniens nucleus to evoke field EPSPs (fEPSPs) in mPFC and CA1 areas during the CS-US interval. No significant changes in synaptic strength were observed at the reuniens-mPFC and reuniens-CA1 synapses during the acquisition of eyelid conditioned responses (CRs). Two successive HFS sessions carried out during the first two conditioning days decreased the percentage of CRs, without evoking any long-term potentiation (LTP) at the recording sites. HFS of the reuniens nucleus also prevented the proper acquisition of an object discrimination task. A subsequent study revealed that HFS of the reuniens nucleus evoked a significant decrease of paired-pulse facilitation. In conclusion, reuniens nucleus projections to prefrontal and hippocampal circuits seem to participate in the acquisition of associative learning through a mechanism that does not required the development of LTP.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6XTGHCGM\\Eleore et al. - Unknown - Role of Reuniens Nucleus Projections to the Medial Prefrontal Cortex and to the Hippocampal Pyramidal CA1 Area.pdf},
  journal = {PLoS ONE},
  number = {8},
  pmid = {21858159}
}

@book{eliasmith_anderson_2004,
  title = {Neural {{Engineering}}: {{Computation Representation}} and {{Dynamics}} in {{Neurobiological Systems}}},
  author = {Eliasmith, Chris and Anderson, Charles H},
  year = {2004},
  publisher = {{MIT Press}},
  address = {{Cambridge, MA}},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5VRDEBJJ\\Eliasmith, Anderson - 2004 - Neural Engineering Computation Representation and Dynamics in Neurobiological Systems.pdf},
  isbn = {978-0-262-55060-4}
}

@article{eliasmith_eliasmith_2005,
  title = {A Unified Approach to Building and Controlling Spiking Attractor Networks.},
  author = {Eliasmith, Chris},
  year = {2005},
  month = jun,
  volume = {17},
  pages = {1276--1314},
  issn = {0899-7667},
  doi = {10.1162/0899766053630332},
  abstract = {Extending work in Eliasmith and Anderson (2003), we employ a general framework to construct biologically plausible simulations of the three classes of attractor networks relevant for biological systems: static (point, line, ring, and plane) attractors, cyclic attractors, and chaotic attractors. We discuss these attractors in the context of the neural systems that they have been posited to help explain: eye control, working memory, and head direction; locomotion (specifically swimming); and olfaction, respectively. We then demonstrate how to introduce control into these models. The addition of control shows how attractor networks can be used as subsystems in larger neural systems, demonstrates how a much larger class of networks can be related to attractor networks, and makes it clear how attractor networks can be exploited for various information processing tasks in neurobiological systems.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RS5HJ6VK\\Eliasmith - 2005 - A unified approach to building and controlling spiking attractor networks.pdf},
  journal = {Neural computation},
  keywords = {Animals,Brain,Brain: physiology,Humans,Models,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neural Pathways,Neural Pathways: physiology,Neurological,Neurons,Neurons: physiology,Nonlinear Dynamics},
  number = {6},
  pmid = {15901399}
}

@article{eliasmith_rasmussen_2012,
  title = {A Large-Scale Model of the Functioning Brain},
  author = {Eliasmith, Chris and Stewart, Terrence C and Choo, Xuan and Bekolay, Trevor and Dewolf, Travis and Tang, Yichuan and Rasmussen, Daniel},
  year = {2012},
  pages = {1202--1205},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QI6VAPG8\\Eliasmith et al. - 2012 - A large-scale model of the functioning brain.pdf},
  journal = {Science},
  number = {NOVEMBER}
}

@article{engel_fries_2010,
  title = {Beta-Band Oscillations-Signalling the Status Quo?},
  author = {Engel, Andreas K and Fries, Pascal},
  year = {2010},
  volume = {20},
  pages = {156--165},
  issn = {09594388},
  doi = {10.1016/j.conb.2010.02.015},
  abstract = {In this review, we consider the potential functional role of beta-band oscillations, which at present is not yet well understood. We discuss evidence from recent studies on top-down mechanisms involved in cognitive processing, on the motor system and on the pathophysiology of movement disorders that suggest a unifying hypothesis: beta-band activity seems related to the maintenance of the current sensorimotor or cognitive state. We hypothesize that beta oscillations and/or coupling in the beta-band are expressed more strongly if the maintenance of the status quo is intended or predicted, than if a change is expected. Moreover, we suggest that pathological enhancement of beta-band activity is likely to result in an abnormal persistence of the status quo and a deterioration of flexible behavioural and cognitive control. ?? 2010 Elsevier Ltd.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZBHK4PHE\\Engel, Fries - 2010 - Beta-band oscillations-signalling the status quo.pdf},
  journal = {Current Opinion in Neurobiology},
  number = {2},
  pmid = {20359884}
}

@article{engel_singer_2001,
  title = {Dynamic Predictions: Oscillations and Synchrony in Top-down Processing.},
  author = {Engel, Andreas K and Fries, P and Singer, W},
  year = {2001},
  month = oct,
  volume = {2},
  pages = {704--716},
  issn = {1471-003X},
  doi = {10.1038/35094565},
  abstract = {Classical theories of sensory processing view the brain as a passive, stimulus-driven device. By contrast, more recent approaches emphasize the constructive nature of perception, viewing it as an active and highly selective process. Indeed, there is ample evidence that the processing of stimuli is controlled by top-down influences that strongly shape the intrinsic dynamics of thalamocortical networks and constantly create predictions about forthcoming sensory events. We discuss recent experiments indicating that such predictions might be embodied in the temporal structure of both stimulus-evoked and ongoing activity, and that synchronous oscillations are particularly important in this process. Coherence among subthreshold membrane potential fluctuations could be exploited to express selective functional relationships during states of expectancy or attention, and these dynamic patterns could allow the grouping and selection of distributed neuronal responses for further processing.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HV98RZM6\\Engel, Fries, Singer - 2001 - Dynamic predictions Oscillations and synchrony in top–down processing(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\J53BLSQX\\Engel, Fries, Singer - 2001 - Dynamic predictions Oscillations and synchrony in top–down processing.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\P7AKJED8\\Engel, Fries, Singer - 2001 - Dynamic predictions Oscillations and synchrony in top–down processing(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\RCAGKPBQ\\Engel, Fries, Singer - 2001 - Dynamic predictions oscillations and synchrony in top-down processing.pdf},
  journal = {Nature reviews. Neuroscience},
  keywords = {Animals,Brain,Brain: physiology,Haplorhini,Humans,Mental Processes,Models,Motor Activity,Motor Activity: physiology,Neurological,Neurons,Neurons: physiology,Oscillometry,Pattern Recognition,Time Factors,Visual,Visual Cortex,Visual Cortex: physiology},
  number = {10},
  pmid = {11584308}
}

@article{epp_galea_2013,
  title = {Hippocampus-Dependent Learning Influences Hippocampal Neurogenesis.},
  author = {Epp, Jonathan R and Chow, Carmen and Galea, Liisa a M},
  year = {2013},
  month = jan,
  volume = {7},
  pages = {57},
  issn = {1662-4548},
  doi = {10.3389/fnins.2013.00057},
  abstract = {The structure of the mammalian hippocampus continues to be modified throughout life by continuous addition of neurons in the dentate gyrus. Although the existence of adult neurogenesis is now widely accepted the function that adult generated granule cells play is a topic of intense debate. Many studies have argued that adult generated neurons, due to unique physiological characteristics, play a unique role in hippocampus-dependent learning and memory. However, it is not currently clear whether this is the case or what specific capability adult generated neurons may confer that developmentally generated neurons do not. These questions have been addressed in numerous ways, from examining the effects of increasing or decreasing neurogenesis to computational modeling. One particular area of research has examined the effects of hippocampus dependent learning on proliferation, survival, integration and activation of immature neurons in response to memory retrieval. Within this subfield there remains a range of data showing that hippocampus dependent learning may increase, decrease or alternatively may not alter these components of neurogenesis in the hippocampus. Determining how and when hippocampus-dependent learning alters adult neurogenesis will help to further clarify the role of adult generated neurons. There are many variables (such as age of immature neurons, species, strain, sex, stress, task difficulty, and type of learning) as well as numerous methodological differences (such as marker type, quantification techniques, apparatus size etc.) that could all be crucial for a clear understanding of the interaction between learning and neurogenesis. Here, we review these findings and discuss the different conditions under which hippocampus-dependent learning impacts adult neurogenesis in the dentate gyrus.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\27WVYZG7\\Epp, Chow, Galea - 2013 - Hippocampus-dependent learning influences hippocampal neurogenesis.pdf},
  journal = {Frontiers in neuroscience},
  keywords = {cell survival,dentate gyrus,hip,hippocampus,memory,neurogenesis,spatial learning},
  number = {April},
  pmid = {23596385}
}

@article{erdem_hasselmo_2012,
  title = {A Goal-Directed Spatial Navigation Model Using Forward Trajectory Planning Based on Grid Cells},
  author = {Erdem, U{\v g}ur M and Hasselmo, Michael E},
  year = {2012},
  volume = {35},
  pages = {916--931},
  issn = {0953816X},
  doi = {10.1111/j.1460-9568.2012.08015.x},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PGRHDYIX\\Erdem, Hasselmo - 2012 - A goal-directed spatial navigation model using forward trajectory planning based on grid cells.pdf},
  journal = {European Journal of Neuroscience},
  keywords = {Grid cell,Hippocampus,Navigation,Place cell,Prefrontal cortex},
  number = {6},
  pmid = {22393918}
}

@article{erdem_hasselmo_2014,
  title = {A Biologically Inspired Hierarchical Goal Directed Navigation Model.},
  author = {Erdem, U{\v g}ur M and Hasselmo, Michael E},
  year = {2014},
  month = feb,
  volume = {108},
  pages = {28--37},
  issn = {1769-7115},
  doi = {10.1016/j.jphysparis.2013.07.002},
  abstract = {We propose an extended version of our previous goal directed navigation model based on forward planning of trajectories in a network of head direction cells, persistent spiking cells, grid cells, and place cells. In our original work the animat incrementally creates a place cell map by random exploration of a novel environment. After the exploration phase, the animat decides on its next movement direction towards a goal by probing linear look-ahead trajectories in several candidate directions while stationary and picking the one activating place cells representing the goal location. In this work we present several improvements over our previous model. We improve the range of linear look-ahead probes significantly by imposing a hierarchical structure on the place cell map consistent with the experimental findings of differences in the firing field size and spacing of grid cells recorded at different positions along the dorsal to ventral axis of entorhinal cortex. The new model represents the environment at different scales by populations of simulated hippocampal place cells with different firing field sizes. Among other advantages this model allows simultaneous constant duration linear look-ahead probes at different scales while significantly extending each probe range. The extension of the linear look-ahead probe range while keeping its duration constant also limits the degrading effects of noise accumulation in the network. We show the extended model's performance using an animat in a large open field environment.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HQ6RF5JE\\Erdem, Hasselmo - 2014 - A biologically inspired hierarchical goal directed navigation model.pdf},
  journal = {Journal of physiology, Paris},
  number = {1},
  pmid = {23891644}
}

@article{erdem_hasselmo_2015,
  title = {A Hierarchical Model of Goal Directed Navigation Selects Trajectories in a Visual Environment},
  author = {Erdem, U{\v g}ur M and Milford, Michael J and Hasselmo, Michael E},
  year = {2015},
  volume = {117},
  pages = {109--121},
  issn = {10959564},
  doi = {10.1016/j.nlm.2014.07.003},
  abstract = {We have developed a Hierarchical Look-Ahead Trajectory Model (HiLAM) that incorporates the firing pattern of medial entorhinal grid cells in a planning circuit that includes interactions with hippocampus and prefrontal cortex. We show the model's flexibility in representing large real world environments using odometry information obtained from challenging video sequences. We acquire the visual data from a camera mounted on a small tele-operated vehicle. The camera has a panoramic field of view with its focal point approximately 5. cm above the ground level, similar to what would be expected from a rat's point of view. Using established algorithms for calculating perceptual speed from the apparent rate of visual change over time, we generate raw dead reckoning information which loses spatial fidelity over time due to error accumulation. We rectify the loss of fidelity by exploiting the loop-closure detection ability of a biologically inspired, robot navigation model termed RatSLAM. The rectified motion information serves as a velocity input to the HiLAM to encode the environment in the form of grid cell and place cell maps. Finally, we show goal directed path planning results of HiLAM in two different environments, an indoor square maze used in rodent experiments and an outdoor arena more than two orders of magnitude larger than the indoor maze. Together these results bridge for the first time the gap between higher fidelity bio-inspired navigation models (HiLAM) and more abstracted but highly functional bio-inspired robotic mapping systems (RatSLAM), and move from simulated environments into real-world studies in rodent-sized arenas and beyond.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9H7MTTN4\\Erdem et al. - 2015 - A hierarchical model of goal directed navigation s.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\RY3PQHDY\\Erdem, Milford, Hasselmo - 2014 - A hierarchical model of goal directed navigation selects trajectories in a visual environment.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\SVST3G7J\\Erdem, Milford, Hasselmo - 2015 - A hierarchical model of goal directed navigation selects trajectories in a visual environment.pdf},
  journal = {Neurobiology of Learning and Memory},
  keywords = {Grid cell,Hippocampus,Navigation,Path planning,Place cell,RatSLAM,SLAM},
  pmid = {25079451}
}

@article{ergen_demiralp_2014,
  title = {Time-Frequency Analysis of the Event-Related Potentials Associated with the {{Stroop}} Test},
  author = {Ergen, Mehmet and Saban, Sara and {Kirmizi-Alsan}, Elif and Uslu, Atilla and {Keskin-Ergen}, Yasemin and Demiralp, Tamer},
  year = {2014},
  volume = {94},
  pages = {463--472},
  issn = {18727697},
  doi = {10.1016/j.ijpsycho.2014.08.177},
  abstract = {Multiple executive processes are suggested to be engaged at Stroop test, and time-frequency analysis is acknowledged to improve the informative utility of EEG in cognitive brain research. We aimed to investigate event-related oscillations associated with the Stroop test. EEG data was collected from 23 healthy volunteers while they performed a computer version of Stroop test. Both evoked (phase-locked) and total (phase-locked. +. non-phase-locked) oscillatory responses in the EEG were analyzed by wavelet transform. Data from the congruent (color-word matching) and incongruent stimuli (color-word non-matching) conditions are compared. In the incongruent condition, N450 wave was more negative and amplitude of the late slow wave was more positive. In the time-frequency plane, the fronto-central total theta amplitude (300-700. ms) was larger in the incongruent condition. The evoked delta (250-600. ms) was larger in the congruent condition particularly over parieto-occipital regions. The larger frontal theta response in the incongruent condition was associated with the detection of interference and inhibition of the response to task-irrelevant features, while the larger evoked delta in the congruent condition was suggestive of the easier decision process owing to congruency between the physical attribute and the verbal meaning of the stimuli. Furthermore, in the incongruent condition, amplitude of the occipital total alpha in the very late phase (700-900. ms) was smaller. This prolonged desynchronization in the alpha band could be reflecting augmentation of attentional filters in visual modality for the next stimulus. These multiple findings on EEG time-frequency plane provide improved description of the overlapping processes in Stroop test.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VK7ARRCY\\Ergen et al. - 2014 - Time-frequency analysis of the event-related potentials associated with the Stroop test.pdf},
  journal = {International Journal of Psychophysiology},
  keywords = {alpha,Delta band,Stroop test,Theta band,Time-frequency analysis},
  number = {3},
  pmid = {25135670}
}

@article{eriksson_nyberg_2015,
  title = {Perspective {{Neurocognitive Architecture}} of {{Working Memory}}},
  author = {Eriksson, Johan and Vogel, Edward K and Lansner, Anders and Bergstr{\"o}, Fredrik and Nyberg, Lars},
  year = {2015},
  volume = {88},
  pages = {33--46},
  doi = {10.1016/j.neuron.2015.09.020},
  abstract = {A crucial role for working memory in temporary information processing and guidance of complex behavior has been recognized for many decades. There is emerging consensus that working-memory maintenance results from the interactions among long-term memory representations and basic processes, including attention, that are instantiated as reentrant loops between frontal and posterior cortical areas, as well as sub-cortical structures. The nature of such interactions can account for capacity limitations, lifespan changes, and restricted transfer after working-memory training. Recent data and models indicate that work-ing memory may also be based on synaptic plasticity and that working memory can operate on non-consciously perceived information.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\D98522T2\\Eriksson et al. - 2015 - Perspective Neurocognitive Architecture of Working Memory.pdf},
  journal = {Neuron}
}

@article{ermentrout_kopell_1998,
  title = {Fine Structure of Neural Spiking and Synchronization in the Presence of Conduction Delays},
  author = {Ermentrout, G B and Kopell, Nancy},
  year = {1998},
  volume = {95},
  pages = {1259--1264},
  abstract = {Hippocampal networks of excitatory and in- hibitory neurons that produce /// -frequency rhythms display behavior in which the inhibitory cells produce spike doublets when there is strong stimulation at separated sites. It has been suggested that the doublets play a key role in the ability to synchronize over a distance. Here we analyze the mechanisms by which timing in the spike doublet can affect the synchro- nization process. The analysis describes two independent effects: one comes from the timing of excitation from sepa- rated local circuits to an inhibitory cell, and the other comes from the timing of inhibition from separated local circuits to an excitatory cell. We show that a network with both of these effects has different synchronization properties than a net- work with either excitatory or inhibitory type of coupling alone, and we give a rationale for the shorter space scales associated with inhibitory interactions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\56CGQ9TU\\Ermentrout, Kopell - 1998 - Fine structure of neural spiking and synchronization in the presence of conduction delays.pdf},
  journal = {Proceedings of the National \{\textbackslash ldots\}},
  number = {February}
}

@article{eshelid_steinbergid_2018,
  title = {Learning What to Approach},
  author = {Eshelid, Neir and Steinbergid, Elizabeth E},
  year = {2018},
  doi = {10.1371/journal.pbio.3000043},
  abstract = {Most decisions share a common goal: maximize reward and minimize punishment. Achieving this goal requires learning which choices are likely to lead to favorable outcomes. Dopa-mine is essential for this process, enabling learning by signaling the difference between what we expect to get and what we actually get. Although all animals appear to use this dopamine prediction error circuit, some do so more than others, and this neural heterogene-ity correlates with individual variability in behavior. In this issue of PLOS Biology, Lee and colleagues show that manipulating a simple task parameter can bias the animals' behavioral strategy and modulate dopamine release, implying that how we learn is just as flexible as what we learn. Learning the value of objects in the environment is critical for survival. Some mushrooms are deadly; others provide sustenance. Rain in the dry season can be a harbinger of life, while in a monsoon, it means heading for cover. How do animals learn these values and adapt them over time? One of the most common ways is through trial and error. As we explore our environment , we make predictions about the value of stimuli around us. If outcomes match our predictions , there is no need to adapt. If outcomes are different, we use that discrepancy to improve our predictions for the future. This difference between actual and expected outcome is known as prediction error, and it turns out to be crucial for learning in animals [1-3] as well as machines [4,5]. As befitting such a conserved learning mechanism, the brain has developed a fine-tuned system to encode it. In the 1990s, Schultz and colleagues [6,7] recorded monkey dopamine (DA) neurons and discovered a curious response. When monkeys received an unexpected reward, such as a drop of juice, DA neurons became excited. If animals received the same reward but fully expected it, DA neurons showed no response. Instead, DA neurons fired to the earliest reliable predictor of the reward, typically a sound or picture that indicated juice was coming soon. Finally, if the reward was expected but never materialized, DA neurons dipped below their baseline firing rate at precisely the moment when the reward was anticipated. Together, these results imply that DA neurons encode the difference between actual and expected reward-in other words, reward prediction error (RPE), the precise signal already known to facilitate learning. The link between DA and RPE has been replicated and extended numerous times in a host of species and tasks (for review see [8]). Notably, modern neuroscience tools have confirmed that prediction error neurons are indeed dopaminergic [9] and have revealed a local circuit in PLOS Biology | https://doi.org/10.1371/journal.pbio.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PVJIVS8S\\Eshelid, Steinbergid - 2018 - Learning what to approach.pdf}
}

@article{evans_burgess_2016,
  title = {How Environment and Self-Motion Combine in Neural Representations of Space: {{Environment}} and Self-Motion in Neural Representations of Space},
  shorttitle = {How Environment and Self-Motion Combine in Neural Representations of Space},
  author = {Evans, Talfan and Bicanski, Andrej and Bush, Daniel and Burgess, Neil},
  year = {2016},
  month = nov,
  volume = {594},
  pages = {6535--6546},
  issn = {00223751},
  doi = {10.1113/JP270666},
  abstract = {Estimates of location or orientation can be constructed solely from sensory information representing environmental cues. In unfamiliar or sensory-poor environments, these estimates can also be maintained and updated by integrating self-motion information. However, the accumulation of error dictates that updated representations of heading direction and location become progressively less reliable over time, and must be corrected by environmental sensory inputs when available. Anatomical, electrophysiological and behavioural evidence indicates that angular and translational path integration contributes to the firing of head direction cells and grid cells. We discuss how sensory inputs may be combined with self-motion information in the firing patterns of these cells. For head direction cells, direct projections from egocentric sensory representations of distal cues can help to correct cumulative errors. Grid cells may benefit from sensory inputs via boundary vector cells and place cells. However, the allocentric code of boundary vector cells and place cells requires consistent head-direction information in order to translate the sensory signal of egocentric boundary distance into allocentric boundary vector cell firing, suggesting that the different spatial representations found in and around the hippocampal formation are interdependent. We conclude that, rather than representing pure path integration, the firing of head-direction cells and grid cells reflects the interface between self-motion and environmental sensory information. Together with place cells and boundary vector cells they can support a coherent unitary representation of space based on both environmental sensory inputs and path integration signals.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9ULTDGFW\\Evans et al. - 2016 - How environment and self-motion combine in neural .pdf},
  journal = {The Journal of Physiology},
  language = {en},
  number = {22}
}

@article{falkenhainer_gentner_1989,
  title = {The Structure-Mapping Engine: {{Algorithm}} and Examples},
  author = {Falkenhainer, Brian and Forbus, Kenneth D and Gentner, Dedre},
  year = {1989},
  volume = {41},
  pages = {1--63},
  issn = {00043702},
  doi = {10.1016/0004-3702(89)90077-5},
  abstract = {This paper describes the structure-mapping engine (SME), a program for studying analogical processing. SME has been built to explore Gentner's structure-mapping theory of analogy, and provides a "tool kit" for constructing matching algorithms consistent with this theory. Its flexibility enhances cognitive simulation studies by simplifying experimentation. Furthermore, SME is very efficient, making it a useful component in machine learning systems as well. We review the structure-mapping theory and describe the design of the engine. We analyze the complexity of the algorithm, and demonstrate that most of the steps are polynomial, typically bounded by O(N2). Next we demonstrate some examples of its operation taken from our cognitive simulation studies and work in machine learning. Finally, we compare SME to other analogy programs and discuss several areas for future work. \textcopyright{} 1989.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9CWP475C\\Falkenhainer, Forbus, Gentner - 1989 - The structure-mapping engine Algorithm and examples.pdf},
  journal = {Artificial Intelligence},
  number = {1},
  pmid = {25246403}
}

@article{fang_qiu_2020,
  title = {Multivariate {{Time Series Classification Using Spiking Neural Networks}}},
  author = {Fang, Haowen and Shrestha, Amar and Qiu, Qinru},
  year = {2020},
  month = jul,
  abstract = {There is an increasing demand to process streams of temporal data in energy-limited scenarios such as embedded devices, driven by the advancement and expansion of Internet of Things (IoT) and Cyber-Physical Systems (CPS). Spiking neural network has drawn attention as it enables low power consumption by encoding and processing information as sparse spike events, which can be exploited for event-driven computation. Recent works also show SNNs' capability to process spatial temporal information. Such advantages can be exploited by power-limited devices to process real-time sensor data. However, most existing SNN training algorithms focus on vision tasks and temporal credit assignment is not addressed. Furthermore, widely adopted rate encoding ignores temporal information, hence it's not suitable for representing time series. In this work, we present an encoding scheme to convert time series into sparse spatial temporal spike patterns. A training algorithm to classify spatial temporal patterns is also proposed. Proposed approach is evaluated on multiple time series datasets in the UCR repository and achieved performance comparable to deep neural networks.},
  archivePrefix = {arXiv},
  eprint = {2007.03547},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CE7WNM3M\\fang_qiu_2020.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\INR27YNH\\2007.html},
  journal = {arXiv:2007.03547 [cs]},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  primaryClass = {cs}
}

@article{farashahi_soltani_2017,
  title = {Feature-Based Learning Improves Adaptability without Compromising Precision},
  author = {Farashahi, Shiva and Rowe, Katherine and Aslami, Zohra and Lee, Daeyeol and Soltani, Alireza},
  year = {2017},
  volume = {8},
  issn = {20411723},
  doi = {10.1038/s41467-017-01874-w},
  abstract = {Learning from reward feedback is essential for survival but can become extremely challenging with myriad choice options. Here, we propose that learning reward values of individual features can provide a heuristic for estimating reward values of choice options in dynamic, multi-dimensional environments. We hypothesize that this feature-based learning occurs not just because it can reduce dimensionality, but more importantly because it can increase adaptability without compromising precision of learning. We experimentally test this hypothesis and find that in dynamic environments, human subjects adopt feature-based learning even when this approach does not reduce dimensionality. Even in static, low-dimensional environments, subjects initially adopt feature-based learning and gradually switch to learning reward values of individual options, depending on how accurately objects' values can be predicted by combining feature values. Our computational models reproduce these results and highlight the importance of neurons coding feature values for parallel learning of values for features and objects.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KSHP85NH\\Farashahi et al. - 2017 - Feature-based learning improves adaptability without compromising precision.pdf},
  journal = {Nature Communications},
  number = {1}
}

@article{faraut_rutishauser_2018,
  title = {Data {{Descriptor}}: {{Dataset}} of Human Medial Temporal Lobe Single Neuron Activity during Declarative Memory Encoding and Recognition},
  author = {Faraut, Mailys C.M. and Carlson, April A. and Sullivan, Shannon and Tudusciuc, Oana and Ross, Ian and Reed, Chrystal M. and Chung, Jeffrey M. and Mamelak, Adam N. and Rutishauser, Ueli},
  year = {2018},
  volume = {5},
  pages = {1--11},
  issn = {20524463},
  doi = {10.1038/sdata.2018.10},
  abstract = {\textcopyright{} The Author(s) 2018. We present a dataset of 1,576 single neurons recorded from the human amygdala and hippocampus in 65 sessions from 42 patients undergoing intracranial monitoring for localization of epileptic seizures. Subjects performed a recognition memory task with pictures as stimuli. Subjects were asked to identify whether they had seen a particular image the first time ('new') or second time ('old') on a 1-6 confidence scale. This comprehensive dataset includes the spike times of all neurons and their extracellular waveforms, behavior, electrode locations determined from post-operative MRI scans, demographics, and the stimuli shown. As technical validation, we provide spike sorting quality metrics and assessment of tuning of cells to verify the presence of visually-and memory selective cells. We also provide analysis code that reproduces key scientific findings published previously on a smaller version of this dataset. Together, this large dataset will facilitate the investigation of the neural mechanism of declarative memory by providing a substantial number of hard to obtain human single-neuron recordings during a well characterized behavioral task.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KLIQ368L\\Faraut et al. - 2018 - Data Descriptor Dataset of human medial temporal lobe single neuron activity during declarative memory encoding a.pdf},
  journal = {Scientific Data},
  pmid = {29437158}
}

@article{farooq_dragoi_2019,
  title = {Strengthened {{Temporal Coordination}} within {{Pre}}-Existing {{Sequential Cell Assemblies Supports Trajectory Replay}}},
  author = {Farooq, Usman and Sibille, Jeremie and Liu, Kefei and Dragoi, George},
  year = {2019},
  month = aug,
  volume = {103},
  pages = {719-733.e7},
  issn = {08966273},
  doi = {10.1016/j.neuron.2019.05.040},
  abstract = {A central goal in learning and memory research is to reveal the neural substrates underlying episodic memory formation. The hallmark of sequential spatial trajectory learning, a model of episodic memory, has remained equivocal, with proposals ranging from de novo creation of compressed sequential replay from blank slate networks to selection of pre-existing compressed preplay sequences. Here, we show that increased millisecond-timescale activation of cell assemblies expressed during de novo sequential experience and increased neuronal firing rate correlations can explain the difference between postexperience trajectory replay and robust preplay. This increased activation results from an improved neuronal tuning to specific cell assemblies, higher recruitment of experience-tuned neurons into preexisting cell assemblies, and increased recruitment of cell assemblies in replay. In contrast, changes in overall neuronal and cell assembly temporal order within extended sequences do not account for sequential trajectory learning. We propose the coordinated strengthening of cell assemblies played sequentially on robust pre-existing temporal frameworks could support rapid formation of episodiclike memory.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6ZFSW5XM\\Farooq et al. - 2019 - Strengthened Temporal Coordination within Pre-exis.pdf},
  journal = {Neuron},
  language = {en},
  number = {4}
}

@article{farovik_eichenbaum_2015,
  title = {Orbitofrontal {{Cortex Encodes Memories}} within {{Value}}-{{Based Schemas}} and {{Represents Contexts That Guide Memory Retrieval}}},
  author = {Farovik, Anja and Place, R J and McKenzie, S and Porter, B and Munro, C E and Eichenbaum, Howard B},
  year = {2015},
  volume = {35},
  pages = {8333--8344},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.0134-15.2015},
  abstract = {? 2015 the authors.There are a substantial number of studies showing that the orbitofrontal cortex links events to reward values, whereas the hippocampus links events to the context in which they occur. Here we asked how the orbitofrontal cortex contributes to memory where context determines the reward values associated with events. After rats learned object?reward associations that differed depending on the spatial context in which the objects were presented, neuronal ensembles in orbitofrontal cortex represented distinct value-based schemas, each composed of a systematic organization of the representations of objects in the contexts and positions where they were associated with reward or nonreward. Orbitofrontal ensembles also represent the different spatial contexts that define the mappings of stimuli to actions that lead to reward or nonreward. These findings, combined with observations on complementary memory representation within the hippocampus, suggest mechanisms through which prefrontal cortex and the hippocampus interact in support of context-guided memory.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TDUMWLRB\\Farovik et al. - 2015 - Orbitofrontal Cortex Encodes Memories within Value-Based Schemas and Represents Contexts That Guide Memory Retri.pdf},
  journal = {Journal of Neuroscience},
  keywords = {context,memory,Memory,orbitofrontal cortex,Orbitofrontal cortex,rat,Rat,Retri,retrieval,value},
  number = {21},
  pmid = {26019346}
}

@article{faulkner_precup_2018,
  title = {Dyna {{Planning}} Using a {{Feature Based Generative Model}}},
  author = {Faulkner, Ryan and Precup, Doina},
  year = {2018},
  month = may,
  abstract = {Dyna-style reinforcement learning is a powerful approach for problems where not much real data is available. The main idea is to supplement real trajectories, or sequences of sampled states over time, with simulated ones sampled from a learned model of the environment. However, in large state spaces, the problem of learning a good generative model of the environment has been open so far. We propose to use deep belief networks to learn an environment model for use in Dyna. We present our approach and validate it empirically on problems where the state observations consist of images. Our results demonstrate that using deep belief networks, which are full generative models, significantly outperforms the use of linear expectation models, proposed in Sutton et al. (2008)},
  archivePrefix = {arXiv},
  eprint = {1805.10129},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5PEPKIVE\\Faulkner and Precup - 2018 - Dyna Planning using a Feature Based Generative Mod.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\NTSY54K7\\1805.html},
  journal = {arXiv:1805.10129 [cs, stat]},
  primaryClass = {cs, stat}
}

@article{feldman_feldman_2013,
  title = {The {{Neural Binding Problem}}(s)},
  author = {Feldman, Jerome},
  year = {2013},
  volume = {7},
  pages = {1--11},
  doi = {10.1007/s11571-012-9219-8},
  abstract = {The famous Neural Binding Problem (NBP) comprises at least four distinct problems with different computational and neural requirements. This review discusses the current state of work on General Coordination, Visual Feature-Binding, Variable Binding, and the Subjective Unity of Perception. There is significant continuing progress, partially masked by confusing the different versions of the NBP.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3TU7RECX\\Feldman2013_Article_TheNeuralBindingProblemS.pdf},
  journal = {Cogn Neurodyn},
  number = {1}
}

@book{feng_feng_2003,
  title = {Computational Neuroscience: A Comprehensive Approach},
  author = {Feng, J},
  year = {2003},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5PJND2SR\\Feng - 2003 - Computational neuroscience a comprehensive approach.pdf},
  isbn = {1-58488-362-6}
}

@book{feng_feng_2004,
  title = {Computational Neuroscience: Comprehensive Approach},
  shorttitle = {Computational Neuroscience},
  editor = {Feng, Jianfeng},
  year = {2004},
  publisher = {{Chapman \& Hall/CRC}},
  address = {{Boca Raton}},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PM5DAR9R\\Feng - 2004 - Computational neuroscience comprehensive approach.pdf},
  isbn = {978-1-58488-362-3},
  keywords = {Computational neuroscience},
  language = {en},
  lccn = {QP357.5 .C633 2004},
  series = {Chapman \& {{Hall}}/{{CRC}} Mathematical Biology and Medicine Series}
}

@article{fernandez_white_2013,
  title = {Entorhinal Stellate Cells Show Preferred Spike Phase-Locking to Theta Inputs That Is Enhanced by Correlations in Synaptic Activity.},
  author = {Fernandez, Fernando R and Malerba, Paola and Bressloff, Paul C and a White, John},
  year = {2013},
  month = apr,
  volume = {33},
  pages = {6027--6040},
  issn = {1529-2401},
  doi = {10.1523/JNEUROSCI.3892-12.2013},
  abstract = {In active networks, excitatory and inhibitory synaptic inputs generate membrane voltage fluctuations that drive spike activity in a probabilistic manner. Despite this, some cells in vivo show a strong propensity to precisely lock to the local field potential and maintain a specific spike-phase relationship relative to other cells. In recordings from rat medial entorhinal cortical stellate cells, we measured spike phase-locking in response to sinusoidal "test" inputs in the presence of different forms of background membrane voltage fluctuations, generated via dynamic clamp. We find that stellate cells show strong and robust spike phase-locking to theta (4-12 Hz) inputs. This response occurs under a wide variety of background membrane voltage fluctuation conditions that include a substantial increase in overall membrane conductance. Furthermore, the IH current present in stellate cells is critical to the enhanced spike phase-locking response at theta. Finally, we show that correlations between inhibitory and excitatory conductance fluctuations, which can arise through feedback and feedforward inhibition, can substantially enhance the spike phase-locking response. The enhancement in locking is a result of a selective reduction in the size of low-frequency membrane voltage fluctuations due to cancellation of inhibitory and excitatory current fluctuations with correlations. Hence, our results demonstrate that stellate cells have a strong preference for spike phase-locking to theta band inputs and that the absolute magnitude of locking to theta can be modulated by the properties of background membrane voltage fluctuations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BMPT62VE\\Fernandez et al. - 2013 - Entorhinal stellate cells show preferred spike phase-locking to theta inputs that is enhanced by correlations.pdf},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  keywords = {Animals,Biophysics,Electric Stimulation,Entorhinal Cortex,Entorhinal Cortex: cytology,Female,Long-Evans,Male,Models,Neural Inhibition,Neurological,Neurons,Neurons: physiology,Newborn,Patch-Clamp Techniques,Rats,Spectrum Analysis,Statistics as Topic,Synapses,Synapses: physiology,Theoretical,Theta Rhythm,Theta Rhythm: physiology},
  number = {14},
  pmid = {23554484}
}

@article{ferrante_hasselmo_2016,
  title = {Post-{{Inhibitory Rebound Spikes}} in {{Rat Medial Entorhinal Layer II}}/{{III Principal Cells}}: {{In}}-{{Vivo}}, {{In}}-{{Vitro}}, and {{Computational Modeling Characterization}}},
  author = {Ferrante, Michele and Shay, Christopher F. and Tsuno, Yusuke and Chapman, G William and Hasselmo, Michael E},
  year = {2016},
  issn = {1047-3211},
  doi = {10.1093/cercor/bhw058},
  abstract = {Abstract Medial Entorhinal Cortex Layer-II stellate cells (mEC-LII-SCs) primarily interact via inhibitory interneurons. This suggests the presence of alternative mechanisms other than excitatory synaptic inputs for triggering action potentials (APs) in stellate cells during spatial navigation. Our intracellular recordings show that the hyperpolarization-activated cation current (Ih) allows Post- Inhibitory-Rebound-Spikes (PIRS) in mEC-LII-SCs. In-vivo, strong Inhibitory-Post-Synaptic- Potentials (IPSPs) immediately preceded most APs shortening their delay and enhancing excitability. In-vitro experiments showed that inhibition initiated spikes more effectively than excitation and that more dorsal mEC-LII-SCs produced faster and more synchronous spikes. In contrast, PIRS in Layer-II/III pyramidal cells (PCs) were harder to evoke, voltage-independent, and slower in dorsal mEC. In computational simulations, mEC-LII-SCs morphology and Ih homeostatically regulated the dorso-ventral (DV) differences in PIRS timing and most dendrites generated PIRS with a narrow range of stimulus amplitudes. These results suggest inhibitory inputs could mediate the emergence of grid cell firing in a neuronal network.},
  copyright = {All rights reserved},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9XX2YX89\\Ferrante et al. - 2016 - Post-Inhibitory Rebound Spikes in Rat Medial Entorhinal Layer IIIII Principal Cells In-Vivo, In-Vitro, and Comp.pdf},
  journal = {Cerebral Cortex},
  keywords = {entorhinal cortex,hyperpolarization-activated cation current (Ih),inhibition,post-inhibitory spikes,stellate cells},
  number = {March}
}

@article{fiebelkorn_kastner_2013,
  title = {Rhythmic Sampling within and between Objects despite Sustained Attention at a Cued Location},
  author = {Fiebelkorn, Ian C and Saalmann, Yuri B and Kastner, Sabine},
  year = {2013},
  volume = {23},
  pages = {2553--2558},
  issn = {09609822},
  doi = {10.1016/j.cub.2013.10.063},
  abstract = {The brain directs its limited processing resources through various selection mechanisms, broadly referred to as attention. The present study investigated the temporal dynamics of two such selection mechanisms: space- and object-based selection. Previous evidence has demonstrated that preferential processing resulting from a spatial cue (i.e., space-based selection) spreads to uncued locations if those locations are part of the same object (i.e., resulting in object-based selection), but little is known about the relationship between these fundamental selection mechanisms. Here, we used human behavioral data to determine how space- and object-based selection simultaneously evolve under conditions that promote sustained attention at a cued location, varying the cue-to-target interval from 300 to 1100 ms. We tracked visual-target detection at a cued location (i.e., space-based selection), at an uncued location that was part of the same object (i.e., object-based selection), and at an uncued location that was part of a different object (i.e., in the absence of space- and object-based selection). The data demonstrate that even under static conditions, there is a moment-to-moment reweighting of attentional priorities based on object properties. This reweighting is revealed through rhythmic patterns of visual-target detection both within (at 8 Hz) and between (at 4 Hz) objects. \textcopyright{} 2013 Elsevier Ltd.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BVQVCP98\\Fiebelkorn, Saalmann, Kastner - 2013 - Rhythmic sampling within and between objects despite sustained attention at a cued location.pdf},
  journal = {Current Biology},
  number = {24},
  pmid = {24316204}
}

@article{fiebelkorn_kastner_2018,
  title = {A {{Rhythmic Theory}} of {{Attention}}},
  author = {Fiebelkorn, Ian C and Kastner, Sabine},
  year = {2018},
  month = dec,
  volume = {xx},
  issn = {13646613},
  doi = {10.1016/j.tics.2018.11.009},
  abstract = {Recent evidence has demonstrated that environmental sampling is a fundamentally rhythmic process. Both perceptual sensitivity during covert spatial attention and the probability of overt exploratory movements are tethered to theta-band activity (3-8 Hz) in the attention network. The fronto-parietal part of this network is positioned at the nexus of sensory and motor functions, directing two tightly coupled processes related to environmental exploration: preferential routing of sensory input and saccadic eye movements. We propose that intrinsic theta rhythms temporally resolve potential functional conflicts by periodically reweighting functional connections between higher-order brain regions and either sensory or motor regions. This rhythmic reweighting alternately promotes either sampling at a behaviorally relevant location (i.e., sensory functions) or shifting to another location (i.e., motor functions). A Rhythmic Pattern of Sampling and Shifting Imagine searching for a child's favorite toy on the floor of a cluttered playroom. Environmental sampling is the means through which the brain directs its limited resources to first select and then boost the processing of behaviorally relevant stimuli. It occurs through a combination of preferential sensory processing (broadly referred to as selective attention) and exploratory movements. Selective attention establishes prioritization of stimuli and enhances neural processing of behaviorally relevant stimuli, while at the same time suppressing neural processing of irrelevant stimuli. In contrast, exploratory movements, such as saccadic eye movements in primates and whisking in rodents, orient the sensory organs toward behaviorally relevant stimuli. In primates, a common network (i.e., the 'attention network') of brain regions directs sensory and motor aspects of environmental sampling [1]. Here, we describe recent evidence that rhythmic neural activity shapes both these aspects of environmental sampling. We specifically propose that theta rhythms in the attention network resolve potential functional conflicts by temporally organizing sensory and motor functions. Even under conditions that promote sustained attention at a behaviorally relevant location, there are alternating periods of either enhanced or diminished perceptual sensitivity [2-4]. Whereas theta-dependent periods of enhanced perceptual sensitivity reflect attention-related sensory sampling, theta-dependent periods of diminished perceptual sensitivity provide opportunities to shift attention. We propose that the presently attended location is periodically reassessed (every 250 ms) to confirm that it is still the most important location. In the following sections, we will elaborate on the neural basis and the functional consequences of this rhythmic pattern of sampling and shifting. We refer to this new, theta-rhythmic characterization of environmental sampling as the 'rhythmic theory of attention'. The present discussion focuses on sampling in visual space, through spatial attention and saccadic eye movements (or saccades). These sampling processes are closely related. Spatial Highlights Spatial attention and saccadic eye movements are typically coupled but can be uncoupled. Spatial attention samples the environment in theta-rhythmic cycles, leading to alternating periods of either enhanced or diminished perceptual sensitivity. The likelihood of saccades similarly fluctuates at a theta rhythm. Rhythmic attentional sampling is linked to theta-band activity in the large-scale network that directs both spatial attention and saccades. Theta rhythms organize neural activity into alternating attentional states associated with either sampling at a beha-viorally relevant location or shifting to another location. Theta rhythms might resolve temporal conflicts between processes that promote either sampling (sensory function) or shifting (motor function), by periodically altering functional connec-tivity between higher-order brain regions and sensory or motor regions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UTYMR9HK\\Fiebelkorn, Kastner - 2018 - A Rhythmic Theory of Attention Environmental Sampling Involves Both Sensory and Motor Processes.pdf},
  journal = {Trends in Cognitive Sciences},
  keywords = {attention,important}
}

@article{fiebelkorn_kastner_2018a,
  title = {A {{Dynamic Interplay}} within the {{Frontoparietal Network Underlies Rhythmic Spatial Attention}}},
  author = {Fiebelkorn, Ian C. and Pinsk, Mark A. and Kastner, Sabine},
  year = {2018},
  volume = {99},
  pages = {842--853.e8},
  issn = {10974199},
  doi = {10.1016/j.neuron.2018.07.038},
  abstract = {Classic studies of spatial attention assumed that its neural and behavioral effects were continuous over time. Recent behavioral studies have instead revealed that spatial attention leads to alternating periods of heightened or diminished perceptual sensitivity. Yet, the neural basis of these rhythmic fluctuations has remained largely unknown. We show that a dynamic interplay within the macaque frontoparietal network accounts for the rhythmic properties of spatial attention. Neural oscillations characterize functional interactions between the frontal eye fields (FEF) and the lateral intraparietal area (LIP), with theta phase (3\textendash 8 Hz) coordinating two rhythmically alternating states. The first is defined by FEF-dominated beta-band activity, associated with suppressed attentional shifts, and LIP-dominated gamma-band activity, associated with enhanced visual processing and better behavioral performance. The second is defined by LIP-specific alpha-band activity, associated with attenuated visual processing and worse behavioral performance. Our findings reveal how network-level interactions organize environmental sampling into rhythmic cycles. Fiebelkorn et al. use simultaneous recordings in two hubs of the macaque frontoparietal network to demonstrate a neural basis of rhythmic sampling during spatial attention. Theta-organized, alternating attentional states, characterized by different spatiotemporal dynamics, shape environmental sampling.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EMH9YMK4\\Fiebelkorn et al. - 2018 - A Dynamic Interplay within the Frontoparietal Netw.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\HSYVVYD4\\Fiebelkorn_et_al_2018_A_dynamic_interplay_within_the_frontoparietal_network_underlies_rhythmic.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\T3VLT2YS\\Fiebelkorn, Pinsk, Kastner - 2018 - A Dynamic Interplay within the Frontoparietal Network Underlies Rhythmic Spatial Attention.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\XWMQ5HHP\\S0896627318306366.html},
  journal = {Neuron},
  keywords = {attention,fef,frontoparietal network,important,LIP,oscillations,phase-dependent behavior,theta,vision},
  number = {4},
  pmid = {30138590}
}

@article{fiebelkorn_kastner_2019,
  title = {The Mediodorsal Pulvinar Coordinates the Macaque Fronto-Parietal Network during Rhythmic Spatial Attention},
  author = {Fiebelkorn, Ian C and Pinsk, Mark A and Kastner, Sabine},
  year = {2019},
  volume = {10},
  pages = {215},
  issn = {2041-1723},
  doi = {10.1038/s41467-018-08151-4},
  abstract = {Spatial attention is discontinuous, sampling behaviorally relevant locations in theta-rhythmic cycles (3-6 Hz). Underlying this rhythmic sampling are intrinsic theta oscillations in frontal and parietal cortices that provide a clocking mechanism for two alternating attentional states that are associated with either engagement at the presently attended location (and enhanced perceptual sensitivity) or disengagement (and diminished perceptual sensitivity). It has remained unclear, however, how these theta-dependent states are coordinated across the large-scale network that directs spatial attention. The pulvinar is a candidate for such coordination, having been previously shown to regulate cortical activity. Here, we examined pulvino-cortical interactions during theta-rhythmic sampling by simultaneously recording from macaque frontal eye fields (FEF), lateral intraparietal area (LIP), and pulvinar. Neural activity propagated from pulvinar to cortex during periods of engagement, and from cortex to pulvinar during periods of disengagement. A rhythmic reweighting of pulvino-cortical interactions thus defines functional dissociations in the attention network.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CS3QQT2S\\Fiebelkorn, Pinsk, Kastner - Unknown - The mediodorsal pulvinar coordinates the macaque fronto-parietal network during rhythmic spatial.pdf},
  journal = {Nature Communications},
  number = {1}
}

@article{fiebig_lansner_2019,
  title = {An {{Indexing Theory}} for {{Working Memory}} Based on {{Fast Hebbian Plasticity}}},
  author = {Fiebig, Florian and Herman, Pawel and Lansner, Anders},
  year = {2019},
  month = apr,
  doi = {10.1101/334821},
  abstract = {Working memory (WM) is a key component of human memory and cognition. Computational models have been used to study the underlying neural mechanisms, but neglected the important role of short- and long-term memory interactions (STM, LTM) for WM. Here, we investigate these using a novel multi-area spiking neural network model of prefrontal cortex (PFC) and two parieto-temporal cortical areas based on macaque data. We propose a WM indexing theory that explains how PFC could associate, maintain and update multi-modal LTM representations. Our simulations demonstrate how simultaneous, brief multi-modal memory cues could build a temporary joint memory representation as an ``index'' in PFC by means of fast Hebbian synaptic plasticity. This index can then reactivate spontaneously and thereby reactivate the associated LTM representations. Cueing one LTM item rapidly pattern-completes the associated un-cued item via PFC. The PFC-STM network updates flexibly as new stimuli arrive thereby gradually over-writing older representations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8ULVC77Z\\Fiebig et al. - 2019 - An Indexing Theory for Working Memory based on Fas.pdf},
  journal = {bioRxiv},
  language = {en}
}

@article{finger_konig_2019,
  title = {Probing Neural Networks for Dynamic Switches of Communication Pathways},
  author = {Finger, Holger and Gast, Richard and Gerloff, Christian and Engel, Andreas K. and K{\"o}nig, Peter},
  editor = {Kumar, Arvind},
  year = {2019},
  month = dec,
  volume = {15},
  pages = {e1007551},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1007551},
  abstract = {Dynamic communication and routing play important roles in the human brain in order to facilitate flexibility in task solving and thought processes. Here, we present a network perturbation methodology that allows investigating dynamic switching between different network pathways based on phase offsets between two external oscillatory drivers. We apply this method in a computational model of the human connectome with delay-coupled neural masses. To analyze dynamic switching of pathways, we define four new metrics that measure dynamic network response properties for pairs of stimulated nodes. Evaluating these metrics for all network pathways, we found a broad spectrum of pathways with distinct dynamic properties and switching behaviors. We show that network pathways can have characteristic timescales and thus specific preferences for the phase lag between the regions they connect. Specifically, we identified pairs of network nodes whose connecting paths can either be (1) insensitive to the phase relationship between the node pair, (2) turned on and off via changes in the phase relationship between the node pair, or (3) switched between via changes in the phase relationship between the node pair. Regarding the latter, we found that 33\% of node pairs can switch their communication from one pathway to another depending on their phase offsets. This reveals a potential mechanistic role that phase offsets and coupling delays might play for the dynamic information routing via communication pathways in the brain.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FNJ9X48L\\Finger et al. - 2019 - Probing neural networks for dynamic switches of co.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\LSS32VH8\\Finger et al. - 2019 - Probing neural networks for dynamic switches of co.pdf},
  journal = {PLOS Computational Biology},
  language = {en},
  number = {12}
}

@techreport{finkelstein_ulanovsky_2019,
  title = {Dynamic Control of Cortical Head-Direction Signal by Angular Velocity},
  author = {Finkelstein, Arseny and Rouault, Herv{\'e} and Romani, Sandro and Ulanovsky, Nachum},
  year = {2019},
  month = aug,
  institution = {{Neuroscience}},
  doi = {10.1101/730374},
  abstract = {The sense of direction requires accurate tracking of head direction at different turningvelocities, yet it remains unclear how this is achieved in the mammalian brain. Here we recorded head-direction cells in bat dorsal presubiculum and found that, surprisingly, the head-direction signal in this cortical region was dynamically controlled by angular velocity. In most neurons, a sharp head-direction tuning emerged at some angular velocity, but was absent at other velocities \textendash{} resulting in a 4-fold increase in head-direction cell abundance. The head-direction tuning changed as a function of angular velocity primarily via a redistribution of spikes between the neuron's preferred and null directions \textendash{} while keeping the average firing-rate constant. These results could not be explained by existing `ring-attractor' models of the head-direction system. We propose a novel recurrent network model that accounts for the observed dynamics of head-direction cells. This model predicts that the new classes of cells we found can improve the sensitivity of the head-direction system to directional sensory cues, and support angular-velocity integration.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\B6IRWNY5\\Finkelstein et al. - 2019 - Dynamic control of cortical head-direction signal .pdf},
  language = {en},
  type = {Preprint}
}

@article{finn_bandettini_2018,
  title = {Layer-Dependent Activity in Human Prefrontal Cortex during Working Memory},
  author = {Finn, Emily S and Huber, Laurentius and Jangraw, David C and Bandettini, Peter A},
  year = {2018},
  doi = {10.1101/425249},
  abstract = {Working memory involves a series of functions: encoding a stimulus, maintaining or manipulating its representation over a delay, and finally making a behavioral response. While working memory engages dorsolateral prefrontal cortex (dlPFC), few studies have investigated whether these subfunctions are localized to different cortical depths in this region, and none have done so in humans. Here, we use high-resolution functional MRI to interrogate the layer specificity of neural activity during different epochs of a working memory task in dlPFC. We detect activity timecourses that follow the hypothesized patterns: superficial layers are preferentially active during the delay period , while deeper layers are preferentially active during the response. Results demonstrate that layer-specific fMRI can be used in higher-order brain regions to non-invasively map cogni-tive information processing along cortical circuitry in humans. high-resolution fMRI | working memory | cortical layers | prefrontal cortex Correspondence: emily.finn@nih.gov},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\633UZIFK\\Finn et al. - Unknown - D R A F T Layer-dependent activity in human prefrontal cortex during working memory.pdf}
}

@article{fioravante_regehr_2011,
  title = {Short-Term Forms of Presynaptic Plasticity},
  author = {Fioravante, Diasynou and Regehr, Wade G.},
  year = {2011},
  volume = {21},
  pages = {269--274},
  issn = {09594388},
  doi = {10.1016/j.conb.2011.02.003},
  abstract = {Synapses exhibit several forms of short-term plasticity that play a multitude of computational roles. Short-term depression suppresses neurotransmitter release for hundreds of milliseconds to tens of seconds; facilitation and post-tetanic potentiation lead to synaptic enhancement lasting hundreds of milliseconds to minutes. Recent advances have provided insight into the mechanisms underlying these forms of plasticity. Vesicle depletion, as well as inactivation of both release sites and calcium channels, contribute to synaptic depression. Mechanisms of short-term enhancement include calcium channel facilitation, local depletion of calcium buffers, increases in the probability of release downstream of calcium influx, altered vesicle pool properties, and increases in quantal size. Moreover, there is a growing appreciation of the heterogeneity of vesicles and release sites and how they can contribute to use-dependent plasticity. \textcopyright{} 2011.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\695HHPAW\\Fioravante, Regehr - 2011 - Short-term forms of presynaptic plasticity.pdf},
  journal = {Current Opinion in Neurobiology},
  number = {2},
  pmid = {21353526}
}

@article{fischer_ullsperger_2018,
  title = {Cortical Beta Power Reflects Decision Dynamics and Uncovers Multiple Facets of Post-Error Adaptation},
  author = {Fischer, Adrian G and Nigbur, Roland and Klein, Tilmann A and Danielmeier, Claudia and Ullsperger, Markus},
  year = {2018},
  doi = {10.1038/s41467-018-07456-8},
  abstract = {Adapting to errors quickly is essential for survival. Reaction slowing after errors is commonly observed but whether this slowing is adaptive or maladaptive is unclear. Here, we analyse a large dataset from a flanker task using two complementary approaches: a multistage drift-diffusion model, and the lateralisation of EEG beta power as a time-resolved index of choice formation. Fitted model parameters and their independently measured neuronal proxies in beta power convergently show a complex interplay of multiple mechanisms initiated after mistakes. Suppression of distracting evidence, response threshold increase, and reduction of evidence accumulation cause slow and accurate post-error responses. This data provides evidence for both adaptive control and maladaptive orienting after errors yielding an adaptive net effect-a decreased likelihood to repeat mistakes. Generally, lateralised beta power provides a non-invasive readout of action selection for the study of speeded cognitive control processes.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\S3F2MDJB\\Fischer et al. - Unknown - Cortical beta power reflects decision dynamics and uncovers multiple facets of post-error adaptation.pdf}
}

@article{flagel_akil_2011,
  title = {A Selective Role for Dopamine in Stimulus-Reward Learning.},
  author = {Flagel, Shelly B and Clark, Jeremy J and Robinson, Terry E and Mayo, Leah and Czuj, Alayna and Willuhn, Ingo and a Akers, Christina and Clinton, Sarah M and Phillips, Paul E M and Akil, Huda},
  year = {2011},
  volume = {469},
  pages = {53--57},
  issn = {1476-4687},
  doi = {10.1038/nature09588},
  abstract = {Individuals make choices and prioritize goals using complex processes that assign value to rewards and associated stimuli. During Pavlovian learning, previously neutral stimuli that predict rewards can acquire motivational properties, becoming attractive and desirable incentive stimuli. However, whether a cue acts solely as a predictor of reward, or also serves as an incentive stimulus, differs between individuals. Thus, individuals vary in the degree to which cues bias choice and potentially promote maladaptive behaviour. Here we use rats that differ in the incentive motivational properties they attribute to food cues to probe the role of the neurotransmitter dopamine in stimulus-reward learning. We show that intact dopamine transmission is not required for all forms of learning in which reward cues become effective predictors. Rather, dopamine acts selectively in a form of stimulus-reward learning in which incentive salience is assigned to reward cues. In individuals with a propensity for this form of learning, reward cues come to powerfully motivate and control behaviour. This work provides insight into the neurobiology of a form of stimulus-reward learning that confers increased susceptibility to disorders of impulse control.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\U5BIU8DK\\Flagel et al. - 2011 - A selective role for dopamine in stimulus-reward learning.pdf},
  journal = {Nature},
  keywords = {Animals,Classical,Classical: drug effects,Classical: physiology,Conditioning,Cues,Dopamine,Dopamine Antagonists,Dopamine Antagonists: pharmacology,Dopamine: metabolism,Flupenthixol,Flupenthixol: pharmacology,Food,Impulse Control Disorders,Impulse Control Disorders: physiopathology,Learning,Learning: drug effects,Learning: physiology,Male,Microelectrodes,Models,Motivation,Motivation: drug effects,Neurological,Nucleus Accumbens,Nucleus Accumbens: metabolism,Phenotype,Probability,Rats,Reward,Signal Transduction,Sprague-Dawley,Synaptic Transmission},
  number = {7328},
  pmid = {21150898}
}

@article{flagel_robinson_2011,
  title = {A Food Predictive Cue Must Be Attributed with Incentive Salience for It to Induce C-Fos {{mRNA}} Expression in Cortico-Striatal-Thalamic Brain Regions},
  author = {Flagel, S B and Cameron, C M and Pickup, K N and Watson, S J and Akil, H and Robinson, T E},
  year = {2011},
  volume = {196},
  pages = {80--96},
  issn = {03064522},
  doi = {10.1016/j.neuroscience.2011.09.004},
  abstract = {Cues associated with rewards acquire the ability to engage the same brain systems as rewards themselves. However, reward cues have multiple properties. For example, they not only act as predictors of reward capable of evoking conditional responses (CRs), but they may also acquire incentive motivational properties. As incentive stimuli they can evoke complex emotional and motivational states. Here we sought to determine whether the predictive value of a reward cue is sufficient to engage brain reward systems, or whether the cue must also be attributed with incentive salience. We took advantage of the fact that there are large individual differences in the extent to which reward cues are attributed with incentive salience. When a cue (conditional stimulus, CS) is paired with delivery of food (unconditional stimulus, US), the cue acquires the ability to evoke a CR in all rats; that is, it is equally predictive and supports learning the CS-US association in all. However, only in a subset of rats is the cue attributed with incentive salience, becoming an attractive and desirable incentive stimulus. We used in situ hybridization histochemistry to quantify the ability of a food cue to induce c-fos mRNA expression in rats that varied in the extent to which they attributed incentive salience to the cue. We found that a food cue induced c-fos mRNA in the orbitofrontal cortex, striatum (caudate and nucleus accumbens), thalamus (paraventricular, intermediodorsal and central medial nuclei), and lateral habenula, only in rats that attributed incentive salience to the cue. Furthermore, patterns of "connectivity" between these brain regions differed markedly between rats that did or did not attribute incentive salience to the food cue. These data suggest that the predictive value of a reward cue is not sufficient to engage brain reward systems-the cue must also be attributed with incentive salience. \{\textcopyright\} 2011 IBRO.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LL5FZGIJ\\Flagel et al. - 2011 - A food predictive cue must be attributed with incentive salience for it to induce c-fos mRNA expression in cortic.pdf},
  journal = {Neuroscience},
  keywords = {C-fos,Goal-trackers,Incentive salience,Mesocorticolimbic,Motive circuit,Sign-trackers},
  pmid = {21945724}
}

@article{fleck_mitroff_2007,
  title = {Rare {{Targets Are Rarely Missed}} in {{Correctable Search}}},
  author = {Fleck, Mathias S. and Mitroff, Stephen R.},
  year = {2007},
  month = nov,
  volume = {18},
  pages = {943--947},
  issn = {0956-7976, 1467-9280},
  doi = {10.1111/j.1467-9280.2007.02006.x},
  abstract = {Failing to find a tumor in an x-ray scan or a gun in an airport baggage screening can have dire consequences, making it fundamentally important to elucidate the mechanisms that hinder performance in such visual searches. Recent laboratory work has indicated that low target prevalence can lead to disturbingly high miss rates in visual search. Here, however, we demonstrate that misses in low-prevalence searches can be readily abated. When targets are rarely present, observers adapt by responding more quickly, and miss rates are high. Critically, though, these misses are often due to response-execution errors, not perceptual or identification errors: Observers know a target was present, but just respond too quickly. When provided an opportunity to correct their last response, observers can catch their mistakes. Thus, low target prevalence may not be a generalizable cause of high miss rates in visual search.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ASW72DPH\\Fleck and Mitroff - 2007 - Rare Targets Are Rarely Missed in Correctable Sear.pdf},
  journal = {Psychological Science},
  language = {en},
  number = {11}
}

@article{flesch_summerfield_2018,
  title = {Focused Learning Promotes Continual Task Performance in Humans},
  author = {Flesch, Timo and Balaguer, Jan and Dekker, Ronald and Nili, Hamed and Summerfield, Christopher},
  year = {2018},
  doi = {10.1101/247460},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5QY56WNV\\Flesch et al. - 2018 - Focused learning promotes continual task performance in humans.pdf}
}

@article{florian_florian_2005,
  title = {A Reinforcement Learning Algorithm for Spiking Neural Networks},
  author = {Florian, R{\u a}zvan V},
  year = {2005},
  pages = {8 pp.},
  doi = {10.1109/SYNASC.2005.13},
  abstract = {The paper presents a new reinforcement learning mechanism for spiking neural networks. The algorithm is derived for networks of stochastic integrate-and-fire neurons, but it can be also applied to generic spiking neural networks. Learning is achieved by synaptic changes that depend on the firing of pre- and postsynaptic neurons, and that are modulated with a global reinforcement signal. The ef- ficacy of the algorithm is verified in a biologically-inspired experiment, featuring a simulated worm that searches for food. Our model recovers a form of neural plasticity experimentally observed in animals, combining spike-timing-dependent synaptic changes of one sign with nonassociative synaptic changes of the opposite sign determined by presynaptic spikes. The model also predicts that the time constant of spike-timing-dependent synaptic changes is equal to the membrane time constant of the neuron, in agreement with experimental observations in the brain. This study also led to the discovery of a biologically-plausible reinforcement learning mechanism that works by modulating spike-timing-dependent plasticity (STDP) with a global reward signal.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8JB5MQD8\\Florian - 2005 - A reinforcement learning algorithm for spiking neural networks.pdf},
  journal = {Seventh International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC'05)},
  number = {Synasc}
}

@article{florian_florian_2007,
  title = {Reinforcement {{Learning Through Modulation}} of {{Spike}}-{{Timing}}-{{Dependent Synaptic Plasticity}}},
  author = {Florian, R{\u a}zvan V.},
  year = {2007},
  month = jun,
  volume = {19},
  pages = {1468--1502},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/neco.2007.19.6.1468},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\E3U3RRES\\Florian - 2007 - Reinforcement Learning Through Modulation of Spike.pdf},
  journal = {Neural Computation},
  language = {en},
  number = {6}
}

@article{fogerson_huguenard_2016,
  title = {Review {{Tapping}} the {{Brakes}} : {{Cellular}} and {{Synaptic Mechanisms}} That {{Regulate Thalamic Oscillations}}},
  author = {Fogerson, P Michelle and Huguenard, John R},
  year = {2016},
  volume = {92},
  pages = {687--704},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2016.10.024},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JVIZT3FA\\Fogerson, Huguenard - 2016 - Review Tapping the Brakes Cellular and Synaptic Mechanisms that Regulate Thalamic Oscillations.pdf},
  journal = {Neuron},
  number = {4}
}

@techreport{fonseca_bonhoeffer_1011,
  title = {Competing for {{Memory}}: {{Hippocampal LTP}} under {{Regimes}} of {{Reduced Protein Synthesis}}},
  author = {Fonseca, Rosalina and Valentin, U and Gerl, N{\"a} and Morris, Richard G M and Bonhoeffer, Tobias},
  year = {1011},
  doi = {10.1016/j.neuron.2004.10.033},
  abstract = {then be possible to observe this competition. We achieved this by limiting protein synthesis during the reactivation of LTP and observed that stabilizing the Results 1 George Square Edinburgh, EH8 9LE In adult hippocampal brain slices, competition was set Scotland up between two independent pathways, hereafter called United Kingdom the "reactivated pathway" (RP; red symbols in Figure 1A and thereafter; single traces shown in Figure 1B) and the "test pathway" (TP; blue symbols in Figure 1A and Summary thereafter; single traces shown in Figure 1B), respectively. After recording baseline postsynaptic potentials The persistence of synaptic potentiation in the hippo-in independent pathways (see Experimental Proce-campus is known to depend on transcription and pro-dures), the RP received a weak tetanus that, by itself, tein synthesis. We report here that, under regimes of induced little or no LTP (100 Hz for 0.25 s; open arrows reduced protein synthesis, competition between syn-in Figure 1A and thereafter), whereas the TP received apses for the relevant intracellular proteins can be strong tetanization that resulted in clear-cut LTP (100 demonstrated. Under such circumstances, the induc-Hz for 1 s; filled arrow in Figure 1A, and thereafter). Both tion of additional protein synthesis-dependent long-weak and strong tetanizing stimuli were then applied term potentiation for a given set of postsynaptic neu-simultaneously (concurrent open and filled arrow in Fig-rons occurs at the expense of the maintenance of prior ure 1A; also see the insert in Figure 1A), and the resulting potentiation on an independent pathway. This new associativity between the two inputs induced LTP on phenomenon, which we call "competitive maintenance," both pathways (Barrionuevo and Brown, 1983). This pro-has important functional consequences, and it may be tocol serves as a control for possible heterosynaptic explained in terms of dynamic interactions between interactions between the two pathways during potentia-synapses and "plasticity factors" over extended peri-tion while also enabling associative LTP on both inputs. ods of time. The key finding of "competitive maintenance" emerged in the next phase of our protocol. LTP on both the "red" Introduction and "blue" pathways was maintained for the next 4 hr (Figure 1A), indicating that the long-lasting, protein syn-Long-term potentiation (LTP) in the hippocampus is a thesis-dependent form of LTP (L-LTP) had been in-prominent cellular model of memory formation (Bliss et duced. Four hours after the start of the experiment, al., 2003). To persist for a sustained period of time, it is anisomycin was applied to the slice to block any ongoing thought to involve gene transcription and translation or further synthesis of new proteins (yellow bar in Figure (Frey et al., 1988; Goelet et al., 1986; Huang et al., 1996; 1A and thereafter). Forty minutes later, a further weak Krug et al., 1984). Exactly how the persistence of LTP tetanus (open arrow in Figure 1A, blowup in Figure 1C) depends on protein synthesis and, in particular, how was applied to the RP, thereby reactivating it (hence the the relevant synapse-to-nucleus and nucleus-to-syn-name "reactivated pathway"). According to the tagging apse signaling is achieved is still a matter of debate hypothesis, this reactivated pathway should display ad-(Deisseroth et al., 1996; Silva et al., 1998). Recent experi-ditional early LTP, at the same time setting further syn-ments point to a mechanism that sets "synaptic tags" aptic tags that would sequester the now limited supply at potentiated synapses, whose role is to sequester of plasticity factors available due to the earlier tetaniza-"plasticity factors" in order to stabilize the expressed tion and so enabling its stabilization as persistent or late potentiation in an input-specific manner (Frey and Mor-LTP. This prediction was upheld (Figures 1A and 1C, ris, 1997, 1998b; Martin et al., 1997). These experiments enhancement of the RP; filled red squares after 5 hr), established the concept and function of synaptic tag-in line with earlier reports (Frey and Morris, 1997). The ging and the idea that plasticity factors induced through application of anisomycin, however, had an important the activation of one input might be shared with other additional effect: the potentiation of the reactivated synapses upon their subsequent activation. However, pathway was at the expense of the enhancement of the sharing is only one side of the coin, and we reasoned test pathway (filled blue circles), which started vanishing that, when the availability of plasticity factors is limited, immediately after LTP in the reactivated pathway had tagged synapses would compete for them, and it should been induced (Figures 1A and 1C). Our proposed explanation of this unexpected "com-petition" between the two input pathways is that sus-*Correspondence: tobias.bonhoeffer@neuro.mpg.de},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CGG63J4Q\\Fonseca et al. - 1011 - Competing for Memory Hippocampal LTP under Regimes of Reduced Protein Synthesis.pdf}
}

@article{fontolan_gutkin_2013,
  title = {Analytical {{Insights}} on {{Theta}}-{{Gamma Coupled Neural Oscillators}}},
  author = {Fontolan, Lorenzo and Krupa, Maciej and Hyafil, Alexandre and Gutkin, Boris},
  year = {2013},
  volume = {3},
  pages = {16},
  issn = {2190-8567},
  doi = {10.1186/2190-8567-3-16},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LD6RRAIM\\Fontolan et al. - 2013 - Analytical Insights on Theta-Gamma Coupled Neural .pdf},
  journal = {The Journal of Mathematical Neuroscience},
  language = {en},
  number = {1}
}

@article{forbus_hinrichs_2017,
  title = {Analogy and {{Qualitative Architecture}}},
  author = {Forbus, Kenneth D and Hinrichs, Thomas},
  year = {2017},
  pages = {34--42},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\M7XBWJN3\\Forbus, Hinrichs - 2017 - Analogy and Qualitative Architecture.pdf}
}

@book{forstmann_wagenmakers_2015,
  title = {An Introduction to Model-Based Cognitive Neuroscience},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  year = {2015},
  publisher = {{Springer}},
  address = {{New York}},
  annotation = {OCLC: ocn909486676},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NN6UYCWI\\Forstmann and Wagenmakers - 2015 - An introduction to model-based cognitive neuroscie.pdf},
  isbn = {978-1-4939-2235-2},
  language = {en},
  lccn = {QP360.5 .I57 2015}
}

@book{forstmann_wagenmakers_2015a,
  title = {An Introduction to Model-Based Cognitive Neuroscience},
  author = {Forstmann, Birte U. and Wagenmakers, Eric Jan},
  year = {2015},
  doi = {10.1007/978-1-4939-2236-9},
  abstract = {Mycotoxins are small (MW approximately 700), toxic chemical products formed as secondary metabolites by a few fungal species that readily colonise crops and contaminate them with toxins in the field or after harvest. Ochratoxins and Aflatoxins are mycotoxins of major significance and hence there has been significant research on broad range of analytical and detection techniques that could be useful and practical. Due to the variety of structures of these toxins, it is impossible to use one standard technique for analysis and/or detection. Practical requirements for high-sensitivity analysis and the need for a specialist laboratory setting create challenges for routine analysis. Several existing analytical techniques, which offer flexible and broad-based methods of analysis and in some cases detection, have been discussed in this manuscript. There are a number of methods used, of which many are lab-based, but to our knowledge there seems to be no single technique that stands out above the rest, although analytical liquid chromatography, commonly linked with mass spectroscopy is likely to be popular. This review manuscript discusses (a) sample pre-treatment methods such as liquid-liquid extraction (LLE), supercritical fluid extraction (SFE), solid phase extraction (SPE), (b) separation methods such as (TLC), high performance liquid chromatography (HPLC), gas chromatography (GC), and capillary electrophoresis (CE) and (c) others such as ELISA. Further currents trends, advantages and disadvantages and future prospects of these methods have been discussed.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XG48SN9E\\Forstmann, Wagenmakers - 2015 - An introduction to model-based cognitive neuroscience.pdf},
  isbn = {978-1-4939-2236-9},
  pmid = {25246403}
}

@article{forstmann_wagenmakers_2016,
  title = {Sequential {{Sampling Models}} in {{Cognitive Neuroscience}}: {{Advantages}}, {{Applications}}, and {{Extensions}}},
  author = {Forstmann, B.U. and Ratcliff, Roger and Wagenmakers, E.-J},
  year = {2016},
  volume = {67},
  pages = {641--666},
  issn = {0066-4308},
  doi = {10.1146/annurev-psych-122414-033645},
  abstract = {Sequential sampling models assume that people make speeded decisions by gradually accumulating noisy information until a threshold of evidence is reached. In cognitive science, one such model-the diffusion decision model-is now regularly used to decompose task performance into underlying processes such as the quality of information processing, response caution, and a priori bias. In the cognitive neurosciences, the diffusion decision model has recently been adopted as a quantitative tool to study the neural basis of decision making under time pressure. We present a selective overview of several recent applications and extensions of the diffusion decision model in the cognitive neurosciences.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5KTVQQBZ\\Forstmann, Ratcliff, Wagenmakers - 2016 - Sequential Sampling Models in Cognitive Neuroscience Advantages, Applications, and Extensions.pdf},
  journal = {Annual Review of Psychology},
  keywords = {decision making,diffusion decision model,drift rate,information accumulation,response time,speed-accuracy trade-off},
  number = {1},
  pmid = {26393872}
}

@article{fortenberry_grossberg_2012,
  title = {Learned Integration of Visual, Vestibular, and Motor Cues in Multiple Brain Regions Computes Head Direction during Visually Guided Navigation.},
  author = {Fortenberry, Bret and Gorchetchnikov, Anatoli and Grossberg, Stephen},
  year = {2012},
  month = dec,
  volume = {22},
  pages = {2219--2237},
  issn = {1098-1063},
  doi = {10.1002/hipo.22040},
  abstract = {Effective navigation depends upon reliable estimates of head direction (HD). Visual, vestibular, and outflow motor signals combine for this purpose in a brain system that includes dorsal tegmental nucleus, lateral mammillary nuclei, anterior dorsal thalamic nucleus, and the postsubiculum. Learning is needed to combine such different cues to provide reliable estimates of HD. A neural model is developed to explain how these three types of signals combine adaptively within the above brain regions to generate a consistent and reliable HD estimate, in both light and darkness, which explains the following experimental facts. Each HD cell is tuned to a preferred head direction. The cell's firing rate is maximal at the preferred direction and decreases as the head turns from the preferred direction. The HD estimate is controlled by the vestibular system when visual cues are not available. A well-established visual cue anchors the cell's preferred direction when the cue is in the animal's field of view. Distal visual cues are more effective than proximal cues for anchoring the preferred direction. The introduction of novel cues in either a novel or familiar environment can gain control over a cell's preferred direction within minutes. Turning out the lights or removing all familiar cues does not change the cell's firing activity, but it may accumulate a drift in the cell's preferred direction. The anticipated time interval (ATI) of the HD estimate is greater in early processing stages of the HD system than at later stages. The model contributes to an emerging unified neural model of how multiple processing stages in spatial navigation, including postsubiculum head direction cells, entorhinal grid cells, and hippocampal place cells, are calibrated through learning in response to multiple types of signals as an animal navigates in the world.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\79LKNLRQ\\Fortenberry, Gorchetchnikov, Grossberg - 2012 - Learned integration of visual, vestibular, and motor cues in multiple brain regions comp.pdf},
  journal = {Hippocampus},
  keywords = {Animals,Artificial Intelligence,Brain,Brain: physiology,Cues,Head,Head: physiology,Learning,Learning: physiology,Models,Neurological,Neurons,Neurons: physiology,Orientation,Orientation: physiology,Photic Stimulation,Rats,Spatial Behavior,Spatial Behavior: physiology},
  number = {12},
  pmid = {22707350}
}

@article{foster_dayan_2000,
  title = {A Model of Hippocampally Dependent Navigation, Using the Temporal Difference Learning Rule},
  author = {Foster, D.J. and Morris, R.G.M. and Dayan, Peter},
  year = {2000},
  volume = {10},
  pages = {1--16},
  issn = {1050-9631, 1098-1063},
  doi = {10.1002/(SICI)1098-1063(2000)10:1<1::AID-HIPO1>3.0.CO;2-1},
  abstract = {This paper presents a model of how hippocampal place cells might be used for spatial navigation in two watermaze tasks: the standard reference memory task and a delayed matching-to-place task. In the reference memory task, the escape platform occupies a single location and rats gradually learn relatively direct paths to the goal over the course of days, in each of which they perform a fixed number of trials. In the delayed matching-to-place task, the escape platform occupies a novel location on each day, and rats gradually acquire one-trial learning, i.e., direct paths on the second trial of each day. The model uses a local, incremental, and statistically efficient connectionist algorithm called temporal difference learning in two distinct components. The first is a reinforcement-based ``actor-critic'' network that is a general model of classical and instrumental conditioning. In this case, it is applied to navigation, using place cells to provide information about state. By itself, the actor-critic can learn the reference memory task, but this learning is inflexible to changes to the platform location. We argue that one-trial learning in the delayed matching-to-place task demands a goal-independent representation of space. This is provided by the second component of the model: a network that uses temporal difference learning and selfmotion information to acquire consistent spatial coordinates in the environment. Each component of the model is necessary at a different stage of the task; the actor-critic provides a way of transferring control to the component that performs best. The model successfully captures gradual acquisition in both tasks, and, in particular, the ultimate development of one-trial learning in the delayed matching-to-place task. Place cells report a form of stable, allocentric information that is well-suited to the various kinds of learning in the model. Hippocampus 2000;10:1\textendash 16. ௠ 2000 Wiley-Liss, Inc.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YS7TA2U2\\Foster et al. - 2000 - A model of hippocampally dependent navigation, usi.pdf},
  journal = {Hippocampus},
  language = {en},
  number = {1}
}

@article{foster_foster_2015,
  title = {Analogical {{Reinforcement Learning}}},
  author = {Foster, James Michael},
  year = {2015},
  volume = {91},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RADQJHVA\\Foster - 2015 - Analogical Reinforcement Learning.pdf},
  journal = {Psychology and Neuroscience Graduate Theses \& Dissertations}
}

@article{foster_foster_2017,
  title = {Replay {{Comes}} of {{Age}}},
  author = {Foster, David J.},
  year = {2017},
  month = jul,
  volume = {40},
  pages = {581--602},
  issn = {0147-006X, 1545-4126},
  doi = {10.1146/annurev-neuro-072116-031538},
  abstract = {Hippocampal place cells take part in sequenced patterns of reactivation after behavioral experience, known as replay. Since replay was first reported, nearly 20 years ago, many new results have been found, necessitating revision of the original interpretations. We review some of these results with a focus on the phenomenology of replay.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BQGUDH5Z\\Foster - 2017 - Replay Comes of Age.pdf},
  journal = {Annual Review of Neuroscience},
  language = {en},
  number = {1}
}

@article{foster_saalmann_2016,
  title = {Spontaneous {{Neural Dynamics}} and {{Multi}}-Scale {{Network Organization}}},
  author = {Foster, Brett L and He, Biyu J and Honey, Christopher J and Jerbi, Karim and Maier, Alexander and Saalmann, Yuri B},
  year = {2016},
  volume = {10},
  pages = {7},
  issn = {1662-5137},
  doi = {10.3389/fnsys.2016.00007},
  abstract = {Spontaneous neural activity has historically been viewed as task-irrelevant noise that should be controlled for via experimental design, and removed through data analysis. However, electrophysiology and functional MRI studies of spontaneous activity patterns, which have greatly increased in number over the past decade, have revealed a close correspondence between these intrinsic patterns and the structural network architecture of functional brain circuits. In particular, by analyzing the large-scale covariation of spontaneous hemodynamics, researchers are able to reliably identify functional networks in the human brain. Subsequent work has sought to identify the corresponding neural signatures via electrophysiological measurements, as this would elucidate the neural origin of spontaneous hemodynamics and would reveal the temporal dynamics of these processes across slower and faster timescales. Here we survey common approaches to quantifying spontaneous neural activity, reviewing their empirical success, and their correspondence with the findings of neuroimaging. We emphasize invasive electrophysiological measurements, which are amenable to amplitude- and phase-based analyses, and which can report variations in connectivity with high spatiotemporal precision. After summarizing key findings from the human brain, we survey work in animal models that display similar multi-scale properties. We highlight that, across many spatiotemporal scales, the covariance structure of spontaneous neural activity reflects structural properties of neural networks and dynamically tracks their functional repertoire.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7L85D94J\\Foster et al. - 2016 - Spontaneous Neural Dynamics and Multi-scale Network Organization.pdf},
  journal = {Frontiers in Systems Neuroscience},
  keywords = {as an organ in,b,brain networks,connectivity,despite constituting only 2,ecog,electrocorticography,electrocorticography (ECoG),neural dynamics,of body weight,of the body,perpetual action,raichle,resting-state fmri,resting-state fMRI,s metabolic budget,spontaneous brain activity,the human brain consumes,this metabolic consumption supports},
  number = {February},
  pmid = {26903823}
}

@incollection{fox_willsky_2009,
  title = {Nonparametric {{Bayesian Learning}} of {{Switching Linear Dynamical Systems}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 21},
  author = {Fox, Emily and Sudderth, Erik B. and Jordan, Michael I. and Willsky, Alan S.},
  editor = {Koller, D. and Schuurmans, D. and Bengio, Y. and Bottou, L.},
  year = {2009},
  pages = {457--464},
  publisher = {{Curran Associates, Inc.}},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KUNPIVK9\\Fox et al_2009_Nonparametric Bayesian Learning of Switching Linear Dynamical Systems.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\6DDMJGGE\\3546-nonparametric-bayesian-learning-of-switching-linear-dynamical-systems.html}
}

@article{francis_kanold_2018,
  title = {Small {{Networks Encode Decision}}-{{Making}} in {{Primary Auditory Cortex}}},
  author = {Francis, Nikolas A. and Winkowski, Daniel E. and Sheikhattar, Alireza and Armengol, Kevin and Babadi, Behtash and Kanold, Patrick O.},
  year = {2018},
  volume = {97},
  pages = {885--897.e6},
  issn = {08966273},
  doi = {10.1016/j.neuron.2018.01.019},
  abstract = {Sensory detection tasks enhance representations of behaviorally meaningful stimuli in primary auditory cortex (A1). However, it remains unclear how A1 encodes decision-making. Neurons in A1 layer 2/3 (L2/3) show heterogeneous stimulus selectivity and complex anatomical connectivity, and receive input from prefrontal cortex. Thus, task-related modulation of activity in A1 L2/3 might differ across subpopulations. To study the neural coding of decision-making, we used two-photon imaging in A1 L2/3 of mice performing a tone-detection task. Neural responses to targets showed attentional gain and encoded behavioral choice. To characterize network representation of behavioral choice, we analyzed functional connectivity using Granger causality, pairwise noise correlations, and neural decoding. During task performance, small groups of four to five neurons became sparsely linked, locally clustered, and rostro-caudally oriented, while noise correlations both increased and decreased. Our results suggest that sensory-based decision-making involves small neural networks driven by the sum of sensory input, attentional gain, and behavioral choice.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HYH9WZJH\\Francis et al. - 2018 - Small Networks Encode Decision-Making in Primary Auditory Cortex.pdf},
  journal = {Neuron},
  number = {4},
  pmid = {29398362}
}

@article{frank_badre_2012,
  title = {Mechanisms of Hierarchical Reinforcement Learning in Corticostriatal Circuits 1: {{Computational}} Analysis},
  author = {Frank, Michael J. and Badre, David},
  year = {2012},
  volume = {22},
  pages = {509--526},
  issn = {10473211},
  doi = {10.1093/cercor/bhr114},
  abstract = {Growing evidence suggests that the prefrontal cortex (PFC) is organized hierarchically, with more anterior regions having increasingly abstract representations. How does this organization support hierarchical cognitive control and the rapid discovery of abstract action rules? We present computational models at different levels of description. A neural circuit model simulates interacting corticostriatal circuits organized hierarchically. In each circuit, the basal ganglia gate frontal actions, with some striatal units gating the inputs to PFC and others gating the outputs to influence response selection. Learning at all of these levels is accomplished via dopaminergic reward prediction error signals in each corticostriatal circuit. This functionality allows the system to exhibit conditional if-then hypothesis testing and to learn rapidly in environments with hierarchical structure. We also develop a hybrid Bayesian-reinforcement learning mixture of experts (MoE) model, which can estimate the most likely hypothesis state of individual participants based on their observed sequence of choices and rewards. This model yields accurate probabilistic estimates about which hypotheses are attended by manipulating attentional states in the generative neural model and recovering them with the MoE model. This 2-pronged modeling approach leads to multiple quantitative predictions that are tested with functional magnetic resonance imaging in the companion paper.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Q3T3XGN2\\Frank, Badre - 2012 - Mechanisms of hierarchical reinforcement learning in corticostriatal circuits 1 Computational analysis.pdf},
  journal = {Cerebral Cortex},
  keywords = {basal ganglia,computational model,hierarchical reinforcement learning,prefrontal cortex},
  number = {3},
  pmid = {21693490}
}

@article{frank_badre_2015,
  title = {How Cognitive Theory Guides Neuroscience},
  author = {Frank, Michael J and Badre, David},
  year = {2015},
  volume = {135},
  pages = {14--20},
  issn = {18737838},
  doi = {10.1016/j.cognition.2014.11.009},
  abstract = {The field of cognitive science studies latent, unobservable cognitive processes that generate observable behaviors. Similarly, cognitive neuroscience attempts to link latent cognitive processes with the neural mechanisms that generate them. Although neural processes are partially observable (with imaging and electrophysiology), it would be a mistake to 'skip' the cognitive level and pursue a purely neuroscientific enterprise to studying behavior. In fact, virtually all of the major advances in understanding the neural basis of behavior over the last century have relied fundamentally on principles of cognition for guiding the appropriate measurements, manipulations, tasks, and interpretations. We provide several examples from the domains of episodic memory, working memory and cognitive control, and decision making in which cognitive theorizing and prior experimentation has been essential in guiding neuroscientific investigations and discoveries.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CIC9BMRB\\Frank, Badre - 2015 - How cognitive theory guides neuroscience.pdf},
  journal = {Cognition},
  keywords = {Cognitive control,Computational models,Decision making,Memory,Neuroscience},
  pmid = {25496988}
}

@article{frank_badre_2015a,
  title = {{{fMRI}} and {{EEG Predictors}} of {{Dynamic Decision Parameters}} during {{Human Reinforcement Learning}}},
  author = {Frank, Michael J and Gagne, Chris and Nyhus, Erika and Masters, Sean and Wiecki, Thomas V and Cavanagh, J. F and Badre, David},
  year = {2015},
  volume = {35},
  pages = {485--494},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.2036-14.2015},
  abstract = {What are the neural dynamics of choice processes during reinforcement learning? Two largely separate literatures have examined dynamics of reinforcement learning (RL) as a function of experience but assuming a static choice process, or conversely, the dynamics of choice processes in decision making but based on static decision values. Here we show that human choice processes during RL are well described by a drift diffusion model (DDM) of decision making in which the learned trial-by-trial reward values are sequentially sampled, with a choice made when the value signal crosses a decision threshold. Moreover, simultaneous fMRI and EEG recordings revealed that this decision threshold is not fixed across trials but varies as a function of activity in the subthalamic nucleus (STN) and is further modulated by trial-by-trial measures of decision conflict and activity in the dorsomedial frontal cortex (pre-SMA BOLD and mediofrontal theta in EEG). These findings provide converging multimodal evidence for a model in which decision threshold in reward-based tasks is adjusted as a function of communication from pre-SMA to STN when choices differ subtly in reward values, allowing more time to choose the statistically more rewarding option.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\INPACWCL\\Frank et al. - 2015 - BehavioralCognitive fMRI and EEG Predictors of Dynamic Decision Parameters during Human Reinforcement Learning.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\PHLA3QGE\\Frank et al. - 2015 - BehavioralCognitive fMRI and EEG Predictors of Dynamic Decision Parameters during Human Reinforcement Learning.pdf},
  journal = {Journal of Neuroscience},
  keywords = {basal ganglia,decision making,drift diffusion model,prefrontal cortex,subthalamic nucleus},
  number = {2},
  pmid = {25589744}
}

@article{frank_hutchison_2007,
  title = {Genetic Triple Dissociation Reveals Multiple Roles for Dopamine in Reinforcement Learning.},
  author = {Frank, Michael J and Moustafa, Ahmed A and Haughey, Heather M and Curran, Tim and Hutchison, Kent E},
  year = {2007},
  volume = {104},
  pages = {16311--16316},
  issn = {0027-8424},
  doi = {10.1073/pnas.0706111104},
  abstract = {What are the genetic and neural components that support adaptive learning from positive and negative outcomes? Here, we show with genetic analyses that three independent dopaminergic mechanisms contribute to reward and avoidance learning in humans. A polymorphism in the DARPP-32 gene, associated with striatal dopamine function, predicted relatively better probabilistic reward learning. Conversely, the C957T polymorphism of the DRD2 gene, associated with striatal D2 receptor function, predicted the degree to which participants learned to avoid choices that had been probabilistically associated with negative outcomes. The Val/Met polymorphism of the COMT gene, associated with prefrontal cortical dopamine function, predicted participants' ability to rapidly adapt behavior on a trial-to-trial basis. These findings support a neurocomputational dissociation between striatal and prefrontal dopaminergic mechanisms in reinforcement learning. Computational maximum likelihood analyses reveal independent gene effects on three reinforcement learning parameters that can explain the observed dissociations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KQ249BND\\Frank et al. - 2007 - Genetic triple dissociation reveals multiple roles for dopamine in reinforcement learning.pdf},
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  keywords = {Algorithms,Behavioral,Brain,Brain: physiology,Catechol O-Methyltransferase,Catechol O-Methyltransferase: genetics,Dopamine,Dopamine and cAMP-Regulated Phosphoprotein 32,Dopamine and cAMP-Regulated Phosphoprotein 32: gen,Dopamine D2,Dopamine D2: genetics,Dopamine: genetics,Dopamine: physiology,Female,Genetic,Genetics,Humans,Male,Models,Polymorphism,Psychological,Receptors,Reinforcement (Psychology)},
  number = {41},
  pmid = {17913879}
}

@article{frank_oreilly_2001,
  title = {Interactions between Frontal Cortex and Basal Ganglia in Working Memory: {{A}} Computational Model},
  author = {Frank, M J and Loughry, B and O'Reilly, Randall C},
  year = {2001},
  volume = {1},
  pages = {137--160},
  doi = {10.3758/CABN.1.2.137},
  abstract = {[PDF]},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MYX22VU8\\Frank, Loughry, O'Reilly - 2001 - Interactions between frontal cortex and basal ganglia in working memory A computational model.pdf},
  journal = {Cognitive},
  number = {2},
  pmid = {3849670352668169566}
}

@article{frank_pryor_2016,
  title = {Altered Structural and Effective Connectivity in Anorexia and Bulimia Nervosa in Circuits That Regulate Energy and Reward Homeostasis},
  author = {Frank, G K W and Shott, M E and Riederer, J and Pryor, T L},
  year = {2016},
  month = nov,
  volume = {6},
  pages = {e932-e932},
  issn = {2158-3188},
  doi = {10.1038/tp.2016.199},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DDDLTWNY\\Frank et al. - 2016 - Altered structural and effective connectivity in a.pdf},
  journal = {Translational Psychiatry},
  language = {en},
  number = {11}
}

@article{frankland_cohen_2019,
  title = {Extracting and {{Utilizing Abstract}}, {{Structured Representations}} for {{Analogy}}},
  author = {Frankland, Steven M and Webb, Taylor W and Petrov, Alexander A and O'Reilly, Randall C and Cohen, Jonathan D},
  year = {2019},
  pages = {7},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TI38X6Y2\\Frankland et al. - Extracting and Utilizing Abstract, Structured Repr.pdf},
  language = {en}
}

@phdthesis{frankland_frankland_2015,
  title = {Man Bites Dog: {{The}} Representation of Structured Meaning in Left-\--mid Superior Temporal Cortex {{A}} Dissertation Presented},
  author = {Frankland, Steven Michael},
  year = {2015},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Z2YS7TRX\\Frankland - 2015 - Man bites dog The representation of structured meaning in left-­‐mid superior temporal cortex A dissertation prese.pdf},
  type = {{{PhD Thesis}}}
}

@article{franklin_chen_2016,
  title = {A {{LIDA}} Cognitive Model Tutorial},
  author = {Franklin, Stan and Madl, Tamas and Strain, Steve and Faghihi, Usef and Dong, Daqi and Kugele, Sean and Snaider, Javier and Agrawal, Pulin and Chen, Sheng},
  year = {2016},
  month = apr,
  volume = {16},
  pages = {105--130},
  issn = {2212683X},
  doi = {10.1016/j.bica.2016.04.003},
  abstract = {Over a decade in the making and described in some seventy-five published papers, the LIDA cognitive model is comprehensive, complex, and hard to ``wrap one's head around''. Here we offer, in tutorial fashion, a current, relatively complete and somewhat detailed, description of the conceptual LIDA model, with pointers to more complete accounts of individual processes in the literature. These descriptions also include some features of the workings of the LIDA model that have not been published previously.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NAEVJL5D\\Franklin et al. - 2016 - A LIDA cognitive model tutorial.pdf},
  journal = {Biologically Inspired Cognitive Architectures},
  language = {en}
}

@techreport{franklin_gershman_2019,
  title = {Structured Event Memory: A Neuro-Symbolic Model of Event Cognition},
  shorttitle = {Structured Event Memory},
  author = {Franklin, Nicholas T. and Norman, Kenneth A. and Ranganath, Charan and Zacks, Jeffrey M. and Gershman, Samuel J.},
  year = {2019},
  month = feb,
  institution = {{Neuroscience}},
  doi = {10.1101/541607},
  abstract = {Humans spontaneously organize a continuous experience into discrete events and use the learned structure of these events to generalize and organize memory. We introduce the Structured Event Memory (SEM) model of event cognition, which accounts for human abilities in event segmentation, memory, and generalization. SEM is derived from a probabilistic generative model of event dynamics defined over structured symbolic scenes. By embedding symbolic scene representations in a vector space and parametrizing the scene dynamics in this continuous space, SEM combines the advantages of structured and neural network approaches to high-level cognition. Using probabilistic reasoning over this generative model, SEM can infer event boundaries, learn event schemata, and use event knowledge to reconstruct past experience. We show that SEM can scale up to high-dimensional input spaces, producing human-like event segmentation for naturalistic video data, and accounts for a wide array of memory phenomena.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KM8Y3UPD\\Franklin et al. - 2019 - Structured event memory a neuro-symbolic model of.pdf},
  language = {en},
  type = {Preprint}
}

@book{franklin_grossberg_2017,
  title = {A Neural Model of Normal and Abnormal Learning and Memory Consolidation: Adaptively Timed Conditioning, Hippocampus, Amnesia, Neurotrophins, and Consciousness},
  author = {Franklin, Daniel J and Grossberg, Stephen},
  year = {2017},
  volume = {17},
  publisher = {{Cognitive, Affective, \{\&\} Behavioral Neuroscience}},
  doi = {10.3758/s13415-016-0463-y},
  abstract = {How do the hippocampus and amygdala interact with thalamocortical systems to regulate cognitive and cognitive-emotional learning? Why do lesions of thalamus, amygdala, hippocampus, and cortex have differential effects depending on the phase of learning when they occur? In particular, why is the hippocampus typically needed for trace conditioning, but not delay conditioning, and what do the exceptions reveal? Why do amygdala lesions made before or immediately after training decelerate conditioning while those made later do not? Why do thalamic or sensory cortical lesions degrade trace conditioning more than delay conditioning? Why do hippocampal lesions during trace conditioning experiments degrade recent but not temporally remote learning? Why do orbitofrontal cortical lesions degrade temporally remote but not recent or post-lesion learning? How is temporally graded amnesia caused by ablation of prefrontal cortex after memory consolidation? How are attention and consciousness linked during conditioning? How do neurotrophins, notably BDNF, influence memory formation and consolidation? Is there a common output path for learned performance? A neural model proposes a unified answer to these questions that overcome problems of alternative memory models.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2TLR4L4B\\Franklin, Grossberg - 2017 - A neural model of normal and abnormal learning and memory consolidation adaptively timed conditioning, hipp.pdf},
  isbn = {1-341-50160-4},
  keywords = {amnesia,amygdala,c ognitive-emotional learning,Cognitive-emotional learning,conditioning,Conditioning,hippocampus,Memory c,memory consolidation,pontine nuclei,time cells},
  pmid = {27905080}
}

@article{fransen_hasselmo_2002,
  title = {Simulations of the Role of the Muscarinic-Activated Calcium-Sensitive Nonspecific Cation Current {{INCM}} in Entorhinal Neuronal Activity during Delayed Matching Tasks.},
  author = {Fransen, Erik and a Alonso, Angel and Hasselmo, Michael E},
  year = {2002},
  volume = {22},
  pages = {1081--1097},
  issn = {1529-2401},
  doi = {22/3/1081 [pii]},
  abstract = {Entorhinal lesions impair performance in delayed matching tasks, and blockade of muscarinic cholinergic receptors also impairs performance in these tasks. Physiological data demonstrate that muscarinic cholinergic receptor stimulation activates intrinsic cellular currents in entorhinal neurons that could underlie the role of entorhinal cortex in performance of these tasks. Here we use a network biophysical simulation of the entorhinal cortex to demonstrate the potential role of this cellular mechanism in the behavioral tasks. Simulations demonstrate how the muscarinic-activated calcium-sensitive nonspecific cation current I(NCM) could provide a cellular mechanism for features of the neuronal activity observed during performance of delayed matching tasks. In particular, I(NCM) could underlie (1) the maintenance of sustained spiking activity during the delay period, (2) the enhancement of spiking activity during the matching period relative to the sample period, and (3) the resistance of sustained activity to distractors. Simulation of a larger entorhinal network with connectivity chosen randomly within constraints on number, distribution, and weight demonstrates appearance of other phenomena observed in unit recordings from awake animals, including match suppression, non-match enhancement, and non-match suppression.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PBUL7CYZ\\Fransen, Alonso, Hasselmo - 2002 - Simulations of the role of the muscarinic-activated calcium-sensitive nonspecific cation current INCM.pdf},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  keywords = {biophysical modeling,com-,delayed match to sample,delayed non-match,medial entorhinal cortex,ncm,nonspecific cationic current i,perpolarization,puter simulation,pyramidal cells,stellate cells,working-memory},
  number = {3},
  pmid = {11826137}
}

@article{freedman_ibos_2018,
  title = {Perspective {{An Integrative Framework}} for {{Sensory}}, {{Motor}}, and {{Cognitive Functions}} of the {{Posterior Parietal Cortex}}},
  author = {Freedman, David J and Ibos, Guilhem},
  year = {2018},
  doi = {10.1016/j.neuron.2018.01.044},
  abstract = {Throughout the history of modern neuroscience, the parietal cortex has been associated with a wide array of sensory, motor, and cognitive functions. The use of non-human primates as a model organism has been instrumental in our current understanding of how areas in the posterior parietal cortex (PPC) modulate our perception and influence our behavior. In this Perspective, we highlight a series of influential studies over the last five decades examining the role of the PPC in visual perception and motor planning. We also integrate long-standing views of PPC functions with more recent evidence to propose a more general model framework to explain integrative sensory, motor, and cognitive functions of the PPC. In the last 50 years, a large corpus of studies has focused on understanding the role of the posterior parietal cortex (PPC) in sensory, motor, and cognitive functions using non-human primates (NHPs), especially rhesus monkeys, as a model organism. Rhesus monkeys are a well-suited model for studying human parietal functions because they explore their environment in a manner similar to humans-mostly visually and manually. Anatomically, their cortical organization, including the parietal cortices, show a high degree of homology with ours (Sereno and Tootell, 2005). Moreover, they are capable of learning complex behavioral tasks that allow for the study of the neural correlates of behavioral and cognitive functions using electro-physiological recordings. Since the 1950s, our understanding of PPC functions has vastly evolved as neurophysiological investigations have shown PPC neurons to be involved in an increasingly diverse set of sensory , cognitive, and motor functions. Here, we present a historical perspective of how key theories of parietal functions in the NHP arose, and we consider these theories within a more general framework based on recent work from our group and others. We mostly focus on cortical areas lateral to the intraparietal sulcus (Figure 1), with a specific emphasis on the lateral intrapar-ietal (LIP) area on the lateral bank of the intraparietal sulcus. We describe how modern theories of PPC functions find their roots in past scientific debates that unfolded in a series of related debates. Our goal is to summarize some of these debates as accurately as possible based on our read from the literature. However, for conciseness and clarity, it is not possible to present a detailed description of each of the relevant studies spanning more than 40 years of research. In the first part, we describe the original discoveries that shaped a high-profile and influential debate regarding the role of the PPC in visual attention and motor intention. We link the evolution of these hypotheses to two dominant current theories that describe the LIP area either as a map reflecting the behavioral relevance (priority) of stimuli or as transforming sensory evidence into decisions. Next, we discuss a range of studies examining the influence of non-spatial variables on PPC activity. Based on these findings and some recently published work, we propose a coherent framework in which we distinguish between signals resulting from integrative mechanisms and signals reflecting local computations. This integrative comparative framework incorporates these diverse functions of the PPC, and it accounts for how the PPC integrates , groups, and compares diverse sensory, motor, and cognitive signals and transforms them into decision-related encoding. How Previous Debates Shaped Recent PPC Models Early investigations of the primate PPC (areas located around the intraparietal sulcus) described distinct subregions that appeared to differ in their encoding of sensory and motor factors. At the end of the nineteenth century, David Ferrier gave a series of lectures before the Royal College of Physicians of London about cerebral localization (Ferrier, 1890), in which he described the effects of selective cortical electrical stimulation or cortical abla-tion on the behavior of different mammals (including macaque monkeys). He described, among other things, that stimulation of the lateral (area 7) and medial (area 5) gyrus around the intra-parietal sulcus resulted in movements of the eyes and upper limbs, respectively. Then 65 years later, Fleming and Crosby (1955) proposed that these cortical structures represent motor areas for controlling extremity, trunk, and head (area 5) and eye movements (area 7). In later characterizations of electrophysiological responses of its neurons, area 5 (medial intraparietal [MIP] area) appeared to be involved in monkeys' manual exploration of their peri-personal space (Duffy and Burchfiel, 1971). Similarly, pioneering studies of area 7 (located on the lateral bank and on the gyrus lateral to the intraparietal sulcus) showed that its neurons were Neuron 97, March 21, 2018 \textordfeminine{} 2018 Elsevier Inc. 1219},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\F6RTFAW6\\Freedman, Ibos - 2018 - Perspective An Integrative Framework for Sensory, Motor, and Cognitive Functions of the Posterior Parietal Corte.pdf},
  keywords = {attention,categorization,cognition,cortex,integration,monkey,neurophysiology,parietal,primate,vision}
}

@book{freksa_wender_1998,
  title = {Spatial Cognition: An Interdisciplinary Approach to Representing and Processing Spatial Knowledge},
  shorttitle = {Spatial Cognition},
  editor = {Freksa, C. and Habel, Christopher and Wender, Karl Friedrich},
  year = {1998},
  publisher = {{Springer}},
  address = {{Berlin ; New York}},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RRSHMLIN\\Freksa et al. - 1998 - Spatial cognition an interdisciplinary approach t.pdf},
  isbn = {978-3-540-64603-7},
  language = {en},
  lccn = {Q387 .S7 1998},
  number = {1404},
  series = {Lecture Notes in Computer Science ; {{Lecture}} Notes in Artificial Intelligence}
}

@article{fremaux_gerstner_2016,
  title = {Neuromodulated {{Spike}}-{{Timing}}-{{Dependent Plasticity}}, and {{Theory}} of {{Three}}-{{Factor Learning Rules}}},
  author = {Fr{\'e}maux, Nicolas and Gerstner, Wulfram},
  year = {2016},
  month = jan,
  volume = {9},
  issn = {1662-5110},
  doi = {10.3389/fncir.2015.00085},
  abstract = {Classical Hebbian learning puts the emphasis on joint pre- and postsynaptic activity, but neglects the potential role of neuromodulators. Since neuromodulators convey information about novelty or reward, the influence of neuromodulators on synaptic plasticity is useful not just for action learning in classical conditioning, but also to decide ``when'' to create new memories in response to a flow of sensory stimuli. In this review, we focus on timing requirements for pre- and postsynaptic activity in conjunction with one or several phasic neuromodulatory signals. While the emphasis of the text is on conceptual models and mathematical theories, we also discuss some experimental evidence for neuromodulation of Spike-Timing-Dependent Plasticity. We highlight the importance of synaptic mechanisms in bridging the temporal gap between sensory stimulation and neuromodulatory signals, and develop a framework for a class of neo-Hebbian three-factor learning rules that depend on presynaptic activity, postsynaptic variables as well as the influence of neuromodulators.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9EM5T7SP\\Frémaux_Gerstner_2016_Neuromodulated Spike-Timing-Dependent Plasticity, and Theory of Three-Factor.pdf},
  journal = {Frontiers in Neural Circuits},
  pmcid = {PMC4717313},
  pmid = {26834568}
}

@techreport{frey_barry_2019,
  title = {Deepinsight: A General Framework for Interpreting Wide-Band Neural Activity},
  shorttitle = {Deepinsight},
  author = {Frey, Markus and Tanni, Sander and Perrodin, Catherine and O'Leary, Alice and Nau, Matthias and Kelly, Jack and Banino, Andrea and Doeller, Christian F. and Barry, Caswell},
  year = {2019},
  month = dec,
  institution = {{Neuroscience}},
  doi = {10.1101/871848},
  abstract = {Rapid progress in technologies such as calcium imaging and electrophysiology has seen a dramatic increase in the size and extent of neural recordings, yet their interpretation still depends on time-intensive manual operations. Decoding provides a means to infer the information content of such recordings but typically requires highly processed data and prior knowledge of variables. Here, we developed DeepInsight - a deep-learning-framework able to decode sensory and behavioural variables directly from wide-band neural data. The network requires little user input and generalizes across stimuli, behaviours, brain regions, and recording techniques. Critically, once trained, it can be analysed to determine elements of the neural code that are informative about a given variable. We validated this approach using data from rodent auditory cortex and hippocampus, identifying a novel representation of head direction encoded by CA1 interneurons. Thus, we present a robust, user-friendly tool for characterising and decoding neural recordings in an automated way. Code is available at https://github.com/CYHSM/DeepInsight.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\T9MGYP8Q\\Frey et al. - 2019 - Deepinsight a general framework for interpreting .pdf},
  language = {en},
  type = {Preprint}
}

@article{friedman_friedman_2013,
  title = {The Cognitive Aging of Episodic Memory: A View Based on the Event-Related Brain Potential.},
  author = {Friedman, David},
  year = {2013},
  month = jan,
  volume = {7},
  pages = {111},
  issn = {1662-5153},
  doi = {10.3389/fnbeh.2013.00111},
  abstract = {A cardinal feature of older-adult cognition is a decline, relative to the young, in the encoding and retrieval of personally relevant events, i.e., episodic memory (EM). A consensus holds that familiarity, a relatively automatic feeling of knowing that can support recognition-memory judgments, is preserved with aging. By contrast, recollection, which requires the effortful, strategic recovery of contextual detail, declines as we age. Over the last decade, event-related brain potential (ERPs) have become increasingly important tools in the study of the aging of EM, because a few, well-researched EM effects have been associated with the cognitive processes thought to underlie successful EM performance. EM effects are operationalized by subtracting the ERPs elicited by correctly rejected, new items from those to correctly recognized, old items. Although highly controversial, the mid-frontal effect (a positive component between {$\sim$}300 and 500 ms, maximal at fronto-central scalp sites) is thought to reflect familiarity-based recognition. A positivity between {$\sim$}500 and 800 ms, maximal at left-parietal scalp, has been labeled the left-parietal EM effect. A wealth of evidence suggests that this brain activity reflects recollection-based retrieval. Here, I review the ERP evidence in support of the hypothesis that familiarity is maintained while recollection is compromised in older relative to young adults. I consider the possibility that the inconsistency in findings may be due to individual differences in performance, executive function, and quality of life indices, such as socio-economic status.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VWMK4PY4\\Friedman - 2013 - The cognitive aging of episodic memory a view based on the event-related brain potential.pdf},
  journal = {Frontiers in behavioral neuroscience},
  keywords = {cognitive aging,episodic memory,erps,familiarity,rec,recollection},
  number = {August},
  pmid = {23986668}
}

@article{friese_engel_2016,
  title = {Oscillatory Brain Activity during Multisensory Attention Reflects Activation, Disinhibition, and Cognitive Control.},
  author = {Friese, Uwe and Daume, Jonathan and G{\"o}schl, Florian and K{\"o}nig, Peter and Wang, Peng and Engel, Andreas K},
  year = {2016},
  volume = {6},
  pages = {32775},
  issn = {2045-2322},
  doi = {10.1038/srep32775},
  abstract = {In this study, we used a novel multisensory attention paradigm to investigate attention-modulated cortical oscillations over a wide range of frequencies using magnetencephalography in healthy human participants. By employing a task that required the evaluation of the congruence of audio-visual stimuli, we promoted the formation of widespread cortical networks including early sensory cortices as well as regions associated with cognitive control. We found that attention led to increased high-frequency gamma-band activity and decreased lower frequency theta-, alpha-, and beta-band activity in early sensory cortex areas. Moreover, alpha-band coherence decreased in visual cortex. Frontal cortex was found to exert attentional control through increased low-frequency phase synchronisation. Crossmodal congruence modulated beta-band coherence in mid-cingulate and superior temporal cortex. Together, these results offer an integrative view on the concurrence of oscillations at different frequencies during multisensory attention.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PSJK27BH\\Friese et al. - 2016 - Oscillatory brain activity during multisensory attention reflects activation, disinhibition, and cognitive contro.pdf},
  journal = {Scientific reports},
  number = {July},
  pmid = {27604647}
}

@book{friston_bowman_2018,
  title = {Deep Temporal Models and Active Inference},
  author = {Friston, Karl J. and Rosch, Richard and Parr, Thomas and Price, Cathy and Bowman, Howard},
  year = {2018},
  month = jul,
  volume = {90},
  doi = {10.1016/j.neubiorev.2018.04.004},
  abstract = {How do we navigate a deeply structured world? Why are you reading this sentence first \textendash{} and did you actually look at the fifth word? This review offers some answers by appealing to active inference based on deep temporal models. It builds on previous formulations of active inference to simulate behavioural and electrophysiological responses under hierarchical generative models of state transitions. Inverting these models corresponds to sequential inference, such that the state at any hierarchical level entails a sequence of transitions in the level below. The deep temporal aspect of these models means that evidence is accumulated over nested time scales, enabling inferences about narratives (i.e., temporal scenes). We illustrate this behaviour with Bayesian belief updating \textendash{} and neuronal process theories \textendash{} to simulate the epistemic foraging seen in reading. These simulations reproduce perisaccadic delay period activity and local field potentials seen empirically. Finally, we exploit the deep structure of these models to simulate responses to local (e.g., font type) and global (e.g., semantic) violations; reproducing mismatch negativity and P300 responses respectively.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7ZI77V5E\\Friston et al. - 2018 - Deep temporal models and active inference.pdf},
  keywords = {Bayesian,Free energy,Hierarchical,MMN,P300,Reading,Violation}
}

@article{friston_buzsaki_2016,
  title = {The {{Functional Anatomy}} of {{Time}}: {{What}} and {{When}} in the {{Brain}}},
  shorttitle = {The {{Functional Anatomy}} of {{Time}}},
  author = {Friston, Karl and Buzs{\'a}ki, Gyorgy},
  year = {2016},
  month = jul,
  volume = {20},
  pages = {500--511},
  issn = {13646613},
  doi = {10.1016/j.tics.2016.05.001},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LNPRGBMI\\Friston and Buzsáki - 2016 - The Functional Anatomy of Time What and When in t.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {7}
}

@article{friston_daunizeau_2008,
  title = {{{DEM}}: {{A}} Variational Treatment of Dynamic Systems},
  shorttitle = {{{DEM}}},
  author = {Friston, K.J. and {Trujillo-Barreto}, N. and Daunizeau, J.},
  year = {2008},
  month = jul,
  volume = {41},
  pages = {849--885},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2008.02.054},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RSRRH5QS\\Friston et al. - 2008 - DEM A variational treatment of dynamic systems.pdf},
  journal = {NeuroImage},
  language = {en},
  number = {3}
}

@article{friston_friston_2005,
  title = {A Theory of Cortical Responses},
  author = {Friston, K.},
  year = {2005},
  volume = {360},
  pages = {815--836},
  issn = {0962-8436},
  doi = {10.1098/rstb.2005.1622},
  abstract = {This article concerns the nature of evoked brain responses and the principles underlying their generation. We start with the premise that the sensory brain has evolved to represent or infer the causes of changes in its sensory inputs. The problem of inference is well formulated in statistical terms. The statistical fundaments of inference may therefore afford important constraints on neuronal implementation. By formulating the original ideas of Helmholtz on perception, in terms of modern-day statistical theories, one arrives at a model of perceptual inference and learning that can explain a remarkable range of neurobiological facts.It turns out that the problems of inferring the causes of sensory input (perceptual inference) and learning the relationship between input and cause (perceptual learning) can be resolved using exactly the same principle. Specifically, both inference and learning rest on minimizing the brain's free energy, as defined in statistical physics. Furthermore, inference and learning can proceed in a biologically plausible fashion. Cortical responses can be seen as the brain's attempt to minimize the free energy induced by a stimulus and thereby encode the most likely cause of that stimulus. Similarly, learning emerges from changes in synaptic efficacy that minimize the free energy, averaged over all stimuli encountered. The underlying scheme rests on empirical Bayes and hierarchical models of how sensory input is caused. The use of hierarchical models enables the brain to construct prior expectations in a dynamic and context-sensitive fashion. This scheme provides a principled way to understand many aspects of cortical organization and responses. The aim of this article is to encompass many apparently unrelated anatomical, physiological and psychophysical attributes of the brain within a single theoretical perspective. In terms of cortical architectures, the theoretical treatment predicts that sensory cortex should be arranged hierarchically, that connections should be reciprocal and that forward and backward connections should show a functional asymmetry (forward connections are driving, whereas backward connections are both driving and modulatory). In terms of synaptic physiology, it predicts associative plasticity and, for dynamic models, spike-timing-dependent plasticity. In terms of electrophysiology, it accounts for classical and extra classical receptive field effects and long-latency or endogenous components of evoked cortical responses. It predicts the attenuation of responses encoding prediction error with perceptual learning and explains many phenomena such as repetition suppression, mismatch negativity (MMN) and the P300 in electroencephalography. In psychophysical terms, it accounts for the behavioural correlates of these physiological phenomena, for example, priming and global precedence. The final focus of this article is on perceptual learning as measured with the MMN and the implications for empirical studies of coupling among cortical areas using evoked sensory responses.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EZM27B7J\\Friston - 2005 - A theory of cortical responses.pdf},
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  keywords = {Bayesian,cortical,generative models,hierarchical,inference,predictive coding},
  number = {1456},
  pmid = {15937014}
}

@article{friston_friston_2008,
  title = {Hierarchical Models in the Brain},
  author = {Friston, Karl},
  year = {2008},
  volume = {4},
  issn = {1553734X},
  doi = {10.1371/journal.pcbi.1000211},
  abstract = {This paper describes a general model that subsumes many parametric models for continuous data. The model comprises hidden layers of state-space or dynamic causal models, arranged so that the output of one provides input to another. The ensuing hierarchy furnishes a model for many types of data, of arbitrary complexity. Special cases range from the general linear model for static data to generalised convolution models, with system noise, for nonlinear time-series analysis. Crucially, all of these models can be inverted using exactly the same scheme, namely, dynamic expectation maximization. This means that a single model and optimisation scheme can be used to invert a wide range of models. We present the model and a brief review of its inversion to disclose the relationships among, apparently, diverse generative models of empirical data. We then show that this inversion can be formulated as a simple neural network and may provide a useful metaphor for inference and learning in the brain.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5WUGELHQ\\Friston - 2008 - Hierarchical models in the brain.pdf},
  journal = {PLoS Computational Biology},
  number = {11},
  pmid = {18989391}
}

@article{friston_friston_2013,
  title = {Consciousness and {{Hierarchical Inference}}},
  author = {Friston, Karl},
  year = {2013},
  month = jan,
  volume = {15},
  pages = {38--42},
  issn = {1529-4145, 2044-3978},
  doi = {10.1080/15294145.2013.10773716},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\F8IIG3ED\\Friston - 2013 - Consciousness and Hierarchical Inference.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\KDWRDLKP\\Friston - 2013 - Consciousness and Hierarchical Inference.pdf},
  journal = {Neuropsychoanalysis},
  language = {en},
  number = {1}
}

@article{friston_pezzulo_2015,
  title = {Active Inference and Epistemic Value},
  author = {Friston, Karl and Rigoli, Francesco and Ognibene, Dimitri and Mathys, Christoph and Fitzgerald, Thomas and Pezzulo, Giovanni},
  year = {2015},
  month = oct,
  volume = {6},
  pages = {187--214},
  issn = {1758-8928, 1758-8936},
  doi = {10.1080/17588928.2015.1020053},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\H59Q4DDS\\Friston et al. - 2015 - Active inference and epistemic value.pdf},
  journal = {Cognitive Neuroscience},
  language = {en},
  number = {4}
}

@article{friston_pezzulo_2017,
  title = {Active {{Inference}}: {{A Process Theory}}},
  shorttitle = {Active {{Inference}}},
  author = {Friston, Karl and FitzGerald, Thomas and Rigoli, Francesco and Schwartenbeck, Philipp and Pezzulo, Giovanni},
  year = {2017},
  month = jan,
  volume = {29},
  pages = {1--49},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/NECO_a_00912},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WRDCJN3Y\\Friston et al. - 2017 - Active Inference A Process Theory.pdf},
  journal = {Neural Computation},
  language = {en},
  number = {1}
}

@article{friston_shipp_2015,
  title = {Cerebral Hierarchies: Predictive Processing, Precision and the Pulvinar},
  author = {Friston, Karl and Kanai, Ryota and Komura, Yutaka and Shipp, Stewart},
  year = {2015},
  doi = {10.1098/rstb.2014.0169},
  abstract = {One contribution of 11 to a theme issue 'Cerebral cartography: a vision of its future'. This paper considers neuronal architectures from a computational perspective and asks what aspects of neuroanatomy and neurophysiology can be disclosed by the nature of neuronal computations? In particular, we extend current formulations of the brain as an organ of inference\textemdash based upon hierarchical pre-dictive coding\textemdash and consider how these inferences are orchestrated. In other words, what would the brain require to dynamically coordinate and contextua-lize its message passing to optimize its computational goals? The answer that emerges rests on the delicate (modulatory) gain control of neuronal populations that select and coordinate (prediction error) signals that ascend cortical hierar-chies. This is important because it speaks to a hierarchical anatomy of extrinsic (between region) connections that form two distinct classes, namely a class of driving (first-order) connections that are concerned with encoding the content of neuronal representations and a class of modulatory (second-order) connec-tions that establish context\textemdash in the form of the salience or precision ascribed to content. We explore the implications of this distinction from a formal perspec-tive (using simulations of feature\textendash ground segregation) and consider the neurobiological substrates of the ensuing precision-engineered dynamics, with a special focus on the pulvinar and attention.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\S2LH3QP5\\Friston et al. - Unknown - Cerebral hierarchies predictive processing, precision and the pulvinar.pdf},
  keywords = {attention,neuromodulation,neuronal computational,neuroscience Keywords,precision,predictive coding,pulvinar,Subject Areas,theoretical biology}
}

@article{fu_rutishauser_2018,
  title = {Single-{{Neuron Correlates}} of {{Error Monitoring}} and {{Post}}-{{Error Adjustments}} in {{Human Medial Frontal Cortex}}},
  author = {Fu, Zhongzheng and Wu, Daw-An J and Ross, Ian and Chung, Jeffrey M and Mamelak, Adam N and Adolphs, Ralph and Rutishauser, Ueli},
  year = {2018},
  doi = {10.1016/j.neuron.2018.11.016},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ACX7V8NV\\Fu et al. - 2018 - Single-Neuron Correlates of Error Monitoring and Post-Error Adjustments in Human Medial Frontal Cortex.pdf},
  keywords = {anterior cingulate,cognitive control,error monitoring,executive function,human intracranial,human single-neuron,medial frontal cortex,post-error slowing,pre-supplementary motor area}
}

@article{fuhrmann_remy_2015,
  title = {Locomotion, {{Theta Oscillations}}, and the {{Speed}}-{{Correlated Firing}} of {{Hippocampal Neurons Are Controlled}} by a {{Medial Septal Glutamatergic Circuit}}},
  author = {Fuhrmann, Falko and Justus, Daniel and Sosulina, Liudmila and Kaneko, Hiroshi and Beutel, Tatjana and Friedrichs, Detlef and Schoch, Susanne and Schwarz, MartinKarl and Fuhrmann, Martin and Remy, Stefan},
  year = {2015},
  volume = {86},
  pages = {1253--1264},
  issn = {10974199},
  doi = {10.1016/j.neuron.2015.05.001},
  abstract = {Before the onset of locomotion, the hippocampus undergoes a transition into an activity-state specialized for the processing of spatially related input. This brain-state transition is associated with increased firing rates of CA1 pyramidal neurons and the occurrence of theta oscillations, which both correlate with locomotion velocity. However, the neural circuit by which locomotor activity is linked to hippocampal oscillations and neuronal firing rates is unresolved. Here we reveal a septo-hippocampal circuit mediated by glutamatergic (VGluT2\{\textbackslash textless\}sup\{\textbackslash textgreater\}+\{\textbackslash textless\}/sup\{\textbackslash textgreater\}) neurons that is activated before locomotion onset and that controls the initiation and velocity of locomotion as well as theentrainment of theta oscillations. Moreover, via septo-hippocampal projections onto alveus/oriens interneurons, this circuit regulates feedforward inhibition of Schaffer collateral and perforant path input to CA1 pyramidal neurons in a locomotion-dependent manner. With higher locomotion speed, the increased activity of medial septal VGluT2 neurons is translated into increased axo-somatic depolarization and higher firing rates of CA1 pyramidal neurons.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L2GT54AZ\\Fuhrmann et al. - 2015 - Locomotion, Theta Oscillations, and the Speed-Correlated Firing of Hippocampal Neurons Are Controlled by a Medi.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\SSVX4HTR\\Fuhrmann et al. - 2015 - Locomotion, Theta Oscillations, and the Speed-Correlated Firing of Hippocampal Neurons Are Controlled by a M(2).pdf},
  journal = {Neuron},
  number = {5},
  pmid = {25982367}
}

@article{fuster_fuster_2006,
  title = {The Cognit: {{A}} Network Model of Cortical Representation},
  shorttitle = {The Cognit},
  author = {Fuster, Joaqu{\'i}n M.},
  year = {2006},
  month = may,
  volume = {60},
  pages = {125--132},
  issn = {01678760},
  doi = {10.1016/j.ijpsycho.2005.12.015},
  abstract = {The prevalent concept in modular models is that there are discrete cortical domains dedicated more or less exclusively to such cognitive functions as visual discrimination, language, spatial attention, face recognition, motor programming, memory retrieval, and working memory. Most of these models have failed or languished for lack of conclusive evidence. In their stead, network models are emerging as more suitable and productive alternatives. Network models are predicated on the basic tenet that cognitive representations consist of widely distributed networks of cortical neurons. Cognitive functions, namely perception, attention, memory, language, and intelligence, consist of neural transactions within and between these networks. The present model postulates that memory and knowledge are represented by distributed, interactive, and overlapping networks of neurons in association cortex. Such networks, named cognits, constitute the basic units of memory or knowledge. The association cortex of posterior-post-rolandic-regions contains perceptual cognits: cognitive networks made of neurons associated by information acquired through the senses. Conversely, frontal association cortex contains executive cognits, made of neurons associated by information related to action. In both posterior and frontal cortex, cognits are hierarchically organized. At the bottom of that organization\textemdash that is, in parasensory and premotor cortex\textemdash cognits are small and relatively simple, representing simple percepts or motor acts. At the top of the organization\textemdash in temporo\textendash parietal and prefrontal cortex\textemdash cognits are wider and represent complex and abstract information of perceptual or executive character. Posterior and frontal networks are associated by long reciprocal cortico\textendash cortical connections. These connections support the dynamics of the perception\textendash action cycle in sequential behavior, speech, and reasoning.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8FZVVVWG\\Fuster - 2006 - The cognit A network model of cortical representa.pdf},
  journal = {International Journal of Psychophysiology},
  language = {en},
  number = {2}
}

@book{fuster_fuster_2009,
  title = {The Prefrontal Cortex},
  author = {Fuster, Joaqu{\'i}n M.},
  year = {2009},
  edition = {4. ed., reprint},
  publisher = {{Elsevier, Acad. Press}},
  address = {{Amsterdam}},
  annotation = {OCLC: 549145889},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YAZ26KNS\\Fuster - 2009 - The prefrontal cortex.pdf},
  isbn = {978-0-12-373644-4},
  language = {en}
}

@article{fuster_fuster_2017,
  title = {Prefrontal {{Executive Functions Predict}} and {{Preadapt}}},
  author = {Fuster, Joaqu{\'i}n M.},
  year = {2017},
  pages = {3--19},
  doi = {10.1016/B978-0-12-803676-1.00001-5},
  abstract = {The prefrontal cortex plays a critical role in the temporal organization of behavior and language within the broad neurobiological framework of the perception-action (PA) cycle, the circular processing of information that regulates the adaptation of the organism to its environment. That temporal organizing role of the prefrontal cortex is supported by three major executive functions that constitute the essential dynamic components of the cognitive control of behavior and language: (1) executive attention, (2) working memory, and (3) decision-making. The three functions are teleonomic in that they have a critical future perspective toward goal or reward. In this chapter, after discussion of the PA cycle and of the physiological role of the prefrontal cortex in it, executive attention, working memory, and decision-making are empirically placed in both cycle and cortex with the available experimental evidence.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VA3XLJLE\\Fuster - 2017 - Prefrontal Executive Functions Predict and Preadapt.pdf},
  journal = {Executive Functions in Health and Disease},
  keywords = {Attention,Cognitive control,Decision-making,Perception-action cycle,Prefrontal cortex,Prospective executive function,working-memory}
}

@article{fyall_pasupathy_2017,
  title = {Dynamic Representation of Partially Occluded Objects in Primate Prefrontal and Visual Cortex},
  author = {Fyall, Amber M and {El-Shamayleh}, Yasmine and Choi, Hannah and {Shea-Brown}, Eric and Pasupathy, Anitha},
  year = {2017},
  month = sep,
  volume = {6},
  pages = {e25784},
  issn = {2050-084X},
  doi = {10.7554/eLife.25784},
  abstract = {Successful recognition of partially occluded objects is presumed to involve dynamic interactions between brain areas responsible for vision and cognition, but neurophysiological evidence for the involvement of feedback signals is lacking. Here, we demonstrate that neurons in the ventrolateral prefrontal cortex (vlPFC) of monkeys performing a shape discrimination task respond more strongly to occluded than unoccluded stimuli. In contrast, neurons in visual area V4 respond more strongly to unoccluded stimuli. Analyses of V4 response dynamics reveal that many neurons exhibit two transient response peaks, the second of which emerges after vlPFC response onset and displays stronger selectivity for occluded shapes. We replicate these findings using a model of V4/vlPFC interactions in which occlusion-sensitive vlPFC neurons feed back to shape-selective V4 neurons, thereby enhancing V4 responses and selectivity to occluded shapes. These results reveal how signals from frontal and visual cortex could interact to facilitate object recognition under occlusion.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\J3QPAGFS\\Fyall et al. - 2017 - Dynamic representation of partially occluded objec.pdf},
  journal = {eLife},
  language = {en}
}

@article{gallego_miller_2020,
  title = {Long-Term Stability of Cortical Population Dynamics Underlying Consistent Behavior},
  author = {Gallego, Juan A. and Perich, Matthew G. and Chowdhury, Raeed H. and Solla, Sara A. and Miller, Lee E.},
  year = {2020},
  month = jan,
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-019-0555-4},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\J5ZBIYB3\\Gallego et al. - 2020 - Long-term stability of cortical population dynamic.pdf},
  journal = {Nature Neuroscience},
  language = {en}
}

@article{gallego_solla_2017,
  title = {Perspective {{Neural Manifolds}} for the {{Control}} of {{Movement}}},
  author = {Gallego, Juan A and Perich, Matthew G and Miller, Lee E and Solla, Sara A},
  year = {2017},
  volume = {94},
  pages = {978--984},
  doi = {10.1016/j.neuron.2017.05.025},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\D22DD6ZJ\\Gallego et al. - 2017 - Perspective Neural Manifolds for the Control of Movement.pdf},
  journal = {Neuron}
}

@book{gallier_gallier_2019,
  title = {Algebra, {{Topology}}, {{Differential Calculus}}, and {{Optimization Theory}} for {{Computer Science}} and {{Machine Learning}}},
  author = {Gallier, Jean},
  year = {2019},
  month = jul,
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GMSD3ZSV\\math-basics.pdf.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\VZ9HXMYR\\view.html}
}

@article{gallinaro_gallinaro_,
  title = {Neuronal Assembly Formation and Non-Random Recurrent Connectivity Induced by Homeostatic Structural Plasticity},
  author = {Gallinaro, J{\'u}lia Vianna},
  pages = {119},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TELL7BSY\\Gallinaro - Neuronal assembly formation and non-random recurre.pdf},
  language = {en}
}

@article{ganguli_sompolinsky_2008,
  title = {Memory Traces in Dynamical Systems},
  author = {Ganguli, S. and Huh, D. and Sompolinsky, H.},
  year = {2008},
  month = dec,
  volume = {105},
  pages = {18970--18975},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.0804451105},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AYJLQD98\\Ganguli et al. - 2008 - Memory traces in dynamical systems.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {48}
}

@techreport{gao_cunningham_2016,
  title = {Linear Dynamical Neural Population Models through Nonlinear Embeddings},
  author = {Gao, Yuanjun and Archer, Evan and Paninski, Liam and Cunningham, John P},
  year = {2016},
  abstract = {A body of recent work in modeling neural activity focuses on recovering low-dimensional latent features that capture the statistical structure of large-scale neural populations. Most such approaches have focused on linear generative models, where inference is computationally tractable. Here, we propose fLDS, a general class of nonlinear generative models that permits the firing rate of each neuron to vary as an arbitrary smooth function of a latent, linear dynamical state. This extra flexibility allows the model to capture a richer set of neural variability than a purely linear model, but retains an easily visualizable low-dimensional latent space. To fit this class of non-conjugate models we propose a variational inference scheme, along with a novel approximate posterior capable of capturing rich temporal correlations across time. We show that our techniques permit inference in a wide class of generative models.We also show in application to two neural datasets that, compared to state-of-the-art neural population models, fLDS captures a much larger proportion of neural variability with a small number of latent dimensions, providing superior predictive performance and interpretability.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\B9H7UHT4\\Gao et al. - Unknown - Linear dynamical neural population models through nonlinear embeddings.pdf}
}

@article{gardner_gershman_2018,
  title = {Rethinking Dopamine as Generalized Prediction Error},
  author = {Gardner, Matthew P H and Schoenbaum, Geoffrey and Gershman, Samuel Joseph},
  year = {2018},
  month = nov,
  volume = {285},
  pages = {20181645},
  issn = {0962-8452},
  doi = {10.1098/rspb.2018.1645},
  abstract = {Midbrain dopamine neurons are commonly thought to report a reward prediction error, as hypothesized by reinforcement learning theory. While this theory has been highly successful, several lines of evidence suggest that dopamine activity also encodes sensory prediction errors unrelated to reward. Here we develop a new theory of dopamine function that embraces a broader conceptualization of prediction errors. By signaling errors in both sensory and reward predictions, dopamine supports a form of reinforcement learning that lies between model-based and model-free algorithms. We show that the theory can account for the role of dopamine in phenomena such as sensory preconditioning and identity unblocking, which ostensibly draw upon knowledge beyond reward predictions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\A8LCVNTK\\Gershman, Gardner, Schoenbaum - Unknown - Rethinking dopamine as generalized prediction error(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\BZJ6QA7U\\Gershman, Gardner, Schoenbaum - Unknown - Rethinking dopamine as generalized prediction error.pdf},
  journal = {Proceedings of the Royal Society B: Biological Sciences},
  keywords = {computational biology Keywords: reinforcement learning,Subject Category: Neuroscience and cognition Subject Areas: neuroscience,successor representation,temporal difference learning},
  number = {1891},
  pmid = {30464063}
}

@article{garnelo_shanahan_2019,
  title = {Reconciling Deep Learning with Symbolic Artificial Intelligence: Representing Objects and Relations},
  author = {Garnelo, Marta and Shanahan, Murray},
  year = {2019},
  volume = {29},
  pages = {17--23},
  issn = {2352-1546},
  doi = {10.1016/j.cobeha.2018.12.010},
  abstract = {In the history of the quest for human-level artificial intelligence, a number of rival paradigms have vied for supremacy. Symbolic artificial intelligence was dominant for much of the 20th century, but currently a connectionist paradigm is in the ascendant, namely machine learning with deep neural networks. However, both paradigms have strengths and weaknesses, and a significant challenge for the field today is to effect a reconciliation. A central tenet of the symbolic paradigm is that intelligence results from the manipulation of abstract compositional representations whose elements stand for objects and relations. If this is correct, then a key objective for deep learning is to develop architectures capable of discovering objects and relations in raw data, and learning how to represent them in ways that are useful for downstream processing. This short review highlights recent progress in this direction. Addresses},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9EPSM7YS\\Garnelo and Shanahan - 2019 - Reconciling deep learning with symbolic artificial.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\EQNC74LR\\Garnelo, Shanahan - 2019 - Reconciling deep learning with symbolic artificial intelligence representing objects and relations.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\KQIRESI6\\Garnelo and Shanahan - 2019 - Reconciling deep learning with symbolic artificial.pdf},
  journal = {COBEHA}
}

@article{gasser_colunga_2000,
  title = {Babies, {{Variables}}, and {{Relational Correlations}}},
  author = {Gasser, Michael and Colunga, Eliana},
  year = {2000},
  pages = {7},
  abstract = {Recent studies have shown that infants have access to highly useful language acquisition skills. On the one hand, they can segment a stream of unmarked syllables into words, based only on the statistical regularities present in it. On the other, they can abstract beyond these input-specific regularities and generalize to rules. It has been argued that these are two separate learning mechanisms, that the former is simply associationist whereas the latter requires variables. In this paper we present a correlational approach to the learning of sequential regularities, and its implementation in a connectionist model, which accommodates both types of learning. We show that when a network is made out of the right stuff, specifically, when it has the ability to represent sameness and the ability to represent relations, a simple correlational learning mechanism suffices to perform both of these tasks. Crucially the model makes different predictions than the variable-based account.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6ANA8VYQ\\Gasser and Colunga - Babies, Variables, and Relational Correlations.pdf},
  language = {en}
}

@article{gatto_jammalamadaka_2007,
  title = {The Generalized von {{Mises}} Distribution},
  author = {Gatto, Riccardo and Jammalamadaka, Sreenivasa Rao},
  year = {2007},
  month = jul,
  volume = {4},
  pages = {341--353},
  issn = {15723127},
  doi = {10.1016/j.stamet.2006.11.003},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GN9B426H\\Gatto, Jammalamadaka - 2007 - The generalized von Mises distribution(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\QGMJ3C2Y\\Gatto, Jammalamadaka - 2007 - The generalized von Mises distribution.pdf},
  journal = {Statistical Methodology},
  keywords = {circular distribution,discusses a wide class,distribution,distributions with,entropy,exponential family,fourier expansion,hood,introduction and significance of,maksimov,maximum likeli-,maximum likelihood,normal,normal distribution,of absolutely continuous circular,offset distribution,symmetry and asymmetry,the model,trigonometric moment,unimodality,unimodality and multimodality},
  number = {3}
}

@article{gazzaley_nobre_2012,
  title = {Top-down Modulation: Bridging Selective Attention and Working Memory},
  shorttitle = {Top-down Modulation},
  author = {Gazzaley, Adam and Nobre, Anna C.},
  year = {2012},
  month = feb,
  volume = {16},
  pages = {129--135},
  issn = {13646613},
  doi = {10.1016/j.tics.2011.11.014},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ENH5IED2\\Gazzaley and Nobre - 2012 - Top-down modulation bridging selective attention .pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {2}
}

@article{gelastopoulos_kopell_2019,
  title = {Parietal Low Beta Rhythm Provides a Dynamical Substrate for a Working Memory Buffer},
  author = {Gelastopoulos, Alexandros and Whittington, Miles A. and Kopell, Nancy J.},
  year = {2019},
  month = aug,
  pages = {201902305},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1902305116},
  abstract = {Working memory (WM) is a component of the brain's memory systems vital for interpretation of sequential sensory inputs and consequent decision making. Anatomically, WM is highly distributed over the prefrontal cortex (PFC) and the parietal cortex (PC). Here we present a biophysically detailed dynamical systems model for a WM buffer situated in the PC, making use of dynamical properties believed to be unique to this area. We show that the natural beta1 rhythm (12 to 20 Hz) of the PC provides a substrate for an episodic buffer that can synergistically combine executive commands (e.g., from PFC) and multimodal information into a flexible and updatable representation of recent sensory inputs. This representation is sensitive to distractors, it allows for a readout mechanism, and it can be readily terminated by executive input. The model provides a demonstration of how information can be usefully stored in the temporal patterns of activity in a neuronal network rather than just synaptic weights between the neurons in that network.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\N224S9TH\\Gelastopoulos et al. - 2019 - Parietal low beta rhythm provides a dynamical subs.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\PF8W9BIG\\pnas.1902305116.sapp.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\TVJWNXR7\\Gelastopoulos et al. - 2019 - Parietal low beta rhythm provides a dynamical subs.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en}
}

@article{gentner_gentner_1983,
  title = {Structure-Mapping: {{A}} Theoretical Framework for Analogy},
  author = {Gentner, Dedre},
  year = {1983},
  volume = {7},
  pages = {155--170},
  issn = {03640213},
  doi = {10.1016/S0364-0213(83)80009-3},
  abstract = {A theory of analogy must describe how the meaning of an analogy is derived from the meanings of its parts. In the structure-mapping theory, the interpretation rules are characterized as implicit rules for mapping knowledge about a base domain into a target domain. Two important features of the theory are (a) the rules depend only on syntactic properties of the knowledge representation, and not on the specific content of the domains; and (b) the theoretical framework allows analogies to be distinguished cleanly from literal similarity statements, applications of abstractions, and other kinds of comparisons. Two mapping principles are described: (a) Relations between objects, rather than attributes of objects, are mapped from base to target; and (b) The particular relations mapped are determined by systematicity, as defined by the existence of higher-order relations. ?? 1983.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5JEH9VUN\\Gentner - 1983 - Structure-mapping A theoretical framework for analogy.pdf},
  journal = {Cognitive Science},
  number = {2},
  pmid = {11547370}
}

@article{gentner_jeziorski_1993,
  title = {The Shift from Metaphor to Analogy in {{Western}} Science},
  author = {Gentner, Dedre and Jeziorski, Michael},
  year = {1993},
  pages = {447--480},
  doi = {10.1017/CBO9781139173865.022},
  abstract = {(from the chapter) (question the idea) that a faculty for analogical reasoning is an innate part of human cognition, and that the concept of a sound, inferentially useful analogy is universal; analyze the way in which analogy and metaphor have been used at different points in the history of Western scientific thought, tracing their use backward from the present time; begin by laying out the current framework for analogical reasoning, followed by two examples that conform to the modern aesthetic, those of Sadi Carnot (1796-1832) and Robert Boyle (1627-1691); consider a very different way of using analogy and metaphor in science, that practiced by the alchemists (about 300 B.C.-1600 A.D.); focus is on the evolution in Western science from the alchemists' pluralistic use of all sorts of metaphorical similarities to the more austere modern focus on structural analogy; begin by laying out what we take to be the current cognitive aesthetics for analogical reasoning.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L2VQ5WL6\\Gentner, Jeziorski - 1993 - The shift from metaphor to analogy in Western science.pdf},
  journal = {Metaphor and Thought}
}

@incollection{gentner_smith_2012,
  title = {Analogical {{Reasoning}}},
  booktitle = {Encyclopedia of {{Human Behavior}}},
  author = {Gentner, Dedre and Smith, L},
  year = {2012},
  pages = {130--136},
  doi = {10.1016/B978-0-12-375000-6.00022-7},
  abstract = {Analogical reasoning \textendash{} the ability to perceive and use relational similarity between two situations or events \textendash{} is a fundamental aspect of human cognition. Indeed, some researchers suggest that it is the crucial cognitive mechanism that most distinguishes human cognition from that of other intelligent species. It is a core process in scientific discovery and problem-solving, as well as in categorization and decision-making. Reasoning by analogy involves identifying a common relational system between two situations and generating further inferences driven by these commonalities. The commonalities may also include concrete property matches between the situations, but this is not necessary for analogy; what is necessary is overlap in relational structure. Although this may sound like a highly complex process, people routinely use analogy in everyday life. For example, people readily apply proverbs to situations based on purely relational matches.When you hear `That's locking the barn door after the horse has gone,' you don't look for a barn; rather, you apply the relational pattern \textendash{} a precaution taken after the damage is done \textendash{} to some current situation. This kind of relational mapping is the essence of analogy.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BLVBFZSH\\Gentner, Smith - 2012 - Analogical Reasoning.pdf},
  isbn = {978-0-08-096180-4},
  keywords = {analogy,Inference,Mapping,Metaphor,Reasoning,Relational similarity,Relational structure,Structural alignment,Structure-mapping}
}

@article{george_hawkins_2009,
  title = {Towards a Mathematical Theory of Cortical Micro-Circuits},
  author = {George, Dileep and Hawkins, Jeff},
  year = {2009},
  volume = {5},
  pages = {1000532},
  issn = {1553734X},
  doi = {10.1371/journal.pcbi.1000532},
  abstract = {The theoretical setting of hierarchical Bayesian inference is gaining acceptance as a framework for understanding cortical computation. In this paper, we describe how Bayesian belief propagation in a spatio-temporal hierarchical model, called Hierarchical Temporal Memory (HTM), can lead to a mathematical model for cortical circuits. An HTM node is abstracted using a coincidence detector and a mixture of Markov chains. Bayesian belief propagation equations for such an HTM node define a set of functional constraints for a neuronal implementation. Anatomical data provide a contrasting set of organizational constraints. The combination of these two constraints suggests a theoretically derived interpretation for many anatomical and physiological features and predicts several others. We describe the pattern recognition capabilities of HTM networks and demonstrate the application of the derived circuits for modeling the subjective contour effect. We also discuss how the theory and the circuit can be extended to explain cortical features that are not explained by the current model and describe testable predictions that can be derived from the model.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7PM4TGA6\\George, Hawkins - 2009 - Towards a mathematical theory of cortical micro-circuits.pdf},
  journal = {PLoS Computational Biology},
  number = {10},
  pmid = {19816557}
}

@article{george_koob_2011,
  title = {Craving, Context and the Cortex},
  author = {George, Olivier and Koob, George F},
  year = {2011},
  month = apr,
  volume = {14},
  pages = {409--410},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn.2787},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QNEYYTGV\\George and Koob - 2011 - Craving, context and the cortex.pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {4}
}

@article{george_koob_2013,
  title = {Control of Craving by the Prefrontal Cortex},
  author = {George, Olivier and Koob, George F.},
  year = {2013},
  month = mar,
  volume = {110},
  pages = {4165--4166},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1301245110},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YIYR9WNB\\George and Koob - 2013 - Control of craving by the prefrontal cortex.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {11}
}

@article{gerhard_eden_2013,
  title = {Successful Reconstruction of a Physiological Circuit with Known Connectivity from Spiking Activity Alone.},
  author = {Gerhard, Felipe and Kispersky, Tilman and Gutierrez, Gabrielle J and Marder, Eve and Kramer, Mark and Eden, Uri T},
  year = {2013},
  month = jan,
  volume = {9},
  pages = {e1003138},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1003138},
  abstract = {Identifying the structure and dynamics of synaptic interactions between neurons is the first step to understanding neural network dynamics. The presence of synaptic connections is traditionally inferred through the use of targeted stimulation and paired recordings or by post-hoc histology. More recently, causal network inference algorithms have been proposed to deduce connectivity directly from electrophysiological signals, such as extracellularly recorded spiking activity. Usually, these algorithms have not been validated on a neurophysiological data set for which the actual circuitry is known. Recent work has shown that traditional network inference algorithms based on linear models typically fail to identify the correct coupling of a small central pattern generating circuit in the stomatogastric ganglion of the crab Cancer borealis. In this work, we show that point process models of observed spike trains can guide inference of relative connectivity estimates that match the known physiological connectivity of the central pattern generator up to a choice of threshold. We elucidate the necessary steps to derive faithful connectivity estimates from a model that incorporates the spike train nature of the data. We then apply the model to measure changes in the effective connectivity pattern in response to two pharmacological interventions, which affect both intrinsic neural dynamics and synaptic transmission. Our results provide the first successful application of a network inference algorithm to a circuit for which the actual physiological synapses between neurons are known. The point process methodology presented here generalizes well to larger networks and can describe the statistics of neural populations. In general we show that advanced statistical models allow for the characterization of effective network structure, deciphering underlying network dynamics and estimating information-processing capabilities.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PW8DF7KZ\\Gerhard et al. - 2013 - Successful Reconstruction of a Physiological Circuit with Known Connectivity from Spiking Activity Alone.pdf},
  journal = {PLoS computational biology},
  keywords = {Biological,Biophysics,Models,Neurons,Neurons: physiology},
  number = {7},
  pmid = {23874181}
}

@techreport{gerlei_nolan_2019,
  title = {Grid Cells Implement a Location-Dependent Directional Code},
  author = {Gerlei, Klara and Passlack, Jessica and Stevens, Holly and Papastathopoulos, Ioannis and Nolan, Matthew F.},
  year = {2019},
  month = jun,
  institution = {{Neuroscience}},
  doi = {10.1101/681312},
  abstract = {Grid and head direction codes in the medial entorhinal cortex represent cognitive spaces for navigation and memory             1,2             . In grid cells the expression of the grid code is thought to be independent of head direction, whereas in conjunctive cells the grid code is tuned to a single head direction             3             . This distinction between non-directional grid cells and unidirectional conjunctive cells is also present in models and proposed functions for grid codes             4\textendash 11             . However, while grid cells are not tuned to a single direction, whether their firing is independent of direction is less clear. Here we demonstrate location-dependent modulation of grid cell firing by head direction. Individual firing fields recorded from mouse and rat grid cells have multiple and different preferred directions. This local directionality of grid firing is accounted for by models in which grid cells integrate inputs from conjunctive cells with co-aligned, spatially non-uniform firing fields. Thus, the firing of grid cells is consistent with their integration of upstream grid codes. For downstream neurons in the dentate gyrus that receive input from grid cells, integration of rich directional information within the grid code may contribute to pattern separation computations by decorrelating different points of view from the same spatial location             12\textendash 14             .},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9PR5BVB2\\Gerlei et al. - 2019 - Grid cells implement a location-dependent directio.pdf},
  language = {en},
  type = {Preprint}
}

@techreport{gershman_beck_2017,
  title = {Complex {{Probabilistic Inference}}: {{From Cognition}} to {{Neural Computation}}},
  author = {Gershman, Samuel J and Beck, Jeffrey M},
  year = {2017},
  abstract = {Our understanding of probabilistic inference in the brain has progressed rapidly. However, there remains a big gap between the relatively simple probabilistic inference problems facing low-level sensory systems and the intractably complex problems facing high-level cognitive systems. Psychologists have begun exploring cognitively plausible algorithms for approximately solving complex inference problems. We review recent attempts to connect these algorithmic accounts to neural circuit mechanisms, and argue that neural mechanisms for solving low-level sensory inference problems can be extended to tackle complex inference problems.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QYHA4DRU\\Gershman, Beck - 2017 - Complex Probabilistic Inference From Cognition to Neural Computation.pdf},
  keywords = {Bayesian inference,cognitive science Word count: 6548,computational neuroscience}
}

@article{gershman_gershman_2018,
  title = {Uncertainty and {{Exploration}}},
  author = {Gershman, Samuel J},
  year = {2018},
  doi = {10.1101/265504},
  abstract = {In order to discover the most rewarding actions, agents must collect information about their environment, potentially foregoing reward. The optimal solution to this " explore-exploit " dilemma is computationally intractable, but principled algorithmic approximations exist. These approximations utilize uncertainty about action values in different ways. Some random exploration algorithms scale the level of choice stochasticity with the level of un-certainty. Other directed exploration algorithms add a " bonus " to action values with high uncertainty. Random exploration algorithms are sensitive to total uncertainty across ac-tions, whereas directed exploration algorithms are sensitive to relative uncertainty. This paper reports a multi-armed bandit experiment in which total and relative uncertainty were orthogonally manipulated. We found that humans employ both exploration strategies, and that these strategies are independently controlled by different uncertainty computations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\C8S3WJ2N\\Gershman - 2018 - Uncertainty and Exploration.pdf},
  keywords = {Bayesian inference,explore-exploit dilemma,reinforcement learning}
}

@article{gershman_gershman_2018a,
  title = {The Successor Representation: Its Computational Logic and Neural Substrates},
  author = {Gershman, Samuel J.},
  year = {2018},
  pages = {0151--18},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.0151-18.2018},
  abstract = {Reinforcement learning is the process by which an agent learns to predict long-term future reward. We now understand a great deal about the brain's reinforcement learning algorithms, but we know considerably less about the representations of states and actions over which these algorithms operate. A useful starting point is asking what kinds of representations we would want the brain to have, given the constraints on its computational architecture. Following this logic leads to the idea of the successor representation, which encodes states of the environment in terms of their predictive relationships with other states. Recent behavioral and neural studies have provided evidence for the successor representation, and computational studies have explored ways to extend the original idea. This paper reviews progress on these fronts, organizing them within a broader framework for understanding how the brain negotiates trade-offs between efficiency and flexibility for reinforcement learning. 2},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KJNG2KAP\\Gershman - 2018 - The Successor Representation Its Computational Lo.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\PMVSPSNQ\\Gershman - 2018 - The Successor Representation Its Computational Lo.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\PRMM4Z3L\\Samuel, Gershman - 2018 - The Successor Representation Its Computational Logic and Neural Substrates.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\7ZJYT84Y\\7193.html},
  journal = {The Journal of Neuroscience},
  keywords = {cognitive map,dopamine,hippocampus,reinforcement learning,reward},
  pmid = {30006364}
}

@article{gershman_jakel_2016,
  title = {Discovering Hierarchical Motion Structure},
  author = {Gershman, Samuel J. and Tenenbaum, Joshua B. and J{\"a}kel, Frank},
  year = {2016},
  month = sep,
  volume = {126},
  pages = {232--241},
  issn = {00426989},
  doi = {10.1016/j.visres.2015.03.004},
  abstract = {Scenes filled with moving objects are often hierarchically organized: the motion of a migrating goose is nested within the flight pattern of its flock, the motion of a car is nested within the traffic pattern of other cars on the road, the motion of body parts are nested in the motion of the body. Humans perceive hierarchical structure even in stimuli with two or three moving dots. An influential theory of hierarchical motion perception holds that the visual system performs a ``vector analysis'' of moving objects, decomposing them into common and relative motions. However, this theory does not specify how to resolve ambiguity when a scene admits more than one vector analysis. We describe a Bayesian theory of vector analysis and show that it can account for classic results from dot motion experiments, as well as new experimental data. Our theory takes a step towards understanding how moving scenes are parsed into objects.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8BEDB6BJ\\Gershman et al. - 2016 - Discovering hierarchical motion structure.pdf},
  journal = {Vision Research},
  language = {en}
}

@article{gerstner_brea_2018,
  title = {Eligibility {{Traces}} and {{Plasticity}} on {{Behavioral Time Scales}}: {{Experimental Support}} of {{NeoHebbian Three}}-{{Factor Learning Rules}}},
  shorttitle = {Eligibility {{Traces}} and {{Plasticity}} on {{Behavioral Time Scales}}},
  author = {Gerstner, Wulfram and Lehmann, Marco and Liakoni, Vasiliki and Corneil, Dane and Brea, Johanni},
  year = {2018},
  month = jul,
  volume = {12},
  pages = {53},
  issn = {1662-5110},
  doi = {10.3389/fncir.2018.00053},
  abstract = {Most elementary behaviors such as moving the arm to grasp an object or walking into the next room to explore a museum evolve on the time scale of seconds; in contrast, neuronal action potentials occur on the time scale of a few milliseconds. Learning rules of the brain must therefore bridge the gap between these two different time scales. Modern theories of synaptic plasticity have postulated that the co-activation of pre- and postsynaptic neurons sets a flag at the synapse, called an eligibility trace, that leads to a weight change only if an additional factor is present while the flag is set. This third factor, signaling reward, punishment, surprise, or novelty, could be implemented by the phasic activity of neuromodulators or specific neuronal inputs signaling special events. While the theoretical framework has been developed over the last decades, experimental evidence in support of eligibility traces on the time scale of seconds has been collected only during the last few years. Here we review, in the context of three-factor rules of synaptic plasticity, four key experiments that support the role of synaptic eligibility traces in combination with a third factor as a biological implementation of neoHebbian three-factor learning rules.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NVP2J7HI\\Gerstner et al. - 2018 - Eligibility Traces and Plasticity on Behavioral Ti.pdf},
  journal = {Frontiers in Neural Circuits},
  language = {en}
}

@book{gerstner_paninski_2014,
  title = {Neuronal {{Dynamics}}: {{From Single Neurons}} to {{Networks}} and {{Models}} of {{Cognition}}},
  shorttitle = {Neuronal {{Dynamics}}},
  author = {Gerstner, Wulfram and Kistler, Werner M. and Naud, Richard and Paninski, Liam},
  year = {2014},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  doi = {10.1017/CBO9781107447615},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\K5AP7UUS\\Gerstner et al. - 2014 - Neuronal Dynamics From Single Neurons to Networks.pdf},
  isbn = {978-1-107-44761-5},
  language = {en}
}

@article{gerwinn_bethge_2009,
  title = {Bayesian Population Decoding of Spiking Neurons.},
  author = {Gerwinn, Sebastian and Macke, Jakob and Bethge, Matthias},
  year = {2009},
  month = jan,
  volume = {3},
  pages = {21},
  issn = {1662-5188},
  doi = {10.3389/neuro.10.021.2009},
  abstract = {The timing of action potentials in spiking neurons depends on the temporal dynamics of their inputs and contains information about temporal fluctuations in the stimulus. Leaky integrate-and-fire neurons constitute a popular class of encoding models, in which spike times depend directly on the temporal structure of the inputs. However, optimal decoding rules for these models have only been studied explicitly in the noiseless case. Here, we study decoding rules for probabilistic inference of a continuous stimulus from the spike times of a population of leaky integrate-and-fire neurons with threshold noise. We derive three algorithms for approximating the posterior distribution over stimuli as a function of the observed spike trains. In addition to a reconstruction of the stimulus we thus obtain an estimate of the uncertainty as well. Furthermore, we derive a 'spike-by-spike' online decoding scheme that recursively updates the posterior with the arrival of each new spike. We use these decoding rules to reconstruct time-varying stimuli represented by a Gaussian process from spike trains of single neurons as well as neural populations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HZ434FFZ\\Gerwinn, Macke, Bethge - 2009 - Bayesian population decoding of spiking neurons.pdf},
  journal = {Frontiers in computational neuroscience},
  keywords = {bayesian decoding,population coding,spiking neurons},
  number = {October},
  pmid = {20011217}
}

@article{gewaltig_plesser_2012,
  title = {{{NEST By Example}}},
  author = {Gewaltig, Marc-Oliver and Morrison, Abigail and Plesser, Hans Ekkehard},
  year = {2012},
  pages = {429--458},
  doi = {10.1007/978-94-007-3858-4},
  abstract = {Computational neurosciences and systems biology are among the main domains of life science research where mathematical modeling made a difference. This book introduces the many different types of computational studies one can develop to study neuronal systems. It is aimed at undergraduate students starting their research in computational neurobiology or more senior researchers who would like, or need, to move towards computational approaches. Based on their specific project, the readers would then move to one of the more specialized excellent textbooks available in the field. The first part of the book deals with molecular systems biology. Functional genomics is introduced through examples of transcriptomics and proteomics studies of neurobiological interest. Quantitative modelling of biochemical systems is presented in homogeneous compartments and using spatial descriptions. A second part deals with the various approaches to model single neuron physiology, and naturally move to neuronal networks. A division is focused on the development of neurons and neuronal systems and the book closes on a series of methodological chapters. From the molecules to the organ, thinking at the level of systems is transforming biology and its impact on society. This book will help the reader to hop on the train directly in the tank engine.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YIILQT8L\\Gewaltig, Morrison, Plesser - 2012 - NEST By Example.pdf},
  journal = {Springer},
  number = {1}
}

@article{ghumare_dupont_2018,
  title = {A {{Time}}-{{Varying Connectivity Analysis}} from {{Distributed EEG Sources}}: {{A Simulation Study}}},
  author = {Ghumare, Eshwar G. and Schrooten, Maarten and Vandenberghe, Rik and Dupont, Patrick},
  year = {2018},
  volume = {0},
  pages = {1--17},
  issn = {15736792},
  doi = {10.1007/s10548-018-0621-3},
  abstract = {\textcopyright{} 2018 The Author(s) Time-varying connectivity analysis based on sources reconstructed using inverse modeling of electroencephalographic (EEG) data is important to understand the dynamic behaviour of the brain. We simulated cortical data from a visual spatial attention network with a time-varying connectivity structure, and then simulated the propagation to the scalp to obtain EEG data. Distributed EEG source modeling using sLORETA was applied. We compared different dipole (representing a source) selection strategies based on their time series in a region of interest. Next, we estimated multivariate autoregressive (MVAR) parameters using classical Kalman filter and general linear Kalman filter approaches followed by the calculation of partial directed coherence (PDC). MVAR parameters and PDC values for the selected sources were compared with the ground-truth. We found that the best strategy to extract the time series of a region of interest was to select a dipole with time series showing the highest correlation with the average time series in the region of interest. Dipole selection based on power or based on the largest singular value offer comparable alternatives. Among the different Kalman filter approaches, the use of a general linear Kalman filter was preferred to estimate PDC based connectivity except when only a small number of trials are available. In the latter case, the classical Kalman filter can be an alternative.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7LGW8FCQ\\Ghumare et al. - 2018 - A Time-Varying Connectivity Analysis from Distributed EEG Sources A Simulation Study.pdf},
  journal = {Brain Topography},
  keywords = {EEG source modeling,Kalman filtering,Multivariate autoregressive (MVAR)modeling,Partial directed coherence (PDC),Visual spatial attention network},
  number = {0}
}

@article{gidaris_komodakis_2018,
  title = {{{UNSUPERVISED REPRESENTATION LEARNING BY PRE}}- {{DICTING IMAGE ROTATIONS}}},
  author = {Gidaris, Spyros and Singh, Praveer and Komodakis, Nikos},
  year = {2018},
  abstract = {Over the last years, deep convolutional neural networks (ConvNets) have trans-formed the field of computer vision thanks to their unparalleled capacity to learn high level semantic image features. However, in order to successfully learn those features, they usually require massive amounts of manually labeled data, which is both expensive and impractical to scale. Therefore, unsupervised semantic fea-ture learning, i.e., learning without requiring manual annotation effort, is of crucial importance in order to successfully harvest the vast amount of visual data that are available today. In our work we propose to learn image features by training Con-vNets to recognize the 2d rotation that is applied to the image that it gets as input. We demonstrate both qualitatively and quantitatively that this apparently simple task actually provides a very powerful supervisory signal for semantic feature learning. We exhaustively evaluate our method in various unsupervised feature learning benchmarks and we exhibit in all of them state-of-the-art performance. Specifically, our results on those benchmarks demonstrate dramatic improvements w.r.t. prior state-of-the-art approaches in unsupervised representation learning and thus significantly close the gap with supervised feature learning. For instance, in PASCAL VOC 2007 detection task our unsupervised pre-trained AlexNet model achieves the state-of-the-art (among unsupervised methods) mAP of 54.4\% that is only 2.4 points lower from the supervised case. We get similarly striking results when we transfer our unsupervised learned features on various other tasks, such as ImageNet classification, PASCAL classification, PASCAL segmentation, and CIFAR-10 classification. The code and models of our paper will be published on: https://github.com/gidariss/FeatureLearningRotNet.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JSXMIZHJ\\Gidaris, Singh, Komodakis - Unknown - UNSUPERVISED REPRESENTATION LEARNING BY PRE- DICTING IMAGE ROTATIONS.pdf}
}

@article{gidon_larkum_2020,
  title = {Dendritic Action Potentials and Computation in Human Layer 2/3 Cortical Neurons},
  author = {Gidon, Albert and Zolnik, Timothy Adam and Fidzinski, Pawel and Bolduan, Felix and Papoutsi, Athanasia and Poirazi, Panayiota and Holtkamp, Martin and Vida, Imre and Larkum, Matthew Evan},
  year = {2020},
  month = jan,
  volume = {367},
  pages = {83--87},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aax6239},
  abstract = {The active electrical properties of dendrites shape neuronal input and output and are fundamental to brain function. However, our knowledge of active dendrites has been almost entirely acquired from studies of rodents. In this work, we investigated the dendrites of layer 2 and 3 (L2/3) pyramidal neurons of the human cerebral cortex ex vivo. In these neurons, we discovered a class of calcium-mediated dendritic action potentials (dCaAPs) whose waveform and effects on neuronal output have not been previously described. In contrast to typical all-or-none action potentials, dCaAPs were graded; their amplitudes were maximal for threshold-level stimuli but dampened for stronger stimuli. These dCaAPs enabled the dendrites of individual human neocortical pyramidal neurons to classify linearly nonseparable inputs\textemdash a computation conventionally thought to require multilayered networks.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XKF3YUN9\\Gidon et al. - 2020 - Dendritic action potentials and computation in hum.pdf},
  journal = {Science},
  language = {en},
  number = {6473}
}

@article{gielow_zaborszky_2017,
  title = {The {{Input}}-{{Output Relationship}} of the {{Cholinergic Basal Forebrain}}},
  author = {Gielow, Matthew R and Zaborszky, Laszlo},
  year = {2017},
  volume = {18},
  pages = {1817--1830},
  issn = {22111247},
  doi = {10.1016/j.celrep.2017.01.060},
  abstract = {Basal forebrain cholinergic neurons influence cortical state, plasticity, learning, and attention. They collectively innervate the entire cerebral cortex, differentially controlling acetylcholine efflux across different cortical areas and timescales. Such control might be achieved by differential inputs driving separable cholinergic outputs, although no input-output relationship on a brain-wide level has ever been demonstrated. Here, we identify input neurons to cholinergic cells projecting to specific cortical regions by infecting cholinergic axon terminals with a monosynaptically restricted viral tracer. This approach revealed several circuit motifs, such as central amygdala neurons synapsing onto basolateral amygdala-projecting cholinergic neurons or strong somatosensory cortical input to motor cortex-projecting cholinergic neurons. The presence of input cells in the parasympathetic midbrain nuclei contacting frontally projecting cholinergic neurons suggest that the network regulating the inner eye muscles are additionally regulating cortical state via acetylcholine efflux. This dataset enables future circuit-level experiments to identify drivers of known cortical cholinergic functions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9V6EUFL6\\Gielow, Zaborszky - 2017 - The Input-Output Relationship of the Cholinergic Basal Forebrain.pdf},
  journal = {Cell Reports},
  keywords = {basal forebrain,basalocortical,ChAT-cre,cholinergic,connectome,monosynaptic,rabies,rat,transgenic},
  number = {7},
  pmid = {28199851}
}

@article{giessing_thiel_2012,
  title = {Pro-Cognitive Drug Effects Modulate Functional Brain Network Organization.},
  author = {Giessing, Carsten and Thiel, Christiane M},
  year = {2012},
  month = jan,
  volume = {6},
  pages = {53},
  issn = {1662-5153},
  doi = {10.3389/fnbeh.2012.00053},
  abstract = {Previous studies document that cholinergic and noradrenergic drugs improve attention, memory and cognitive control in healthy subjects and patients with neuropsychiatric disorders. In humans neural mechanisms of cholinergic and noradrenergic modulation have mainly been analyzed by investigating drug-induced changes of task-related neural activity measured with functional magnetic resonance imaging (fMRI). Endogenous neural activity has often been neglected. Further, although drugs affect the coupling between neurons, only a few human studies have explicitly addressed how drugs modulate the functional connectome, i.e., the functional neural interactions within the brain. These studies have mainly focused on synchronization or correlation of brain activations. Recently, there are some drug studies using graph theory and other new mathematical approaches to model the brain as a complex network of interconnected processing nodes. Using such measures it is possible to detect not only focal, but also subtle, widely distributed drug effects on functional network topology. Most important, graph theoretical measures also quantify whether drug-induced changes in topology or network organization facilitate or hinder information processing. Several studies could show that functional brain integration is highly correlated with behavioral performance suggesting that cholinergic and noradrenergic drugs which improve measures of cognitive performance should increase functional network integration. The purpose of this paper is to show that graph theory provides a mathematical tool to develop theory-driven biomarkers of pro-cognitive drug effects, and also to discuss how these approaches can contribute to the understanding of the role of cholinergic and noradrenergic modulation in the human brain. Finally we discuss the "global workspace" theory as a theoretical framework of pro-cognitive drug effects and argue that pro-cognitive effects of cholinergic and noradrenergic drugs might be related to higher network integration.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FFL6XZYG\\Giessing, Thiel - 2012 - Pro-cognitive drug effects modulate functional brain network organization.pdf},
  journal = {Frontiers in behavioral neuroscience},
  keywords = {cholinergic,compl,complex network,fmri,graph,imaging,nicotine,noradrenergic,topology},
  number = {August},
  pmid = {22973209}
}

@article{gifford_jefferson_2015,
  title = {Subjective {{Memory Complaint Only Relates}} to {{Verbal Episodic Memory Performance}} in {{Mild Cognitive Impairment}}},
  author = {a Gifford, Katherine and Liu, Dandan and Damon, Stephen M and Chapman, G William and Romano, Raymond R and Samuels, Lauren R. and Lu, Zengqi and Jefferson, Angela L.},
  year = {2015},
  month = jan,
  volume = {44},
  pages = {309--318},
  issn = {18758908},
  doi = {10.3233/JAD-140636},
  copyright = {All rights reserved},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NILAVFSV\\Gifford et al. - Unknown - Subjective memory complaint relates to only verbal episodic memory performance in mild cognitive impairment K.pdf},
  journal = {Journal of Alzheimer's Disease},
  number = {1}
}

@article{gigerenzer_brighton_2009,
  title = {Homo {{Heuristicus}}: {{Why Biased Minds Make Better Inferences}}},
  author = {Gigerenzer, Gerd and Brighton, Henry},
  year = {2009},
  volume = {1},
  pages = {107--143},
  issn = {17568757},
  doi = {10.1111/j.1756-8765.2008.01006.x},
  abstract = {Heuristics are efficient cognitive processes that ignore information. In contrast to the widely held view that less processing reduces accuracy, the study of heuristics shows that less information, computation, and time can in fact improve accuracy. We review the major progress made so far: (a) the discovery of less-is-more effects; (b) the study of the ecological rationality of heuristics, which examines in which environments a given strategy succeeds or fails, and why; (c) an advancement from vague labels to computational models of heuristics; (d) the development of a systematic theory of heuristics that identifies their building blocks and the evolved capacities they exploit, and views the cognitive system as relying on an ``adaptive toolbox;'' and (e) the development of an empirical methodology that accounts for individual differences, conducts competitive tests, and has provided evidence for people's adaptive use of heuristics. Homo heuristicus has a biased mind and ignores part of the available information, yet a biased mind can handle uncertainty more efficiently and robustly than an unbiased mind relying on more resource-intensive and general-purpose processing strategies.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4IVTJTX5\\Gigerenzer, Brighton - 2009 - Homo Heuristicus Why Biased Minds Make Better Inferences.pdf},
  journal = {Topics in Cognitive Science},
  keywords = {Decision-making,Heuristics,Induction,Inferences,Rationality,Uncertainity},
  number = {1},
  pmid = {25164802}
}

@article{gilbert_li_2013,
  title = {Top-down Influences on Visual Processing},
  author = {Gilbert, Charles D. and Li, Wu},
  year = {2013},
  month = may,
  volume = {14},
  pages = {350--363},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn3476},
  abstract = {Re-entrant or feedback pathways between cortical areas carry rich and varied information about behavioural context, including attention, expectation, perceptual tasks, working memory and motor commands. Neurons receiving such inputs effectively function as adaptive processors that are able to assume different functional states according to the task being executed. Recent data suggest that the selection of particular inputs, representing different components of an association field, enable neurons to take on different functional roles. In this Review, we discuss the various top-down influences exerted on the visual cortical pathways and highlight the dynamic nature of the receptive field, which allows neurons to carry information that is relevant to the current perceptual demands.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\886SM7EG\\Gilbert and Li - 2013 - Top-down influences on visual processing.pdf},
  journal = {Nature Reviews Neuroscience},
  language = {en},
  number = {5}
}

@article{gilmore_mcdermott_2015,
  title = {A Parietal Memory Network Revealed by Multiple {{MRI}} Methods},
  author = {Gilmore, Adrian W and Nelson, Steven M and McDermott, Kathleen B},
  year = {2015},
  volume = {19},
  pages = {534--543},
  issn = {1879307X},
  doi = {10.1016/j.tics.2015.07.004},
  abstract = {The manner by which the human brain learns and recognizes stimuli is a matter of ongoing investigation. Through examination of meta-analyses of task-based functional MRI and resting state functional connectivity MRI, we identified a novel network strongly related to learning and memory. Activity within this network at encoding predicts subsequent item memory, and at retrieval differs for recognized and unrecognized items. The direction of activity flips as a function of recent history: from deactivation for novel stimuli to activation for stimuli that are familiar due to recent exposure. We term this network the 'parietal memory network' (PMN) to reflect its broad involvement in human memory processing. We provide a preliminary framework for understanding the key functional properties of the network.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\88JCRMDD\\Gilmore, Nelson, McDermott - 2015 - A parietal memory network revealed by multiple MRI methods.pdf},
  journal = {Trends in Cognitive Sciences},
  keywords = {Encoding,Familiarity,Functional networks,Memory,Parietal cortex,Retrieval},
  number = {9},
  pmid = {26254740}
}

@article{gilra_gerstner_2017,
  title = {Predicting Non-Linear Dynamics by Stable Local Learning in a Recurrent Spiking Neural Network},
  author = {Gilra, Aditya and Gerstner, Wulfram},
  year = {2017},
  month = nov,
  volume = {6},
  pages = {e28295},
  issn = {2050-084X},
  doi = {10.7554/eLife.28295},
  abstract = {The brain needs to predict how the body reacts to motor commands, but how a network of spiking neurons can learn non-linear body dynamics using local, online and stable learning rules is unclear. Here, we present a supervised learning scheme for the feedforward and recurrent connections in a network of heterogeneous spiking neurons. The error in the output is fed back through fixed random connections with a negative gain, causing the network to follow the desired dynamics. The rule for Feedback-based Online Local Learning Of Weights (FOLLOW) is local in the sense that weight changes depend on the presynaptic activity and the error signal projected onto the postsynaptic neuron. We provide examples of learning linear, non-linear and chaotic dynamics, as well as the dynamics of a two-link arm. Under reasonable approximations, we show, using the Lyapunov method, that FOLLOW learning is uniformly stable, with the error going to zero asymptotically.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YZMT2NU9\\Gilra and Gerstner - 2017 - Predicting non-linear dynamics by stable local lea.pdf},
  journal = {eLife},
  language = {en}
}

@article{giocomo_hasselmo_2008,
  title = {Time Constants of h Current in Layer Ii Stellate Cells Differ along the Dorsal to Ventral Axis of Medial Entorhinal Cortex.},
  author = {Giocomo, Lisa M and Hasselmo, Michael E},
  year = {2008},
  month = sep,
  volume = {28},
  pages = {9414--9425},
  issn = {1529-2401},
  doi = {10.1523/JNEUROSCI.3196-08.2008},
  abstract = {Chronic recordings in the medial entorhinal cortex of behaving rats have found grid cells, neurons that fire when the rat is in a hexagonal array of locations. Grid cells recorded at different dorsal-ventral anatomical positions show systematic changes in size and spacing of firing fields. To test possible mechanisms underlying these differences, we analyzed properties of the hyperpolarization-activated cation current I(h) in voltage-clamp recordings from stellate cells in entorhinal slices from different dorsal-ventral locations. The time constant of h current was significantly different between dorsal and ventral neurons. The time constant of h current correlated with membrane potential oscillation frequency and the time constant of the sag potential in the same neurons. Differences in h current could underlie differences in membrane potential oscillation properties and contribute to grid cell periodicity along the dorsal-ventral axis of medial entorhinal cortex.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QIYLUHBF\\Giocomo, Hasselmo - 2008 - Time constants of h current in layer ii stellate cells differ along the dorsal to ventral axis of medial ento.pdf},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  keywords = {Animals,Biological Clocks,Biological Clocks: physiology,Cation Transport Proteins,Cation Transport Proteins: physiology,Entorhinal Cortex,Entorhinal Cortex: cytology,Entorhinal Cortex: physiology,Female,Interneurons,Interneurons: physiology,Ion Channels,Ion Channels: physiology,Long-Evans,Male,Membrane Potentials,Membrane Potentials: physiology,Neural Pathways,Neural Pathways: physiology,Organ Culture Techniques,Patch-Clamp Techniques,Rats,Synaptic Transmission,Synaptic Transmission: physiology,Time Factors},
  number = {38},
  pmid = {18799674}
}

@article{giocomo_hasselmo_2009,
  title = {Knock-out of {{HCN1}} Subunit Flattens Dorsal-Ventral Frequency Gradient of Medial Entorhinal Neurons in Adult Mice.},
  author = {Giocomo, Lisa M and Hasselmo, Michael E},
  year = {2009},
  month = jun,
  volume = {29},
  pages = {7625--7630},
  issn = {1529-2401},
  doi = {10.1523/JNEUROSCI.0609-09.2009},
  abstract = {Layer II stellate cells at different locations along the dorsal to ventral axis of medial entorhinal cortex show differences in the frequency of intrinsic membrane potential oscillations and resonance (Giocomo et al., 2007). The frequency differences scale with differences in the size and spacing of grid-cell firing fields recorded in layer II of the medial entorhinal cortex in behaving animals. To determine the mechanism for this difference in intrinsic frequency, we analyzed oscillatory properties in adult control mice and adult mice with a global deletion of the HCN1 channel. Data from whole-cell patch recordings show that the oscillation frequency gradient along the dorsal-ventral axis previously shown in juvenile rats also appears in control adult mice, indicating that the dorsal-ventral gradient generalizes across age and species. Knock-out of the HCN1 channel flattens the dorsal-ventral gradient of the membrane potential oscillation frequency, the resonant frequency, the time constant of the "sag" potential and the amplitude of the sag potential. This supports a role of the HCN1 subunit in the mechanism of the frequency gradient in these neurons. These findings have important implications for models of grid cells and generate predictions for future in vivo work on entorhinal grid cells.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CNQA945G\\Giocomo, Hasselmo - 2009 - Knock-out of HCN1 subunit flattens dorsal-ventral frequency gradient of medial entorhinal neurons in adult mi.pdf},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  keywords = {aging,Animals,Cyclic Nucleotide-Gated Cation Channels,Cyclic Nucleotide-Gated Cation Channels: genetics,Cyclic Nucleotide-Gated Cation Channels: metabolis,Entorhinal Cortex,Entorhinal Cortex: cytology,Entorhinal Cortex: physiology,Hyperpolarization-Activated Cyclic Nucleotide-Gate,Knockout,Membrane Potentials,Membrane Potentials: physiology,Mice,Neurons,Neurons: physiology,Patch-Clamp Techniques,Periodicity,Potassium Channels,Potassium Channels: genetics,Potassium Channels: metabolism,Species Specificity},
  number = {23},
  pmid = {19515931}
}

@article{giovannucci_wang_2017,
  title = {Cerebellar Granule Cells Acquire a Widespread Predictive Feedback Signal during Motor Learning},
  author = {Giovannucci, Andrea and Badura, Aleksandra and Deverett, Ben and Najafi, Farzaneh and Pereira, Talmo D and Gao, Zhenyu and Ozden, Ilker and Kloth, Alexander D and Pnevmatikakis, Eftychios and Paninski, Liam and De Zeeuw, Chris I and Medina, Javier F and Wang, Samuel S-H},
  year = {2017},
  volume = {20},
  pages = {727--734},
  issn = {1097-6256},
  doi = {10.1038/nn.4531},
  abstract = {Cerebellar granule cells, which constitute half the brain's neurons, supply Purkinje cells with contextual information necessary for motor learning, but how they encode this information is unknown. Here we show, using two-photon microscopy to track neural activity over multiple days of cerebellum-dependent eyeblink conditioning in mice, that granule cell populations acquire a dense representation of the anticipatory eyelid movement. Initially, granule cells responded to neutral visual and somatosensory stimuli as well as periorbital airpuffs used for training. As learning progressed, two-thirds of monitored granule cells acquired a conditional response whose timing matched or preceded the learned eyelid movements. Granule cell activity covaried trial by trial to form a redundant code. Many granule cells were also active during movements of nearby body structures. Thus, a predictive signal about the upcoming movement is widely available at the input stage of the cerebellar cortex, as required by forward models of cerebellar control.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\87DNKHQ8\\Giovannucci et al. - 2017 - Cerebellar granule cells acquire a widespread predictive feedback signal during motor learning.pdf},
  journal = {Nature Neuroscience},
  number = {5},
  pmid = {28319608}
}

@article{giraud_arnal_2018,
  title = {Hierarchical {{Predictive Information Is Channeled}} by {{Asymmetric Oscillatory Activity}}},
  author = {Giraud, Anne-Lise and Arnal, Luc H},
  year = {2018},
  doi = {10.1016/j.neuron.2018.11.020},
  abstract = {Predictive coding and neural oscillations are two descriptive levels of brain functioning whose overlap is not yet understood. Chao et al. (2018) now show that hierarchical predictive coding is instantiated by asymmetric information channeling in the g and a/b oscillatory ranges. Predictive coding is a prolific general theory of the brain assuming that any cere-bral process, whatever its scale and purpose , tends to prevent surprise-or, in thermodynamic terms, entropy. The theory entails that the sources of sensory changes are neutralized by predicting their likely causes and that eventually only what cannot be accounted for by anticipation is processed further. In this view, the coincidental effect of prediction and external input is the neural representation. Along Marr's classical model (Marr and Poggio, 1976), this level of brain description could be argued to be computational to -algorithmic (Figure 1A), as it depicts a general neural principle, disregarding its scale or specific physical instantiation. Although connections have been made to the neurotransmitter level in brain pathologies (e.g., Sterzer et al., 2018), predictive coding still requires concrete overlap with the algorithmic-to-implementational level, i.e., how predictions and prediction errors are (bio)physi-cally generated and deployed, notably in the temporal domain (Friston et al., 2018). By contrast, many if not all cortical operations involve neural oscillations, electrical phenomena that capture composite neural activity at a spatio-temporal integration scale that can easily be related to complex cognitive processes. The generation of neural oscillations is fairly well understood at the biophysical level: it follows from rhythmic neuronal membrane potential fluctuations, extending to basic and complex neural networks through excitatory-excitatory, inhibitory-inhibitory, and excitatory-inhibitory synaptic connections as well as through ion-mediated coupling. Different families of neural oscillations involving different frequency ranges are associated with different cognitive functions, and the neural architecture underlying their coordinated action, i.e., their nesting, accounts for specific functions (Hyafil et al., 2015), including the maintenance of processing hierarchy and its deployment in the time domain. This function is particularly important in fields of cognition requiring temporal integration of sensory stimuli and on-line action planning , such as language and spatial navigation. In language, neural oscillations at different scales, and their nesting, could be at the heart of a stream of critical interdependent operations, including sequence timing signaling and prediction, chunking and grouping, maintenance of order within sequences, detection of pattern violations , and encoding of hierarchies (Chao et al., 2018; Dehaene et al., 2015; Ding et al., 2015; Hyafil et al., 2015). Distinct ranges of neural oscillations have also been implicated in general principles of interregional information propagation. In particular, a relatively recent stream of converging findings indicates that feedforward and feedback information is associated, respectively, with g-and low-b-range oscillations (Michalareas et al., 2016). This asymmetry could reflect the independence of information chan-neling for distinct types of information, namely predictions and prediction errors, and could constitute an interesting connecting point between the theory of predictive coding and the way it is instantiated at the neuronal population level. Interestingly, Bastos and colleagues (Bas-tos et al., 2012) even argued that frequency asymmetry between up-and down-going format of information flow directly ensues from the predictive coding mathematical formalism. This intriguing observation opens a whole new field of research at the interface of two distinct description levels of dynamic sensory processing and action planning (Figure 1A, blue area). In this issue of Neuron, Chao et al. (Chao et al., 2018) elegantly connect these two levels of description by using a now-classical experimental paradigm, the local-global oddball paradigm, that allows probing of hierarchical predictive coding by violating expectations simultaneously at two distinct processing levels and timescales. At a low, local level, expectation violations result from the perception of an oddball sound deviating from a sequence of standard sounds. Local sequences, whether normal or oddball, are repetitively presented to form 2 nd-order sequences (of sequences), thereby generating expectations at a higher-order global level. Importantly, in their experimental design the authors ensured that standard and deviant local sequences were equally presented within global sequences in a balanced manner. This clever paradig-matic trick enables separation of local from global effects, all sensory inputs being equal, in the factorial analysis design. Leveraging the intrinsically nested organization between these two levels of expectations , the authors could derive specific hypotheses about the amount and location of predictions and prediction errors at distinct anatomical and functional levels (Figure 1B). Importantly, while previous attempts at singling out predictions and errors focused on a unique hierarchical level, the local-global approach measures predictive processing at one level along with the conditional propagation of prediction errors to the next, depending on the predictive context. This aspect is crucial, as it allows exploration of an Neuron Previews 1022 Neuron 100, December 5, 2018 \textordfeminine{} 2018 Elsevier Inc.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2K88MYVZ\\Giraud, Arnal - 2018 - Hierarchical Predictive Information Is Channeled by Asymmetric Oscillatory Activity(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\RI2R3D2P\\Giraud, Arnal - 2018 - Hierarchical Predictive Information Is Channeled by Asymmetric Oscillatory Activity(2).pdf},
  keywords = {beta,gamma,hierarchical depth,oscillations,predictive coding}
}

@article{giret_hahnloser_2014,
  title = {Evidence for a Causal Inverse Model in an Avian Cortico-Basal Ganglia Circuit},
  author = {Giret, Nicolas and Kornfeld, Joergen and Ganguli, Surya and Hahnloser, Richard H R},
  year = {2014},
  volume = {111},
  pages = {6063--6068},
  issn = {0027-8424},
  doi = {10.1073/pnas.1317087111},
  abstract = {Learning by imitation is fundamental to both communication and social behavior and requires the conversion of complex, nonlinear sensory codes for perception into similarly complex motor codes for generating action. To understand the neural substrates underlying this conversion, we study sensorimotor transformations in songbird cortical output neurons of a basal-ganglia pathway involved in song learning. Despite the complexity of sensory and motor codes, we find a simple, temporally specific, causal correspondence between them. Sensory neural responses to song playback mirror motor-related activity recorded during singing, with a temporal offset of roughly 40 ms, in agreement with short feedback loop delays estimated using electrical and auditory stimulation. Such matching of mirroring offsets and loop delays is consistent with a recent Hebbian theory of motor learning and suggests that cortico-basal ganglia pathways could support motor control via causal inverse models that can invert the rich correspondence between motor exploration and sensory feedback.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RBUA2CFN\\Giret et al. - 2014 - Evidence for a causal inverse model in an avian cortico-basal ganglia circuit.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  number = {16},
  pmid = {24711417}
}

@article{gitelman_mesulam_2002,
  title = {Functional Anatomy of Visual Search: {{Regional}} Segregations within the Frontal Eye Fields and Effective Connectivity of the Superior Colliculus},
  author = {Gitelman, Darren R and Parrish, Todd B and Friston, Karl J and Mesulam, M. Marsel},
  year = {2002},
  volume = {15},
  pages = {970--982},
  issn = {10538119},
  doi = {10.1006/nimg.2001.1006},
  abstract = {The ability to find targets embedded within complex visual environments requires the dynamic programming of visuomotor search behaviors. Functional magnetic resonance imaging was used to image subjects while they visually searched for targets embedded among foils. Visuomotor search activated the posterior parietal cortex and the frontal eye fields. Both regions showed a greater number of activated voxels on the right, consistent with the known pattern of right hemispheric dominance for spatial attention. The superior colliculus showed prominent activation in the search versus eye movement contrast, demonstrating, for the first time in humans, activation of this region specifically related to an exploratory attentional contingency. An analysis of effective connectivity demonstrated that the search-dependent variance in the activity of the superior colliculus was significantly influenced by the activity in a network of cortical regions including the right frontal eye fields and bilateral parietal and occipital cortices. These experiments also revealed the presence of a mosaic of activated sites within the frontal eye field region wherein saccadic eye movements, covert shifts of attention, and visuomotor search elicited overlapping but not identical zones of activation. In contrast to the existing literature on functional imaging, which has focused on covert shifts of spatial attention, this study helps to characterize the functional anatomy of overt spatial exploration. \textcopyright{} 2002 Elsevier Science (USA).},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4NK7NLZA\\Gitelman et al. - 2002 - Functional anatomy of visual search Regional segregations within the frontal eye fields and effective connectiv.pdf},
  journal = {NeuroImage},
  keywords = {Eye movements,Functional magnetic resonance imaging,Occipital cortex,Parietal cortex,Spatial attention},
  number = {4},
  pmid = {11906237}
}

@article{gjorgjieva_leoncooper_2011,
  title = {A Triplet Spike-Timing\textendash Dependent Plasticity Model Generalizes the {{Bienenstock}}\textendash{{Cooper}}\textendash{{Munro}} Rule to Higher-Order Spatiotemporal Correlations},
  author = {Gjorgjieva, Julijana and Clopath, Claudia and Audet, Juliette and Pfister, Jean-Pascal and Leon Cooper, by N},
  year = {2011},
  doi = {10.1073/pnas.1105933108},
  abstract = {Synaptic strength depresses for low and potentiates for high ac-tivation of the postsynaptic neuron. This feature is a key property of the Bienenstock\textendash Cooper\textendash Munro (BCM) synaptic learning rule, which has been shown to maximize the selectivity of the postsynaptic neu-ron, and thereby offers a possible explanation for experience-depen-dent cortical plasticity such as orientation selectivity. However, the BCM framework is rate-based and a significant amount of recent work has shown that synaptic plasticity also depends on the precise timing of presynaptic and postsynaptic spikes. Here we consider a trip-let model of spike-timing\textendash dependent plasticity (STDP) that depends on the interactions of three precisely timed spikes. Triplet STDP has been shown to describe plasticity experiments that the classical STDP rule, based on pairs of spikes, has failed to capture. In the case of rate-based patterns, we show a tight correspondence between the triplet STDP rule and the BCM rule. We analytically demonstrate the selec-tivity property of the triplet STDP rule for orthogonal inputs and perform numerical simulations for nonorthogonal inputs. Moreover, in contrast to BCM, we show that triplet STDP can also induce selec-tivity for input patterns consisting of higher-order spatiotemporal correlations, which exist in natural stimuli and have been measured in the brain. We show that this sensitivity to higher-order correlations can be used to develop direction and speed selectivity. S ynaptic plasticity depends on the activity of presynaptic and postsynaptic neurons and is believed to provide the basis for learning and memory (1, 2). It has been shown that low-frequency stimulation (1\textendash 3 Hz) (3) or stimulation paired with low post-synaptic depolarization (4) induces synaptic long-term depression (LTD), whereas synapses undergo long-term potentiation (LTP) after high-frequency stimulation (100 Hz) (5). Such findings are consistent with the well-known Bienenstock\textendash Cooper\textendash Munro (BCM) learning rule (6). This BCM model has been shown to elicit orientation selectivity and other aspects of experience-dependent cortical plasticity (6, 7). Furthermore, in this model the modifica-tion threshold between LTP and LTD varies as a function of the history of postsynaptic activity, a prediction that has been con-firmed experimentally (8). Despite its consistency with experimental data and its functional relevance, the BCM framework is still limited experimentally and functionally. Experimentally, because the learning rule is expressed in terms of firing rates, it cannot predict synaptic modification on the basis of the timing of pre-and postsynaptic spikes (9, 10). This form of plasticity, called spike-timing\textendash dependent plasticity (STDP), uses the timing of spike pairs to induce synaptic modifi-cation (11, 12). The presynaptic spike is required to shortly precede the postsynaptic spike to elicit LTP, whereas the reverse timing of pre-and postsynaptic spikes leads to LTD (9, 10). Functionally, the BCM model cannot segregate input patterns that are characterized by their temporal spiking structure. STDP provides a possible so-lution, but how STDP relates to BCM remains debated (13\textendash 15). Here, we consider a spike-based learning rule, " the triplet STDP model " (15, 16), and show that it overcomes those two important limitations of the BCM rule and thus generalizes the BCM framework. This triplet model uses sets of three spikes (triplets)\textemdash{} instead of pairs of spikes as in the case of classical STDP\textemdash to induce potentiation. More precisely, LTP depends on the interval between the pre-and postsynaptic spikes and on the timing of the previous postsynaptic spike (Fig. 1A). Furthermore, this triplet learning rule has been shown to explain a variety of synaptic plasticity data (17, 18) significantly better than pair-based STDP (15) (Fig. 1B). Plasticity induced by multiples of spikes has also been the focus of other studies (19, 20); despite using the same spike combinations some differences have been observed, most likely due to the different (extracellular or intracellular) stimula-tion protocols used in these studies (21). Computationally, it has been shown that under some rather crude assumptions\textemdash when the input and output neurons have independent Poisson statistics\textemdash the triplet STDP model can be mapped to the BCM learning rule (16). In this paper, we take a more biologically plausible approach by incorporating con-tributions from input\textendash output spiking correlations in inducing synaptic plasticity. Consistent with results from the BCM theory, we demonstrate that in the presence of orthogonal rate-based patterns, the maximally selective fixed points of the weight dy-namics induced by the triplet rule are stable. Furthermore, we show that the triplet rule acts as a generalized BCM rule in the sense that postsynaptic neurons become selective not only to rate-based patterns of the inputs, but also to patterns differentiated only by their spiking correlation structure. The mathematical simplicity of the triplet model allowed us to characterize the explicit dependence of the weight dynamics on higher-order input corre-lations. We believe this study is of great relevance given the ubiq-uity of higher-order correlations in the brain (22, 23) and their relevance for neural coding (24).},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IGTXTWPX\\Gjorgjieva et al. - Unknown - A triplet spike-timing–dependent plasticity model generalizes the Bienenstock–Cooper–Munro rule to h.pdf}
}

@article{gluth_rieskamp_2017,
  title = {Variability in Behavior That Cognitive Models Do Not Explain Can Be Linked to Neuroimaging Data},
  author = {Gluth, Sebastian and Rieskamp, J{\"o}rg},
  year = {2017},
  volume = {76},
  pages = {104--116},
  issn = {10960880},
  doi = {10.1016/j.jmp.2016.04.012},
  abstract = {It is known that behavior is substantially variable even across nearly identical situations. Many cognitive models are not able to explain this intraindividual variability but focus on explaining interindividual differences captured in model parameters. In sequential sampling models of decision making, for instance, one single threshold parameter value is estimated for every person to quantify how much evidence must be accumulated for committing to a choice. However, this threshold may vary across trials even within subjects and experimental conditions. Neuroimaging tools such as functional magnetic resonance imaging (fMRI) or electroencephalography (EEG) can reveal moment-to-moment fluctuations in the neural system that are likely to contribute to fluctuations in behavior. We propose that neural and behavioral variability could be linked to each other by assuming and estimating trial-by-trial variability in model parameters. To illustrate our proposal, we first highlight recent studies in model-based cognitive neuroscience that have gone beyond correlating model predictions with neuroimaging data. These studies made use of variance in behavior that remained unexplained by cognitive modeling but could be linked to specific fMRI or EEG signals. Second, we specify in a tutorial a novel and efficient approach, how to extract such variance and to apply it to neuroimaging data. Our proposal shows how the variability in behavior and the neural system can provide a fruitful source of theory development in cognitive neuroscience.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9IKZ4X5X\\Gluth, Rieskamp - 2017 - Variability in behavior that cognitive models do not explain can be linked to neuroimaging data.pdf},
  journal = {Journal of Mathematical Psychology},
  keywords = {Bayes,Cognitive modeling,Decision making,eeg,fmri,Intraindividual differences}
}

@incollection{glynn_glynn_2008,
  title = {Making Science Concepts Meaningful to Students: {{Teaching}} with Analogies},
  booktitle = {Four {{Decades}} of {{Research}} in {{Science Education}}: {{From Curriculum Development}} to {{Quality Improvement}}},
  author = {Glynn, Shawn M},
  year = {2008},
  pages = {113--125},
  abstract = {Science-education research studies and science teachers' classroom experiences have shown that analogies, when used properly, can help make science concepts meaningful to students. This chapter explains what analogies are, how analogies foster learning and interest, and what form analogies should take to be effective. A research-based model for teaching with analogies is described: It provides guidelines for the use of analogies in sci- ence classrooms, textbooks, and web-based science instruction.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PLEKSBFX\\Glynn - 2008 - Making science concepts meaningful to students Teaching with analogies.pdf}
}

@article{goel_dolan_2001,
  title = {Functional Neuroanatomy of Three-Term Relational Reasoning},
  author = {Goel, Vinod and Dolan, Raymond J},
  year = {2001},
  volume = {39},
  pages = {901--909},
  issn = {00283932},
  doi = {10.1016/S0028-3932(01)00024-0},
  abstract = {In a recent study we demonstrated that reasoning with categorical syllogisms engages two dissociable mechanisms. Reasoning involving concrete sentences engaged a left hemisphere linguistic system while formally identical arguments, involving abstract sentences, recruited a parietal spatial network. The involvement of a parietal visuo-spatial system in abstract syllogism reasoning raised the question whether argument forms involving explicit spatial relations (or relations that can be easily mapped onto spatial relations) are sufficient to engage the parietal system? We addressed this question in an event-related fMRI study of three-term relational reasoning, using sentences with concrete and abstract content. Our findings indicate that both concrete and abstract three-term relational arguments activate a similar bilateral occipital-parietal-frontal network. However, the abstract reasoning condition engendered greater parietal activation than the concrete reasoning condition. We conclude that arguments involving relations that can be easily mapped onto explicit spatial relations engage a visuo-spatial system, irrespective of concrete or abstract content. Copyright \textcopyright{} 2001 Elsevier Science Ltd.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5KY5EYD7\\Goel, Dolan - 2001 - Functional neuroanatomy of three-term relational reasoning.pdf},
  journal = {Neuropsychologia},
  keywords = {Deductive reasoning,fmri,Higher cognitive functions,Mental logic,Mental models,Neuroimaging,Spatial reasoning},
  number = {9},
  pmid = {11516443}
}

@article{gofman_derdikman_2019,
  title = {Dissociation between {{Postrhinal Cortex}} and {{Downstream Parahippocampal Regions}} in the {{Representation}} of {{Egocentric Boundaries}}},
  author = {Gofman, Xenia and Tocker, Gilad and Weiss, Shahaf and Boccara, Charlotte N. and Lu, Li and Moser, May-Britt and Moser, Edvard I. and Morris, Genela and Derdikman, Dori},
  year = {2019},
  month = aug,
  pages = {S0960982219308528},
  issn = {09609822},
  doi = {10.1016/j.cub.2019.07.007},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AAU2EJTY\\Gofman et al. - 2019 - Dissociation between Postrhinal Cortex and Downstr.pdf},
  journal = {Current Biology},
  language = {en}
}

@article{gola_wrobel_2013,
  title = {{{EEG}} Beta Band Activity Is Related to Attention and Attentional Deficits in the Visual Performance of Elderly Subjects},
  author = {Gola, Mateusz and Magnuski, Miko{\textbackslash}laj and Szumska, Izabela and Wr{\'o}bel, Andrzej},
  year = {2013},
  volume = {89},
  pages = {334--341},
  issn = {01678760},
  doi = {10.1016/j.ijpsycho.2013.05.007},
  abstract = {We have previously shown that beta-band EEG activity is related to attentional modulation in the visual system of cats and humans. In a separate experiment we also observed that some elderly subjects expressed beta-band power decreases during a simple visual attention task, an effect which was accompanied by low behavioral accuracy in this subgroup. Here, we conducted a detailed examination of beta power deficits in elderly subjects in comparison to young controls. In order to do so, we equalized the subjective level of task difficulty by adjusting visual stimuli presentation duration in such a way that elderly and young subjects achieved similar behavioral results. We found that: (1) beta-band power of EEG signals recorded over occipital regions in elderly and young groups is related to visual attention, as judged from increases in beta power preceding correct responses and lack of beta activity change before erroneous responses; (2) despite forming a homogeneous group when screened for dementia (MMSE), age, education level, visual correction, and speed-accuracy trade-off strategy, elderly subjects could be assigned into one of the two subgroups: high performers, who did not differ from young performers in terms of beta-band power increases, and low performers, whose beta power decreased during the most difficult attentional conditions (shortest - 3. s and longest - 11. s cue-target delays). These findings posit that the beta-band activity decrease recorded in low performing elderly subjects reflects difficulty in activation and deficits in sustaining attentional processes. \textcopyright{} 2013 Elsevier B.V.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AVXHBJ76\\Gola et al. - 2013 - EEG beta band activity is related to attention and attentional deficits in the visual performance of elderly subjec.pdf},
  journal = {International Journal of Psychophysiology},
  keywords = {aging,Attention,Beta band,Human EEG},
  number = {3},
  pmid = {23688673}
}

@article{gold_shadlen_2007,
  title = {The Neural Basis of Decision Making},
  author = {Gold, J I and Shadlen, M N},
  year = {2007},
  volume = {30},
  pages = {535--574},
  issn = {0147-006X},
  doi = {10.1146/annurev.neuro.29.051605.113038},
  abstract = {The study of decision making spans such varied fields as neuroscience, psychology, economics, statistics, political science, and computer science. Despite this diversity of applications, most decisions share common elements including deliberation and commitment. Here we evaluate recent progress in understanding how these basic elements of decision formation are implemented in the brain. We focus on simple decisions that can be studied in the laboratory but emphasize general principles likely to extend to other settings. Copyright \{\textcopyright\} 2007 by Annual Reviews. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\S6528XPF\\Gold, Shadlen - 2007 - The neural basis of decision making.pdf},
  journal = {Annu. Rev. Neurosci.},
  keywords = {choice,motion,perception,psychophysics,reaction time,sequential analysis,signal detection theory,vibrotactile perception},
  pmid = {17600525}
}

@article{goldman-rakic_goldman-rakic_1995,
  title = {Cellular Basis of Working Memory},
  author = {{Goldman-Rakic}, P.S},
  year = {1995},
  month = mar,
  volume = {14},
  pages = {477--485},
  issn = {08966273},
  doi = {10.1016/0896-6273(95)90304-6},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PQNB9HIH\\Goldman-Rakic - 1995 - Cellular basis of working memory.pdf},
  journal = {Neuron},
  language = {en},
  number = {3}
}

@article{goldsborough_goldsborough_2016,
  title = {A {{Tour}} of {{TensorFlow Proseminar Data Mining}}},
  author = {Goldsborough, Peter},
  year = {2016},
  abstract = {Deep learning is a branch of artificial intelligence employing deep neural network architectures that has signifi-cantly advanced the state-of-the-art in computer vision, speech recognition, natural language processing and other domains. In November 2015, Google released TensorFlow, an open source deep learning software library for defining, training and deploying machine learning models. In this paper, we review TensorFlow and put it in context of modern deep learning concepts and software. We discuss its basic computational paradigms and distributed execution model, its programming interface as well as accompanying visualization toolkits. We then compare Ten-sorFlow to alternative libraries such as Theano, Torch or Caffe on a qualitative as well as quantitative basis and finally comment on observed use-cases of TensorFlow in academia and industry.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YXWINARG\\Goldsborough - 2016 - A Tour of TensorFlow Proseminar Data Mining.pdf},
  journal = {Arxiv}
}

@article{gong_liu_2019,
  title = {Continuous and Discrete Representations of Feature-Based Attentional Priority in Human Frontoparietal Network},
  author = {Gong, Mengyuan and Liu, Taosheng},
  year = {2019},
  month = mar,
  pages = {1--13},
  issn = {1758-8928, 1758-8936},
  doi = {10.1080/17588928.2019.1601074},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LGLBJ7SU\\Gong and Liu - 2019 - Continuous and discrete representations of feature.pdf},
  journal = {Cognitive Neuroscience},
  language = {en}
}

@article{gonzalez_wagner_2015,
  title = {Electrocorticography Reveals the Temporal Dynamics of Posterior Parietal Cortical Activity during Recognition Memory Decisions.},
  author = {Gonzalez, Alex and Hutchinson, J Benjamin and Uncapher, Melina R and Chen, Janice and LaRocque, Karen F and Foster, Brett L and Rangarajan, Vinitha and Parvizi, Josef and Wagner, Anthony D},
  year = {2015},
  volume = {112},
  pages = {11066--11071},
  issn = {1091-6490},
  doi = {10.1073/pnas.1510749112},
  abstract = {Theories of the neurobiology of episodic memory predominantly focus on the contributions of medial temporal lobe structures, based on extensive lesion, electrophysiological, and imaging evidence. Against this backdrop, functional neuroimaging data have unexpectedly implicated left posterior parietal cortex (PPC) in episodic retrieval, revealing distinct activation patterns in PPC subregions as humans make memory-related decisions. To date, theorizing about the functional contributions of PPC has been hampered by the absence of information about the temporal dynamics of PPC activity as retrieval unfolds. Here, we leveraged electrocorticography to examine the temporal profile of high gamma power (HGP) in dorsal PPC subregions as participants made old/new recognition memory decisions. A double dissociation in memory-related HGP was observed, with activity in left intraparietal sulcus (IPS) and left superior parietal lobule (SPL) differing in time and sign for recognized old items (Hits) and correctly rejected novel items (CRs). Specifically, HGP in left IPS increased for Hits 300-700 ms poststimulus onset, and decayed to baseline {$\sim$}200 ms preresponse. By contrast, HGP in left SPL increased for CRs early after stimulus onset (200-300 ms) and late in the memory decision (from 700 ms to response). These memory-related effects were unique to left PPC, as they were not observed in right PPC. Finally, memory-related HGP in left IPS and SPL was sufficiently reliable to enable brain-based decoding of the participant's memory state at the single-trial level, using multivariate pattern classification. Collectively, these data provide insights into left PPC temporal dynamics as humans make recognition memory decisions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AN6T3IQV\\Gonzalez et al. - 2015 - Electrocorticography reveals the temporal dynamics of posterior parietal cortical activity during recognitio(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\EHXA97E7\\Gonzalez et al. - 2015 - Electrocorticography reveals the temporal dynamics of posterior parietal cortical activity during recognition m.pdf},
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  keywords = {Electrocorticography,Electrodes,Humans,Memory,Parietal Lobe,Parietal Lobe: physiology,Pattern Recognition,Visual},
  number = {35},
  pmid = {26283375}
}

@article{gonzalez-sulser_nolan_2014,
  title = {{{GABAergic Projections}} from the {{Medial Septum Selectively Inhibit Interneurons}} in the {{Medial Entorhinal Cortex}}},
  author = {{Gonzalez-Sulser}, a. and Parthier, D and Candela, a. and McClure, C and Pastoll, H and Garden, D and Surmeli, G and Nolan, M F},
  year = {2014},
  month = dec,
  volume = {34},
  pages = {16739--16743},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.1612-14.2014},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L4X4YI2B\\Gonzalez-Sulser et al. - 2014 - GABAergic Projections from the Medial Septum Selectively Inhibit Interneurons in the Medial Entorhinal C.pdf},
  journal = {Journal of Neuroscience},
  keywords = {gamma,interneuron,lamina organization,medial entorhinal cortex,medial septum,theta},
  number = {50}
}

@article{goodroe_brown_2018,
  title = {The {{Complex Nature}} of {{Hippocampal}}-{{Striatal Interactions}} in {{Spatial Navigation}}},
  author = {Goodroe, Sarah C. and Starnes, Jon and Brown, Thackery I.},
  year = {2018},
  month = jun,
  volume = {12},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2018.00250},
  abstract = {Decades of research have established the importance of the hippocampus for episodic and spatial memory. In spatial navigation tasks, the role of the hippocampus has been classically juxtaposed with the role of the dorsal striatum, the latter of which has been characterized as a system important for implementing stimulus-response and action-outcome associations. In many neuroimaging paradigms, this has been explored through contrasting way finding and route-following behavior. The distinction between the contributions of the hippocampus and striatum to spatial navigation has been supported by extensive literature. Convergent research has also underscored the fact that these different memory systems can interact in dynamic ways and contribute to a broad range of navigational scenarios. For example, although familiar routes may often be navigable based on stimulus-response associations, hippocampal episodic memory mechanisms can also contribute to egocentric route-oriented memory, enabling recall of context-dependent sequences of landmarks or the actions to be made at decision points. Additionally, the literature has stressed the importance of subdividing the striatum into functional gradients\textemdash with more ventral and medial components being important for the behavioral expression of hippocampal-dependent spatial memories. More research is needed to reveal how networks involving these regions process and respond to dynamic changes in memory and control demands over the course of navigational events. In this Perspective article, we suggest that a critical direction for navigation research is to further characterize how hippocampal and striatal subdivisions interact in different navigational contexts.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5B3LTHP3\\Goodroe et al. - 2018 - The Complex Nature of Hippocampal-Striatal Interac.pdf},
  journal = {Frontiers in Human Neuroscience},
  language = {en}
}

@inproceedings{gorchetchnikov_carter_2011,
  title = {A {{Unified Learning Framework}} for {{Memristive Neuromorphic Hardware}}},
  booktitle = {Nternational {{Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  author = {Gorchetchnikov, Anatoli and Versace, Massimiliano and Ames, Heather and Chandler, Ben and L{\'e}veill{\'e}, Jasmin and Livitz, Gennady and Mingolla, Ennio and Snider, Gregory S and Amerson, Rick and Carter, Dick},
  year = {2011},
  abstract = {Realizing adaptive brain functions subserving perception, cognition, and motor behavior on biological temporal and spatial scales remains out of reach for even the fastest computers. Newly introduced memristive hardware approaches open the opportunity to implement dense, low-power synaptic memories of up to 1015 bits per square centimeter. Memristors have the unique property of ``remembering'' the past history of their stimulation in their resistive state and do not require power to maintain their memory, making them ideal candidates to implement large arrays of plastic synapses supporting learning in neural models. Over the past decades, many learning laws have been proposed in the literature to explain how neural activity shapes synaptic connections to support adaptive behavior. To ensure an optimal implementation of a large variety of learning laws in hardware, some general and easily parameterized form of learning law must be designed. This general form learning equation would allow instantiation of multiple learning laws through different parameterizations, without rewiring the hardware. This paper characterizes a subset of local learning laws amenable to implementation in memristive hardware. The analyzed laws belong to four broad classes: Hebb rule derivatives with various methods for gating learning and decay; Threshold rule variations including the covariance and BCM families; Input reconstruction-based learning rules; and Explicit temporal trace-based rules.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L6U84Q4U\\Gorchetchnikov et al. - 2011 - A Unified Learning Framework for Memristive Neuromorphic Hardware.pdf}
}

@phdthesis{gorchetchnikov_gorchetchnikov_2005,
  title = {A {{Model}} of {{Goal}}-{{Directed Spatial Navigation Based}} on {{Rodent Neurophysiological Data}}},
  author = {Gorchetchnikov, Anatoli},
  year = {2005},
  abstract = {This dissertation presents a biophysical model that combines evidence from neurophys- iological studies of goal-directed spatial navigation in the rat into a single algorithm based on bidirectional graph search. Application of this algorithm allows the model to simulate behavioral and neurophysiological data from rats performing memory-dependent spatial tasks. The behavioral component is represented as a virtual animal in a virtual environ? ment. The neurophysiological component is represented as a network of simulated neurons, which receives sensory input from the environment and directs the movement of the ani? mal. The binding of the physiology and behavior in the model allows several experimental phenomena to be addressed, such as (1) activities of the principal cells in the hippocampal area are correlated with an animal's position in space; (2) this positional information de? grades after a lesion that disconnects the hippocampus from the medial septum; (3) after lesions of the medial septum, reduction of hippocampal theta rhythm is correlated with an impairment in spatial tasks; (4) cells in the hippocampus tend to fire at a preferred phase of the theta cycle, and (5) the arrival of different inputs to the hippocampus corresponds to specific phases of the theta cycle. The model shows how these physiological properties allow such behavioral functions as successful navigation through various mazes towards a desired goal, selection of a goal on the basis of distance and salience, and reshaping its knowledge about the environment. The latter is based on a throughly analyzed spatially and tempo? rally local spike-timing-dependent synaptic modification rule. Four types of gated learning are compared in the context of simulated behavior. Presynaptic and dual OR (triggered by either presynaptic or postsynaptic activity) gatings are more noise tolerant and produce experience-dependent changes in place cell firing patterns shown experimentally. Postsy? naptic gating leads to a better competition between input patterns. Dual AND gating (based on the simultaneous presence of both presynaptic and postsynaptic activity) leads to stabilization of the network activity. Each of these gatings can be used to subserve different aspects of the exploratory behavior. The proposed model can be further extended to more general problem-solving based on classical graph search.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\33NSLS4V\\Gorchetchnikov - 2005 - A Model of Goal-Directed Spatial Navigation Based on Rodent Neurophysiological Data.pdf},
  school = {Boston University},
  type = {{{PhD Thesis}}}
}

@article{gorchetchnikov_grossberg_2007,
  title = {Space, Time and Learning in the Hippocampus: How Fine Spatial and Temporal Scales Are Expanded into Population Codes for Behavioral Control.},
  author = {Gorchetchnikov, Anatoli and Grossberg, Stephen},
  year = {2007},
  month = mar,
  volume = {20},
  pages = {182--193},
  issn = {0893-6080},
  doi = {10.1016/j.neunet.2006.11.007},
  abstract = {The hippocampus participates in multiple functions, including spatial navigation, adaptive timing and declarative (notably, episodic) memory. How does it carry out these particular functions? The present article proposes that hippocampal spatial and temporal processing are carried out by parallel circuits within entorhinal cortex, dentate gyrus and CA3 that are variations of the same circuit design. In particular, interactions between these brain regions transform fine spatial and temporal scales into population codes that are capable of representing the much larger spatial and temporal scales that are needed to control adaptive behaviors. Previous models of adaptively timed learning propose how a spectrum of cells tuned to brief but different delays are combined and modulated by learning to create a population code for controlling goal-oriented behaviors that span hundreds of milliseconds or even seconds. Here it is proposed how projections from entorhinal grid cells can undergo a similar learning process to create hippocampal place cells that can cover a space of many meters that are needed to control navigational behaviors. The suggested homology between spatial and temporal processing may clarify how spatial and temporal information may be integrated into an episodic memory. The model proposes how a path integration process activates a spatial map of grid cells. Path integration has a limited spatial capacity, and must be reset periodically, leading to the observed grid cell periodicity. Integration-to-map transformations have been proposed to exist in other brain systems. These include cortical mechanisms for numerical representation in the parietal cortex. As in the grid-to-place cell spatial expansion, the analog representation of number is extended by additional mechanisms to represent much larger numbers. The model also suggests how visual landmarks may influence grid cell activities via feedback projections from hippocampal place cells to the entorhinal cortex.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8MFWJXUA\\Gorchetchnikov, Grossberg - 2007 - Space, time and learning in the hippocampus how fine spatial and temporal scales are expanded into po.pdf},
  journal = {Neural networks : the official journal of the International Neural Network Society},
  keywords = {Animals,Behavior,Behavior: physiology,Hippocampus,Hippocampus: cytology,Hippocampus: physiology,Learning,Learning: physiology,Models,Neural Pathways,Neural Pathways: physiology,Neurological,Neurons,Neurons: physiology,Space Perception,Space Perception: physiology,Time Perception,Time Perception: physiology},
  number = {2},
  pmid = {17222533}
}

@article{gorchetchnikov_hasselmo_2005,
  title = {A Model of {{STDP}} Based on Spatially and Temporally Local Information: Derivation and Combination with Gated Decay.},
  author = {Gorchetchnikov, Anatoli and Versace, Massimiliano and Hasselmo, Michael E},
  year = {2005},
  volume = {18},
  pages = {458--466},
  issn = {0893-6080},
  doi = {10.1016/j.neunet.2005.06.019},
  abstract = {Temporal relationships between neuronal firing and plasticity have received significant attention in recent decades. Neurophysiological studies have shown the phenomenon of spike-timing-dependent plasticity (STDP). Various models were suggested to implement an STDP-like learning rule in artificial networks based on spiking neuronal representations. The rule presented here was developed under three constraints. First, it only depends on the information that is available at the synapse at the time of synaptic modification. Second, it naturally follows from neurophysiological and psychological research starting with Hebb's postulate [D. Hebb. (1949). The organization of behavior. Wiley, New York]. Third, it is simple, computationally cheap and its parameters are straightforward to determine. This rule is further extended by addition of four different types of gating derived from conventionally used types of gated decay in learning rules for continuous firing rate neural networks. The results show that the advantages of using these gatings are transferred to the new rule without sacrificing its dependency on spike-timing.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QHNITTYT\\Gorchetchnikov, Versace, Hasselmo - 2005 - A model of STDP based on spatially and temporally local information derivation and combinatio.pdf},
  journal = {Neural networks : the official journal of the International Neural Network Society},
  keywords = {Algorithms,Artificial Intelligence,Electrophysiology,Excitatory Postsynaptic Potentials,Ion Channel Gating,Ion Channel Gating: physiology,Models,Neural Networks (Computer),Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Statistical,Synapses,Synapses: physiology},
  number = {5-6},
  pmid = {16095878}
}

@article{gore_axel_2015,
  title = {Neural {{Representations}} of {{Unconditioned Stimuli}} in {{Basolateral Amygdala Mediate Innate}} and {{Learned Responses}}},
  author = {Gore, Felicity and Schwartz, Edmund C and Brangers, Baylor C and Aladi, Stanley and Stujenske, Joseph M and Likhtik, Ekaterina and Russo, Marco J and Gordon, Joshua A and Salzman, C Daniel and Axel, Richard},
  year = {2015},
  volume = {162},
  pages = {134--145},
  issn = {10974172},
  doi = {10.1016/j.cell.2015.06.027},
  abstract = {Stimuli that possess inherently rewarding or aversive qualities elicit emotional responses and also induce learning by imparting valence upon neutral sensory cues. Evidence has accumulated implicating the amygdala as a critical structure in mediating these processes. We have developed a genetic strategy to identify the representations of rewarding and aversive unconditioned stimuli (USs) in the basolateral amygdala (BLA) and have examined their role in innate and learned responses. Activation of an ensemble of US-responsive cells in the BLA elicits innate physiological and behavioral responses of different valence. Activation of this US ensemble can also reinforce appetitive and aversive learning when paired with differing neutral stimuli. Moreover, we establish that the activation of US-responsive cells in the BLA is necessary for the expression of a conditioned response. Neural representations of conditioned and unconditioned stimuli therefore ultimately connect to US-responsive cells in the BLA to elicit both innate and learned responses.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KIXVUH6M\\Gore et al. - 2015 - Neural Representations of Unconditioned Stimuli in Basolateral Amygdala Mediate Innate and Learned Responses.pdf},
  journal = {Cell},
  number = {1},
  pmid = {26140594}
}

@article{gosmann_gosmann_2016,
  title = {{{PLOS ONE Optimizing Semantic Pointer Representations}} for {{Symbol}}-like {{Processing}} in {{Spiking Neural Networks}}},
  author = {Gosmann, Jan},
  year = {2016},
  pages = {1--18},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0149928},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HN3UR2VW\\Gosmann - 2016 - PLOS ONE Optimizing Semantic Pointer Representations for Symbol-like Processing in Spiking Neural Networks.pdf}
}

@article{gosmann_gosmann_2018,
  title = {Vector-Derived Transformation Binding : {{An}} Improved Binding Operation for Deep Symbol-like Processing in Neural Networks},
  author = {Gosmann, Jan},
  year = {2018},
  pages = {1--21},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\H9AGCQ2C\\Gosmann and Eliasmith - 2019 - Vector-Derived Transformation Binding An Improved.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\T2FUGAWJ\\Gosmann - 2018 - Vector-derived transformation binding An improved binding operation for deep symbol-like processing in neural networks.pdf},
  number = {Gayler 2004}
}

@article{goudarzi_miller_2017,
  title = {Neuronal Rhythms Orchestrate Cell Assembles to Distinguish Perceptual Categories},
  author = {Goudarzi, Morteza Moazami and Cromer, Jason and Roy, Jefferson and Miller, Earl K},
  year = {2017},
  pages = {1--23},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\J9QY9YNC\\Goudarzi et al. - 2017 - Neuronal rhythms orchestrate cell assembles to distinguish perceptual categories.pdf}
}

@book{goulas_hilgetag_2018,
  title = {Cortical {{Gradients}} and {{Laminar Projections}} in {{Mammals}}},
  author = {Goulas, Alexandros and Zilles, Karl and Hilgetag, Claus C},
  year = {2018},
  volume = {41},
  doi = {10.1016/j.tins.2018.06.003},
  abstract = {A key component of current theories of brain structure and function is the layer-specific origin of structural connections of the cerebral cortex. This fundamental connectional feature pertains to different mammalian cortices, and recent neuroimaging advancements have started to pave the way for its function-based mapping in humans. Here, we propose a framework that systematically explains the characteristic layer-specific origin of structural connections and its graded variation across the cortical sheet and across mammalian species. The framework unifies seemingly dispersed observations on multiple levels of cortical organization, including the cellular, connectional, and functional level. Moreover, the framework allows the prediction of the layer-specific origin of connections in a spectrum of mammals, from rodents to humans.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SRLDNXWJ\\Goulas, Zilles, Hilgetag - 2018 - Cortical Gradients and Laminar Projections in Mammals.pdf},
  keywords = {comparative connectomics,Cortical connectivity,mammalian brain architecture,wiring principles},
  pmid = {29980393}
}

@article{gradinaru_deisseroth_2009,
  title = {Optical {{Deconstruction}} of {{Parkinsonian Neural Circuitry}}},
  author = {Gradinaru, Viviana and Mogri, Murtaza and Thompson, Kimberly R and Henderson, Jaimie M and Deisseroth, Karl},
  year = {2009},
  volume = {324},
  pages = {7},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\V3AFMT42\\Gradinaru et al. - 2009 - Optical Deconstruction of Parkinsonian Neural Circ.pdf},
  language = {en}
}

@article{gramfort_hamalainen_2013,
  title = {{{MEG}} and {{EEG}} Data Analysis with {{MNE}}-{{Python}}},
  author = {Gramfort, Alexandre and Luessi, Martin and Larson, Eric and Engemann, Denis A. and Strohmeier, Daniel and Brodbeck, Christian and Goj, Roman and Jas, Mainak and Brooks, Teon and Parkkonen, Lauri and H{\"a}m{\"a}l{\"a}inen, Matti},
  year = {2013},
  volume = {7},
  pages = {1--13},
  issn = {1662453X},
  doi = {10.3389/fnins.2013.00267},
  abstract = {Magnetoencephalography and electroencephalography (M/EEG) measure the weak electromagnetic signals generated by neuronal activity in the brain. Using these signals to characterize and locate neural activation in the brain is a challenge that requires expertise in physics, signal processing, statistics, and numerical methods. As part of the MNE software suite, MNE-Python is an open-source software package that addresses this challenge by providing state-of-the-art algorithms implemented in Python that cover multiple methods of data preprocessing, source localization, statistical analysis, and estimation of functional connectivity between distributed brain regions. All algorithms and utility functions are implemented in a consistent manner with well-documented interfaces, enabling users to create M/EEG data analysis pipelines by writing Python scripts. Moreover, MNE-Python is tightly integrated with the core Python libraries for scientific comptutation (NumPy, SciPy) and visualization (matplotlib and Mayavi), as well as the greater neuroimaging ecosystem in Python via the Nibabel package. The code is provided under the new BSD license allowing code reuse, even in commercial products. Although MNE-Python has only been under heavy development for a couple of years, it has rapidly evolved with expanded analysis capabilities and pedagogical tutorials because multiple labs have collaborated during code development to help share best practices. MNE-Python also gives easy access to preprocessed datasets, helping users to get started quickly and facilitating reproducibility of methods by other researchers. Full documentation, including dozens of examples, is available at http://martinos.org/mne.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BUGK7QVJ\\Gramfort et al. - 2013 - MEG and EEG data analysis with MNE-Python.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\QUX7EYAD\\Gramfort - 2013 - MEG and EEG data analysis with MNE-Python.pdf},
  journal = {Frontiers in Neuroscience},
  keywords = {Electroencephalography (EEG),Magnetoencephalography (MEG),Neuroimaging,Open-source,Python,Software},
  number = {7 DEC},
  pmid = {24431986}
}

@article{grant_itti_2017,
  title = {Biologically Plausible Learning in Neural Networks with Modulatory Feedback},
  author = {Grant, W. Shane and Tanner, James and Itti, Laurent},
  year = {2017},
  volume = {88},
  pages = {32--48},
  issn = {18792782},
  doi = {10.1016/j.neunet.2017.01.007},
  abstract = {Although Hebbian learning has long been a key component in understanding neural plasticity, it has not yet been successful in modeling modulatory feedback connections, which make up a significant portion of connections in the brain. We develop a new learning rule designed around the complications of learning modulatory feedback and composed of three simple concepts grounded in physiologically plausible evidence. Using border ownership as a prototypical example, we show that a Hebbian learning rule fails to properly learn modulatory connections, while our proposed rule correctly learns a stimulus-driven model. To the authors' knowledge, this is the first time a border ownership network has been learned. Additionally, we show that the rule can be used as a drop-in replacement for a Hebbian learning rule to learn a biologically consistent model of orientation selectivity, a network which lacks any modulatory connections. Our results predict that the mechanisms we use are integral for learning modulatory connections in the brain and furthermore that modulatory connections have a strong dependence on inhibition.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RBSWI5KA\\Grant, Tanner, Itti - 2017 - Biologically plausible learning in neural networks with modulatory feedback.pdf},
  journal = {Neural Networks},
  keywords = {Border ownership,Computational modeling,Feedback,Modulatory,Plasticity,Self-organization}
}

@article{graves_danihelka_2014,
  title = {Neural {{Turing Machines}}},
  author = {Graves, Alex and Wayne, Greg and Danihelka, Ivo},
  year = {2014},
  pages = {1--26},
  abstract = {We extend the capabilities of neural networks by coupling them to external memory re-sources, which they can interact with by attentional processes. The combined system is analogous to a Turing Machine or Von Neumann architecture but is differentiable end-to-end, allowing it to be efficiently trained with gradient descent. Preliminary results demon-strate that Neural Turing Machines can infer simple algorithms such as copying, sorting, and associative recall from input and output examples.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5RQNTRCK\\Graves, Wayne, Danihelka - 2014 - Neural Turing Machines.pdf},
  journal = {Arxiv}
}

@article{gregoriou_desimone_2009,
  title = {High-{{Frequency}}, {{Long}}-{{Range Coupling Between Prefrontal}} and {{Visual Cortex During Attention}}},
  author = {Gregoriou, G. G. and Gotts, S. J. and Zhou, H. and Desimone, R.},
  year = {2009},
  month = may,
  volume = {324},
  pages = {1207--1210},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1171402},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\C3NS67V5\\Gregoriou et al. - 2009 - High-Frequency, Long-Range Coupling Between Prefro.pdf},
  journal = {Science},
  language = {en},
  number = {5931}
}

@article{gregoryhickok_davidpoeppel_2007,
  title = {The Cortical Organization of Speech Processing},
  author = {{Gregory Hickok} and {David Poeppel}},
  year = {2007},
  volume = {8},
  pages = {393--402},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\R2VGHQFY\\Gregory Hickok, David Poeppel - 2007 - The cortical organization of speech processing.pdf},
  journal = {Nature Reviews (Neuroscience)},
  number = {May}
}

@article{grieves_jeffery_2017,
  title = {The Representation of Space in the Brain},
  author = {Grieves, Roddy M. and Jeffery, Kate J.},
  year = {2017},
  month = feb,
  volume = {135},
  pages = {113--131},
  issn = {03766357},
  doi = {10.1016/j.beproc.2016.12.012},
  abstract = {Animals can navigate vast distances and often display behaviours or activities that indicate a detailed, internal spatial representation of their surrounding environment or a `cognitive map'. Over a century of behavioural research on spatial navigation in humans and animals has greatly increased our understanding of how this highly complex feat is achieved. In turn this has inspired half a century of electrophysiological spatial navigation and memory research which has further advanced our understanding of the brain. In particular, three functional cell types have been suggested to underlie cognitive mapping processes; place cells, head direction cells and grid cells. However, there are numerous other spatially modulated neurons in the brain. For a more complete understanding of the electrophysiological systems and behavioural processes underlying spatial navigation we must also examine these lesser understood neurons. In this review we will briefly summarise the literature surrounding place cells, head direction cells, grid cells and the evidence that these cells collectively form the neural basis of a cognitive map. We will then review literature covering many other spatially modulated neurons in the brain that perhaps further augment this cognitive map.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RAQMIDVQ\\Grieves and Jeffery - 2017 - The representation of space in the brain.pdf},
  journal = {Behavioural Processes},
  language = {en}
}

@article{griffiths_yuille_2006,
  title = {Technical {{Introduction}} : {{A}} Primer on Probabilistic Inference},
  author = {Griffiths, Thomas L and Yuille, Alan},
  year = {2006},
  pages = {19--25},
  doi = {10.1093/acprof:oso/9780199216093.003.0002},
  abstract = {Research in computer science, engineering, mathematics and statistics has produced a variety of tools that are useful in developing probabilistic models of human cognition. We provide an introduction to the principles of probabilistic inference that are used in the papers appearing in this special issue. We lay out the basic principles that underlie probabilistic models in detail, and then briefly survey some of the tools that can be used in applying these models to human cognition.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PS69SXT6\\Griffiths, Yuille - 2006 - Technical Introduction A primer on probabilistic inference.pdf},
  journal = {Trends in cognitive sciences},
  number = {Mcmc}
}

@incollection{grossberg_grossberg_1973,
  title = {Contour Enhancement, Short Term Memory, and Constancies in Reverberating Neural Networks},
  booktitle = {Studies in {{Applied Mathematics}}},
  author = {Grossberg, S},
  year = {1973},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YAFJWD6G\\Grossberg - 1973 - Contour enhancement, short term memory, and constancies in reverberating neural networks.pdf}
}

@incollection{grossberg_grossberg_1976,
  title = {Adaptive Pattern Classification and Universal Recoding},
  booktitle = {Biological Cybernetics},
  author = {Grossberg, Stephen},
  year = {1976},
  volume = {23},
  pages = {121--134},
  abstract = {This paper analyses a model for the parallel development of adult coding of neural feature detectors. The model was introduced in Grossberg (1976). We show how experience can retune feature detectors to respond to a prescribed convex set of spatial patterns. In particular the detectors automatically respond to aerage features chosen from the set even if the average features have bever been experienced. Using this procedure, any set of arbitraty spatial patterns can be recoded, or transformed, into any other spatial patterns (universal recoding), if there are sufficiently many cells in the network's cortex. The network is built from short term memory and long term memory mechanisms, including mechanisms of adaptation, filtering, contrast enhanceent, tuning and nonspecific arousal. These mechanisms capture some experimental properties of plasticity in the kitten visual cortex. The model also suggests a classification of adult feature detector properties in terms of a small number of functional principles. In particular, experiments on retinal dynamics, including amacrine cell function, are suggested.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HN4A5R39\\Grossberg - 1976 - Adaptive pattern classification and universal recoding.pdf}
}

@incollection{grossberg_grossberg_1980,
  title = {Appendix {{C}}},
  booktitle = {How Does the {{Brain Build}} a {{Cognitive Code}}},
  author = {Grossberg, Stephen},
  year = {1980},
  pages = {394--396},
  abstract = {This section summarizes how feedforward competitive interactions solve the saturdation problem using automatic grain control by inhibitory signals, and how properties such as noise suppression, pattern matchine, edge enchangement, and spatial frequency sensitivity follow as special cases.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6KS63452\\Grossberg - 1980 - Appendix C.pdf}
}

@incollection{grossberg_grossberg_1980a,
  title = {Appendix {{B}}},
  booktitle = {How Does the {{Brain Build}} a {{Cognitive Code}}},
  author = {Grossberg, Stephen},
  year = {1980},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WEQVMN4P\\Grossberg - 1980 - Appendix B.pdf}
}

@article{grossberg_grossberg_1980b,
  title = {How Does a Brain Build a Cognitive Code?},
  author = {Grossberg, S},
  year = {1980},
  month = jan,
  volume = {87},
  pages = {1--51},
  issn = {0033-295X},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ESBMIMXM\\Grossberg - 1980 - How does a brain build a cognitive code.pdf},
  journal = {Psychological review},
  keywords = {Animals,Arousal,Arousal: physiology,Brain,Brain: physiology,Cerebral,Cerebral: physiology,Cognition,Cognition: physiology,Conditioning (Psychology),Conditioning (Psychology): physiology,Dominance,Feedback,Humans,Perception,Perception: physiology},
  number = {1},
  pmid = {7375607}
}

@article{grossberg_grossberg_2014,
  title = {From Brain Synapses to Systems for Learning and Memory: {{Object}} Recognition, Spatial Navigation, Timed Conditioning, and Movement Control},
  author = {Grossberg, Stephen},
  year = {2014},
  month = nov,
  pages = {1--24},
  issn = {00068993},
  doi = {10.1016/j.brainres.2014.11.018},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XQNTMMUX\\Grossberg - 2014 - From brain synapses to systems for learning and memory Object recognition, spatial navigation, timed conditioning, an.pdf},
  journal = {Brain Research},
  keywords = {Attention,Autism,Category learning,Cognitive working memory,Eye movement,Grid cell,Laminar cortical circuits,Learning,Medial temporal amnesia,Memory,mGluR,Place cell,Predictive remapping,Spatial navigation,Speech perception,Time cell}
}

@article{grossberg_grossberg_2018,
  title = {Desirability, Availability, Credit Assignment, Category Learning, and Attention: {{Cognitive}}-Emotional and Working Memory Dynamics of Orbitofrontal, Ventrolateral, and Dorsolateral Prefrontal Cortices},
  author = {Grossberg, Stephen},
  year = {2018},
  volume = {2},
  pages = {239821281877217},
  issn = {2398-2128},
  doi = {10.1177/2398212818772179},
  abstract = {Background:The prefrontal cortices play an essential role in cognitive-emotional and working memory processes through interactions with multiple brain regions.Methods:This article further develops a unified neural architecture that explains many recent and classical data about prefrontal function and makes testable predictions.Results:Prefrontal properties of desirability, availability, credit assignment, category learning, and feature-based attention are explained. These properties arise through interactions of orbitofrontal, ventrolateral prefrontal, and dorsolateral prefrontal cortices with the inferotemporal cortex, perirhinal cortex, parahippocampal cortices; ventral bank of the principal sulcus, ventral prearcuate gyrus, frontal eye fields, hippocampus, amygdala, basal ganglia, hypothalamus, and visual cortical areas V1, V2, V3A, V4, middle temporal cortex, medial superior temporal area, lateral intraparietal cortex, and posterior parietal cortex. Model explanations also include how the value of vis...},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\73QDUFXP\\Grossberg - 2018 - Desirability, availability, credit assignment, category learning, and attention Cognitive-emotional and working memor.pdf},
  journal = {Brain and Neuroscience Advances},
  keywords = {amygdala,basal ganglia,Category learning,cognitive-emotional interactions,contextual cueing,dorsolateral prefrontal cortex,frontal eye fields,incentive motivational learning,inferotemporal cortex,orbitofrontal cortex,parahippocampal cortex,perirhinal cortex,reinforcement learning,ventral bank of the principal sulcus,ventral prearcuate gyrus,ventrolateral prefrontal cortex,working-memory}
}

@article{grossberg_grossberg_2019,
  title = {The {{Embodied Brain}} of {{SOVEREIGN2}}: {{From Space}}-{{Variant Conscious Percepts During Visual Search}} and {{Navigation}} to {{Learning Invariant Object Categories}} and {{Cognitive}}-{{Emotional Plans}} for {{Acquiring Valued Goals}}},
  shorttitle = {The {{Embodied Brain}} of {{SOVEREIGN2}}},
  author = {Grossberg, Stephen},
  year = {2019},
  month = jun,
  volume = {13},
  issn = {1662-5188},
  doi = {10.3389/fncom.2019.00036},
  abstract = {This article develops a model of how reactive and planned behaviors interact in real time. Controllers for both animals and animats need reactive mechanisms for exploration, and learned plans to efficiently reach goal objects once an environment becomes familiar. The SOVEREIGN model embodied these capabilities, and was tested in a 3D virtual reality environment. Neural models have characterized important adaptive and intelligent processes that were not included in SOVEREIGN. A major research program is summarized herein by which to consistently incorporate them into an enhanced model called SOVEREIGN2. Key new perceptual, cognitive, cognitive-emotional, and navigational processes require feedback networks which regulate resonant brain states that support conscious experiences of seeing, feeling, and knowing. Also included are computationally complementary processes of the mammalian neocortical What and Where processing streams, and homologous mechanisms for spatial navigation and arm movement control. These include: Unpredictably moving targets are tracked using coordinated smooth pursuit and saccadic movements. Estimates of target and present position are computed in the Where stream, and can activate approach movements. Motion cues can elicit orienting movements to bring new targets into view. Cumulative movement estimates are derived from visual and vestibular cues. Arbitrary navigational routes are incrementally learned as a labeled graph of angles turned and distances traveled between turns. Noisy and incomplete visual sensor data are transformed into representations of visual form and motion. Invariant recognition categories are learned in the What stream. Sequences of invariant object categories are stored in a cognitive working memory, whereas sequences of movement positions and directions are stored in a spatial working memory. Stored sequences trigger learning of cognitive and spatial/motor sequence categories or plans, also called list chunks, which control planned decisions and movements toward valued goal objects. Predictively successful list chunk combinations are selectively enhanced or suppressed via reinforcement learning and incentive motivational learning. Expected vs. unexpected event disconfirmations regulate these enhancement and suppressive processes. Adaptively timed learning enables attention and action to match task constraints. Social cognitive joint attention enables imitation learning of skills by learners who observe teachers from different spatial vantage points.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RLG5WD3C\\Grossberg_2019_The Embodied Brain of SOVEREIGN2.pdf},
  journal = {Frontiers in Computational Neuroscience},
  pmcid = {PMC6620614},
  pmid = {31333437}
}

@article{grossberg_grossberg_2020,
  title = {Developmental {{Designs}} and {{Adult Functions}} of {{Cortical Maps}} in {{Multiple Modalities}}: {{Perception}}, {{Attention}}, {{Navigation}}, {{Numbers}}, {{Streaming}}, {{Speech}}, and {{Cognition}}},
  shorttitle = {Developmental {{Designs}} and {{Adult Functions}} of {{Cortical Maps}} in {{Multiple Modalities}}},
  author = {Grossberg, Stephen},
  year = {2020},
  month = feb,
  volume = {14},
  pages = {4},
  issn = {1662-5196},
  doi = {10.3389/fninf.2020.00004},
  abstract = {This article unifies neural modeling results that illustrate several basic design principles and mechanisms that are used by advanced brains to develop cortical maps with multiple psychological functions. One principle concerns how brains use a strip map that simultaneously enables one feature to be represented throughout its extent, as well as an ordered array of another feature at different positions of the strip. Strip maps include circuits to represent ocular dominance and orientation columns, placevalue numbers, auditory streams, speaker-normalized speech, and cognitive working memories that can code repeated items. A second principle concerns how feature detectors for multiple functions develop in topographic maps, including maps for optic flow navigation, reinforcement learning, motion perception, and category learning at multiple organizational levels. A third principle concerns how brains exploit a spatial gradient of cells that respond at an ordered sequence of different rates. Such a rate gradient is found along the dorsoventral axis of the entorhinal cortex, whose lateral branch controls the development of time cells, and whose medial branch controls the development of grid cells. Populations of time cells can be used to learn how to adaptively time behaviors for which a time interval of hundreds of milliseconds, or several seconds, must be bridged, as occurs during trace conditioning. Populations of grid cells can be used to learn hippocampal place cells that represent the large spaces in which animals navigate. A fourth principle concerns how and why all neocortical circuits are organized into layers, and how functionally distinct columns develop in these circuits to enable map development. A final principle concerns the role of Adaptive Resonance Theory top-down matching and attentional circuits in the dynamic stabilization of early development and adult learning. Cortical maps are modeled in visual, auditory, temporal, parietal, prefrontal, entorhinal, and hippocampal cortices.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MZ5NWF85\\Grossberg - 2020 - Developmental Designs and Adult Functions of Corti.pdf},
  journal = {Frontiers in Neuroinformatics},
  language = {en}
}

@article{grossberg_levine_1975,
  title = {Some Developmental and Attentional Biases in the Contrast Enhancement and Short Term Memory of Recurrent Neural Networks},
  author = {Grossberg, Stephen and Levine, Daniel},
  year = {1975},
  volume = {53},
  pages = {341--380},
  abstract = {This paper studies the global dynamics of neurons, or neuron populations, in a recurrent on-center off-surround anatomy undergoing nonlinear shunting interactions. In such an anatomy, a given population excites itself and inhibits other populations. The interactions are defined by multiplicative mass action laws. Grossberg (1973) studied the case in which all populations have the same weight (or total number of unit cell sites). Here the effect of an arbitrary distribution of population weights is studied; each set of populations with equal weight is called a subfield. Possible causes of variable population weights are developmental biases (eg: whic feature detectors are represented in a field), attentional changes (eg: which features are relevant at any time), and statistical errors in network design. Such factors can bias the totla field towards accentuating or suppressing in shirt-term memory a given subield of sensory features. In particular, a maehcanism is noted for su[[ressing the activity of populations whose trigger features are infequently experienced by the network. These variables interact with the reccurent on-center off-surround interactions, that have previously been shown capable of contrast enhancing significant input information, sustaining this information in short-term memory, adapting the field's total activity while producing multistable equilibrium points of this activity, suppressing noise , and preventing saturation of population response even to input patterns whose intensities are high.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\W3U4XVFJ\\Grossberg, Levine - 1975 - Some developmental and attentional biases in the contrast enhancement and short term memory of recurrent neur.pdf},
  journal = {Journal of Theoretical Biology}
}

@article{gruber_ranganath_2019,
  title = {How {{Curiosity Enhances Hippocampus}}-{{Dependent Memory}}: {{The Prediction}}, {{Appraisal}}, {{Curiosity}}, and {{Exploration}} ({{PACE}}) {{Framework}}},
  shorttitle = {How {{Curiosity Enhances Hippocampus}}-{{Dependent Memory}}},
  author = {Gruber, Matthias J. and Ranganath, Charan},
  year = {2019},
  month = dec,
  volume = {23},
  pages = {1014--1025},
  issn = {13646613},
  doi = {10.1016/j.tics.2019.10.003},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XPTVJIIF\\Gruber and Ranganath - 2019 - How Curiosity Enhances Hippocampus-Dependent Memor.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {12}
}

@article{gudowska-nowak_tarnowski_2020,
  title = {From {{Synaptic Interactions}} to {{Collective Dynamics}} in {{Random Neuronal Networks Models}}: {{Critical Role}} of {{Eigenvectors}} and {{Transient Behavior}}},
  shorttitle = {From {{Synaptic Interactions}} to {{Collective Dynamics}} in {{Random Neuronal Networks Models}}},
  author = {{Gudowska-Nowak}, E. and Nowak, M. A. and Chialvo, D. R. and Ochab, J. K. and Tarnowski, W.},
  year = {2020},
  month = feb,
  volume = {32},
  pages = {395--423},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/neco_a_01253},
  abstract = {The study of neuronal interactions is at the center of several big collaborative neuroscience projects (including the Human Connectome Project, the Blue Brain Project, and the Brainome) that attempt to obtain a detailed map of the entire brain. Under certain constraints, mathematical theory can advance predictions of the expected neural dynamics based solely on the statistical properties of the synaptic interaction matrix. This work explores the application of free random variables to the study of large synaptic interaction matrices. Besides recovering in a straightforward way known results on eigenspectra in types of models of neural networks proposed by Rajan and Abbott ( 2006 ), we extend them to heavy-tailed distributions of interactions. More important, we analytically derive the behavior of eigenvector overlaps, which determine the stability of the spectra. We observe that on imposing the neuronal excitation/inhibition balance, despite the eigenvalues remaining unchanged, their stability dramatically decreases due to the strong nonorthogonality of associated eigenvectors. This leads us to the conclusion that understanding the temporal evolution of asymmetric neural networks requires considering the entangled dynamics of both eigenvectors and eigenvalues, which might bear consequences for learning and memory processes in these models. Considering the success of free random variables theory in a wide variety of disciplines, we hope that the results presented here foster the additional application of these ideas in the area of brain sciences.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9WDRTYMF\\Gudowska-Nowak et al. - 2020 - From Synaptic Interactions to Collective Dynamics .pdf},
  journal = {Neural Computation},
  language = {en},
  number = {2}
}

@article{gudwin_raizer_2017,
  title = {The {{Multipurpose Enhanced Cognitive Architecture}} ({{MECA}})},
  author = {Gudwin, Ricardo and Paraense, Andr{\'e} and {de Paula}, Suelen M. and Fr{\'o}es, Eduardo and Gibaut, Wandemberg and Castro, Elisa and Figueiredo, Vera and Raizer, Klaus},
  year = {2017},
  month = oct,
  volume = {22},
  pages = {20--34},
  issn = {2212683X},
  doi = {10.1016/j.bica.2017.09.006},
  abstract = {In this paper, we present an introduction to MECA, the Multipurpose Enhanced Cognitive Architecture, a cognitive architecture developed by our research group and implemented in the Java language. MECA was designed based on many ideas coming from Dual Process Theory, Dynamic Subsumption, Conceptual Spaces and Grounded Cognition, and constructed using CST, a toolkit for the construction of cognitive architectures in Java, also developed by our group. Basically MECA promotes an hybridism of SOAR, used to implement rule-based processing and space-state exploration in System 2 modules, with a Dynamic Subsumption Motivational System performing the role of System 1, using a representational system based on conceptual spaces and grounded cognition. We review the conceptual background used on MECA and further provide a detailed description of the many MECA sub-systems.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZKZ62F2D\\Gudwin et al. - 2017 - The Multipurpose Enhanced Cognitive Architecture (.pdf},
  journal = {Biologically Inspired Cognitive Architectures},
  language = {en}
}

@article{guenther_johnson_1998,
  title = {A {{Theoretical Investigation}} of {{Reference Frames}} for the {{Planning}} of {{Speech Movements}}},
  author = {Guenther, Frank H. and Hampson, Michelle and Johnson, Dave},
  year = {1998},
  issn = {0033295X},
  doi = {10.1037/0033-295X.105.4.611-633},
  abstract = {Does the speech motor control system use invariant vocal tract shape targets when producing vowels and semivowels? A 4-part theoretical treatment favoring models whose only invariant targets are regions in auditory perceptual space over models that posit invariant constriction targets is presented. Auditory target regions are hypothesized to arise during development as an emergent property of neural map formation in the auditory system. Furthermore, speech movements are planned as trajectories in auditory perceptual space. These trajectories are then mapped into articulator movements through a neural mapping that allows motor equivalent variability in constriction locations and degrees when needed. These hypotheses are illustrated using computer simulations of the DIVA model of speech acquisition and production. Finally, several difficult challenges to proponents of constriction theories based on this theoretical treatment are posed.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KP2D4G9F\\Guenther, Hampson, Johnson - 1998 - A Theoretical Investigation of Reference Frames for the Planning of Speech Movements.pdf},
  journal = {Psychological Review},
  pmid = {9830375}
}

@article{guest_love_2019,
  title = {Levels of {{Representation}} in a {{Deep Learning Model}} of {{Categorization}}},
  author = {Guest, Olivia and Love, Bradley C.},
  year = {2019},
  month = may,
  pages = {626374},
  doi = {10.1101/626374},
  abstract = {{$<$}p{$>$}Deep convolutional neural networks (DCNNs) rival humans in object recognition. The layers (or levels of representation) in DCNNs have been successfully aligned with processing stages along the ventral stream for visual processing. Here, we propose a model of concept learning that uses visual representations from these networks to build memory representations of novel categories, which may rely on the medial temporal lobe (MTL) and medial prefrontal cortex (mPFC). Our approach opens up two possibilities: a) formal investigations can involve photographic stimuli as opposed to stimuli handcrafted and coded by the experimenter; b) model comparison can determine which level of representation within a DCNN a learner is using during categorization decisions. Pursuing the latter point, DCNNs suggest that the shape bias in children relies on representations at more advanced network layers whereas a learner that relied on lower network layers would display a color bias. These results confirm the role of natural statistics in the shape bias (i.e., shape is predictive of category membership) while highlighting that the type of statistics matter, i.e., those from lower or higher levels of representation. We use the same approach to provide evidence that pigeons performing seemingly sophisticated categorization of complex imagery may in fact be relying on representations that are very low-level (i.e., retinotopic). Although complex features, such as shape, relatively predominate at more advanced network layers, even simple features, such as spatial frequency and orientation, are better represented at the more advanced layers, contrary to a standard hierarchical view.{$<$}/p{$>$}},
  copyright = {\textcopyright{} 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\327UA3ND\\Guest_Love_2019_Levels of Representation in a Deep Learning Model of Categorization.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\EC5TALNR\\626374v2.html},
  journal = {bioRxiv},
  language = {en}
}

@article{guestrin_guestrin_2007,
  title = {{{VC Dimension}}},
  author = {Guestrin, Carlos},
  year = {2007},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FV5EIX7T\\Guestrin - 2007 - VC Dimension.pdf}
}

@article{gulli_martinez-trujillo_2020,
  title = {Context-Dependent Representations of Objects and Space in the Primate Hippocampus during Virtual Navigation},
  author = {Gulli, Roberto A. and Duong, Lyndon R. and Corrigan, Benjamin W. and Doucet, Guillaume and Williams, Sylvain and Fusi, Stefano and {Martinez-Trujillo}, Julio C.},
  year = {2020},
  month = jan,
  volume = {23},
  pages = {103--112},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-019-0548-3},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9GCCIZ2F\\Gulli et al. - 2020 - Context-dependent representations of objects and s.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\L9DZJ95Y\\Gulli et al. - 2020 - Context-dependent representations of objects and s.pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {1}
}

@article{guo_berkhahn_2016,
  title = {Entity {{Embeddings}} of {{Categorical Variables}}},
  author = {Guo, Cheng and Berkhahn, Felix},
  year = {2016},
  issn = {15505499},
  doi = {10.1109/ICCV.2017.324},
  abstract = {We map categorical variables in a function approximation problem into Euclidean spaces, which are the entity embeddings of the categorical variables. The mapping is learned by a neural network during the standard supervised training process. Entity embedding not only reduces memory usage and speeds up neural networks compared with one-hot encoding, but more importantly by mapping similar values close to each other in the embedding space it reveals the intrinsic properties of the categorical variables. We applied it successfully in a recent Kaggle competition and were able to reach the third position with relative simple features. We further demonstrate in this paper that entity embedding helps the neural network to generalize better when the data is sparse and statistics is unknown. Thus it is especially useful for datasets with lots of high cardinality features, where other methods tend to overfit. We also demonstrate that the embeddings obtained from the trained neural network boost the performance of all tested machine learning methods considerably when used as the input features instead. As entity embedding defines a distance measure for categorical variables it can be used for visualizing categorical data and for data clustering.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NFR2ND2X\\Guo, Berkhahn - 2016 - Entity Embeddings of Categorical Variables.pdf},
  journal = {arXiv},
  pmid = {23766329}
}

@article{guo_chen_2019,
  title = {Hierarchical {{Bayesian Inference}} and {{Learning}} in {{Spiking Neural Networks}}},
  author = {Guo, S. and Yu, Z. and Deng, F. and Hu, X. and Chen, F.},
  year = {2019},
  month = jan,
  volume = {49},
  pages = {133--145},
  issn = {2168-2267},
  doi = {10.1109/TCYB.2017.2768554},
  abstract = {Numerous experimental data from neuroscience and psychological science suggest that human brain utilizes Bayesian principles to deal the complex environment. Furthermore, hierarchical Bayesian inference has been proposed as an appropriate theoretical framework for modeling cortical processing. However, it remains unknown how such a computation is organized in the network of biologically plausible spiking neurons. In this paper, we propose a hierarchical network of winner-take-all circuits which can carry out hierarchical Bayesian inference and learning through a spike-based variational expectation maximization (EM) algorithm. Particularly, we show how the firing activities of spiking neurons in response to the input stimuli and the spike-timing-dependent plasticity rule can be understood, respectively, as variational E-step and M-step of variational EM. Finally, we demonstrate the utility of this spiking neural network on the MNIST benchmark for unsupervised classification of handwritten digits.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\52JVQIDS\\Guo et al_2019_Hierarchical Bayesian Inference and Learning in Spiking Neural Networks.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\VG55RNUF\\8101517.html},
  journal = {IEEE Transactions on Cybernetics},
  number = {1}
}

@article{guo_munos_2018,
  title = {Neural {{Predictive Belief Representations}}},
  author = {Guo, Zhaohan Daniel and Azar, Mohammad Gheshlaghi and Piot, Bilal and Pires, Bernardo A and Pohlen, Toby and Munos, R{\'e}mi},
  year = {2018},
  doi = {arXiv:1811.06407v1},
  abstract = {Unsupervised representation learning has succeeded with excellent results in many applications. It is an especially powerful tool to learn a good representation of environments with partial or noisy observations. In partially observable domains it is important for the representation to encode a belief state, a sufficient statistic of the observations seen so far. In this paper, we investigate whether it is possible to learn such a belief representation using modern neural architectures. Specifically, we focus on one-step frame prediction and two variants of contrastive predictive coding (CPC) as the objective functions to learn the representations. To evaluate these learned representations, we test how well they can predict various pieces of information about the underlying state of the environment, e.g., position of the agent in a 3D maze. We show that all three methods are able to learn belief representations of the environment, they encode not only the state information, but also its uncertainty, a crucial aspect of belief states. We also find that for CPC multi-step predictions and action-conditioning are critical for accurate belief representations in visually complex environments. The ability of neural representations to capture the belief information has the potential to spur new advances for learning and planning in partially observable domains, where leveraging uncertainty is essential for optimal decision making.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CVRMRCPJ\\Daniel et al. - Unknown - NEURAL PREDICTIVE BELIEF REPRESENTATIONS.pdf}
}

@article{gupta_hasselmo_2014,
  title = {Medial Entorhinal Grid Cells and Head Direction Cells Rotate with a {{T}}-Maze More Often during Less Recently Experienced Rotations},
  author = {Gupta, Kishan and Beer, Nathan J and Keller, Lauren A and Hasselmo, Michael E},
  year = {2014},
  volume = {24},
  pages = {1630--1644},
  issn = {14602199},
  doi = {10.1093/cercor/bht020},
  abstract = {Prior studies of head direction (HD) cells indicate strong landmark control over the preferred firing direction of these cells, with few studies exhibiting shifts away from local reference frames over time. We recorded spiking activity of grid and HD cells in the medial entorhinal cortex of rats, testing correlations of local environmental cues with the spatial tuning curves of these cells' firing fields as animals performed continuous spatial alternation on a T-maze that shared the boundaries of an open-field arena. The environment was rotated into configurations the animal had either seen or not seen in the past recording week. Tuning curves of both cell types demonstrated commensurate shifts of tuning with T-maze rotations during less recent rotations, more so than recent rotations. This strongly suggests that animals are shifting their reference frame away from the local environmental cues over time, learning to use a different reference frame more likely reliant on distal or idiothetic cues. In addition, grid fields demonstrated varying levels of "fragmentation" on the T-maze. The propensity for fragmentation does not depend on grid spacing and grid score, nor animal trajectory, indicating the cognitive treatment of environmental subcompartments is likely driven by task demands.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LIAXPZ9J\\Gupta et al. - 2014 - Medial entorhinal grid cells and head direction cells rotate with a T-maze more often during less recently experie.pdf},
  journal = {Cerebral Cortex},
  keywords = {Entorhinal cortex,Experience,Fragmentation,Grid cells,Head direction cells},
  number = {6},
  pmid = {23382518}
}

@article{gutierrez_gutierrez_2019,
  title = {Population Adaptation in Efficient Balanced Networks},
  author = {Gutierrez, Gabrielle J},
  year = {2019},
  pages = {17},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GIV4U6FE\\Gutierrez - Population adaptation in efficient balanced networ.pdf},
  language = {en}
}

@article{gutig_gutig_2016,
  title = {Spiking Neurons Can Discover Predictive Features by Aggregate-Label Learning},
  author = {Gutig, R.},
  year = {2016},
  month = mar,
  volume = {351},
  pages = {aab4113-aab4113},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aab4113},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\25K3WBSP\\Gutig - 2016 - Spiking neurons can discover predictive features b.pdf},
  journal = {Science},
  language = {en},
  number = {6277}
}

@article{guzman_jonas_2016,
  title = {Synaptic Mechanisms of Pattern Completion in the Hippocampal {{CA3}} Network},
  author = {Guzman, Segundo J and Schlogl, A and Frotscher, Michael and Jonas, Peter},
  year = {2016},
  month = sep,
  volume = {353},
  pages = {1117--1123},
  issn = {0036-8075},
  doi = {10.1126/science.aaf1836},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8CWWXVZ2\\Guzman et al. - 2016 - Synaptic mechanisms of pattern completion in the hippocampal CA3 network.pdf},
  journal = {Science},
  number = {6304},
  pmid = {27609885}
}

@article{haber_haber_2016,
  title = {Corticostriatal Circuitry},
  author = {Haber, Suzanne N},
  year = {2016},
  volume = {18},
  pages = {15},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\E3ALD83F\\Haber - 2016 - Corticostriatal circuitry.pdf},
  journal = {Dialogues in Clinical Neuroscience},
  language = {en},
  number = {1}
}

@article{haegens_jensen_2011,
  title = {-{{Oscillations}} in the Monkey Sensorimotor Network Influence Discrimination Performance by Rhythmical Inhibition of Neuronal Spiking},
  author = {Haegens, S. and Nacher, V. and Luna, R. and Romo, R. and Jensen, O.},
  year = {2011},
  month = nov,
  volume = {108},
  pages = {19377--19382},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1117190108},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2W4LH7AC\\Haegens et al. - 2011 - -Oscillations in the monkey sensorimotor network i.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {48}
}

@article{haeusler_maass_2007,
  title = {A Statistical Analysis of Information-Processing Properties of Lamina-Specific Cortical Microcircuit Models},
  author = {Haeusler, Stefan and Maass, Wolfgang},
  year = {2007},
  volume = {17},
  pages = {149--162},
  issn = {10473211},
  doi = {10.1093/cercor/bhj132},
  abstract = {A major challenge for computational neuroscience is to understand the computational function of lamina-specific synaptic connection patterns in stereotypical cortical microcircuits. Previous work on this problem had focused on hypothesized specific computational roles of individual layers and connections between layers and had tested these hypotheses through simulations of abstract neural network models. We approach this problem by studying instead the dynamical system defined by more realistic cortical microcircuit models as a whole and by investigating the influence that its laminar structure has on the transmission and fusion of information within this dynamical system. The circuit models that we examine consist of Hodgkin-Huxley neurons with dynamic synapses, based on detailed data from Thomson and others (2002), Markram and others (1998), and Gupta and others (2000). We investigate to what extent this cortical microcircuit template supports the accumulation and fusion of information contained in generic spike inputs into layer 4 and layers 2/3 and how well it makes this information accessible to projection neurons in layers 2/3 and layer 5. We exhibit specific computational advantages of such data-based lamina-specific cortical microcircuit model by comparing its performance with various types of control models that have the same components and the same global statistics of neurons and synaptic connections but are missing the lamina-specific structure of real cortical microcircuits. We conclude that computer simulations of detailed lamina-specific cortical microcircuit models provide new insight into computational consequences of anatomical and physiological data.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\A4EY6Q5P\\Haeusler, Maass - Unknown - A Statistical Analysis of Information-Processing Properties of Lamina-Specific Cortical Microcircuit Models.pdf},
  journal = {Cerebral Cortex},
  keywords = {canonical microcircuit,Cortical layers,Lamination,Microcircuit models,Real-time computations,Small-world networks,Temporal integration},
  number = {1},
  pmid = {16481565}
}

@article{hafting_moser_2005,
  title = {Microstructure of a Spatial Map in the Entorhinal Cortex.},
  author = {Hafting, Torkel and Fyhn, Marianne and Molden, Sturla and Moser, May-Britt and Moser, Edvard I},
  year = {2005},
  month = aug,
  volume = {436},
  pages = {801--806},
  issn = {1476-4687},
  doi = {10.1038/nature03721},
  abstract = {The ability to find one's way depends on neural algorithms that integrate information about place, distance and direction, but the implementation of these operations in cortical microcircuits is poorly understood. Here we show that the dorsocaudal medial entorhinal cortex (dMEC) contains a directionally oriented, topographically organized neural map of the spatial environment. Its key unit is the 'grid cell', which is activated whenever the animal's position coincides with any vertex of a regular grid of equilateral triangles spanning the surface of the environment. Grids of neighbouring cells share a common orientation and spacing, but their vertex locations (their phases) differ. The spacing and size of individual fields increase from dorsal to ventral dMEC. The map is anchored to external landmarks, but persists in their absence, suggesting that grid cells may be part of a generalized, path-integration-based map of the spatial environment.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UQ23X28X\\Hafting et al. - 2005 - Microstructure of a spatial map in the entorhinal cortex.pdf},
  journal = {Nature},
  keywords = {Animals,Cues,Electrodes,Entorhinal Cortex,Entorhinal Cortex: anatomy {\&} histology,Entorhinal Cortex: anatomy \& histology,Entorhinal Cortex: cytology,Entorhinal Cortex: physiology,Environment,Long-Evans,Male,Models,Neurological,Neurons,Neurons: cytology,Neurons: physiology,Orientation,Orientation: physiology,Rats,Space Perception,Space Perception: physiology},
  number = {7052},
  pmid = {15965463}
}

@article{haggard_haggard_2017,
  title = {Sense of Agency in the Human Brain},
  author = {Haggard, Patrick},
  year = {2017},
  volume = {18},
  pages = {197--208},
  issn = {1471-003X},
  doi = {10.1038/nrn.2017.14},
  abstract = {In adult life, people normally know what they are doing. This experience of controlling one's own actions and, through them, the course of events in the outside world is called `sense of agency'. It forms a central feature of human experience; however, the brain mechanisms that produce the sense of agency have only recently begun to be investigated systematically. This recent progress has been driven by the development of better measures of the experience of agency, improved design of cognitive and behavioural experiments, and a growing understanding of the brain circuits that generate this distinctive but elusive experience. The sense of agency is a mental and neural state of cardinal importance in human civilization, because it is frequently altered in psychopathology and because it underpins the concept of responsibility in human societies.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2FY6CXVV\\Haggard - 2017 - Sense of agency in the human brain.pdf},
  journal = {Nature Reviews Neuroscience},
  number = {4},
  pmid = {28251993}
}

@article{hakim_vogel_2018,
  title = {Phase-Coding Memories in Mind},
  author = {Hakim, Nicole and Vogel, Edward K},
  year = {2018},
  doi = {10.1371/journal.pbio.3000012},
  abstract = {Temporarily holding information in mind is an important part of many cognitive processes, such as reasoning and language. The amount of information that can be actively held "in mind" at any time is greatly limited-research suggests that we can only actively hold three or four pieces of information at once. A central question in cognitive neuroscience is how a system comprised of billions of neurons can actively maintain such a limited amount of information. A new study published in this issue of PLOS Biology by Bahramisharif and colleagues provides significant insights into this question.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PM5CGTQJ\\Hakim, Vogel - 2018 - Phase-coding memories in mind.pdf}
}

@article{halassa_sherman_2019,
  title = {Thalamocortical {{Circuit Motifs}}: {{A General Framework}}},
  shorttitle = {Thalamocortical {{Circuit Motifs}}},
  author = {Halassa, Michael M. and Sherman, S. Murray},
  year = {2019},
  month = sep,
  volume = {103},
  pages = {762--770},
  issn = {08966273},
  doi = {10.1016/j.neuron.2019.06.005},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\79TF7LTZ\\Halassa and Sherman - 2019 - Thalamocortical Circuit Motifs A General Framewor.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\AJ6CJ5II\\Halassa and Sherman - 2019 - Thalamocortical Circuit Motifs A General Framewor.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\GTE56BGL\\Halassa and Sherman - 2019 - Thalamocortical Circuit Motifs A General Framewor.pdf},
  journal = {Neuron},
  language = {en},
  number = {5}
}

@article{halevy_pereira_2009,
  title = {The {{Unreasonable Effectiveness}} of {{Data}}},
  author = {Halevy, Alon and Norvig, Peter and Pereira, Fernando},
  year = {2009},
  month = mar,
  volume = {24},
  pages = {8--12},
  issn = {1541-1672},
  doi = {10.1109/MIS.2009.36},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3PWUUV8N\\Halevy, Norvig, Pereira - 2009 - The Unreasonable Effectiveness of Data.pdf},
  journal = {IEEE Intelligent Systems},
  number = {2}
}

@article{halford_philips_1998,
  title = {Processing Capacity Defined by Relational Complexity: {{Implications}} for Comparative, Developmental, and Cognitive Psychology},
  author = {Halford, Graeme S. and Wilson, William H. and Philips, Steven},
  year = {1998},
  month = dec,
  volume = {21},
  pages = {831--832},
  issn = {0140-525X, 1469-1825},
  doi = {10.1017/S0140525X98221765},
  abstract = {Working memory limits are best defined in terms of the complexity of the relations that can be processed in parallel. Complexity is defined as the number of related dimensions or sources of variation. A unary relation has one argument and one source of variation; its argument can be instantiated in only one way at a time. A binary relation has two arguments, two sources of variation, and two instantiations, and so on. Dimensionality is related to the number of chunks, because both attributes on dimensions and chunks are independent units of information of arbitrary size. Studies of working memory limits suggest that there is a soft limit corresponding to the parallel processing of one quaternary relation. More complex concepts are processed by ``segmentation'' or ``conceptual chunking.'' In segmentation, tasks are broken into components that do not exceed processing capacity and can be processed serially. In conceptual chunking, representations are ``collapsed'' to reduce their dimensionality and hence their processing load, but at the cost of making some relational information inaccessible. Neural net models of relational representations show that relations with more arguments have a higher computational cost that coincides with experimental findings on higher processing loads in humans. Relational complexity is related to processing load in reasoning and sentence comprehension and can distinguish between the capacities of higher species. The complexity of relations processed by children increases with age. Implications for neural net models and theories of cognition and cognitive development are discussed.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UEFP5R5W\\Anderson et al. - 1998 - ACT-R A higher-level account of processing capaci.pdf},
  journal = {Behavioral and Brain Sciences},
  language = {en},
  number = {6}
}

@article{halgren_cash_2019,
  title = {The Generation and Propagation of the Human Alpha Rhythm},
  author = {Halgren, Milan and Ulbert, Istv{\'a}n and Bastuji, H{\'e}l{\`e}ne and Fab{\'o}, D{\'a}niel and Er{\H o}ss, Lorand and Rey, Marc and Devinsky, Orrin and Doyle, Werner K. and {Mak-McCully}, Rachel and Halgren, Eric and Wittner, Lucia and Chauvel, Patrick and Heit, Gary and Eskandar, Emad and Mandell, Arnold and Cash, Sydney S.},
  year = {2019},
  month = nov,
  volume = {116},
  pages = {23772--23782},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1913092116},
  abstract = {The alpha rhythm is the longest-studied brain oscillation and has been theorized to play a key role in cognition. Still, its physiology is poorly understood. In this study, we used microelectrodes and macroelectrodes in surgical epilepsy patients to measure the intracortical and thalamic generators of the alpha rhythm during quiet wakefulness. We first found that alpha in both visual and somatosensory cortex propagates from higher-order to lower-order areas. In posterior cortex, alpha propagates from higher-order anterosuperior areas toward the occipital pole, whereas alpha in somatosensory cortex propagates from associative regions toward primary cortex. Several analyses suggest that this cortical alpha leads pulvinar alpha, complicating prevailing theories of a thalamic pacemaker. Finally, alpha is dominated by currents and firing in supragranular cortical layers. Together, these results suggest that the alpha rhythm likely reflects short-range supragranular feedback, which propagates from higher- to lower-order cortex and cortex to thalamus. These physiological insights suggest how alpha could mediate feedback throughout the thalamocortical system.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\H8RUZZ3I\\Halgren et al. - 2019 - The generation and propagation of the human alpha .pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {47}
}

@article{haller_shestyuk_2018,
  title = {Persistent Neuronal Activity in Human Prefrontal Cortex Links Perception and Action},
  author = {Haller, Matar and Case, John and Crone, Nathan E. and Chang, Edward F. and {King-Stephens}, David and Laxer, Kenneth D. and Weber, Peter B. and Parvizi, Josef and Knight, Robert T. and Shestyuk, Avgusta Y.},
  year = {2018},
  volume = {2},
  pages = {80--91},
  issn = {23973374},
  doi = {10.1038/s41562-017-0267-2},
  abstract = {How do humans flexibly respond to changing environmental demands on a subsecond temporal scale? Extensive research has highlighted the key role of the prefrontal cortex in flexible decision-making and adaptive behaviour, yet the core mechanisms that translate sensory information into behaviour remain undefined. Using direct human cortical recordings, we investigated the temporal and spatial evolution of neuronal activity (indexed by the broadband gamma signal) in 16 participants while they performed a broad range of self-paced cognitive tasks. Here we describe a robust domain- and modality-independent pattern of persistent stimulus-to-response neural activation that encodes stimulus features and predicts motor output on a trial-by-trial basis with near-perfect accuracy. Observed across a distributed network of brain areas, this persistent neural activation is centred in the prefrontal cortex and is required for successful response implementation, providing a functional substrate for domain-general transformation of perception into action, critical for flexible behaviour.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\E6I6YDKY\\Haller et al. - 2017 - Persistent neuronal activity in human prefrontal cortex links perception and action.pdf},
  journal = {Nature Human Behaviour},
  number = {1},
  pmid = {29963646}
}

@article{haller_voytek_2018,
  title = {Parameterizing Neural Power Spectra},
  author = {Haller, Matar and Donoghue, Thomas and Peterson, Erik and Varma, Paroma and Sebastian, Priyadarshini and Gao, Richard and Noto, Torben and Knight, Robert T and Shestyuk, Avgusta and Voytek, Bradley},
  year = {2018},
  pages = {299859},
  doi = {10.1101/299859},
  abstract = {Electrophysiological signals across species and recording scales exhibit both periodic and aperiodic features. Periodic oscillations have been widely studied and linked to numerous physiological, cognitive, behavioral, and disease states, while the aperiodic "background" 1/f component of neural power spectra has received far less attention. Most analyses of oscillations are conducted on a priori, canonically-defined frequency bands without consideration of the underlying aperiodic structure, or verification that a periodic signal even exists in addition to the aperiodic signal. This is problematic, as recent evidence shows that the aperiodic signal is dynamic, changing with age, task demands, and cognitive state. It has also been linked to the relative excitation/inhibition of the underlying neuronal population. This means that standard analytic approaches easily conflate changes in the periodic and aperiodic signals with one another because the aperiodic parameters\textendash along with oscillation center frequency, power, and bandwidth\textendash are all dynamic in physiologically meaningful, but likely different, ways. In order to overcome the limitations of traditional narrowband analyses and to reduce the potentially deleterious effects of conflating these features, we introduce a novel algorithm for automatic parameterization of neural power spectral densities (PSDs) as a combination of the aperiodic signal and putative periodic oscillations. Notably, this algorithm requires no a priori specification of band limits and accounts for potentially-overlapping oscillations while minimizing the degree to which they are confounded with one another. This algorithm is amenable to large-scale data exploration and analysis, providing researchers with a tool to quickly and accurately parameterize neural power spectra.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MYAQ4R5F\\Haller et al. - 2018 - Parameterizing neural power spectra.pdf},
  journal = {bioRxiv}
}

@book{halliday_resnick_2018,
  title = {Fundamentals of {{Physics}}},
  author = {Halliday and Resnick},
  year = {2018},
  edition = {Tenth},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TISGW3NP\\Walker - Fundamentals of Physics.pdf},
  language = {en}
}

@article{hamel_schnitzer_2015,
  title = {Review {{Cellular Level Brain Imaging}} in {{Behaving Mammals}} : {{An Engineering Approach}}},
  author = {Hamel, Elizabeth J O and Grewe, Benjamin F and Parker, Jones G and Schnitzer, Mark J},
  year = {2015},
  volume = {86},
  pages = {140--159},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2015.03.055},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\55TA3C3I\\Hamel et al. - 2015 - Review Cellular Level Brain Imaging in Behaving Mammals An Engineering Approach.pdf},
  journal = {Neuron},
  number = {1}
}

@article{han_han_2012,
  title = {In Vivo Application of Optogenetics for Neural Circuit Analysis.},
  author = {Han, Xue},
  year = {2012},
  month = aug,
  volume = {3},
  pages = {577--584},
  issn = {1948-7193},
  doi = {10.1021/cn300065j},
  abstract = {Optogenetics combines optical and genetic methods to rapidly and reversibly control neural activities or other cellular functions. Using genetic methods, specific cells or anatomical pathways can be sensitized to light through exogenous expression of microbial light activated opsin proteins. Using optical methods, opsin expressing cells can be rapidly and reversibly controlled by pulses of light of specific wavelength. With the high spatial temporal precision, optogenetic tools have enabled new ways to probe the causal role of specific cells in neural computation and behavior. Here, we overview the current state of the technology, and provide a brief introduction to the practical considerations in applying optogenetics in vivo to analyze neural circuit functions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JI6UQXFX\\Han - 2012 - In vivo application of optogenetics for neural circuit analysis.pdf},
  journal = {ACS chemical neuroscience},
  keywords = {Animals,Electrodes,Electrophysiological Phenomena,Genetic Vectors,Genetically Modified,Humans,Ion Channels,Ion Channels: physiology,Ion Channels: radiation effects,Light,Molecular Probes,Nerve Net,Nerve Net: physiology,Nerve Net: radiation effects,Neurons,Neurons: physiology,Opsins,Opsins: diagnostic use,Photic Stimulation,Rhodopsin,Rhodopsin: genetics,Rhodopsin: physiology,Signal Transduction,Signal Transduction: drug effects,Signal Transduction: physiology,Viruses,Viruses: genetics},
  number = {8},
  pmid = {22896801}
}

@techreport{han_ku_2019,
  title = {Reorienting {{Spatial Attention}} within {{Visual Working Memory}}},
  author = {Han, Sizhu and Ku, Yixuan},
  year = {2019},
  month = nov,
  institution = {{Neuroscience}},
  doi = {10.1101/854703},
  abstract = {Abstract                        Attention and working memory (WM) are intertwined core cognitive processes. Through four experiments with 133 participants, we dissociated the impact of two types of covert spatial attention, endogenous             vs.             exogenous, on visual WM. Behavioral results consistently indicated that exogenous attentional cues were more advantageous than endogenous ones in enhancing the precision of visual WM under load-2, while they equalized under load-4. In addition, physiological and neural data explained the mechanisms. Converging evidence from eye-tracking, electroencephalography, and magnetoencephalography suggested that fast attentional processing induced by exogenous cues lead to early top-down information from the dorsal lateral prefrontal cortex (DLPFC) to sensory cortices. The differential frontal activities were further correlated with the behavioral distinctions between exogenous and endogenous cues, and transcranial magnetic stimulation over DLPFC at the same time period abolished the exogenous advantage. Taken together, traditionally considered bottom-up attentional processing induced by exogenous cues rapidly engages top-down signals from the frontal cortex, which leads to stronger behavioral benefits compared with the benefits produced by endogenous cues under the low load condition.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\M7BCCVU4\\Han and Ku - 2019 - Reorienting Spatial Attention within Visual Workin.pdf},
  language = {en},
  type = {Preprint}
}

@article{han_liu_2018,
  title = {Deep {{Predictive Coding Network}} with {{Local Recurrent Processing}} for {{Object Recognition}}},
  author = {Han, Kuan and Wen, Haiguang and Zhang, Yizhen and Fu, Di and Culurciello, Eugenio and Liu, Zhongming},
  year = {2018},
  abstract = {Inspired by "predictive coding" - a theory in neuroscience, we develop a bi-directional and dynamical neural network with local recurrent processing, namely predictive coding network (PCN). Unlike any feedforward-only convolutional neural network, PCN includes both feedback connections, which carry top-down predictions, and feedforward connections, which carry bottom-up errors of prediction. Feedback and feedforward connections enable adjacent layers to interact locally and recurrently to refine representations towards minimization of layer-wise prediction errors. When unfolded over time, the recurrent processing gives rise to an increasingly deeper hierarchy of non-linear transformation, allowing a shallow network to dynamically extend itself into an arbitrarily deep network. We train and test PCN for image classification with SVHN, CIFAR and ImageNet datasets. Despite notably fewer layers and parameters, PCN achieves competitive performance compared to classical and state-of-the-art models. Further analysis shows that the internal representations in PCN converge over time and yield increasingly better accuracy in object recognition. Errors of top-down prediction also map visual saliency or bottom-up attention. This work takes us one step closer to bridging human and machine intelligence in vision.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RVD4W4H6\\Wen et al. - Unknown - Deep Predictive Coding Network for Object Recognition.pdf}
}

@article{hanson_hanson_2018,
  title = {Attentional {{Bias}} in {{Human Category Learning}}: {{The Case}} of {{Deep Learning}}},
  author = {Hanson, Catherine and Caglar, Leyla Roskan and Hanson, Stephen Jos{\'e}},
  year = {2018},
  volume = {9},
  pages = {374},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2018.00374},
  abstract = {Category learning performance is influenced by both the nature of the category's structure and the way category features are processed during learning. Shepard (1987; 1964) showed that categories can be divided into those having features that are statistically uncorrelated (separable) or statistically correlated (integral). Humans find it much easier to learn categories having separable features, especially when attention to only a subset of relevant features is required, and harder to learn categories having integral features, which require consideration of all the available features and then integration of all the relevant category features (Garner, 1974). In contrast to humans, a single hidden layer backpropagation (BP) neural network has been shown to learn both separable and integral categories equally easily, independent of the category rule (Kruschke, 1993). This `failure' to replicate human category performance appeared to be strong evidence that connectionist networks were incapable of modeling human attentional bias. We tested the presumed limitations of attentional bias in networks in two ways: 1) by having networks learn categories with exemplars that have high feature complexity in contrast to the low dimensional stimuli previously used, and 2) by investigating whether a Deep Learning (DL) network, which has demonstrated humanlike performance in many different kinds of tasks (language translation, autonomous driving, etc), would display human-like attentional bias during category learning. We were able to show a number of interesting results. First, we replicated the failure of BP to differentially process integral and separable category structures when low dimensional stimuli are used (Kruschke, 1993, Garner, 1974). Second, we show that using the same low dimensional stimuli, Deep Learning (DL), unlike BP but similar to humans, learns separable category structures more quickly than integral category structures. Third, we show that even BP can exhibit humanlike learning differences between integral and separable category structures when high dimensional stimuli (face exemplars) are used. We conclude, after visualizing the hidden unit representations, that DL appears to extend initial learning due to feature development thereby reducing destructive feature competition by incrementally refining feature detectors throughout later layers until a tipping point (in terms of error) is reached resulting in rapid},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8Z2SDBZP\\Hanson, Caglar, Hanson - 2018 - Attentional Bias in Human Category Learning The Case of Deep Learning.pdf},
  journal = {Frontiers in Psychology},
  keywords = {attentional bias,Categorization,condensation,deep learning,Filtration,Learning Theory,neural networks},
  number = {April}
}

@article{hao_xu_2020,
  title = {A Biologically Plausible Supervised Learning Method for Spiking Neural Networks Using the Symmetric {{STDP}} Rule},
  author = {Hao, Yunzhe and Huang, Xuhui and Dong, Meng and Xu, Bo},
  year = {2020},
  month = jan,
  volume = {121},
  pages = {387--395},
  issn = {08936080},
  doi = {10.1016/j.neunet.2019.09.007},
  abstract = {Spiking neural networks (SNNs) possess energy-efficient potential due to event-based computation. However, supervised training of SNNs remains a challenge as spike activities are non-differentiable. Previous SNNs training methods can be generally categorized into two basic classes, i.e., backpropagation-like training methods and plasticity-based learning methods. The former methods are dependent on energy-inefficient real-valued computation and non-local transmission, as also required in artificial neural networks (ANNs), whereas the latter are either considered to be biologically implausible or exhibit poor performance. Hence, biologically plausible (bio-plausible) high-performance supervised learning (SL) methods for SNNs remain deficient. In this paper, we proposed a novel bioplausible SNN model for SL based on the symmetric spike-timing dependent plasticity (sym-STDP) rule found in neuroscience. By combining the sym-STDP rule with bio-plausible synaptic scaling and intrinsic plasticity of the dynamic threshold, our SNN model implemented SL well and achieved good performance in the benchmark recognition task (MNIST dataset). To reveal the underlying mechanism of our SL model, we visualized both layer-based activities and synaptic weights using the t-distributed stochastic neighbor embedding (t-SNE) method after training and found that they were well clustered, thereby demonstrating excellent classification ability. Furthermore, to verify the robustness of our model, we trained it on another more realistic dataset (Fashion-MNIST), which also showed good performance. As the learning rules were bio-plausible and based purely on local spike events, our model could be easily applied to neuromorphic hardware for online training and may be helpful for understanding SL information processing at the synaptic level in biological neural systems.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5K2KE3SM\\Hao et al. - 2020 - A biologically plausible supervised learning metho.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\DE9SBMN4\\Hao et al. - 2020 - A biologically plausible supervised learning metho.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\QBGVAAKN\\Hao et al. - 2020 - A biologically plausible supervised learning metho.pdf},
  journal = {Neural Networks},
  language = {en}
}

@article{hardcastle_giocomo_2015,
  title = {Environmental {{Boundaries}} as an {{Error Correction Mechanism}} for {{Grid Cells}}},
  author = {Hardcastle, Kiah and Ganguli, Surya and Giocomo, Lisa M},
  year = {2015},
  volume = {86},
  pages = {827--839},
  issn = {08966273},
  doi = {10.1016/j.neuron.2015.03.039},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XJCN3XVB\\Hardcastle, Ganguli, Giocomo - 2015 - Environmental Boundaries as an Error Correction Mechanism for Grid Cells.pdf},
  journal = {Neuron},
  number = {3}
}

@article{harnett_magee_2012,
  title = {Synaptic Amplification by Dendritic Spines Enhances Input Cooperativity},
  author = {Harnett, Mark T. and Makara, Judit K. and Spruston, Nelson and Kath, William L. and Magee, Jeffrey C.},
  year = {2012},
  month = nov,
  volume = {491},
  pages = {599--602},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature11554},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HVVHD6WX\\Harnett et al. - 2012 - Synaptic amplification by dendritic spines enhance.pdf},
  journal = {Nature},
  language = {en},
  number = {7425}
}

@article{harris_attwell_2012,
  title = {Synaptic Energy Use and Supply.},
  author = {Harris, Julia J and Jolivet, Renaud and Attwell, David},
  year = {2012},
  month = sep,
  volume = {75},
  pages = {762--777},
  issn = {1097-4199},
  doi = {10.1016/j.neuron.2012.08.019},
  abstract = {Neuronal computation is energetically expensive. Consequently, the brain's limited energy supply imposes constraints on its information processing capability. Most brain energy is used on synaptic transmission, making it important to understand how energy is provided to and used by synapses. We describe how information transmission through presynaptic terminals and postsynaptic spines is related to their energy consumption, assess which mechanisms normally ensure an adequate supply of ATP to these structures, consider the influence of synaptic plasticity and changing brain state on synaptic energy use, and explain how disruption of the energy supply to synapses leads to neuropathology.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZWMW7MN8\\Harris, Jolivet, Attwell - 2012 - Synaptic energy use and supply.pdf},
  journal = {Neuron},
  keywords = {Animals,Brain,Brain Chemistry,Brain Chemistry: physiology,Brain: metabolism,Brain: physiology,Energy Metabolism,Energy Metabolism: physiology,Humans,Neuronal Plasticity,Neuronal Plasticity: physiology,Synaptic Transmission,Synaptic Transmission: physiology},
  number = {5},
  pmid = {22958818}
}

@article{harris_zeng_2019,
  title = {Hierarchical Organization of Cortical and Thalamic Connectivity},
  author = {Harris, Julie A. and Mihalas, Stefan and Hirokawa, Karla E. and Whitesell, Jennifer D. and Choi, Hannah and Bernard, Amy and Bohn, Phillip and Caldejon, Shiella and Casal, Linzy and Cho, Andrew and Feiner, Aaron and Feng, David and Gaudreault, Nathalie and Gerfen, Charles R. and Graddis, Nile and Groblewski, Peter A. and Henry, Alex M. and Ho, Anh and Howard, Robert and Knox, Joseph E. and Kuan, Leonard and Kuang, Xiuli and Lecoq, Jerome and Lesnar, Phil and Li, Yaoyao and Luviano, Jennifer and McConoughey, Stephen and Mortrud, Marty T. and Naeemi, Maitham and Ng, Lydia and Oh, Seung Wook and Ouellette, Benjamin and Shen, Elise and Sorensen, Staci A. and Wakeman, Wayne and Wang, Quanxin and Wang, Yun and Williford, Ali and Phillips, John W. and Jones, Allan R. and Koch, Christof and Zeng, Hongkui},
  year = {2019},
  month = nov,
  volume = {575},
  pages = {195--202},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/s41586-019-1716-z},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QZY8XW44\\Harris et al. - 2019 - Hierarchical organization of cortical and thalamic.pdf},
  journal = {Nature},
  language = {en},
  number = {7781}
}

@article{harrison_forest_2014,
  title = {Microchip Amplifier for in Vitro, in Vivo, and Automated Whole-Cell Patch-Clamp Recording},
  author = {Harrison, R R and Kolb, I and Kodandaramaiah, S B and a. Chubykin, a. and Yang, a. and Bear, M F and Boyden, E S and Forest, C},
  year = {2014},
  month = nov,
  issn = {0022-3077},
  doi = {10.1152/jn.00629.2014},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WUJRX7IB\\Harrison et al. - 2014 - Microchip amplifier for in vitro, in vivo, and automated whole-cell patch-clamp recording.pdf},
  journal = {Journal of Neurophysiology}
}

@article{hartley_okeefe_2000,
  title = {Modeling Place Fields in Terms of the Cortical Inputs to the Hippocampus},
  author = {Hartley, Tom and Burgess, N and Lever, C and Cacucci, Francesca and O'Keefe, J},
  year = {2000},
  volume = {10},
  pages = {369--379},
  issn = {10509631},
  doi = {10.1002/1098-1063(2000)10:4<369::AID-HIPO3>3.0.CO;2-0},
  abstract = {A model of place-cell firing is presented that makes quantitative predictions about specific place cells' spatial receptive fields following changes to the rat's environment. A place cell's firing rate is modeled as a function of the rat's location by the thresholded sum of the firing rates of a number of putative cortical inputs. These inputs are tuned to respond whenever an environmental boundary is at a particular distance and allocentric direction from the rat. The initial behavior of a place cell in any environment is simply determined by its set of inputs and its threshold; learning is not necessary. The model is shown to produce a good fit to the firing of individual place cells, and populations of place cells across environments of differing shape. The cells' behavior can be predicted for novel environments of arbitrary size and shape, or for manipulations such as introducing a barrier. The model can be extended to make behavioral predictions regarding spatial memory.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DT3584PQ\\Hartley et al. - 2000 - Modeling place fields in terms of the cortical inputs to the hippocampus.pdf},
  journal = {Hippocampus},
  keywords = {Model,Neural network,Rat,Space},
  number = {4},
  pmid = {10985276}
}

@article{harvey_harvey_2011,
  title = {Detection {{Theory}}: {{Sensory}} and {{Decision Processes}}},
  author = {Harvey, Lewis O Jr},
  year = {2011},
  volume = {4165-100},
  abstract = {Lecture for course. psychology of perception},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GUXYIPGI\\Harvey - 2011 - Detection Theory Sensory and Decision Processes.pdf},
  journal = {Psych-Www.Colorado.Edu},
  keywords = {psychology},
  pmid = {1000164430}
}

@article{hashemi_sleigh_2017,
  title = {Anesthetic Action on the Transmission Delay between Cortex and Thalamus Explains the Beta-Buzz Observed under Propofol Anesthesia},
  author = {Hashemi, Meysam and Hutt, Axel and Hight, Darren and Sleigh, Jamie},
  year = {2017},
  volume = {12},
  issn = {19326203},
  doi = {10.1371/journal.pone.0179286},
  abstract = {In recent years, more and more surgeries under general anesthesia have been performed with the assistance of electroencephalogram (EEG) monitors. An increase in anesthetic concentration leads to characteristic changes in the power spectra of the EEG. Although tracking the anesthetic-induced changes in EEG rhythms can be employed to estimate the depth of anesthesia, their precise underlying mechanisms are still unknown. A prominent feature in the EEG of some patients is the emergence of a strong power peak in the {$\beta$}-frequency band, which moves to the {$\alpha$}-frequency band while increasing the anesthetic concentration. This feature is called the beta-buzz. In the present study, we use a thalamo-cortical neural population feedback model to reproduce observed characteristic features in frontal EEG power obtained experimentally during propofol general anesthesia, such as this beta-buzz. First, we find that the spectral power peak in the {$\alpha$}- and {$\delta$}-frequency ranges depend on the decay rate constant of excitatory and inhibitory synapses, but the anesthetic action on synapses does not explain the beta-buzz. Moreover, considering the action of propofol on the transmission delay between cortex and thalamus, the model reveals that the beta-buzz may result from a prolongation of the transmission delay by increasing propofol concentration. A corresponding relationship between transmission delay and anesthetic blood concentration is derived. Finally, an analytical stability study demonstrates that increasing propofol concentration moves the systems resting state towards its stability threshold.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\M98852RD\\Hashemi et al. - 2017 - Anesthetic action on the transmission delay between cortex and thalamus explains the beta-buzz observed under pr.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\VXVLD8SK\\Hashemi et al. - 2017 - Anesthetic action on the transmission delay between cortex and thalamus explains the beta-buzz observed under pr.pdf},
  journal = {PLoS ONE},
  number = {6},
  pmid = {28622355}
}

@article{hassabis_botvinick_2017,
  title = {Review {{Neuroscience}}-{{Inspired Artificial Intelligence}}},
  author = {Hassabis, Demis and Kumaran, Dharshan and Summerfield, Christopher and Botvinick, Matthew},
  year = {2017},
  volume = {95},
  doi = {10.1016/j.neuron.2017.06.011},
  abstract = {The fields of neuroscience and artificial intelligence (AI) have a long and intertwined history. In more recent times, however, communication and collaboration between the two fields has become less commonplace. In this article, we argue that better understanding biological brains could play a vital role in building intelligent machines. We survey historical interactions between the AI and neuroscience fields and emphasize current advances in AI that have been inspired by the study of neural computation in humans and other animals. We conclude by highlighting shared themes that may be key for advancing future research in both fields. In recent years, rapid progress has been made in the related fields of neuroscience and artificial intelligence (AI). At the dawn of the computer age, work on AI was inextricably intertwined with neuroscience and psychology, and many of the early pioneers straddled both fields, with collaborations between these disciplines proving highly productive (Churchland and Sejnowski, 1988; Hebb, 1949; Hinton et al., 1986; Hopfield, 1982; McCulloch and Pitts, 1943; Turing, 1950). However, more recently, the interaction has become much less commonplace , as both subjects have grown enormously in complexity and disciplinary boundaries have solidified. In this review, we argue for the critical and ongoing importance of neuroscience in generating ideas that will accelerate and guide AI research (see Hassabis commentary in Brooks et al., 2012). We begin with the premise that building human-level general AI (or ''Turing-powerful'' intelligent systems; Turing, 1936) is a daunting task, because the search space of possible solutions is vast and likely only very sparsely populated. We argue that this therefore underscores the utility of scrutinizing the inner workings of the human brain-the only existing proof that such an intelligence is even possible. Studying animal cognition and its neural implementation also has a vital role to play, as it can provide a window into various important aspects of higher-level general intelligence. The benefits to developing AI of closely examining biological intelligence are twofold. First, neuroscience provides a rich source of inspiration for new types of algorithms and architec-tures, independent of and complementary to the mathematical and logic-based methods and ideas that have largely dominated traditional approaches to AI. For example, were a new facet of biological computation found to be critical to supporting a cogni-tive function, then we would consider it an excellent candidate for incorporation into artificial systems. Second, neuroscience can provide validation of AI techniques that already exist. If a known algorithm is subsequently found to be implemented in the brain, then that is strong support for its plausibility as an integral component of an overall general intelligence system. Such clues can be critical to a long-term research program when determining where to allocate resources most productively. For example, if an algorithm is not quite attaining the level of performance required or expected, but we observe it is core to the functioning of the brain, then we can surmise that redoubled engineering efforts geared to making it work in artificial systems are likely to pay off. Of course from a practical standpoint of building an AI system, we need not slavishly enforce adherence to biological plausibility. From an engineering perspective, what works is ultimately all that matters. For our purposes then, biological plausibility is a guide, not a strict requirement. What we are interested in is a systems neuroscience-level understanding of the brain, namely the algorithms, architectures, functions, and representations it utilizes. This roughly corresponds to the top two levels of the three levels of analysis that Marr famously stated are required to understand any complex biological system (Marr and Poggio, 1976): the goals of the system (the computational level) and the process and computations that realize this goal (the algorithmic level). The precise mechanisms by which this is physically realized in a biological substrate are less relevant here (the implementation level). Note this is where our approach to neuroscience-inspired AI differs from other initiatives, such as the Blue Brain Project (Markram, 2006) or the field of neuromorphic computing systems (Esser et al., 2016), which attempt to closely mimic or directly reverse engineer the specifics of neural circuits (albeit with different goals in mind). By focusing on the computational and algorithmic levels, we gain transferrable insights into general mechanisms of brain function, while leaving room to accommodate the distinctive opportunities and challenges that arise when building intelligent machines in silico. The following sections unpack these points by considering the past, present, and future of the AI-neuroscience interface. Before beginning, we offer a clarification. Throughout this article, we employ the terms ''neuroscience'' and ''AI.'' We use these terms in the widest possible sense. When we say neuroscience, we mean to include all fields that are involved with the study of the brain, the behaviors that it generates, and the mechanisms by which it does so, including cognitive neuroscience, systems neuroscience and psychology. When we say AI, we mean work},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3KPQT8NU\\Hassabis et al. - 2017 - Review Neuroscience-Inspired Artificial Intelligence.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\947L6KMR\\Hassabis et al. - 2017 - Neuroscience-Inspired Artificial Intelligence.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\A2LXBYZP\\Hassabis et al. - 2017 - Review Neuroscience-Inspired Artificial Intelligence.pdf},
  journal = {Neuron},
  keywords = {artificial intelligence,brain,cognition,learning,neural network}
}

@article{hassan_dausilio_2014,
  title = {{{EEG Source Connectivity Analysis}}: {{From Dense Array Recordings}} to {{Brain Networks}}},
  author = {Hassan, Mahmoud and Dufor, Olivier and Merlet, Isabelle and Berrou, Claude and Wendling, Fabrice and D 'ausilio, Alessandro},
  year = {2014},
  volume = {9},
  doi = {10.5281/zenodo.10498},
  abstract = {The recent past years have seen a noticeable increase of interest for electroencephalography (EEG) to analyze functional connectivity through brain sources reconstructed from scalp signals. Although considerable advances have been done both on the recording and analysis of EEG signals, a number of methodological questions are still open regarding the optimal way to process the data in order to identify brain networks. In this paper, we analyze the impact of three factors that intervene in this processing: i) the number of scalp electrodes, ii) the combination between the algorithm used to solve the EEG inverse problem and the algorithm used to measure the functional connectivity and iii) the frequency bands retained to estimate the functional connectivity among neocortical sources. Using High-Resolution (hr) EEG recordings in healthy volunteers, we evaluated these factors on evoked responses during picture recognition and naming task. The main reason for selection this task is that a solid literature background is available about involved brain networks (ground truth). From this a priori information, we propose a performance criterion based on the number of connections identified in the regions of interest (ROI) that belong to potentially activated networks. Our results show that the three studied factors have a dramatic impact on the final result (the identified network in the source space) as strong discrepancies were evidenced depending on the methods used. They also suggest that the combination of weighted Minimum Norm Estimator (wMNE) and the Phase Synchronization (PS) methods applied on High-Resolution EEG in beta/gamma bands provides the best performance in term of topological distance between the identified network and the expected network in the above-mentioned cognitive task.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GIP76VU3\\Hassan et al. - 2014 - EEG Source Connectivity Analysis From Dense Array Recordings to Brain Networks.pdf},
  journal = {PLoS ONE},
  number = {8}
}

@article{hasselmo_brandon_2012,
  title = {A Model Combining Oscillations and Attractor Dynamics for Generation of Grid Cell Firing.},
  author = {Hasselmo, Michael E and Brandon, Mark P},
  year = {2012},
  month = jan,
  volume = {6},
  pages = {30},
  issn = {1662-5110},
  doi = {10.3389/fncir.2012.00030},
  abstract = {Different models have been able to account for different features of the data on grid cell firing properties, including the relationship of grid cells to cellular properties and network oscillations. This paper describes a model that combines elements of two major classes of models of grid cells: models using interactions of oscillations and models using attractor dynamics. This model includes a population of units with oscillatory input representing input from the medial septum. These units are termed heading angle cells because their connectivity depends upon heading angle in the environment as well as the spatial phase coded by the cell. These cells project to a population of grid cells. The sum of the heading angle input results in standing waves of circularly symmetric input to the grid cell population. Feedback from the grid cell population increases the activity of subsets of the heading angle cells, resulting in the network settling into activity patterns that resemble the patterns of firing fields in a population of grid cells. The properties of heading angle cells firing as conjunctive grid-by-head-direction cells can shift the grid cell firing according to movement velocity. The pattern of interaction of oscillations requires use of separate populations that fire on alternate cycles of the net theta rhythmic input to grid cells.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EH9WSAUN\\Hasselmo, Brandon - 2012 - A model combining oscillations and attractor dynamics for generation of grid cell firing.pdf},
  journal = {Frontiers in neural circuits},
  keywords = {entorhinal cortex,oscillatory interference,patch-recording,spatial navigation,stellate cells},
  number = {May},
  pmid = {22654735}
}

@article{hasselmo_dannenberg_2020,
  title = {The Unexplored Territory of Neural Models: {{Potential}} Guides for Exploring the Function of Metabotropic Neuromodulation},
  shorttitle = {The Unexplored Territory of Neural Models},
  author = {Hasselmo, Michael E. and Alexander, Andrew S. and Hoyland, Alec and Robinson, Jennifer C. and Bezaire, Marianne J. and Chapman, G. William and Saudargiene, Ausra and Carstensen, Lucas C. and Dannenberg, Holger},
  year = {2020},
  month = apr,
  pages = {S0306452220302141},
  issn = {03064522},
  doi = {10.1016/j.neuroscience.2020.03.048},
  copyright = {All rights reserved},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YWW66DI2\\Hasselmo et al. - 2020 - The unexplored territory of neural models Potenti.pdf},
  journal = {Neuroscience},
  language = {en}
}

@article{hasselmo_hasselmo_1999,
  title = {Neuromodulation: Acetylcholine and Memory Consolidation.},
  author = {Hasselmo, Michael E},
  year = {1999},
  month = sep,
  volume = {3},
  pages = {351--359},
  issn = {1879-307X},
  abstract = {Clinical and experimental evidence suggests that hippocampal damage causes more severe disruption of episodic memories if those memories were encoded in the recent rather than the more distant past. This decrease in sensitivity to damage over time might reflect the formation of multiple traces within the hippocampus itself, or the formation of additional associative links in entorhinal and association cortices. Physiological evidence also supports a two-stage model of the encoding process in which the initial encoding occurs during active waking and deeper consolidation occurs via the formation of additional memory traces during quiet waking or slow-wave sleep. In this article I will describe the changes in cholinergic tone within the hippocampus in different stages of the sleep-wake cycle and will propose that these changes modulate different stages of memory formation. In particular, I will suggest that the high levels of acetylcholine that are present during active waking might set the appropriate dynamics for encoding new information in the hippocampus, by partially suppressing excitatory feedback connections and so facilitating encoding without interference from previously stored information. By contrast, the lower levels of acetylcholine that are present during quiet waking and slow-wave sleep might release this suppression and thereby allow a stronger spread of activity within the hippocampus itself and from the hippocampus to the entorhinal cortex, thus facilitating the process of consolidation of separate memory traces.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZTKUIBR6\\Hasselmo - 1999 - Neuromodulation acetylcholine and memory consolidation.pdf},
  journal = {Trends in cognitive sciences},
  number = {9},
  pmid = {10461198}
}

@article{hasselmo_hasselmo_2005,
  title = {What Is the Function of Hippocampal Theta Rhythm?\textemdash{{Linking}} Behavioral Data to Phasic Properties of Field Potential and Unit Recording Data},
  author = {Hasselmo, Michael E},
  year = {2005},
  volume = {15},
  pages = {936--949},
  issn = {1050-9631},
  doi = {10.1002/hipo.20116},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JH568BHP\\Hasselmo - 2005 - What is the function of hippocampal theta rhythm—Linking behavioral data to phasic properties of field potential and.pdf},
  journal = {Hippocampus},
  keywords = {computational,eeg oscillations,fornix,region ca1,region ca3,septum,spatial,theta phase precession},
  number = {7}
}

@article{hasselmo_hasselmo_2005a,
  title = {A Model of Prefrontal Cortical Mechanisms for Goal-Directed Behavior.},
  author = {Hasselmo, Michael E},
  year = {2005},
  volume = {17},
  pages = {1115--1129},
  issn = {0898-929X},
  doi = {10.1162/0898929054475190},
  abstract = {Many behavioral tasks require goal-directed actions to obtain delayed reward. The prefrontal cortex appears to mediate many aspects of goal-directed decision making. This article presents a model of prefrontal cortex function emphasizing the influence of goal-related activity on the choice of the next motor output. The model can be interpreted in terms of key elements of Reinforcement Learning Theory. Different neocortical minicolumns represent distinct sensory input states and distinct motor output actions. The dynamics of each minicolumn include separate phases of encoding and retrieval. During encoding, strengthening of excitatory connections forms forward and reverse associations between each state, the following action, and a subsequent state, which may include reward. During retrieval, activity spreads from reward states throughout the network. The interaction of this spreading activity with a specific input state directs selection of the next appropriate action. Simulations demonstrate how these mechanisms can guide performance in a range of goal-directed tasks, and provide a functional framework for some of the neuronal responses previously observed in the medial prefrontal cortex during performance of spatial memory tasks in rats.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\77KKCNF6\\Hasselmo - 2005 - A model of prefrontal cortical mechanisms for goal-directed behavior.pdf},
  journal = {Journal of cognitive neuroscience},
  number = {7},
  pmid = {16102240}
}

@book{hasselmo_hasselmo_2012,
  title = {How We Remember: Brain Mechanisms of Episodic Memory},
  shorttitle = {How We Remember},
  author = {Hasselmo, Michael E.},
  year = {2012},
  publisher = {{MIT Press}},
  address = {{Cambridge, Mass}},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YZ4YXPEN\\Hasselmo - 2012 - How we remember brain mechanisms of episodic memo.pdf},
  isbn = {978-0-262-01635-3},
  language = {en},
  lccn = {QP406 .H37 2012}
}

@article{hasselmo_hasselmo_2013,
  title = {R01: {{Mechanisms}} of {{Entorhinal Cortex Function}}},
  author = {Hasselmo, Michael E},
  year = {2013},
  pages = {23--46},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MPFZ247K\\Hasselmo - 2013 - R01 Mechanisms of Entorhinal Cortex Function.pdf}
}

@article{hasselmo_hasselmo_2014,
  title = {Neuronal Rebound Spiking, Resonance Frequency and Theta Cycle Skipping May Contribute to Grid Cell Firing in Medial Entorhinal Cortex},
  author = {Hasselmo, Michael E},
  year = {2014},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9MM4YBDC\\Hasselmo - 2014 - Neuronal rebound spiking, resonance frequency and theta cycle skipping may contribute to grid cell firing in medial en.pdf},
  journal = {Transactions of the Royal Society B: \{\textbackslash ldots\}},
  keywords = {behaviour,cognition,neuroscience,physiology}
}

@techreport{hasselmo_hasselmo_2015,
  title = {R01: {{Neuromodulation}} and {{Cortical Memory Function}}},
  author = {Hasselmo, Michael E},
  year = {2015},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\E398I2RE\\Hasselmo - 2015 - R01 Neuromodulation and Cortical Memory Function.pdf}
}

@article{hasselmo_hasselmo_2017,
  title = {Avoiding {{Catastrophic Forgetting}}},
  author = {Hasselmo, Michael E},
  year = {2017},
  month = jun,
  volume = {21},
  pages = {407--408},
  issn = {1879307X},
  doi = {10.1016/j.tics.2017.04.001},
  abstract = {Humans regularly perform new learning without losing memory for previous information, but neural network models suffer from the phenomenon of catastrophic forgetting in which new learning impairs prior function. A recent article presents an algorithm that spares learning at synapses important for previously learned function, reducing catastrophic forgetting.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HYZSBGNX\\Hasselmo - 2017 - Avoiding Catastrophic Forgetting.pdf},
  journal = {Trends in Cognitive Sciences},
  number = {6},
  pmid = {28442279}
}

@article{hasselmo_hasselmo_2018,
  title = {A Model of Cortical Cognitive Function Using Hierarchical Interactions of Gating Matrices in Internal Agents Coding Relational Representations},
  author = {Hasselmo, Michael E},
  year = {2018},
  abstract = {Flexible cognition requires the ability to rapidly detect systematic functions of variables and guide future behavior based on predictions. The model described here proposes a potential framework for patterns of neural activity to detect systematic functions and relations between components of sensory input and apply them in a predictive manner. This model includes multiple internal gating agents that operate within the state space of neural activity, in analogy to external agents behaving in the external environment. The multiple internal gating agents represent patterns of neural activity that detect and gate patterns of matrix connectivity representing the relations between different neural populations. The patterns of gating matrix connectivity represent functions that can be used to predict future components of a series of sensory inputs or the relationship between different features of a static sensory stimulus. The model is applied to the prediction of dynamical trajectories, the internal relationship between features of different sensory stimuli and to the prediction of affine transformations that could be useful for solving cognitive tasks such as the Raven's progressive matrices task.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZV2G79JT\\Hasselmo_A model of cortical cognitive function using hierarchical interactions of.pdf},
  keywords = {grant numbers r01,health,mh60013,neocortex,object,phase coding,predictive coding,r01 mh61492 and by,research muri n00014-16-1-2832,semantic memory,spatiotemporal trajectory coding,the author has,the national institutes of,the office of naval,this work supported by,transformation}
}

@article{hasselmo_howardeichenbaum_2005,
  title = {Hippocampal Mechanisms for the Context-Dependent Retrieval of Episodes},
  author = {Hasselmo, Michael E. and {Howard Eichenbaum}},
  year = {2005},
  month = nov,
  volume = {18},
  pages = {1172--1190},
  issn = {08936080},
  doi = {10.1016/j.neunet.2005.08.007},
  abstract = {Behaviors ranging from delivering newspapers to waiting tables depend on remembering previous episodes to avoid incorrect repetition. Physiologically, this requires mechanisms for long-term storage and selective retrieval of episodes based on the time of occurrence, despite variable intervals and similarity of events in a familiar environment. Here, this process has been modeled based on the physiological properties of the hippocampal formation, including mechanisms for sustained activity in entorhinal cortex and theta rhythm oscillations in hippocampal subregions. The model simulates the context-sensitive firing properties of hippocampal neurons including trial-specific firing during spatial alternation and trial by trial changes in theta phase precession on a linear track. This activity is used to guide behavior, and lesions of the hippocampal network impair memory-guided behavior. The model links data at the cellular level to behavior at the systems level, describing a physiologically plausible mechanism for the brain to recall a given episode which occurred at a specific place and time.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TPLMVF8U\\Hasselmo and Howard Eichenbaum - 2005 - Hippocampal mechanisms for the context-dependent r.pdf},
  journal = {Neural Networks},
  language = {en},
  number = {9}
}

@article{hasselmo_shay_2014,
  title = {Grid Cell Firing Patterns May Arise from Feedback Interaction between Intrinsic Rebound Spiking and Transverse Traveling Waves with Multiple Heading Angles.},
  author = {Hasselmo, Michael E and Shay, Christopher F},
  year = {2014},
  month = jan,
  volume = {8},
  pages = {201},
  issn = {1662-5137},
  doi = {10.3389/fnsys.2014.00201},
  abstract = {This article presents a model using cellular resonance and rebound properties to model grid cells in medial entorhinal cortex. The model simulates the intrinsic resonance properties of single layer II stellate cells with different frequencies due to the hyperpolarization activated cation current (h current). The stellate cells generate rebound spikes after a delay interval that differs for neurons with different resonance frequency. Stellate cells drive inhibitory interneurons to cause rebound from inhibition in an alternate set of stellate cells that drive interneurons to activate the first set of cells. This allows maintenance of activity with cycle skipping of the spiking of cells that matches recent physiological data on theta cycle skipping. The rebound spiking interacts with subthreshold oscillatory input to stellate cells or interneurons regulated by medial septal input and defined relative to the spatial location coded by neurons. The timing of rebound determines whether the network maintains the activity for the same location or shifts to phases of activity representing a different location. Simulations show that spatial firing patterns similar to grid cells can be generated with a range of different resonance frequencies, indicating how grid cells could be generated with low frequencies present in bats and in mice with knockout of the HCN1 subunit of the h current.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IXEUTARH\\Hasselmo, Shay - 2014 - Grid cell firing patterns may arise from feedback interaction between intrinsic rebound spiking and transverse t.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\VTNZWFDG\\Hasselmo, Shay - 2014 - Grid cell firing patterns may arise from feedback interaction between intrinsic rebound spiking and transverse t.pdf},
  journal = {Frontiers in systems neuroscience},
  keywords = {entorhinal cortex,oscillatory interference,patch-recording,spatial navigation,stellate cells},
  number = {October},
  pmid = {25400555}
}

@article{hasselmo_stern_2006,
  title = {Mechanisms Underlying Working Memory for Novel Information},
  author = {Hasselmo, Michael E. and Stern, Chantal E.},
  year = {2006},
  month = nov,
  volume = {10},
  pages = {487--493},
  issn = {13646613},
  doi = {10.1016/j.tics.2006.09.005},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PNY7H53L\\Hasselmo and Stern - 2006 - Mechanisms underlying working memory for novel inf.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {11}
}

@article{hasselmo_stern_2014,
  title = {Theta Rhythm and the Encoding and Retrieval of Space and Time.},
  author = {Hasselmo, Michael E and Stern, Chantal E},
  year = {2014},
  month = jan,
  volume = {85 Pt 2},
  pages = {656--666},
  issn = {1095-9572},
  doi = {10.1016/j.neuroimage.2013.06.022},
  abstract = {Physiological data demonstrates theta frequency oscillations associated with memory function and spatial behavior. Modeling and data from animals provide a perspective on the functional role of theta rhythm, including correlations with behavioral performance and coding by timing of spikes relative to phase of oscillations. Data supports a theorized role of theta rhythm in setting the dynamics for encoding and retrieval within cortical circuits. Recent data also supports models showing how network and cellular theta rhythmicity allows neurons in the entorhinal cortex and hippocampus to code time and space as a possible substrate for encoding events in episodic memory. Here we discuss these models and relate them to current physiological and behavioral data.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PF76IP25\\Hasselmo, Stern - 2014 - Theta rhythm and the encoding and retrieval of space and time.pdf},
  journal = {NeuroImage},
  keywords = {Electroencephalograph,Entorhinal cortex,Grid cells,Hippocampus,Memory,Place cells,Resonance},
  pmid = {23774394}
}

@article{hasselmo_stern_2015,
  title = {Current Questions on Space and Time Encoding},
  author = {Hasselmo, Michael E and Stern, Chantal E},
  year = {2015},
  volume = {25},
  pages = {744--752},
  issn = {10981063},
  doi = {10.1002/hipo.22454},
  abstract = {The groundbreaking findings on place cells and grid cells have provided an essential foothold on the understanding the cognitive encoding of space and time in episodic memory function. This foothold provides a closer view of a broad new world of important research questions raised by the phenomena of place cells and grid cells. These questions concern the mechanisms of generation of place and grid cell responses, as well as responses of time cells, including sensory influences, circuit dynamics and intrinsic properties. In addition, questions concern the functional role of place cells, grid cells and time cells in mediating goal-directed behavior and episodic memory function. This article is protected by copyright. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\J7RDEMLE\\Hasselmo, Stern - 2015 - Current questions on space and time encoding.pdf},
  journal = {Hippocampus},
  keywords = {Entorhinal cortex,Grid cells,Place cells,Rat},
  number = {6},
  pmid = {25786389}
}

@article{hasselmo_stern_2018,
  title = {A Network Model of Behavioural Performance in a Rule Learning Task},
  author = {Hasselmo, Michael E and Stern, Chantal E.},
  year = {2018},
  volume = {373},
  issn = {14712970},
  doi = {10.1098/rstb.2017.0275},
  abstract = {Humans demonstrate differences in performance on cognitive rule learning tasks which could involve differences in properties of neural circuits. An example model is presented to show how gating of the spread of neural activity could underlie rule learning and the generalization of rules to previously unseen stimuli. This model uses the activity of gating units to regulate the pattern of connectivity between neurons responding to sensory input and subsequent gating units or output units. This model allows analysis of network parameters that could contribute to differences in cognitive rule learning. These network parameters include differences in the parameters of synaptic modification and presynaptic inhibition of synaptic transmission that could be regulated by neuromodulatory influences on neural circuits. Neuromodulatory receptors play an important role in cognitive function, as demonstrated by the fact that drugs that block cholinergic muscarinic receptors can cause cognitive impairments. In discussions of the links between neuromodulatory systems and biologically based traits, the issue of mechanisms through which these linkages are realized is often missing. This model demonstrates potential roles of neural circuit parameters regulated by acetylcholine in learning context-dependent rules, and demonstrates the potential contribution of variation in neural circuit properties and neuromodulatory function to individual differences in cognitive function. This article is part of the theme issue `Diverse perspectives on diversity: multi-disciplinary approaches to taxonomies of individual differences'.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\39UAG9P8\\Hasselmo, Stern - 2018 - A network model of behavioural performance in a rule learning task(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\FCW9KD66\\Hasselmo, Stern - 2018 - A network model of behavioural performance in a rule learning task.pdf},
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  keywords = {Muscarinic receptors,Neocortex,Rule learning},
  number = {1744}
}

@article{hasson_goldstein_2020,
  title = {Direct {{Fit}} to {{Nature}}: {{An Evolutionary Perspective}} on {{Biological}} and {{Artificial Neural Networks}}},
  shorttitle = {Direct {{Fit}} to {{Nature}}},
  author = {Hasson, Uri and Nastase, Samuel A. and Goldstein, Ariel},
  year = {2020},
  month = feb,
  volume = {105},
  pages = {416--434},
  issn = {08966273},
  doi = {10.1016/j.neuron.2019.12.002},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\C6ZDWXPW\\Hasson et al. - 2020 - Direct Fit to Nature An Evolutionary Perspective .pdf},
  journal = {Neuron},
  language = {en},
  number = {3}
}

@book{hastie_friedman_2008,
  title = {The {{Elements}} of {{Statistical Learning The Elements}} of {{Statistical Learning}}},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year = {2008},
  abstract = {During the past decade there has been an explosion in computation and information tech-nology. With it have come vast amounts of data in a variety of fields such as medicine, biolo-gy, finance, and marketing. The challenge of understanding these data has led to the devel-opment of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It should be a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting\textemdash the first comprehensive treatment of this topic in any book. This major new edition features many topics not covered in the original, including graphical models, random forests, ensemble methods, least angle regression \& path algorithms for the lasso, non-negative matrix factorization, and spectral clustering. There is also a chapter on methods for " wide " data (p bigger than n), including multiple testing and false discovery rates. Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie co-developed much of the statistical modeling software and environment in R/S-PLUS and invented principal curves and surfaces. Tibshirani proposed the lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, projection pursuit and gradient boosting.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TYBC5AZY\\Hastie, Tibshirani, Friedman - Unknown - The Elements of Statistical Learning The Elements of Statistical Learning.pdf}
}

@article{hasuo_gallagher_1990,
  title = {A Calcium-Dependent Slow Afterdepolarization Recorded in Rat Dorsolateral Septal Nucleus Neurons in Vitro.},
  author = {Hasuo, H and Phelan, K D and Twery, M J and Gallagher, J P},
  year = {1990},
  volume = {64},
  pages = {1838--1846},
  issn = {09218696},
  doi = {10.1016/S0921-8696(06)80357-9},
  abstract = {1. Conventional intracellular and single-electrode voltage-clamp recordings were obtained from rat brain slices containing dorsolateral septal nucleus (DLSN) neurons in vitro. 2. We observed a slow afterdepolarizing potential (slow-ADP) that lasted up to several seconds (half-decay time was in the range of 0.7-1.4 s) in almost 15\{\%\} of DLSN neurons; these same neurons could exhibit burst firing activity. The amplitude of this slow-ADP was not affected by hyperpolarization of the membrane potential. 3. The slow-ADP was associated with an increased membrane conductance. Hybrid voltage clamping of the slow-ADP revealed a transient slow inward current (slow-ADC). The current-voltage relationship of the slow-ADC was linear between -40 and -100 mV and generated an extrapolated reversal potential of -30 mV. 4. We investigated the ionic mechanism of the slow-ADP in the rat DLSN. Slow-ADPs were not blocked by 1 microM tetrodotoxin (TTX) but were markedly depressed by 200 microM Cd2+, Ca2(+)-free, low-Na+ solutions, and the intracellular injection of ethylene glycol-bis(B-aminoethyl ether)-N,N,N',N'-tetraacetic acid (EGTA). Neither diltiazam (10 microM), an L-type Ca2+ channel blocker nor omega-conatoxin (0.2-2.5 microM), an N-type Ca2+ channel blocker affected the slow-ADP. Similarly, the slow-ADP was not affected in a low-Cl- solution. On the other hand, the slow-ADP was enhanced in a K(+)-free solution. In addition, the slow-ADP was not affected by 1 mM kynurenic acid, a broad-spectrum excitatory amino acid antagonist. 5. We conclude that the slow-ADP in the rat DLSN is mediated by a novel Ca2(+)-dependent, Na(+)-dependent, and nonsynaptic inward current that may be similar to the Ca2(+)-activated nonspecific cation channel currents (i.e., CAN-currents) described in various tissues. This current appears to underlie some forms of spontaneous bursting activity recorded from rat DLSN neurons. It may also be responsible for some types of bursting activity recorded in other CNS neurons.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IPH85864\\Hasuo et al. - 1990 - A calcium-dependent slow afterdepolarization recorded in rat dorsolateral septal nucleus neurons in vitro.pdf},
  journal = {Journal of neurophysiology},
  number = {6},
  pmid = {2074467}
}

@article{haueis_haueis_2012,
  title = {The Fuzzy Brain. {{Vagueness}} and Mapping Connectivity of the Human Cerebral Cortex.},
  author = {Haueis, Philipp},
  year = {2012},
  month = jan,
  volume = {6},
  pages = {37},
  issn = {1662-5129},
  doi = {10.3389/fnana.2012.00037},
  abstract = {While the past century of neuroscientific research has brought considerable progress in defining the boundaries of the human cerebral cortex, there are cases in which the demarcation of one area from another remains fuzzy. Despite the existence of clearly demarcated areas, examples of gradual transitions between areas are known since early cytoarchitectonic studies. Since multi-modal anatomical approaches and functional connectivity studies brought renewed attention to the topic, a better understanding of the theoretical and methodological implications of fuzzy boundaries in brain science can be conceptually useful. This article provides a preliminary conceptual framework to understand this problem by applying philosophical theories of vagueness to three levels of neuroanatomical research. For the first two levels (cytoarchitectonics and fMRI studies), vagueness will be distinguished from other forms of uncertainty, such as imprecise measurement or ambiguous causal sources of activation. The article proceeds to discuss the implications of these levels for the anatomical study of connectivity between cortical areas. There, vagueness gets imported into connectivity studies since the network structure is dependent on the parcellation scheme and thresholds have to be used to delineate functional boundaries. Functional connectivity may introduce an additional form of vagueness, as it is an organizational principle of the brain. The article concludes by discussing what steps are appropriate to define areal boundaries more precisely.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TIBLT6QG\\Haueis - 2012 - The fuzzy brain. Vagueness and mapping connectivity of the human cerebral cortex.pdf},
  journal = {Frontiers in neuroanatomy},
  keywords = {connectivity,cytoarchitectonics,fuzzy boundaries,neuroanatomy,statistical thresholding,vagueness},
  number = {September},
  pmid = {22973199}
}

@article{hauk_marslen-wilson_2006,
  title = {The Time Course of Visual Word Recognition as Revealed by Linear Regression Analysis of {{ERP}} Data},
  author = {Hauk, O and Davis, M H and Ford, M and Pulverm{\"u}ller, F. and {Marslen-Wilson}, W D},
  year = {2006},
  volume = {30},
  pages = {1383--1400},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2005.11.048},
  abstract = {EEG correlates of a range of psycholinguistic word properties were used to investigate the time course of access to psycholinguistic information during visual word recognition. Neurophysiological responses recorded in a visual lexical decision task were submitted to linear regression analysis. First, 10 psycholinguistic features of each of 300 stimulus words were submitted to a principal component analysis, which yielded four orthogonal variables likely to reflect separable processes in visual word recognition: Word length, Letter n-gram frequency, Lexical frequency and Semantic coherence of a word's morphological family. Since the lexical decision task required subjects to distinguish between words and pseudowords, the binary variable Lexicality was also investigated using a factorial design. Word-pseudoword differences in the event-related potential first appeared at 160 ms after word onset. However, regression analysis of EEG data documented a much earlier effect of both Word length and Letter n-gram frequency around 90 ms. Lexical frequency showed its earliest effect slightly later, at 110 ms, and Semantic coherence significantly correlated with neurophysiological measures around 160 ms, simultaneously with the lexicality effect. Source estimates indicated parieto-temporo-occipital generators for the factors Length, Letter n-gram frequency and Word frequency, but widespread activation with foci in left anterior temporal lobe and inferior frontal cortex related to Semantic coherence. At later stages (\textbackslash textgreater200 ms), all variables exhibited simultaneous EEG correlates. These results indicate that information about surface form and meaning of a lexical item is first accessed at different times in different brain systems and then processed simultaneously, thus supporting cascaded interactive processing models. \textcopyright{} 2005 Elsevier Inc. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4BFNYJ5D\\Hauk et al. - 2006 - The time course of visual word recognition as revealed by linear regression analysis of ERP data.pdf},
  journal = {NeuroImage},
  keywords = {Lexical decision,Lexicality,LSA,Source estimation,Visual word recognition},
  number = {4},
  pmid = {16460964}
}

@article{hauser_ray_2019,
  title = {State-{{Space Representations}} of {{Deep Neural Networks}}},
  author = {Hauser, Michael and Gunn, Sean and Saab, Samer and Ray, Asok},
  year = {2019},
  month = mar,
  volume = {31},
  pages = {538--554},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/neco_a_01165},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CSU69C92\\Hauser et al. - 2019 - State-Space Representations of Deep Neural Network.pdf},
  journal = {Neural Computation},
  language = {en},
  number = {3}
}

@article{hawellek_pesaran_2016,
  title = {Temporal Coding of Reward-Guided Choice in the Posterior Parietal Cortex},
  author = {Hawellek, David J and Wong, Yan T and Pesaran, Bijan},
  year = {2016},
  volume = {113},
  pages = {13492--13497},
  issn = {0027-8424},
  doi = {10.1073/pnas.1606479113},
  abstract = {Making a decision involves computations across distributed cortical and subcortical networks. How such distributed processing is performed remains unclear. We test how the encoding of choice in a key decision-making node, the posterior parietal cortex (PPC), depends on the temporal structure of the surrounding population activity. We recorded spiking and local field potential (LFP) activity in the PPC while two rhesus macaques performed a decision-making task. We quantified the mutual information that neurons carried about an upcoming choice and its dependence on LFP activity. The spiking of PPC neurons was correlated with LFP phases at three distinct time scales in the theta, beta, and gamma frequency bands. Importantly, activity at these time scales encoded upcoming decisions differently. Choice information contained in neural firing varied with the phase of beta and gamma activity. For gamma activity, maximum choice information occurred at the same phase as the maximum spike count. However, for beta activity, choice information and spike count were greatest at different phases. In contrast, theta activity did not modulate the encoding properties of PPC units directly but was correlated with beta and gamma activity through cross-frequency coupling. We propose that the relative timing of local spiking and choice information reveals temporal reference frames for computations in either local or large-scale decision networks. Differences between the timing of task information and activity patterns may be a general signature of distributed processing across large-scale networks.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YHW8FV4H\\Hawellek, Wong, Pesaran - 2016 - Temporal coding of reward-guided choice in the posterior parietal cortex.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  number = {47},
  pmid = {27821752}
}

@article{hawkins_ahmad_2018,
  title = {A {{Framework}} for {{Intelligence}} and {{Cortical Function Based}} on {{Grid Cells}} in the {{Neocortex}}},
  author = {Hawkins, Jeff and Lewis, Marcus and Klukas, Mirko and Purdy, Scott and Ahmad, Subutai},
  year = {2018},
  pages = {442418},
  doi = {10.1101/442418},
  abstract = {How the neocortex works is a mystery. In this paper we propose a novel framework for understanding its function. Grid cells are neurons in the entorhinal cortex that represent the location of an animal in its environment. Recent evidence suggests that grid cell-like neurons may also be present in the neocortex. We propose that grid cells exist throughout the neocortex, in every region and in every cortical column. They define a location-based framework for how the neocortex functions. Whereas grid cells in the entorhinal cortex represent the location of one thing, the body relative to its environment, we propose that cortical grid cells simultaneously represent the location of many things. Cortical columns in somatosensory cortex track the location of tactile features relative to the object being touched and cortical columns in visual cortex track the location of visual features relative to the object being viewed. We propose that mechanisms in the entorhinal cortex and hippocampus that evolved for learning the structure of environments are now used by the neocortex to learn the structure of objects. Having a representation of location in each cortical column suggests mechanisms for how the neocortex represents object compositionality and object behaviors. It leads to the hypothesis that every part of the neocortex learns complete models of objects and that there are many models of each object distributed throughout the neocortex. The similarity of circuitry observed in all cortical regions is strong evidence that even high-level cognitive tasks are learned and represented in a location-based framework.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4WW74599\\Hawkins et al. - Unknown - A Framework for Intelligence and Cortical Function Based on Grid Cells in the Neocortex.pdf},
  journal = {bioRxiv}
}

@article{hawkins_heathcote_2017,
  title = {On the Efficiency of Neurally-Informed Cognitive Models to Identify Latent Cognitive States},
  author = {Hawkins, Guy E and Mittner, Matthias and Forstmann, Birte U and Heathcote, Andrew},
  year = {2017},
  volume = {76},
  pages = {142--155},
  doi = {10.1016/j.jmp.2016.06.007},
  abstract = {\textbullet{} Explores the recovery of cognitive models that are informed with neural data. \textbullet{} Contrasts two frameworks for using neural data to identify latent cognitive states. \textbullet{} Neural data have more power to recover discrete versus continuous latent states. \textbullet{} Reliably identifying latent cognitive states depends on effect size in neural data. a b s t r a c t Psychological theory is advanced through empirical tests of predictions derived from quantitative cog-nitive models. As cognitive models are developed and extended, they tend to increase in complexity \textendash{} leading to more precise predictions \textendash{} which places concomitant demands on the behavioral data used to discriminate between candidate theories. To aid discrimination between cognitive models and, more recently, to constrain parameter estimation, neural data have been used as an adjunct to behavioral data, or as a central stream of information, in the evaluation of cognitive models. Such a model-based neuro-science approach entails many advantages, including precise tests of hypotheses about brain\textendash behavior relationships. There have, however, been few systematic investigations of the capacity for neural data to constrain the recovery of cognitive models. Through the lens of cognitive models of speeded decision-making, we investigated the efficiency of neural data to aid identification of latent cognitive states in models fit to behavioral data. We studied two theoretical frameworks that differed in their assumptions about the composition of the latent generating state. The first assumed that observed performance was generated from a mixture of discrete latent states. The second conceived of the latent state as dynami-cally varying along a continuous dimension. We used a simulation-based approach to compare recovery of latent data-generating states in neurally-informed versus neurally-uninformed cognitive models. We found that neurally-informed cognitive models were more reliably recovered under a discrete state rep-resentation than a continuous dimension representation for medium effect sizes, although recovery was difficult for small sample sizes and moderate noise in neural data. Recovery improved for both represen-tations when a larger effect size differentiated the latent states. We conclude that neural data aids the identification of latent states in cognitive models, but different frameworks for quantitatively inform-ing cognitive models with neural information have different model recovery efficiencies. We provide full worked examples and freely-available code to implement the two theoretical frameworks.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3S9XAETE\\Hawkins et al. - 2017 - On the efficiency of neurally-informed cognitive models to identify latent cognitive states.pdf},
  journal = {Journal of Mathematical Psychology},
  keywords = {Behavioral data,Cognitive model,Model recovery,Neural data,Simulation}
}

@article{hayakawa_fukai_2020,
  title = {Spontaneous and Stimulus-Induced Coherent States of Critically Balanced Neuronal Networks},
  author = {Hayakawa, Takashi and Fukai, Tomoki},
  year = {2020},
  month = mar,
  volume = {2},
  pages = {013253},
  issn = {2643-1564},
  doi = {10.1103/PhysRevResearch.2.013253},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\E9TEQRQD\\Hayakawa and Fukai - 2020 - Spontaneous and stimulus-induced coherent states o.pdf},
  journal = {Physical Review Research},
  language = {en},
  number = {1}
}

@article{hayworth_hayworth_2012,
  title = {Dynamically {{Partitionable Autoassociative Networks}} as a {{Solution}} to the {{Neural Binding Problem}}},
  author = {Hayworth, Kenneth J},
  year = {2012},
  volume = {6},
  pages = {1--22},
  issn = {1662-5188},
  doi = {10.3389/fncom.2012.00073},
  abstract = {An outstanding question in theoretical neuroscience is how the brain solves the neural binding problem. In vision, binding can be summarized as the ability to represent that certain properties belong to one object while other properties belong to a different object. I review the binding problem in visual and other domains, and review its simplest proposed solution - the anatomical binding hypothesis. This hypothesis has traditionally been rejected as a true solution because it seems to require a type of one-to-one wiring of neurons that would be impossible in a biological system (as opposed to an engineered system like a computer). I show that this requirement for one-to-one wiring can be loosened by carefully considering how the neural representation is actually put to use by the rest of the brain. This leads to a solution where a symbol is represented not as a particular pattern of neural activation but instead as a piece of a global stable attractor state. I introduce the Dynamically Partitionable AutoAssociative Network (DPAAN) as an implementation of this solution and show how DPANNs can be used in systems which perform perceptual binding and in systems that implement syntax-sensitive rules. Finally I show how the core parts of the cognitive architecture ACT-R can be neurally implemented using a DPAAN as ACT-R's global workspace. Because the DPAAN solution to the binding problem requires only "flat" neural representations (as opposed to the phase encoded representation hypothesized in neural synchrony solutions) it is directly compatible with the most well developed neural models of learning, memory, and pattern recognition.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HY3YTXAC\\Hayworth - 2012 - Dynamically Partitionable Autoassociative Networks as a Solution to the Neural Binding Problem.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\RFZBTBRN\\Hayworth - 2012 - Dynamically Partitionable Autoassociative Networks as a Solution to the Neural Binding Problem(2).pdf},
  journal = {Frontiers in Computational Neuroscience},
  keywords = {binding problem,global workspace},
  number = {September},
  pmid = {23060784}
}

@article{hayworth_marblestone_2018,
  title = {How Thalamic Relays Might Orchestrate Supervised Deep Training and Symbolic Computation in the Brain},
  author = {Hayworth, Kenneth J and Marblestone, Adam H},
  year = {2018},
  doi = {10.1101/304980},
  abstract = {The thalamus appears to be involved in the flexible routing of information among cortical areas, yet the computational implications of such routing are only beginning to be explored. Here we create a connectionist model of how selectively gated cortico-thalamo-cortical relays could underpin both symbolic and sub-symbolic computations. We first show how gateable relays can be used to create a Dynamically Partitionable Auto-Associative Network (DPAAN) (Hayworth, 2012) consisting of a set of cross-connected cortical memory buffers. All buffers and relays in a DPAAN are trained simultaneously to have a common set of stable attractor states that become the symbol vocabulary of the DPAAN. We show via simulations that such a DPAAN can support operations necessary for syntactic rule-based computation, namely buffer-to-buffer copying and equality detection. We then provide each DPAAN module with a multilayer input network trained to map sensory inputs to the DPAAN's symbol vocabulary, and demonstrate how gateable thalamic relays can provide recall and clamping operations to train this input network by Contrastive Hebbian Learning (CHL) (Xie and Seung, 2003). We suggest that many such DPAAN modules may exist at the highest levels of the brain's sensory hierarchies and show how a joint snapshot of the contents of multiple DPAAN modules can be stored as a declarative memory in a simple model of the hippocampus. We speculate that such an architecture might first have been 'discovered' by evolution as a means to bootstrap learning of more meaningful cortical representations feeding the striatum, eventually leading to a system that could support symbolic computation. Our model serves as a bridging hypothesis for linking controllable thalamo-cortical information routing with computations that could underlie aspects of both learning and symbolic reasoning in the brain.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5UMJA8V8\\Hayworth, Marblestone - Unknown - How thalamic relays might orchestrate supervised deep training and symbolic computation in the brain.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\9SUKA9S7\\Hayworth, Marblestone - Unknown - How thalamic relays might orchestrate supervised deep training and symbolic computation in the brai(2).pdf}
}

@article{hazan_kozma_2018,
  title = {{{BindsNET}}: {{A Machine Learning}}-{{Oriented Spiking Neural Networks Library}} in {{Python}}},
  shorttitle = {{{BindsNET}}},
  author = {Hazan, Hananel and Saunders, Daniel J. and Khan, Hassaan and Patel, Devdhar and Sanghavi, Darpan T. and Siegelmann, Hava T. and Kozma, Robert},
  year = {2018},
  volume = {12},
  issn = {1662-5196},
  doi = {10.3389/fninf.2018.00089},
  abstract = {The development of spiking neural network simulation software is a critical component enabling the modeling of neural systems and the development of biologically inspired algorithms. Existing software frameworks support a wide range of neural functionality, software abstraction levels, and hardware devices, yet are typically not suitable for rapid prototyping or application to problems in the domain of machine learning. In this paper, we describe a new Python package for the simulation of spiking neural networks, specifically geared towards machine learning and reinforcement learning. Our software, called \textbackslash texttt\{BindsNET\}, enables rapid building and simulation of spiking networks and features user-friendly, concise syntax. \textbackslash texttt\{BindsNET\} is built on the \textbackslash texttt\{PyTorch\} deep neural networks library, facilitating the implementation of spiking neural networks on fast CPU and GPU computational platforms. Moreover, the \textbackslash texttt\{BindsNET\} framework can be adjusted to utilize other existing computing and hardware backends; e.g., \textbackslash texttt\{TensorFlow\} and \textbackslash texttt\{SpiNNaker\}. We provide an interface with the OpenAI \textbackslash texttt\{gym\} library, allowing for training and evaluation of spiking networks on reinforcement learning environments. We argue that this package facilitates the use of spiking networks for large-scale machine learning problems and show some simple examples by using \textbackslash texttt\{BindsNET\} in practice. \textbackslash blfootnote\{\textbackslash texttt\{BindsNET\} code is available at \textbackslash texttt\{https://github.com/Hananel-Hazan/bindsnet\}. To install the version of the code used for this paper, use \textbackslash texttt\{pip install bindsnet=0.2.1\}.\}},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\S2J39NTX\\Hazan et al. - 2018 - BindsNET A Machine Learning-Oriented Spiking Neur.pdf},
  journal = {Frontiers in Neuroinformatics},
  language = {English}
}

@article{hazy_oreilly_2006,
  title = {Banishing the Homunculus: {{Making}} Working Memory Work},
  author = {Hazy, T. E. and Frank, M. J. and O'Reilly, Randall C},
  year = {2006},
  volume = {139},
  pages = {105--118},
  issn = {03064522},
  doi = {10.1016/j.neuroscience.2005.04.067},
  abstract = {The prefrontal cortex has long been thought to subserve both working memory and "executive" function, but the mechanistic basis of their integrated function has remained poorly understood, often amounting to a homunculus. This paper reviews the progress in our laboratory and others pursuing a long-term research agenda to deconstruct this homunculus by elucidating the precise computational and neural mechanisms underlying these phenomena. We outline six key functional demands underlying working memory, and then describe the current state of our computational model of the prefrontal cortex and associated systems in the basal ganglia (BG). The model, called PBWM (prefrontal cortex, basal ganglia working memory model), relies on actively maintained representations in the prefrontal cortex, which are dynamically updated/gated by the basal ganglia. It is capable of developing human-like performance largely on its own by taking advantage of powerful reinforcement learning mechanisms, based on the midbrain dopaminergic system and its activation via the basal ganglia and amygdala. These learning mechanisms enable the model to learn to control both itself and other brain areas in a strategic, task-appropriate manner. The model can learn challenging working memory tasks, and has been corroborated by several important empirical studies. ?? 2005.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9J47YTRA\\Hazy, Frank, O'Reilly - 2006 - Banishing the homunculus Making working memory work.pdf},
  journal = {Neuroscience},
  keywords = {basal ganglia,computational modeling,dopamine,Pavlovian conditioning,prefrontal cortex,reinforcement learning},
  number = {1},
  pmid = {16343792}
}

@article{hazy_oreilly_2010,
  title = {Neural Mechanisms of Acquired Phasic Dopamine Responses in Learning},
  author = {Hazy, Thomas E. and Frank, Michael J. and O'Reilly, Randall C},
  year = {2010},
  volume = {34},
  pages = {701--720},
  issn = {01497634},
  doi = {10.1016/j.neubiorev.2009.11.019},
  abstract = {What biological mechanisms underlie the reward-predictive firing properties of midbrain dopaminergic neurons, and how do they relate to the complex constellation of empirical findings understood as Pavlovian and instrumental conditioning? We previously presented PVLV, a biologically inspired Pavlovian learning algorithm accounting for DA activity in terms of two interrelated systems: a primary value (PV) system, which governs how DA cells respond to a US (reward) and; a learned value (LV) system, which governs how DA cells respond to a CS. Here, we provide a more extensive review of the biological mechanisms supporting phasic DA firing and their relation to the spate of Pavlovian conditioning phenomena and their sensitivity to focal brain lesions. We further extend the model by incorporating a new NV (novelty value) component reflecting the ability of novel stimuli to trigger phasic DA firing, providing "novelty bonuses" which encourages exploratory working memory updating and in turn speeds learning in trace conditioning and other working memory-dependent paradigms. The evolving PVLV model builds upon insights developed in many earlier computational models, especially reinforcement learning models based on the ideas of Sutton and Barto, biological models, and the psychological model developed by Savastano and Miller. The PVLV framework synthesizes these various approaches, overcoming important shortcomings of each by providing a coherent and specific mapping to much of the relevant empirical data at both the micro- and macro-levels, and examines their relevance for higher order cognitive functions. ?? 2009 Elsevier Ltd. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PV6DVFJQ\\Hazy, Frank, O'Reilly - 2010 - Neural mechanisms of acquired phasic dopamine responses in learning.pdf},
  journal = {Neuroscience and Biobehavioral Reviews},
  keywords = {Basal ganglia,Computational model,Conditioning,Dopamine,Learning},
  number = {5},
  pmid = {19944716}
}

@article{he_koenig_2019,
  title = {Electrophysiological {{Brain Connectivity}}: {{Theory}} and {{Implementation}}},
  shorttitle = {Electrophysiological {{Brain Connectivity}}},
  author = {He, Bin and Astolfi, Laura and {Valdes-Sosa}, Pedro A. and Marinazzo, Daniele and Palva, Satu and Benar, Christian G. and Michel, Christoph M. and Koenig, Thomas},
  year = {2019},
  pages = {1--1},
  issn = {0018-9294, 1558-2531},
  doi = {10.1109/TBME.2019.2913928},
  abstract = {We review the theory and algorithms of electrophysiological brain connectivity analysis. This tutorial is aimed at providing an introduction to brain functional connectivity from electrophysiological signals, including electroencephalography (EEG), magnetoencephalography (MEG), electrocorticography (ECoG), stereoelectroencephalography (SEEG). Various connectivity estimators are discussed, and algorithms introduced. Important issues for estimating and mapping brain functional connectivity with electrophysiology are discussed.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TU5IS6LN\\He et al. - 2019 - Electrophysiological Brain Connectivity Theory an.pdf},
  journal = {IEEE Transactions on Biomedical Engineering},
  language = {en}
}

@article{he_zhao_2013,
  title = {Spectral Analysis for Nonstationary and Nonlinear Systems: A Discrete-Time-Model-Based Approach.},
  author = {He, Fei and a Billings, Stephen and Wei, Hua-Liang and Sarrigiannis, Ptolemaios G and Zhao, Yifan},
  year = {2013},
  month = aug,
  volume = {60},
  pages = {2233--2241},
  issn = {1558-2531},
  doi = {10.1109/TBME.2013.2252347},
  abstract = {A new frequency-domain analysis framework for nonlinear time-varying systems is introduced based on parametric time-varying nonlinear autoregressive with exogenous input models. It is shown how the time-varying effects can be mapped to the generalized frequency response functions (FRFs) to track nonlinear features in frequency, such as intermodulation and energy transfer effects. A new mapping to the nonlinear output FRF is also introduced. A simulated example and the application to intracranial electroencephalogram data are used to illustrate the theoretical results.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HFV7MVU7\\He et al. - 2013 - Spectral analysis for nonstationary and nonlinear systems a discrete-time-model-based approach.pdf},
  journal = {IEEE transactions on bio-medical engineering},
  keywords = {Algorithms,Brain,Brain: physiology,Computer Simulation,Computer-Assisted,Data Interpretation,Electroencephalography,Electroencephalography: methods,Models,Neurological,Nonlinear Dynamics,Signal Processing,Statistical,Stochastic Processes},
  number = {8},
  pmid = {23508247}
}

@article{heathcote_brown_2014,
  title = {The Falsifiability of Actual Decision-Making Models.},
  author = {Heathcote, Andrew and Wagenmakers, E.-J and Brown, Scott D},
  year = {2014},
  volume = {121},
  pages = {676--678},
  issn = {1939-1471},
  doi = {10.1037/a0037771},
  abstract = {Jones and Dzhafarov (2014) provided a useful service in pointing out that some assumptions of modern decision-making models require additional scrutiny. Their main result, however, is not surprising: If an infinitely complex model was created by assigning its parameters arbitrarily flexible distributions, this new model would be able to fit any observed data perfectly. Such a hypothetical model would be unfalsifiable. This is exactly why such models have never been proposed in over half a century of model development in decision making. Additionally, the main conclusion drawn from this result-that the success of existing decision-making models can be attributed to assumptions about parameter distributions-is wrong. (PsycINFO Database Record (c) 2014 APA, all rights reserved).},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\T2QN7U3S\\Heathcote, Wagenmakers, Brown - 2014 - The falsifiability of actual decision-making models.pdf},
  journal = {Psychological Review},
  keywords = {choice reaction time,diffusion model,linear ballistic accumulator,model falsifiability},
  number = {4},
  pmid = {25347313}
}

@article{hebscher_gilboa_2016,
  title = {A Boost of Confidence: {{The}} Role of the Ventromedial Prefrontal Cortex in Memory, Decision-Making, and Schemas},
  author = {Hebscher, Melissa and Gilboa, Asaf},
  year = {2016},
  volume = {90},
  pages = {46--58},
  issn = {18733514},
  doi = {10.1016/j.neuropsychologia.2016.05.003},
  abstract = {The ventromedial prefrontal cortex (vmPFC) has been implicated in a wide array of functions across multiple domains. In this review, we focus on the vmPFC's involvement in mediating strategic aspects of memory retrieval, memory-related schema functions, and decision-making. We suggest that vmPFC generates a confidence signal that informs decisions and memory-guided behaviour. Confidence is central to these seemingly diverse functions: (1) Strategic retrieval: lesions to the vmPFC impair an early, automatic, and intuitive monitoring process (???feeling of rightness???; FOR) often associated with confabulation (spontaneous reporting of erroneous memories). Critically, confabulators typically demonstrate high levels of confidence in their false memories, suggesting that faulty monitoring following vmPFC damage may lead to indiscriminate confidence signals. (2) Memory schemas: the vmPFC is critically involved in instantiating and maintaining contextually relevant schemas, broadly defined as higher level knowledge structures that encapsulate lower level representational elements. The correspondence between memory retrieval cues and these activated schemas leads to FOR monitoring. Stronger, more elaborate schemas produce stronger FOR and influence confidence in the veracity of memory candidates. (3) Finally, we review evidence on the vmPFC's role in decision-making, extending this role to decision-making during memory retrieval. During non-mnemonic and mnemonic decision-making the vmPFC automatically encodes confidence. Confidence signal in the vmPFC is revealed as a non-linear relationship between a first-order monitoring assessment and second-order action or choice. Attempting to integrate the multiple functions of the vmPFC, we propose a posterior-anterior organizational principle for this region. More posterior vmPFC regions are involved in earlier, automatic, subjective, and contextually sensitive functions, while more anterior regions are involved in controlled actions based on these earlier functions. Confidence signals reflect the non-linear relationship between first-order, posterior-mediated and second-order, anterior-mediated processes and are represented along the entire axis.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\R7TS4T9I\\Hebscher, Gilboa - 2016 - A boost of confidence The role of the ventromedial prefrontal cortex in memory, decision-making, and schemas.pdf},
  journal = {Neuropsychologia},
  keywords = {Confabulation,Confidence,Decision-Making,Memory,Schema,Ventromedial Prefrontal Cortex},
  pmid = {27150705}
}

@article{heeger_heeger_2017,
  title = {Theory of Cortical Function},
  author = {Heeger, David J.},
  year = {2017},
  month = feb,
  volume = {114},
  pages = {1773--1782},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1619788114},
  abstract = {Most models of sensory processing in the brain have a feedforward architecture in which each stage comprises simple linear filtering operations and nonlinearities. Models of this form have been used to explain a wide range of neurophysiological and psychophysical data, and many recent successes in artificial intelligence (with deep convolutional neural nets) are based on this architecture. However, neocortex is not a feedforward architecture. This paper proposes a first step toward an alternative computational framework in which neural activity in each brain area depends on a combination of feedforward drive (bottom-up from the previous processing stage), feedback drive (top-down context from the next stage), and prior drive (expectation). The relative contributions of feedforward drive, feedback drive, and prior drive are controlled by a handful of state parameters, which I hypothesize correspond to neuromodulators and oscillatory activity. In some states, neural responses are dominated by the feedforward drive and the theory is identical to a conventional feedforward model, thereby preserving all of the desirable features of those models. In other states, the theory is a generative model that constructs a sensory representation from an abstract representation, like memory recall. In still other states, the theory combines prior expectation with sensory input, explores different possible perceptual interpretations of ambiguous sensory inputs, and predicts forward in time. The theory, therefore, offers an empirically testable framework for understanding how the cortex accomplishes inference, exploration, and prediction.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4EAM2YD5\\Heeger - 2017 - Theory of cortical function.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {8}
}

@article{heeger_mackey_2019,
  title = {Oscillatory Recurrent Gated Neural Integrator Circuits ({{ORGaNICs}}), a Unifying Theoretical Framework for Neural Dynamics},
  author = {Heeger, David J. and Mackey, Wayne E.},
  year = {2019},
  month = nov,
  volume = {116},
  pages = {22783--22794},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1911633116},
  abstract = {Working memory is an example of a cognitive and neural process that is not static but evolves dynamically with changing sensory inputs; another example is motor preparation and execution. We introduce a theoretical framework for neural dynamics, based on oscillatory recurrent gated neural integrator circuits (ORGaNICs), and apply it to simulate key phenomena of working memory and motor control. The model circuits simulate neural activity with complex dynamics, including sequential activity and traveling waves of activity, that manipulate (as well as maintain) information during working memory. The same circuits convert spatial patterns of premotor activity to temporal profiles of motor control activity and manipulate (e.g., time warp) the dynamics. Derivative-like recurrent connectivity, in particular, serves to manipulate and update internal models, an essential feature of working memory and motor execution. In addition, these circuits incorporate recurrent normalization, to ensure stability over time and robustness with respect to perturbations of synaptic weights.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\996P83NZ\\Heeger and Mackey - 2019 - Oscillatory recurrent gated neural integrator circ.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {45}
}

@article{heeger_zemlianova_2020,
  title = {A Recurrent Circuit Implements Normalization, Simulating the Dynamics of {{V1}} Activity},
  author = {Heeger, David J. and Zemlianova, Klavdia O.},
  year = {2020},
  month = aug,
  pages = {202005417},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.2005417117},
  abstract = {The normalization model has been applied to explain neural activity in diverse neural systems including primary visual cortex (V1). The model's defining characteristic is that the response of each neuron is divided by a factor that includes a weighted sum of activity of a pool of neurons. Despite the success of the normalization model, there are three unresolved issues. 1) Experimental evidence supports the hypothesis that normalization in V1 operates via recurrent amplification, i.e., amplifying weak inputs more than strong inputs. It is unknown how normalization arises from recurrent amplification. 2) Experiments have demonstrated that normalization is weighted such that each weight specifies how one neuron contributes to another's normalization pool. It is unknown how weighted normalization arises from a recurrent circuit. 3) Neural activity in V1 exhibits complex dynamics, including gamma oscillations, linked to normalization. It is unknown how these dynamics emerge from normalization. Here, a family of recurrent circuit models is reported, each of which comprises coupled neural integrators to implement normalization via recurrent amplification with arbitrary normalization weights, some of which can recapitulate key experimental observations of the dynamics of neural activity in V1.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YS2ZAFFX\\Heeger and Zemlianova - 2020 - A recurrent circuit implements normalization, simu.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en}
}

@book{heilbron_chait_2018,
  title = {Great {{Expectations}}: {{Is}} There {{Evidence}} for {{Predictive Coding}} in {{Auditory Cortex}}?},
  author = {Heilbron, Micha and Chait, Maria},
  year = {2018},
  month = oct,
  volume = {389},
  doi = {10.1016/j.neuroscience.2017.07.061},
  abstract = {Predictive coding is possibly one of the most influential, comprehensive, and controversial theories of neural function. While proponents praise its explanatory potential, critics object that key tenets of the theory are untested or even untestable. The present article critically examines existing evidence for predictive coding in the auditory modality. Specifically, we identify five key assumptions of the theory and evaluate each in the light of animal, human and modeling studies of auditory pattern processing. For the first two assumptions \textendash{} that neural responses are shaped by expectations and that these expectations are hierarchically organized \textendash{} animal and human studies provide compelling evidence. The anticipatory, predictive nature of these expectations also enjoys empirical support, especially from studies on unexpected stimulus omission. However, for the existence of separate error and prediction neurons, a key assumption of the theory, evidence is lacking. More work exists on the proposed oscillatory signatures of predictive coding, and on the relation between attention and precision. However, results on these latter two assumptions are mixed or contradictory. Looking to the future, more collaboration between human and animal studies, aided by model-based analyses will be needed to test specific assumptions and implementations of predictive coding \textendash{} and, as such, help determine whether this popular grand theory can fulfill its expectations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4TWW2DD2\\Heilbron, Chait - 2018 - Great Expectations Is there Evidence for Predictive Coding in Auditory Cortex.pdf},
  isbn = {1873-7544},
  keywords = {auditory,bayesian brain,MMN,predictive coding,SSA},
  pmid = {28782642}
}

@article{helfer_shultz_2019,
  title = {A Computational Model of Systems Memory Consolidation and Reconsolidation},
  author = {Helfer, Peter and Shultz, Thomas R.},
  year = {2019},
  month = dec,
  pages = {hipo.23187},
  issn = {1050-9631, 1098-1063},
  doi = {10.1002/hipo.23187},
  abstract = {In the mammalian brain, newly acquired memories depend on the hippocampus (HPC) for maintenance and recall, but over time, the neocortex takes over these functions, rendering memories HPC-independent. The process responsible for this transformation is called systems memory consolidation. Reactivation of a well-consolidated memory can trigger a temporary return to a HPC-dependent state, a phenomenon known as systems memory reconsolidation. The neural mechanisms underlying systems memory consolidation and reconsolidation are not well understood. Here, we propose a neural model based on welldocumented mechanisms of synaptic plasticity and stability and describe a computational implementation that demonstrates the model's ability to account for a range of findings from the systems consolidation and reconsolidation literature. We derive several predictions from the computational model and suggest experiments that may test its validity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UFXDGIZ9\\Helfer and Shultz - 2019 - A computational model of systems memory consolidat.pdf},
  journal = {Hippocampus},
  language = {en}
}

@article{helfrich_kastner_2018,
  title = {Neural {{Mechanisms}} of {{Sustained Attention Are Rhythmic}}},
  author = {Helfrich, Randolph F. and Fiebelkorn, Ian C. and Szczepanski, Sara M. and Lin, Jack J. and Parvizi, Josef and Knight, Robert T. and Kastner, Sabine},
  year = {2018},
  volume = {99},
  pages = {854--865.e5},
  issn = {10974199},
  doi = {10.1016/j.neuron.2018.07.032},
  abstract = {Classic models of attention suggest that sustained neural firing constitutes a neural correlate of sustained attention. However, recent evidence indicates that behavioral performance fluctuates over time, exhibiting temporal dynamics that closely resemble the spectral features of ongoing, oscillatory brain activity. Therefore, it has been proposed that periodic neuronal excitability fluctuations might shape attentional allocation and overt behavior. However, empirical evidence to support this notion is sparse. Here, we address this issue by examining data from large-scale subdural recordings, using two different attention tasks that track perceptual ability at high temporal resolution. Our results reveal that perceptual outcome varies as a function of the theta phase even in states of sustained spatial attention. These effects were robust at the single-subject level, suggesting that rhythmic perceptual sampling is an inherent property of the frontoparietal attention network. Collectively, these findings support the notion that the functional architecture of top-down attention is intrinsically rhythmic. Helfrich et al. demonstrate that the neural basis of sustained attention is rhythmic. Using human intracranial recordings, they show that attentional allocation and overt behavior are modulated by a {$\sim$}4 Hz theta rhythm that predicts endogenous excitability fluctuations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5WLL5VFK\\Helfrich_et_al_2018_Neural_mechanisms_of_sustained_attention_are_rhythmic.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\8TUKII28\\Helfrich et al. - 2018 - Neural Mechanisms of Sustained Attention Are Rhythmic.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\A6VXMZDZ\\Helfrich et al. - 2018 - Neural Mechanisms of Sustained Attention Are Rhyth.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\JTYIGLYT\\S0896627318306305.html},
  journal = {Neuron},
  keywords = {discrete perception,electrocorticography,frontoparietal attention network,functional network parcellation,high-frequency activity,intracranial EEG,perceptual cycles,phase-dependent behavior,rhythmic attention,theta oscillations},
  number = {4},
  pmid = {30138591}
}

@article{helfrich_knight_2016,
  title = {Oscillatory {{Dynamics}} of {{Prefrontal Cognitive Control}}},
  author = {Helfrich, Randolph F and Knight, Robert T},
  year = {2016},
  volume = {xx},
  pages = {1--15},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2016.09.007},
  abstract = {The prefrontal cortex (PFC) provides the structural basis for numerous higher cognitive functions. However, it is still largely unknown which mechanisms provide the functional basis for flexible cognitive control of goal-directed behavior. Here, we review recent findings that suggest that the functional architecture of cognition is profoundly rhythmic and propose that the PFC serves as a conductor to orchestrate task-relevant large-scale networks. We highlight several studies that demonstrated that oscillatory dynamics, such as phase resetting, cross-frequency coupling (CFC), and entrainment, sup- port PFC-dependent recruitment of task-relevant regions into coherent func- tional networks. Importantly, these findings support the notion that distinct spectral signatures reflect different cortical computations supporting effec- tive multiplexing on different temporal channels along the same anatomical pathways. The},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AQWCLN9N\\Helfrich and Knight - 2016 - Oscillatory Dynamics of Prefrontal Cognitive Contr.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\MEQ8G45E\\Helfrich, Knight - 2016 - Oscillatory Dynamics of Prefrontal Cognitive Control.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\RHZZI83V\\Helfrich_Knight_2016_Oscillatory_dynamics_of_prefrontal_cognitive_control.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\9SZK5C9D\\S136466131630153X.html},
  journal = {Trends in Cognitive Sciences},
  number = {12},
  pmid = {27743685}
}

@article{helfrich_knight_2017,
  title = {Prefrontal Cortex Modulates Posterior Alpha Oscillations during Top-down Guided Visual Perception},
  author = {Helfrich, Randolph F. and Huang, Melody and Wilson, Guy and Knight, Robert T.},
  year = {2017},
  pages = {201705965},
  issn = {0027-8424},
  doi = {10.1073/pnas.1705965114},
  abstract = {Conscious visual perception is proposed to arise from the selective synchronization of functionally specialized but widely distributed cortical areas. It has been suggested that different frequency bands index distinct canonical computations. Here, we probed visual perception on a fine-grained temporal scale to study the oscillatory dynamics supporting prefrontal-dependent sensory processing. We tested whether a predictive context that was embedded in a rapid visual stream modulated the perception of a subsequent near-threshold target. The rapid stream was presented either rhythmically at 10 Hz, to entrain parietooccipital alpha oscillations, or arrhythmically. We identified a 2- to 4-Hz delta signature that modulated posterior alpha activity and behavior during predictive trials. Importantly, delta-mediated top-down control diminished the behavioral effects of bottom-up alpha entrainment. Simultaneous source-reconstructed EEG and cross-frequency directionality analyses revealed that this delta activity originated from prefrontal areas and modulated posterior alpha power. Taken together, this study presents converging behavioral and electrophysiological evidence for frontal delta-mediated top-down control of posterior alpha activity, selectively facilitating visual perception.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FFWGWFHV\\Helfrich et al. - 2017 - Prefrontal cortex modulates posterior alpha oscillations during top-down guided visual perception(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\XMTTDTPC\\Helfrich et al. - 2017 - Prefrontal cortex modulates posterior alpha oscill.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  number = {model 2},
  pmid = {28808023}
}

@article{helfrich_knight_2019,
  title = {Neural {{Entrainment}} and {{Network Resonance}} in {{Support}} of {{Top}}-down Guided {{Attention}}},
  author = {Helfrich, Randolph F and Breska, Assaf and Knight, Robert T},
  year = {2019},
  volume = {XX},
  pages = {XX--XX},
  issn = {2352250X},
  doi = {10.1016/j.copsyc.2018.12.016},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3WFB386P\\Helfrich et al. - 2019 - Neural entrainment and network resonance in suppor.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\TJZNJ6FH\\Helfrich_et_al_2019_Neural_entrainment_and_network_resonance_in_support_of_top-down_guided_attention.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\YTASK4YV\\Helfrich, Breska, Knight - 2018 - Title Neural Entrainment and Network Resonance in Support of Top-down guided Attention.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\YJND2JDA\\S2352250X18301611.html},
  journal = {Frontiers in Psychology},
  number = {XX}
}

@article{helmstaedter_helmstaedter_2015,
  title = {The {{Mutual Inspirations}} of {{Machine Learning}} and {{Neuroscience}}},
  author = {Helmstaedter, Moritz},
  year = {2015},
  volume = {86},
  pages = {25--28},
  issn = {08966273},
  doi = {10.1016/j.neuron.2015.03.031},
  abstract = {Neuron, 86 (2015) 25-28. doi:10.1016/j.neuron.2015.03.031},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\P6L7PFY2\\Helmstaedter - 2015 - The Mutual Inspirations of Machine Learning and Neuroscience.pdf},
  journal = {Neuron},
  number = {1},
  pmid = {25856482}
}

@article{henare_henare_,
  title = {Investigating the {{Relationship Between Working Memory}} and {{Selective Attention}}},
  author = {Henare, Dion T},
  pages = {212},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2835L8JB\\Henare - Investigating the Relationship Between Working Mem.pdf},
  language = {en}
}

@article{herd_friedman_2014,
  title = {A Neural Network Model of Individual Differences in Task Switching Abilities},
  author = {Herd, Seth A and O׳Reilly, Randall C and Hazy, Tom E and Chatham, Christopher H and Brant, Angela M and Friedman, Naomi P},
  year = {2014},
  volume = {62},
  pages = {375--389},
  issn = {00283932},
  doi = {10.1016/j.neuropsychologia.2014.04.014},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VUGCDLNU\\Herd et al. - 2014 - A neural network model of individual differences in task switching abilities.pdf},
  journal = {Neuropsychologia},
  number = {SEPTEMBER}
}

@article{herd_oreilly_2006,
  title = {Neural Mechanisms of Cognitive Control: An Integrative Model of Stroop Task Performance and {{FMRI}} Data.},
  author = {Herd, Seth A. and Banich, Marie T and O'Reilly, Randall C},
  year = {2006},
  volume = {18},
  pages = {22--32},
  issn = {0898-929X},
  doi = {10.1162/089892906775250012},
  abstract = {We address the connection between conceptual knowledge and cognitive control using a neural network model. This model extends a widely held theory of cognitive control [Cohen, J. D., Dunbar, K., \& McClelland, J. L. On the control of automatic processes: A parallel distributed processing model of the Stroop effect. Psychological Review, 97, 332-361, 1990] so that it can explain new empirical findings. Leveraging other computational modeling work, we hypothesize that representations used for task control are recruited from preexisting representations for categories, such as the concept of color relevant to the Stroop task we model here. This hypothesis allows the model to account for otherwise puzzling fMRI results, such as increased activity in brain regions processing to-be-ignored information. In addition, biologically motivated changes in the model's pattern of connectivity show how global competition can arise when inhibition is strictly local, as it seems to be in the cortex. We also discuss the potential for this theory to unify models of task control with other forms of attention.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\P3I43Y65\\Herd, Banich, O'Reilly - 2006 - Neural mechanisms of cognitive control an integrative model of stroop task performance and FMRI data.pdf},
  journal = {Journal of Cognitive Neuroscience},
  keywords = {Algorithms,Artificial Intelligence,Cognition,Cognition: physiology,Color Perception,Color Perception: physiology,Humans,Magnetic Resonance Imaging,Models,Neural Networks (Computer),Neurological,Neuropsychological Tests,Psychomotor Performance,Psychomotor Performance: physiology,Reaction Time,Reaction Time: physiology,Reading},
  number = {1},
  pmid = {16417680}
}

@article{herrmann_struber_2013,
  title = {Transcranial Alternating Current Stimulation: A Review of the Underlying Mechanisms and Modulation of Cognitive Processes.},
  author = {Herrmann, Christoph S and Rach, Stefan and Neuling, Toralf and Str{\"u}ber, Daniel},
  year = {2013},
  month = jan,
  volume = {7},
  pages = {279},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2013.00279},
  abstract = {Brain oscillations of different frequencies have been associated with a variety of cognitive functions. Convincing evidence supporting those associations has been provided by studies using intracranial stimulation, pharmacological interventions and lesion studies. The emergence of novel non-invasive brain stimulation techniques like repetitive transcranial magnetic stimulation (rTMS) and transcranial alternating current stimulation (tACS) now allows to modulate brain oscillations directly. Particularly, tACS offers the unique opportunity to causally link brain oscillations of a specific frequency range to cognitive processes, because it uses sinusoidal currents that are bound to one frequency only. Using tACS allows to modulate brain oscillations and in turn to influence cognitive processes, thereby demonstrating the causal link between the two. Here, we review findings about the physiological mechanism of tACS and studies that have used tACS to modulate basic motor and sensory processes as well as higher cognitive processes like memory, ambiguous perception, and decision making.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\D2ZJ536K\\Herrmann et al. - 2013 - Transcranial alternating current stimulation a review of the underlying mechanisms and modulation of cognitive.pdf},
  journal = {Frontiers in human neuroscience},
  keywords = {alpha,eeg,electroencephalogram,gamma,oscillati,oscillations,transcranial alternating current stimulation,transcranial direct current stimulation,transcranial magnetic stimulation},
  number = {June},
  pmid = {23785325}
}

@techreport{hertag_sprekeler_2020,
  title = {Learning Prediction Error Neurons in a Canonical Interneuron Circuit},
  author = {Hert{\"a}g, Loreen and Sprekeler, Henning},
  year = {2020},
  month = feb,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.02.27.968776},
  abstract = {Sensory systems constantly compare external sensory information with internally generated predictions. While neural hallmarks of prediction errors have been found throughout the brain, the circuit-level mechanisms that underlie their computation are still largely unknown. Here, we show that a well-orchestrated interplay of three interneuron types shapes the development and re nement of negative prediction-error neurons in a computational model of mouse primary visual cortex. By balancing excitation and inhibition in multiple pathways, experience-dependent inhibitory plasticity can generate di erent variants of prediction-error circuits, which can be distinguished by simulated optogenetic experiments. The experience-dependence of the model circuit is consistent with that of negative prediction-error circuits in layer 2/3 of mouse primary visual cortex. Our model makes a range of testable predictions that may shed light on the circuitry underlying the neural computation of prediction errors.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ED3YPEG6\\Hertäg and Sprekeler - 2020 - Learning prediction error neurons in a canonical i.pdf},
  language = {en},
  type = {Preprint}
}

@incollection{hesse_hesse_1966,
  title = {The {{Function}} of {{Models}}: {{A Dialogue}}},
  booktitle = {Models and {{Analogies}} in {{Science}}},
  author = {Hesse, Mary B.},
  year = {1966},
  abstract = {2nd print.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4GX63W9D\\Hesse - 1966 - The Function of Models A Dialogue.pdf},
  isbn = {978-0-268-00337-1}
}

@article{hettiarachchi_nahavandi_2016,
  title = {Multivariate {{Adaptive Autoregressive Modeling}} and {{Kalman Filtering}} for {{Motor Imagery BCI}}},
  author = {Hettiarachchi, Imali T. and Nguyen, Thanh Thi and Nahavandi, Saeid},
  year = {2016},
  pages = {3164--3168},
  doi = {10.1109/SMC.2015.549},
  abstract = {\textcopyright{} 2015 IEEE. Adaptive autoregressive (AAR) modeling of the EEG time series and the AAR parameters has been widely used in Brain computer interface (BCI) systems as input features for the classification stage. Multivariate adaptive autoregressive modeling (MVAAR) also has been used in literature. This paper revisits the use of MVAAR models and propose the use of adaptive Kalman filter (AKF) for estimating the MVAAR parameters as features in a motor imagery BCI application. The AKF approach is compared to the alternative short time moving window (STMW) MVAAR parameter estimation approach. Though the two MVAAR methods show a nearly equal classification accuracy, the AKF possess the advantage of higher estimation update rates making it easily adoptable for on-line BCI systems.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TGNM8WV2\\Hettiarachchi, Nguyen, Nahavandi - 2016 - Multivariate Adaptive Autoregressive Modeling and Kalman Filtering for Motor Imagery BCI.pdf},
  journal = {Proceedings - 2015 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2015},
  keywords = {Brain Computer Interface,Motor Imagery,Multivariate Autoregressive Modeling}
}

@article{heusser_davachi_2016,
  title = {Episodic Sequence Memory Is Supported by a Theta-Gamma Phase Code.},
  author = {Heusser, Andrew C and Poeppel, David and Ezzyat, Youssef and Davachi, Lila},
  year = {2016},
  volume = {19},
  pages = {In Revision},
  issn = {1546-1726},
  doi = {10.1038/nn.4374},
  abstract = {The meaning we derive from our experiences is not a simple static extraction of the elements but is largely based on the order in which those elements occur. Models propose that sequence encoding is supported by interactions between high- and low-frequency oscillations, such that elements within an experience are represented by neural cell assemblies firing at higher frequencies (gamma) and sequential order is encoded by the specific timing of firing with respect to a lower frequency oscillation (theta). During episodic sequence memory formation in humans, we provide evidence that items in different sequence positions exhibit greater gamma power along distinct phases of a theta oscillation. Furthermore, this segregation is related to successful temporal order memory. Our results provide compelling evidence that memory for order, a core component of an episodic memory, capitalizes on the ubiquitous physiological mechanism of theta-gamma phase-amplitude coupling.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\92L97HQ7\\Heusser et al. - 2016 - Episodic sequence memory is supported by a theta-gamma phase code.pdf},
  journal = {Nature neuroscience},
  number = {August},
  pmid = {27571010}
}

@article{heys_dombeck_2014,
  title = {The {{Functional Micro}}-Organization of {{Grid Cells Revealed}} by {{Cellular}}-{{Resolution Imaging}}},
  author = {Heys, James G and Rangarajan, Krsna V and a Dombeck, Daniel},
  year = {2014},
  volume = {84},
  pages = {1079--1090},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2014.10.048},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TUIHGV99\\Heys, Rangarajan, Dombeck - 2014 - The Functional Micro-organization of Grid Cells Revealed by Cellular-Resolution Imaging.pdf},
  journal = {Neuron},
  number = {5}
}

@article{heys_hasselmo_2012,
  title = {Effects of Acetylcholine on Neuronal Properties in Entorhinal Cortex.},
  author = {Heys, James G and Schultheiss, Nathan W and Shay, Christopher F and Tsuno, Yusuke and Hasselmo, Michael E},
  year = {2012},
  month = jan,
  volume = {6},
  pages = {32},
  issn = {1662-5153},
  doi = {10.3389/fnbeh.2012.00032},
  abstract = {The entorhinal cortex (EC) receives prominent cholinergic innervation from the medial septum and the vertical limb of the diagonal band of Broca (MSDB). To understand how cholinergic neurotransmission can modulate behavior, research has been directed toward identification of the specific cellular mechanisms in EC that can be modulated through cholinergic activity. This review focuses on intrinsic cellular properties of neurons in EC that may underlie functions such as working memory, spatial processing, and episodic memory. In particular, the study of stellate cells (SCs) in medial entorhinal has resulted in discovery of correlations between physiological properties of these neurons and properties of the unique spatial representation that is demonstrated through unit recordings of neurons in medial entorhinal cortex (mEC) from awake-behaving animals. A separate line of investigation has demonstrated persistent firing behavior among neurons in EC that is enhanced by cholinergic activity and could underlie working memory. There is also evidence that acetylcholine plays a role in modulation of synaptic transmission that could also enhance mnemonic function in EC. Finally, the local circuits of EC demonstrate a variety of interneuron physiology, which is also subject to cholinergic modulation. Together these effects alter the dynamics of EC to underlie the functional role of acetylcholine in memory.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EFF6PFWJ\\Heys et al. - 2012 - Effects of acetylcholine on neuronal properties in entorhinal cortex.pdf},
  journal = {Frontiers in behavioral neuroscience},
  keywords = {entorhinal cortex,oscillatory,oscillatory interference,spatial navigation},
  number = {July},
  pmid = {22837741}
}

@article{heys_hasselmo_2012a,
  title = {Neuromodulation of {{I}}(h) in Layer {{II}} Medial Entorhinal Cortex Stellate Cells: A Voltage-Clamp Study.},
  author = {Heys, James G and Hasselmo, Michael E},
  year = {2012},
  month = jun,
  volume = {32},
  pages = {9066--9072},
  issn = {1529-2401},
  doi = {10.1523/JNEUROSCI.0868-12.2012},
  abstract = {Stellate cells in layer II of medial entorhinal cortex (mEC) are endowed with a large hyperpolarization-activated cation current [h current (I(h))]. Recent work using in vivo recordings from awake behaving rodents demonstrate that I(h) plays a significant role in regulating the characteristic spatial periodicity of "grid cells" in mEC. A separate, yet related, line of research demonstrates that grid field spacing changes as a function of behavioral context. To understand the neural mechanism or mechanisms that could be underlying these changes in grid spacing, we have conducted voltage-clamp recordings of I(h) in layer II stellate cells. In particular, we have studied I(h) under the influence of several neuromodulators. The results demonstrate that I(h) amplitude can be both upregulated and downregulated through activation of distinct neuromodulators in mEC. Activation of muscarinic acetylcholine receptors produces a significant decrease in the I(h) tail current and a hyperpolarizing shift in the activation, whereas upregulation of cAMP through application of forskolin produces a significant increase in the I(h) amplitude and a depolarizing shift in I(h) activation curve. In addition, there was evidence of differential modulation of I(h) along the dorsal-ventral axis of mEC. Voltage-clamp protocols were also used to determine whether M current is present in stellate cells. In contrast to CA1 pyramidal neurons, which express M current, the data demonstrate that M current is not present in stellate cells. The results from this study provide key insights into a potential mechanism that could be underlying changes seen in grid field spacing during distinct behavioral contexts.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MRAUA6ZK\\Heys, Hasselmo - 2012 - Neuromodulation of I(h) in layer II medial entorhinal cortex stellate cells a voltage-clamp study.pdf},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  keywords = {Animals,Anthracenes,Atropine,Atropine: pharmacology,Biophysical Processes,Biophysical Processes: drug effects,Biophysical Processes: physiology,Carbachol,Carbachol: pharmacology,Cardiotonic Agents,Cardiotonic Agents: pharmacology,Cholinergic Antagonists,Cholinergic Antagonists: pharmacology,Colforsin,Colforsin: pharmacology,Cyclic AMP,Cyclic AMP: pharmacology,Cyclic Nucleotide-Gated Cation Channels,Cyclic Nucleotide-Gated Cation Channels: agonists,Cyclic Nucleotide-Gated Cation Channels: antagonis,Cyclic Nucleotide-Gated Cation Channels: physiolog,Electric Stimulation,Entorhinal Cortex,Entorhinal Cortex: cytology,Female,Hyperpolarization-Activated Cyclic Nucleotide-Gate,Long-Evans,Male,Membrane Potentials,Membrane Potentials: drug effects,Membrane Potentials: physiology,Neurons,Neurons: drug effects,Neurons: physiology,Neurotransmitter Agents,Neurotransmitter Agents: pharmacology,Newborn,Patch-Clamp Techniques,Potassium Channels,Potassium Channels: agonists,Potassium Channels: physiology,Pyrimidines,Pyrimidines: pharmacology,Rats,Sodium Channel Blockers,Sodium Channel Blockers: pharmacology,Tetrodotoxin,Tetrodotoxin: pharmacology,Time Factors},
  number = {26},
  pmid = {22745506}
}

@article{heys_hasselmo_2013,
  title = {Bat and Rat Neurons Differ in Theta-Frequency Resonance despite Similar Coding of Space.},
  author = {Heys, James G and MacLeod, Katrina M and Moss, Cynthia F and Hasselmo, Michael E},
  year = {2013},
  month = apr,
  volume = {340},
  pages = {363--367},
  issn = {1095-9203},
  doi = {10.1126/science.1233831},
  abstract = {Both bats and rats exhibit grid cells in medial entorhinal cortex that fire as they visit a regular array of spatial locations. In rats, grid-cell firing field properties correlate with theta-frequency rhythmicity of spiking and membrane-potential resonance; however, bat grid cells do not exhibit theta rhythmic spiking, generating controversy over the role of theta rhythm. To test whether this discrepancy reflects differences in rhythmicity at a cellular level, we performed whole-cell patch recordings from entorhinal neurons in both species to record theta-frequency resonance. Bat neurons showed no theta-frequency resonance, suggesting grid-cell coding via different mechanisms in bats and rats or lack of theta rhythmic contributions to grid-cell firing in either species.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MS9JI85S\\Heys et al. - 2013 - Bat and rat neurons differ in theta-frequency resonance despite similar coding of space.pdf},
  journal = {Science (New York, N.Y.)},
  keywords = {Animals,Chiroptera,Entorhinal Cortex,Entorhinal Cortex: cytology,Entorhinal Cortex: physiology,Female,Long-Evans,Male,Membrane Potentials,Models,Neurological,Neurons,Neurons: cytology,Neurons: physiology,Patch-Clamp Techniques,Rats,Theta Rhythm},
  number = {6130},
  pmid = {23599495}
}

@article{higgins_lerchner_2017,
  title = {{{SCAN}}: {{Learning Hierarchical Compositional Visual Concepts}}},
  author = {Higgins, Irina and Sonnerat, Nicolas and Matthey, Loic and Pal, Arka and Burgess, Christopher P and Bosnjak, Matko and Shanahan, Murray and Botvinick, Matthew and Hassabis, Demis and Lerchner, Alexander},
  year = {2017},
  issn = {1346-9843},
  doi = {10.1186/s12884-017-1520-4},
  abstract = {The seemingly infinite diversity of the natural world arises from a relatively small set of coherent rules, such as the laws of physics or chemistry. We conjecture that these rules give rise to regularities that can be discovered through primarily unsupervised experiences and represented as abstract concepts. If such representations are compositional and hierarchical, they can be recombined into an exponentially large set of new concepts. This paper describes SCAN (Symbol-Concept Association Network), a new framework for learning such abstractions in the visual domain. SCAN learns concepts through fast symbol association, grounding them in disentangled visual primitives that are discovered in an unsupervised manner. Unlike state of the art multimodal generative model baselines, our approach requires very few pairings between symbols and images and makes no assumptions about the form of symbol representations. Once trained, SCAN is capable of multimodal bi-directional inference, generating a diverse set of image samples from symbolic descriptions and vice versa. It also allows for traversal and manipulation of the implicit hierarchy of visual concepts through symbolic instructions and learnt logical recombination operations. Such manipulations enable SCAN to break away from its training data distribution and imagine novel visual concepts through symbolically instructed recombination of previously learnt concepts.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3M43BBIE\\Higgins et al. - Unknown - SCAN LEARNING HIERARCHICAL COMPOSITIONAL VISUAL CONCEPTS.pdf},
  pmid = {19225210}
}

@article{hill_lillicrap_2019,
  title = {{{LEARNING TO MAKE ANALOGIES BY CONTRASTING ABSTRACT RELATIONAL STRUCTURE}}},
  author = {Hill, Felix and Santoro, Adam and Barrett, David G T and Morcos, Ari and Lillicrap, Tim},
  year = {2019},
  pages = {18},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8J253D5C\\Hill et al. - 2019 - LEARNING TO MAKE ANALOGIES BY CONTRASTING ABSTRACT.pdf},
  language = {en}
}

@article{hinman_hasselmo_2016,
  title = {Multiple {{Running Speed Signals}} in {{Medial Entorhinal Cortex}}},
  author = {Hinman, James R and Brandon, Mark P and Climer, Jason R and Chapman, G William and Hasselmo, Michael E},
  year = {2016},
  volume = {91},
  pages = {666--679},
  issn = {10974199},
  doi = {10.1016/j.neuron.2016.06.027},
  abstract = {Grid cells in medial entorhinal cortex (MEC) can be modeled using oscillatory interference or attractor dynamic mechanisms that perform path integration, a computation requiring information about running direction and speed. The two classes of computational models often use either an oscillatory frequency or a firing rate that increases as a function of running speed. Yet it is currently not known whether these are two manifestations of the same speed signal or dissociable signals with potentially different anatomical substrates. We examined coding of running speed in MEC and identified these two speed signals to be independent of each other within individual neurons. The medial septum (MS) is strongly linked to locomotor behavior, and removal of MS input resulted in strengthening of the firing rate speed signal, while decreasing the strength of the oscillatory speed signal. Thus, two speed signals are present in MEC that are differentially affected by disrupted MS input.},
  copyright = {All rights reserved},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2D4Q9QIE\\Hinman et al. - 2016 - Multiple Running Speed Signals in Medial Entorhinal Cortex.pdf},
  journal = {Neuron},
  keywords = {entorhinal cortex,grid cell,medial septum,path integration,theta rhythm},
  number = {3},
  pmid = {27427460}
}

@article{hinman_hasselmo_2018,
  title = {Neural Mechanisms of Navigation Involving Interactions of Cortical and Subcortical Structures},
  author = {Hinman, James R and Dannenberg, Holger and Alexander, Andrew and Hasselmo, Michael E},
  year = {2018},
  volume = {119},
  pages = {jn.00498.2017},
  issn = {0022-3077},
  doi = {10.1152/jn.00498.2017},
  abstract = {Animals must perform spatial navigation for a range of different behaviors, including selection of trajectories toward goal locations and foraging for food sources. To serve this function, a number of different brain regions play a role in coding different dimensions of sensory input important for spatial behavior, including the entorhinal cortex, the retrosplenial cortex, the hippocampus and the medial septum. This article will review data concerning the coding of the spatial aspects of animal behavior, including location of the animal within an environment, the speed of movement, the trajectory of movement, the direction of the head in the environment, and the position of barriers and objects both relative to the animal's head direction (egocentric) and relative to the layout of the environment (allocentric). The mechanisms for coding these important spatial representations are not yet fully understood, but could involve mechanisms including integration of self-motion information or coding of location b...},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IURM2XEY\\Hinman et al. - 2018 - Neural mechanisms of navigation involving interactions of cortical and subcortical structures(2).pdf},
  journal = {Journal of Neurophysiology},
  pmid = {29442559}
}

@article{hinman_hasselmo_2019,
  title = {Neuronal Representation of Environmental Boundaries in Egocentric Coordinates},
  author = {Hinman, James R. and Chapman, G. William and Hasselmo, Michael E.},
  year = {2019},
  month = dec,
  volume = {10},
  pages = {2772},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-10722-y},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\F7UYJPX9\\Hinman et al. - 2019 - Neuronal representation of environmental boundarie.pdf},
  journal = {Nature Communications},
  language = {en},
  number = {1}
}

@article{hippmann_jessen_2019,
  title = {Boosting the Effect of Reward on Cognitive Control Using {{TMS}} over the Left {{IFJ}}},
  author = {Hippmann, Bernadette and Kuhlemann, Ivo and B{\"a}umer, Tobias and Bahlmann, J{\"o}rg and M{\"u}nte, Thomas F. and Jessen, Sarah},
  year = {2019},
  month = mar,
  volume = {125},
  pages = {109--115},
  issn = {00283932},
  doi = {10.1016/j.neuropsychologia.2019.01.016},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\57LNTQ2M\\Hippmann et al. - 2019 - Boosting the effect of reward on cognitive control.pdf},
  journal = {Neuropsychologia},
  language = {en}
}

@article{hodgkin_huxley_1952,
  title = {A Quantitative Description of Membrane Current and Its Application to Conduction and Excitation in Nerve},
  author = {Hodgkin, A L and Huxley, A F},
  year = {1952},
  pages = {500--544},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AC8D5I5B\\Hodgkin, Huxley - 1952 - A quantitative description of membrane current and its application to conduction and excitation in nerve.pdf},
  journal = {The Journal of physiology}
}

@article{hoffman_lambonralph_2018,
  title = {Concepts, {{Control}}, and {{Context}}: {{A Connectionist Account}} of {{Normal}} and {{Disordered Semantic Cognition}}},
  author = {Hoffman, Paul and McClelland, James L and Lambon Ralph, Matthew A},
  year = {2018},
  volume = {125},
  pages = {293--328},
  doi = {10.1037/rev0000094},
  abstract = {Semantic cognition requires conceptual representations shaped by verbal and nonverbal experience and executive control processes that regulate activation of knowledge to meet current situational demands. A complete model must also account for the representation of concrete and abstract words, of taxonomic and associative relationships, and for the role of context in shaping meaning. We present the first major attempt to assimilate all of these elements within a unified, implemented computational framework. Our model combines a hub-and-spoke architecture with a buffer that allows its state to be influenced by prior context. This hybrid structure integrates the view, from cognitive neuroscience, that concepts are grounded in sensory-motor representation with the view, from computational linguistics, that knowledge is shaped by patterns of lexical co-occurrence. The model successfully codes knowledge for abstract and concrete words, associative and taxonomic relationships, and the multiple meanings of homonyms, within a single representational space. Knowledge of abstract words is acquired through (a) their patterns of co-occurrence with other words and (b) acquired embodiment, whereby they become indirectly associated with the perceptual features of co-occurring concrete words. The model accounts for executive influences on semantics by including a controlled retrieval mechanism that provides top-down input to amplify weak semantic relationships. The representational and control elements of the model can be damaged independently, and the consequences of such damage closely replicate effects seen in neuropsycho-logical patients with loss of semantic representation versus control processes. Thus, the model provides a wide-ranging and neurally plausible account of normal and impaired semantic cognition. Our interactions with the world are suffused with meaning. Each of us has acquired a vast collection of semantic knowledge\textemdash{} including the meanings of words and the properties of objects\textemdash{} which is constantly called upon as we interpret sensory inputs and plan speech and action. In addition to storing such conceptual information in a readily accessible form, we must call upon dif-ferent aspects of knowledge to guide behavior under different circumstances. The knowledge that books are heavy, for example, is irrelevant to most of our interactions with them but becomes important when one is arranging a delivery to a library. These},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6R3N97EP\\Hoffman, McClelland, Lambon Ralph - 2018 - Concepts, Control, and Context A Connectionist Account of Normal and Disordered Semantic Cogn.pdf},
  journal = {Psychological Review},
  keywords = {imageability,parallel distributed processing,semantic aphasia,semantic dementia,semantic diversity},
  number = {3}
}

@article{hofstadter_hofstadter_1985,
  title = {Waking up from the {{Boolean}} Dream, or, Subcognition as Computation},
  author = {Hofstadter, Douglas R.},
  year = {1985},
  pages = {631--665},
  issn = {0036-8733},
  doi = {10.1038/scientificamerican0581-15},
  abstract = {THE philosopher John Searle has recently made quite a stir in the cognitive-science and philosophy-of-mind circles with his-celebrated article ``Minds, Brains, and Programs'', in which he puts forth his ``Chinese room'' thought experiment. Its purpose is to reveal as illusory the aims of artificial intelligence, and particularly to discredit what he labels strong AI-the belief that a programmed computer can, in principle, be conscious. Various synonymous phrases could be substituted for ``be conscious" here, such as: * think; * have a soul (in a humanistic rather than a religious sense); * have an inner lfe; * have semantics (as distinguished from ``mere syntax''); * have content (as distinguished from ``mere form''); * have intentionality; * be something it is like something to be (a weird phrase due to T. Nagel); * have personhood; and others. Each of these phrases has its own peculiar set of connotations and imagery attached to it, as well as its own history and proponents. For our purposes, however, we shall consider them all as equivalent, and lump them all tbgether, so that the claim of strong AI now becomes very strong indeed. 63},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\W2T486SN\\Hofstadter - 1985 - Waking up from the Boolean dream, or, subcognition as computation.pdf},
  journal = {Metamagical themas: Questing for the essence of mind and pattern}
}

@article{hogendoorn_burkitt_2019,
  title = {Predictive {{Coding}} with {{Neural Transmission Delays}}: {{A Real}}-{{Time Temporal Alignment Hypothesis}}},
  shorttitle = {Predictive {{Coding}} with {{Neural Transmission Delays}}},
  author = {Hogendoorn, Hinze and Burkitt, Anthony N.},
  year = {2019},
  month = mar,
  volume = {6},
  pages = {ENEURO.0412-18.2019},
  issn = {2373-2822},
  doi = {10.1523/ENEURO.0412-18.2019},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3VZRMPJA\\Hogendoorn and Burkitt - 2019 - Predictive Coding with Neural Transmission Delays.pdf},
  journal = {eneuro},
  language = {en},
  number = {2}
}

@article{holmes_snyder_2018,
  title = {Dissociation of {{LFP Power}} and {{Tuning}} in the {{Frontal Cortex}} during {{Memory}}},
  author = {Holmes, Charles D. and Papadimitriou, Charalampos and Snyder, Lawrence H.},
  year = {2018},
  month = sep,
  volume = {38},
  pages = {8177--8186},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.3629-17.2018},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MMJF5XZA\\Holmes et al. - 2018 - Dissociation of LFP Power and Tuning in the Fronta.pdf},
  journal = {The Journal of Neuroscience},
  language = {en},
  number = {38}
}

@incollection{holyoak_holyoak_2012,
  title = {Analogy and {{Relational Reasoning}}},
  booktitle = {The {{Oxford Handbook}} of {{Thinking}} and {{Reasoning}}},
  author = {Holyoak, Keith J.},
  year = {2012},
  doi = {10.1093/oxfordhb/9780199734689.013.0013},
  abstract = {Analogy is an inductive mechanism based on structured comparisons of mental representations. It is an important special case of role-based relational reasoning, in which inferences are generated on the basis of patterns of relational roles. Analogical reasoning is a complex process involving retrieval of structured knowledge from long-term memory, representing and manipulating role-filler bindings in working memory, identifying elements that play corresponding roles, generating new inferences, and learning abstract schemas. For empirical analogies, analogical inference is guided by causal knowledge about how the source analog operates. Simpler types of relation-based transfer can be produced by relational priming. Human analogical reasoning is heavily dependent on working memory and other executive functions supported by the prefrontal cortex, with the frontopolar subregion being selectively activated when multiple relations must be integrated to solve a problem.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L6PYLVU7\\Holyoak - 2012 - Analogy and Relational Reasoning.pdf},
  isbn = {978-0-19-996871-8},
  keywords = {analogy,Causal models,Cognitive development,Frontal cortex,Induction,Inference,Iq,Mapping,Metaphor,Neuroimaging,Relational priming,Retrieval,Role-based relational reasoning,Schemas,Symbolic connectionism,System 1,System 2}
}

@article{holyoak_monti_2020,
  title = {Relational {{Integration}} in the {{Human Brain}}: {{A Review}} and {{Synthesis}}},
  shorttitle = {Relational {{Integration}} in the {{Human Brain}}},
  author = {Holyoak, Keith J. and Monti, Martin M.},
  year = {2020},
  month = aug,
  pages = {1--15},
  issn = {0898-929X, 1530-8898},
  doi = {10.1162/jocn_a_01619},
  abstract = {Relational integration is required when multiple explicit representations of relations between entities must be jointly considered to make inferences. We provide an overview of the neural substrate of relational integration in humans and the processes that support it, focusing on work on analogical and deductive reasoning. In addition to neural evidence, we consider behavioral and computational work that has informed neural investigations of the representations of individual relations and of relational integration. In very general terms, evidence from neuroimaging, neuropsychological, and neuromodulatory studies points to a small set of regions (generally left lateralized) that appear to constitute key substrates for component processes of relational integration. These include posterior parietal cortex, implicated in the representation of first-order relations (e.g., A: B); rostrolateral pFC, apparently central in integrating first-order relations so as to generate and/or evaluate higher-order relations (e.g., A: B:: C: D); dorsolateral pFC, involved in maintaining relations in working memory; and ventrolateral pFC, implicated in interference control (e.g., inhibiting salient information that competes with relevant relations). Recent work has begun to link computational models of relational representation and reasoning with patterns of neural activity within these brain areas.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VPVIUKM2\\Holyoak and Monti - 2020 - Relational Integration in the Human Brain A Revie.pdf},
  journal = {Journal of Cognitive Neuroscience},
  language = {en}
}

@article{homann_berryii_2017,
  title = {Predictive {{Coding}} of {{Novel}} versus {{Familiar Stimuli}} in the {{Primary Visual Cortex}}},
  author = {Homann, Jan and Koay, Sue Ann and Glidden, Alistair M and Tank, David W and Berry Ii, Michael J},
  year = {2017},
  doi = {10.1101/197608},
  abstract = {To explore theories of predictive coding, we presented mice with repeated sequences of images with novel im-ages sparsely substituted. Under these conditions, mice could be rapidly trained to lick in response to a novel image, demonstrating a high level of performance on the first day of testing. Using 2-photon calcium imaging to record from layer 2/3 neurons in the primary visual cor-tex, we found that novel images evoked excess activity in the majority of neurons. When a new stimulus se-quence was repeatedly presented, a majority of neurons had similarly elevated activity for the first few presenta-tions, which then decayed to almost zero activity. The decay time of these transient responses was not fixed, but instead scaled with the length of the stimulus sequence. However, at the same time, we also found a small fraction of the neurons within the population ({$\sim$}2\%) that contin-ued to respond strongly and periodically to the repeated stimulus. Decoding analysis demonstrated that both the transient and sustained responses encoded information about stimulus identity. We conclude that the layer 2/3 population uses a two-channel predictive code: a dense transient code for novel stimuli and a sparse sustained code for familiar stimuli. These results extend and unify existing theories about the nature of predictive neural codes.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RZZZKSCT\\Homann et al. - Unknown - Predictive Coding of Novel versus Familiar Stimuli in the Primary Visual Cortex.pdf}
}

@article{honey_schapiro_2017,
  title = {Switching between Internal and External Modes: {{A}} Multiscale Learning Principle},
  author = {Honey, Christopher J and Newman, Ehren L and Schapiro, Anna C},
  year = {2017},
  volume = {1},
  pages = {339--356},
  issn = {2472-1751},
  doi = {10.1162/NETN_a_00024},
  abstract = {Brains construct internal models that support perception, prediction, and action in the external world. Individual circuits within a brain also learn internal models of the local world of input they receive, in order to facilitate efficient and robust representation. How are these internal models learned? We propose that learning is facilitated by continual switching between internally biased and externally biased modes of processing. We review computational evidence that this mode-switching can produce an error signal to drive learning. We then consider empirical evidence for the instantiation of mode-switching in diverse neural systems, ranging from subsecond fluctuations in the hippocampus to wake-sleep alternations across the whole brain. We hypothesize that these internal/external switching processes, which occur at multiple scales, can drive learning at each scale. This framework predicts that (a) slower mode-switching should be associated with learning of more temporally extended input features and (b) disruption of switching should impair the integration of new information with prior information.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BPNNEEL9\\Honey, Newman, Schapiro - 2017 - Switching between internal and external modes A multiscale learning principle(2).pdf},
  journal = {Network Neuroscience},
  keywords = {Contrastive learning,Default mode,Hippocampus,Learning,Sleep,Switching,Timescale},
  number = {4},
  pmid = {18056803}
}

@article{hornik_hornik_1991,
  title = {Approximation Capabilities of Multilayer Feedforward Networks},
  author = {Hornik, Kurt},
  year = {1991},
  volume = {4},
  pages = {251--257},
  issn = {08936080},
  doi = {10.1016/0893-6080(91)90009-T},
  abstract = {We show that standard multilayer feedforward networks with as few as a single hidden layer and arbitrary bounded and nonconstant activation function are universal approximators with respect to Lp(??) performance criteria, for arbitrary finite input environment measures ??, provided only that sufficiently many hidden units are available. If the activation function is continuous, bounded and nonconstant, then continuous mappings can be learned uniformly over compact input sets. We also give very general conditions ensuring that networks with sufficiently smooth activation functions are capable of arbitrarily accurate approximation to a function and its derivatives. ?? 1991.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\542PC4KR\\Hornik - 1991 - Approximation capabilities of multilayer feedforward networks.pdf},
  journal = {Neural Networks},
  keywords = {Input environment measure,Lp(??) approximation,Multilayer feedforward networks,Smooth approximation,Sobolev spaces,Uniform approximation,Universal approximation capabilities},
  number = {2},
  pmid = {25246403}
}

@article{hosseini_maida_2020,
  title = {Hierarchical {{Predictive Coding Models}} in a {{Deep}}-{{Learning Framework}}},
  author = {Hosseini, Matin and Maida, Anthony},
  year = {2020},
  month = may,
  abstract = {Bayesian predictive coding is a putative neuromorphic method for acquiring higher-level neural representations to account for sensory input. Although originating in the neuroscience community, there are also efforts in the machine learning community to study these models. This paper reviews some of the more well known models. Our review analyzes module connectivity and patterns of information transfer, seeking to find general principles used across the models. We also survey some recent attempts to cast these models within a deep learning framework. A defining feature of Bayesian predictive coding is that it uses top-down, reconstructive mechanisms to predict incoming sensory inputs or their lower-level representations. Discrepancies between the predicted and the actual inputs, known as prediction errors, then give rise to future learning that refines and improves the predictive accuracy of learned higher-level representations. Predictive coding models intended to describe computations in the neocortex emerged prior to the development of deep learning and used a communication structure between modules that we name the Rao-Ballard protocol. This protocol was derived from a Bayesian generative model with some rather strong statistical assumptions. The RB protocol provides a rubric to assess the fidelity of deep learning models that claim to implement predictive coding.},
  archivePrefix = {arXiv},
  eprint = {2005.03230},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FGZAXTP9\\hosseini_maida_2020.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\CP65Z4MQ\\2005.html},
  journal = {arXiv:2005.03230 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{hosseini_raju_2020,
  title = {Inception-Inspired {{LSTM}} for {{Next}}-Frame {{Video Prediction}}},
  author = {Hosseini, Matin and Maida, Anthony S. and Hosseini, Majid and Raju, Gottumukkala},
  year = {2020},
  month = apr,
  abstract = {The problem of video frame prediction has received much interest due to its relevance to many computer vision applications such as autonomous vehicles or robotics. Supervised methods for video frame prediction rely on labeled data, which may not always be available. In this paper, we provide a novel unsupervised deep-learning method called Inception-based LSTM for video frame prediction. The general idea of inception networks is to implement wider networks instead of deeper networks. This network design was shown to improve the performance of image classification. The proposed method is evaluated on both Inception-v1 and Inception-v2 structures. The proposed Inception LSTM methods are compared with convolutional LSTM when applied using PredNet predictive coding framework for both the KITTI and KTH data sets. We observed that the Inception based LSTM outperforms the convolutional LSTM. Also, Inception LSTM has better prediction performance compared to Inception v2 LSTM. However, Inception v2 LSTM has a lower computational cost compared to Inception LSTM.},
  archivePrefix = {arXiv},
  eprint = {1909.05622},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L37IXMDS\\hosseini_raju_2020.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\XBS9JRQB\\1909.html},
  journal = {arXiv:1909.05622 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{howard_criss_2015,
  title = {A Distributed Representation of Internal Time.},
  author = {Howard, Marc W. and Shankar, Karthik H. and Aue, William R. and Criss, Amy H.},
  year = {2015},
  month = jan,
  volume = {122},
  pages = {24--53},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/a0037840},
  abstract = {This article pursues the hypothesis that a scale-invariant representation of history could support performance in a variety of learning and memory tasks. This representation maintains a conjunctive representation of what happened when that grows continuously less accurate for events further and further in the past. Simple behavioral models using a few operations, including scanning, matching and a ``jump back in time'' that recovers previous states of the history, describe a range of behavioral phenomena. These behavioral applications include canonical results from the judgment of recency task over short and long scales, the recency and contiguity effect across scales in episodic recall, and temporal mapping phenomena in conditioning. A growing body of neural data suggests that neural representations in several brain regions have qualitative properties predicted by the representation of temporal history. Taken together, these results suggest that a scale-invariant representation of temporal history may serve as a cornerstone of a physical model of cognition in learning and memory.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VFA762MQ\\Howard et al. - 2015 - A distributed representation of internal time..pdf},
  journal = {Psychological Review},
  language = {en},
  number = {1}
}

@article{howard_kahana_2002,
  title = {A {{Distributed Representation}} of {{Temporal Context}}},
  author = {Howard, Marc W. and Kahana, Michael J.},
  year = {2002},
  month = jun,
  volume = {46},
  pages = {269--299},
  issn = {0022-2496},
  doi = {10.1006/jmps.2001.1388},
  abstract = {The principles of recency and contiguity are two cornerstones of the theoretical and empirical analysis of human memory. Recency has been alternatively explained by mechanisms of decay, displacement, and retroactive interference. Another account of recency is based on the idea of variable context (Estes, 1955; Mensink \& Raaijmakers, 1989). Such notions are typically cast in terms of a randomly fluctuating population of elements reflective of subtle changes in the environment or in the subjects' mental state. This random context view has recently been incorporated into distributed and neural network memory models (Murdock, 1997; Murdock, Smith, \& Bai, 2001). Here we propose an alternative model. Rather than being driven by random fluctuations, this formulation, the temporal context model (TCM), uses retrieval of prior contextual states to drive contextual drift. In TCM, retrieved context is an inherently asymmetric retrieval cue. This allows the model to provide a principled explanation of the widespread advantage for forward recalls in free and serial recall. Modeling data from single-trial free recall, we demonstrate that TCM can simultaneously explain recency and contiguity effects across time scales.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LA5GDQS9\\Howard and Kahana - 2002 - A Distributed Representation of Temporal Context.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\7SWIHKVG\\S0022249601913884.html},
  journal = {Journal of Mathematical Psychology},
  number = {3}
}

@article{howe_dombeck_2016,
  title = {Rapid Signalling in Distinct Dopaminergic Axons during Locomotion and Reward},
  author = {Howe, M W and Dombeck, D A},
  year = {2016},
  issn = {0028-0836},
  doi = {10.1038/nature18942},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PR3IM2EV\\Howe, Dombeck - 2016 - Rapid signalling in distinct dopaminergic axons during locomotion and reward.pdf},
  journal = {Nature},
  pmid = {27398617}
}

@article{howe_sarter_2017,
  title = {Acetylcholine Release in Prefrontal Cortex Promotes Gamma Oscillations and Theta-Gamma Coupling during Cue Detection},
  author = {Howe, W M and Gritton, H J and Lusk, N and Roberts, Erik A and Hetrick, Vaughn L and Berke, Joshua D and Sarter, Martin},
  year = {2017},
  volume = {37},
  pages = {2716--2737},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.2737-16.2017},
  abstract = {The capacity for using external cues to guide behavior (``cue detection'') constitutes an essential aspect of attention and goal-directed behavior. The cortical cholinergic input system, via phasic increases in prefrontal acetylcholine release, plays an essential role in attention by mediating such cue detection. However, the relationship between cholinergic signaling during cue detection and neural activity dynamics in prefrontal networks remains unclear. Here we combined subsecond measures of cholinergic signaling, neurophysiological recordings, and cholinergic receptor blockade to delineate the cholinergic contributions to prefrontal oscillations during cue detection in rats. We first confirmed that detected cues evoke phasic acetylcholine release. These cholinergic signals were coincident with increased neuronal synchrony across several frequency bands and the emergence of theta\textendash gamma coupling. Muscarinic and nicotinic cholinergic receptors both contributed specifically to gamma synchrony evoked by detected cues, but the effects of blocking the two receptor subtypes were dissociable. Blocking nicotinic receptors primarily attenuated high-gamma oscillations occurring during the earliest phases of the cue detection process, while muscarinic (M1) receptor activity was preferentially involved in the transition from high to low gamma power that followed and corresponded to the mobilization of networks involved in cue-guided decision making. Detected cues also promoted coupling between gamma and theta oscillations, and both nicotinic and muscarinic receptor activity contributed to this process. These results indicate that acetylcholine release coordinates neural oscillations during the process of cue detection.SIGNIFICANCE STATEMENT The capacity of learned cues to direct attention and guide responding (``cue detection'') is a key component of goal-directed behavior. Rhythmic neural activity and increases in acetylcholine release in the prefrontal cortex contribute to this process; however, the relationship between these neuronal mechanisms is not well understood. Using a combination of in vivo neurochemistry, neurophysiology, and pharmacological methods, we demonstrate that cue-evoked acetylcholine release, through distinct actions at both nicotinic and muscarinic receptors, triggers a procession of neural oscillations that map onto the multiple stages of cue detection. Our data offer new insights into cholinergic function by revealing the temporally orchestrated changes in prefrontal network synchrony modulated by acetylcholine release during cue detection.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9Q3HMQ59\\Howe et al. - 2017 - Acetylcholine release in prefrontal cortex promotes gamma oscillations and theta-gamma coupling during cue detectio.pdf},
  journal = {The Journal of Neuroscience},
  keywords = {and guide responding,behavior,contribute to this process,cue detection,cues to direct attention,in the prefrontal cortex,increases in acetylcholine release,is a key component,of goal-directed,oscillations,prefrontal cortex,rhythmic neural activity and,significance statement,the capacity of learned},
  number = {12},
  pmid = {28213446}
}

@article{hoydal_moser_2018,
  title = {Object-Vector Coding in the Medial Entorhinal Cortex},
  author = {Hoydal, Oyvind Arne and Skytoen, Emilie Ranheim and Moser, May-Britt and Moser, Edvard Ingjald},
  year = {2018},
  pages = {286286},
  doi = {10.1101/286286},
  abstract = {Mammals use distances and directions from local objects to calculate trajectories during navigation but how such vectorial operations are implemented in neural representations of space has not been determined. Here we show in freely moving mice that a population of neurons in the medial entorhinal cortex (MEC) responds specifically when the animal is at a given distance and direction from a spatially confined object. These "object-vector cells" are tuned similarly to a spectrum of discrete objects, irrespective of their location in the test arena. The vector relationships are expressed from the outset in novel environments with novel objects. Object-vector cells are distinct from grid cells, which use a distal reference frame, but the cells exhibit some mixed selectivity with head-direction and border cells. Collectively, these observations show that object locations are integrated in metric representations of self-location, with specific subsets of MEC neurons encoding vector relationships to individual objects.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\J3DYKV6X\\Unknown - Unknown - Object-vector coding in the medial entorhinal cortex.pdf},
  journal = {bioRxiv}
}

@article{hoydal_moser_2019,
  title = {Object-Vector Coding in the Medial Entorhinal Cortex},
  author = {H{\o}ydal, {\O}yvind Arne and Skyt{\o}en, Emilie Ranheim and Andersson, Sebastian Ola and Moser, May-Britt and Moser, Edvard I.},
  year = {2019},
  month = apr,
  volume = {568},
  pages = {400--404},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/s41586-019-1077-7},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HNVTYDZ3\\Høydal et al. - 2019 - Object-vector coding in the medial entorhinal cort.pdf},
  journal = {Nature},
  language = {en},
  number = {7752}
}

@article{hsiao_berger_2013,
  title = {Nonlinear Dynamical Model Based Control of in Vitro Hippocampal Output.},
  author = {Hsiao, Min-Chi and Song, Dong and Berger, Theodore W},
  year = {2013},
  month = jan,
  volume = {7},
  pages = {20},
  issn = {1662-5110},
  doi = {10.3389/fncir.2013.00020},
  abstract = {This paper describes a modeling-control paradigm to control the hippocampal output (CA1 response) for the development of hippocampal prostheses. In order to bypass a damaged hippocampal region (e.g., CA3), downstream hippocampal signal (e.g., CA1 responses) needs to be reinstated based on the upstream hippocampal signal (e.g., dentate gyrus responses) via appropriate stimulations to the downstream (CA1) region. In this approach, we optimize the stimulation signal to CA1 by using a predictive DG-CA1 nonlinear model (i.e., DG-CA1 trajectory model) and an inversion of the CA1 input-output model (i.e., inverse CA1 plant model). The desired CA1 responses are first predicted by the DG-CA1 trajectory model and then used to derive the optimal stimulation intensity through the inverse CA1 plant model. Laguerre-Volterra kernel models for random-interval, graded-input, contemporaneous-graded-output system are formulated and applied to build the DG-CA1 trajectory model and the CA1 plant model. The inverse CA1 plant model to transform desired output to input stimulation is derived from the CA1 plant model. We validate this paradigm with rat hippocampal slice preparations. Results show that the CA1 responses evoked by the optimal stimulations accurately replicate the CA1 responses recorded in the hippocampal slice with intact trisynaptic pathway.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8CY9IIDG\\Hsiao, Song, Berger - 2013 - Nonlinear dynamical model based control of in vitro hippocampal output.pdf},
  journal = {Frontiers in neural circuits},
  keywords = {Animals,Hippocampus,Hippocampus: physiology,Male,Neural Pathways,Neural Pathways: physiology,Nonlinear Dynamics,Organ Culture Techniques,Rats,Sprague-Dawley},
  number = {February},
  pmid = {23429994}
}

@article{hsieh_ranganath_2014,
  title = {Hippocampal {{Activity Patterns Carry Information}} about {{Objects}} in {{Temporal Context}}},
  author = {Hsieh, Liang Tien and Gruber, Matthias J and Jenkins, Lucas J and Ranganath, Charan},
  year = {2014},
  volume = {81},
  pages = {1165--1178},
  issn = {10974199},
  doi = {10.1016/j.neuron.2014.01.015},
  abstract = {The hippocampus is critical for human episodic memory, but its role remains controversial. One fundamental question concerns whether the hippocampus represents specific objects or assigns context-dependent representations to objects. Here, we used multivoxel pattern similarity analysis of fMRI data during retrieval of learned object sequences to systematically investigate hippocampal coding of object and temporal context information. Hippocampal activity patterns carried information about the temporal positions of objects in learned sequences, but not about objects or temporal positions in random sequences. Hippocampal activity patterns differentiated between overlapping object sequences and between temporally adjacent objects that belonged to distinct sequence contexts. Parahippocampal and perirhinal cortex showed different pattern information profiles consistent with coding of temporal position and object information, respectively. These findings are consistent with models proposing that the hippocampus represents objects within specific temporal contexts, a capability that might explain its critical role in episodic memory. ?? 2014 Elsevier Inc.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3WFEN5BP\\Hsieh et al. - 2014 - Hippocampal Activity Patterns Carry Information about Objects in Temporal Context.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\G44GLJ8U\\Hsieh et al. - 2014 - Hippocampal Activity Patterns Carry Information about Objects in Temporal Context(2).pdf},
  journal = {Neuron},
  number = {5},
  pmid = {24607234}
}

@article{hu_dan_2019,
  title = {Prefrontal {{Corticotectal Neurons Enhance Visual Processing}} through the {{Superior Colliculus}} and {{Pulvinar Thalamus}}},
  author = {Hu, Fei and Kamigaki, Tsukasa and Zhang, Zhe and Zhang, Siyu and Dan, Usan and Dan, Yang},
  year = {2019},
  month = dec,
  volume = {104},
  pages = {1141-1152.e4},
  issn = {08966273},
  doi = {10.1016/j.neuron.2019.09.019},
  abstract = {Top-down modulation of visual processing is mediated in part by direct prefrontal to visual cortical projections. Here, we show that the mouse cingulate cortex (Cg) regulates visual processing not only through corticocortical neurons projecting to the visual cortex but also through corticotectal neurons projecting subcortically. Bidirectional optogenetic manipulation demonstrated a prominent contribution of Cg corticotectal neurons to visually guided behavior, which is mediated by their collateral projections to both the motor-related layers of the superior colliculus (SC) and the lateral posterior nucleus of the thalamus (LP, analogous to the primate pulvinar). Whereas the Cg innervates the anterior LP (LPa), the SC innervates the posterior LP (LPp). Activating each stage of the Cg/SC/LPp or the Cg/ LPa pathway strongly enhanced visual performance of the mouse and the sensory responses of visual cortical neurons. These results delineate two subcortical pathways by which a subtype of prefrontal pyramidal neurons exerts a powerful top-down influence on visual processing.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CQRDEEZ9\\Hu et al. - 2019 - Prefrontal Corticotectal Neurons Enhance Visual Pr.pdf},
  journal = {Neuron},
  language = {en},
  number = {6}
}

@article{hu_zheng_2007,
  title = {Effective Brain Network Analysis with Resting-State {{EEG}} Data: A Comparison between Heroin Abstinent and Non-Addicted Subjects},
  author = {Hu, Bin and Dong, Qunxi and Hao, Yanrong and Zhao, Qinglin and Shen, Jian and Zheng, Fang},
  year = {2007},
  pages = {aa6c6f},
  issn = {03784320},
  doi = {10.1088/1741-2552-aa6c6f},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QPHV8DP2\\Hu et al. - 2007 - Effective brain network analysis with resting-state EEG data a comparison between heroin abstinent and non-addicted s.pdf},
  journal = {Journal of Neural Engineering}
}

@article{huang_eden_2009,
  title = {Decoding {{Movement Trajectories Through}} a {{T}}-{{Maze Using Point Process Filters Applied}} to {{Place Field Data}} from {{Rat Hippocampal Region CA1}}},
  author = {Huang, Yifei and Brandon, Mark P and Griffin, Amy L and Hasselmo, Michael E and Eden, Uri T},
  year = {2009},
  volume = {21},
  pages = {3305--3334},
  issn = {0899-7667},
  doi = {10.1162/neco.2009.10-08-893},
  abstract = {Firing activity from neural ensembles in rat hippocampus has been previously used to determine an animal's position in an open environment and separately to predict future behavioral decisions. However, a unified statistical procedure to combine information about position and behavior in environments with complex topological features from ensemble hippocampal activity has yet to be described. Here we present a two-stage computational framework that uses point process filters to simultaneously estimate the animal's location and predict future behavior from ensemble neural spiking activity. First, in the encoding stage, we linearized a two-dimensional T-maze, and used spline-based generalized linear models to characterize the place-field structure of different neurons. All of these neurons displayed highly specific position-dependent firing, which frequently had several peaks at multiple locations along the maze. When the rat was at the stem of the T-maze, the firing activity of several of these neurons also varied significantly as a function of the direction it would turn at the decision point, as detected by ANOVA. Second, in the decoding stage, we developed a state-space model for the animal's movement along a T-maze and used point process filters to accurately reconstruct both the location of the animal and the probability of the next decision. The filter yielded exact full posterior densities that were highly nongaussian and often multimodal. Our computational framework provides a reliable approach for characterizing and extracting information from ensembles of neurons with spatially specific context or task-dependent firing activity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5UZYZ4LH\\huang_et_al_2009_decoding_movement_trajectories_through_a_t-maze_using_point_process_filters.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\FS3PRF6X\\Huang et al. - 2009 - Decoding Movement Trajectories Through a T-Maze Us.pdf},
  journal = {Neural Computation},
  number = {12},
  pmid = {19764871}
}

@article{huber_bandettini_2017,
  title = {High-{{Resolution CBV}}-{{fMRI Allows Mapping}} of {{Laminar Activity}} and {{Connectivity}} of {{Cortical Input}} and {{Output}} in {{Human M1}}},
  author = {Huber, Laurentius and Handwerker, Daniel A. and Jangraw, David C. and Chen, Gang and Hall, Andrew and St{\"u}ber, Carsten and {Gonzalez-Castillo}, Javier and Ivanov, Dimo and Marrett, Sean and Guidi, Maria and Goense, Jozien and Poser, Benedikt A. and Bandettini, Peter A.},
  year = {2017},
  month = dec,
  volume = {96},
  pages = {1253-1263.e7},
  issn = {08966273},
  doi = {10.1016/j.neuron.2017.11.005},
  abstract = {Layer-dependent fMRI allows measurements of information flow in cortical circuits, as afferent and efferent connections terminate in different cortical layers. However, it is unknown to what level human fMRI is specific and sensitive enough to reveal directional functional activity across layers. To answer this question, we developed acquisition and analysis methods for blood-oxygen-level-dependent (BOLD) and cerebral-blood-volume (CBV)-based laminar fMRI and used these to discriminate four different tasks in the human motor cortex (M1). In agreement with anatomical data from animal studies, we found evidence for somatosensory and premotor input in superficial layers of M1 and for cortico-spinal motor output in deep layers. Laminar resting-state fMRI showed directional functional connectivity of M1 with somatosensory and premotor areas. Our findings demonstrate that CBV-fMRI can be used to investigate cortical activity in humans with unprecedented detail, allowing investigations of information flow between brain regions and outperforming conventional BOLD results that are often buried under vascular biases.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\X8VP4E5G\\Huber et al. - 2017 - High-Resolution CBV-fMRI Allows Mapping of Laminar.pdf},
  journal = {Neuron},
  language = {en},
  number = {6}
}

@article{hudson_manning_2018,
  title = {Compositional {{Attention Networks}} for {{Machine Reasoning}}},
  author = {Hudson, Drew A. and Manning, Christopher D.},
  year = {2018},
  month = mar,
  abstract = {We present the MAC network, a novel fully differentiable neural network architecture, designed to facilitate explicit and expressive reasoning. MAC moves away from monolithic black-box neural architectures towards a design that encourages both transparency and versatility. The model approaches problems by decomposing them into a series of attention-based reasoning steps, each performed by a novel recurrent Memory, Attention, and Composition (MAC) cell that maintains a separation between control and memory. By stringing the cells together and imposing structural constraints that regulate their interaction, MAC effectively learns to perform iterative reasoning processes that are directly inferred from the data in an end-to-end approach. We demonstrate the model's strength, robustness and interpretability on the challenging CLEVR dataset for visual reasoning, achieving a new state-of-the-art 98.9\% accuracy, halving the error rate of the previous best model. More importantly, we show that the model is computationally-efficient and data-efficient, in particular requiring 5x less data than existing models to achieve strong results.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\26BSIDMJ\\hudson_manning_2018_compositional_attention_networks_for_machine_reasoning.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\AKENKMUA\\Unknown - Unknown - attention.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\3895XWLT\\1803.html}
}

@article{hudson_manning_2019,
  title = {Learning by {{Abstraction}}: {{The Neural State Machine}}},
  shorttitle = {Learning by {{Abstraction}}},
  author = {Hudson, Drew A. and Manning, Christopher D.},
  year = {2019},
  month = jul,
  abstract = {We introduce the Neural State Machine, seeking to bridge the gap between the neural and symbolic views of AI and integrate their complementary strengths for the task of visual reasoning. Given an image, we first predict a probabilistic graph that represents its underlying semantics and serves as a structured world model. Then, we perform sequential reasoning over the graph, iteratively traversing its nodes to answer a given question or draw a new inference. In contrast to most neural architectures that are designed to closely interact with the raw sensory data, our model operates instead in an abstract latent space, by transforming both the visual and linguistic modalities into semantic concept-based representations, thereby achieving enhanced transparency and modularity. We evaluate our model on VQA-CP and GQA, two recent VQA datasets that involve compositionality, multi-step inference and diverse reasoning skills, achieving state-of-the-art results in both cases. We provide further experiments that illustrate the model's strong generalization capacity across multiple dimensions, including novel compositions of concepts, changes in the answer distribution, and unseen linguistic structures, demonstrating the qualities and efficacy of our approach.},
  archivePrefix = {arXiv},
  eprint = {1907.03950},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DFNR2YE9\\Hudson_Manning_2019_Learning_by_Abstraction.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\ZGG3ZXIR\\Hudson and Manning - 2019 - Learning by Abstraction The Neural State Machine.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\73NRHCNK\\1907.html},
  journal = {arXiv:1907.03950 [cs]},
  primaryClass = {cs}
}

@article{hummel_holyoak_2003,
  title = {A Symbolic-Connectionist Theory of Relational Inference and Generalization.},
  author = {Hummel, John E and Holyoak, Keith J.},
  year = {2003},
  volume = {110},
  pages = {220--264},
  issn = {1939-1471},
  doi = {10.1037/0033-295X.110.2.220},
  abstract = {The authors present a theory of how relational inference and generalization can be accomplished within a cognitive architecture that is psychologically and neurally realistic. Their proposal is a form of symbolic connectionism: a connectionist system based on distributed representations of concept meanings, using temporal synchrony to bind fillers and roles into relational structures. The authors present a specific instantiation of their theory in the form of a computer simulation model, Learning and Inference with Schemas and Analogies (LISA). By using a kind of self-supervised learning, LISA can make specific inferences and form new relational generalizations and can hence acquire new schemas by induction from examples. The authors demonstrate the sufficiency of the model by using it to simulate a body of empirical phenomena concerning analogical inference and relational generalization.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FFICNBV4\\Hummel, Holyoak - 2003 - A symbolic-connectionist theory of relational inference and generalization.pdf},
  journal = {Psychological Review},
  number = {2},
  pmid = {12747523}
}

@techreport{hung_wayne_2018,
  title = {Optimizing {{Agent Behavior}} over {{Long Time Scales}} by {{Transporting Value}}},
  author = {Hung, Chia-Chun and Lillicrap, Timothy and Abramson, Josh and Wu, Yan and Mirza, Mehdi and Carnevale, Federico and Ahuja, Arun and Wayne, Greg},
  year = {2018},
  abstract = {Humans spend a remarkable fraction of waking life engaged in acts of "mental time travel" 1. We dwell on our actions in the past and experience satisfaction or regret. More than merely autobiographical storytelling, we use these event recollections to change how we will act in similar scenarios in the future. This process endows us with a computationally important ability to link actions and consequences across long spans of time, which figures prominently in addressing the problem of long-term temporal credit assignment; in artificial intelligence (AI) this is the question of how to evaluate the utility of the actions within a long-duration behavioral sequence leading to success or failure in a task. Existing approaches to shorter-term credit assignment in AI cannot solve tasks with long delays between actions and consequences. Here, we introduce a new paradigm for reinforcement learning where agents use recall of specific memories to credit actions from the past, allowing them to solve problems that are intractable for existing algorithms. This paradigm broadens the scope of problems that can be investigated in AI and offers a mechanistic account of behaviors that may inspire computational models in neuroscience, psychology, and behavioral economics. The theory of how humans and animals express preferences and make decisions to ensure future welfare is a question of long-standing concern, dating to the origins of economic utility theory 2. Within multiple fields, including economics and behavioral psychology, there remains unresolved debate about the appropriate formalism to explain valuation of temporally distant reward outcomes in long-term decision making. In AI research, the problem of how to learn rational behavior that is temporally far-sighted is known as the credit assignment problem 3-5. An AI agent must evaluate the utility of individual actions within a long sequence. To address the credit assignment problem, deep learning has been combined with reinforcement learning (RL) to provide a flexible class of architectures and algorithms that can be used practically to estimate the utility of courses of action for behaving agent models engaged in sensorimotor tasks in complex environments. These algorithms have almost exclusively borrowed the assumptions of discounted utility theory 2, 6, 7 and achieve credit assignment using value function bootstrapping and backpropagation 8 (deep RL). Practical and convergent deep RL algorithms discount the future, reducing their applicability for problems with long delays between decisions and consequences 9, 10 .},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RX7XMR7F\\Hung et al. - 2018 - Optimizing Agent Behavior over Long Time Scales by Transporting Value.pdf}
}

@article{hunsberger_hunsberger_2017,
  title = {Spiking {{Deep Neural Networks}}: {{Engineered}} and {{Biological Approaches}} to {{Object Recognition}}},
  author = {Hunsberger, Eric},
  year = {2017},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\H22SXAMK\\Hunsberger - Unknown - Spiking Deep Neural Networks Engineered and Biological Approaches to Object Recognition.pdf}
}

@article{hunt_hayden_2017,
  title = {A Distributed, Hierarchical and Recurrent Framework for Reward-Based Choice},
  author = {Hunt, Laurence T. and Hayden, Benjamin Y.},
  year = {2017},
  volume = {18},
  pages = {172--182},
  issn = {1471-003X},
  doi = {10.1038/nrn.2017.7},
  abstract = {Many accounts of reward-based choice argue for distinct component processes that are serial and functionally localized. In this Opinion article, we argue for an alternative viewpoint, in which choices emerge from repeated computations that are distributed across many brain regions. We emphasize how several features of neuroanatomy may support the implementation of choice, including mutual inhibition in recurrent neural networks and the hierarchical organization of timescales for information processing across the cortex. This account also suggests that certain correlates of value are emergent rather than represented explicitly in the brain.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GIT2WGPG\\Hunt, Hayden - 2017 - A distributed, hierarchical and recurrent framework for reward-based choice.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\YJ5UXZM8\\Hunt and Hayden - 2017 - A distributed, hierarchical and recurrent framewor.pdf},
  journal = {Nature Reviews Neuroscience},
  number = {3},
  pmid = {28209978}
}

@article{hunt_kennerley_2015,
  title = {Capturing the Temporal Evolution of Choice across Prefrontal Cortex},
  author = {Hunt, Laurence T and Behrens, Timothy Ej and Hosokawa, Takayuki and Wallis, Jonathan D and Kennerley, Steven W},
  year = {2015},
  volume = {4},
  issn = {2050084X},
  doi = {10.7554/eLife.11945},
  abstract = {Activity in prefrontal cortex (PFC) has been richly described using economic models of choice. Yet such descriptions fail to capture the dynamics of decision formation. Describing dynamic neural processes has proven challenging due to the problem of indexing the internal state of PFC and its trial-by-trial variation. Using primate neurophysiology and human magnetoencephalography, we here recover a single-trial index of PFC internal states from multiple simultaneously recorded PFC subregions. This index can explain the origins of neural representations of economic variables in PFC. It describes the relationship between neural dynamics and behavior in both human and monkey PFC, directly bridging between human neuroimaging data and underlying neuronal activity. Moreover, it reveals a functionally dissociable interaction between orbitofrontal cortex, anterior cingulate cortex and dorsolateral PFC in guiding cost-benefit decisions. We cast our observations in terms of a neural network model of choice, providing formal links to mechanistic dynamical accounts of decision-making.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JN23HUQJ\\Hunt et al. - 2015 - Capturing the temporal evolution of choice across prefrontal cortex.pdf},
  journal = {eLife},
  keywords = {Decision-making,electrophysiology,human,macaque monkey,magnetoencephalography,Neural dynamics,neuroscience,Prefrontal cortex,Reaction time},
  pmid = {25246403}
}

@article{hunt_kennerley_2017,
  title = {Triple Dissociation of Attention and Decision Computations across Prefrontal Cortex},
  author = {Hunt, Laurence T. and Malalasekera, W. M. Nishantha and {de Berker}, Archy O. and Miranda, Bruno and Farmer, Simon F. and Behrens, Timothy E. J. and Kennerley, Steven W.},
  year = {2017},
  month = aug,
  pages = {171173},
  doi = {10.1101/171173},
  abstract = {Anatomical, neuroimaging and lesion studies indicate that prefrontal cortex (PFC) can be subdivided into different subregions supporting distinct aspects of decision making. However, explanations of neuronal computations within these subregions varies widely across studies. An integrated and mechanistic account of PFC function therefore remains elusive. Resolving these debates demands a rich dataset that directly contrasts neuronal activity across multiple PFC subregions within a single paradigm, whilst experimentally controlling factors such as the order, duration and frequency in which choice options are attended and compared. Here, we contrast neuronal population responses between macaque orbitofrontal (OFC), anterior cingulate (ACC) and dorsolateral prefrontal cortices (DLPFC) during sequential value-guided information search and choice. From the first fixation of choice-related stimuli, a strong triple dissociation of information encoding emerges in parallel across these PFC subregions. As further information is gathered, population responses in OFC reflect an attention-guided value comparison process. Meanwhile, parallel signals in ACC reflect belief updating in light of new evidence, integration of that evidence to a decision bound, and an emerging action plan for which option should be chosen. Our findings demonstrate the co-existence of multiple, distributed decision-related computations across PFC subregions during value-guided choice. They provide a synthesis of several competing accounts of PFC function.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FTSUJXDC\\Hunt et al. - 2017 - Triple dissociation of attention and decision computations across prefrontal cortex.pdf},
  journal = {bioRxiv}
}

@article{huster_herrmann_2012,
  title = {Methods for Simultaneous {{EEG}}-{{fMRI}}: An Introductory Review.},
  author = {Huster, Ren{\'e} J and Debener, Stefan and Eichele, Tom and Herrmann, Christoph S},
  year = {2012},
  volume = {32},
  pages = {6053--6060},
  issn = {1529-2401},
  doi = {10.1523/JNEUROSCI.0447-12.2012},
  abstract = {The simultaneous recording and analysis of electroencephalography (EEG) and fMRI data in human systems, cognitive and clinical neurosciences is rapidly evolving and has received substantial attention. The significance of multimodal brain imaging is documented by a steadily increasing number of laboratories now using simultaneous EEG-fMRI aiming to achieve both high temporal and spatial resolution of human brain function. Due to recent developments in technical and algorithmic instrumentation, the rate-limiting step in multimodal studies has shifted from data acquisition to analytic aspects. Here, we introduce and compare different methods for data integration and identify the benefits that come with each approach, guiding the reader toward an understanding and informed selection of the integration approach most suitable for addressing a particular research question.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Q2DIYVRA\\Huster et al. - 2012 - Methods for simultaneous EEG-fMRI an introductory review.pdf},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  keywords = {Algorithms,Brain,Brain Mapping,Brain Mapping: methods,Brain: physiology,Computer-Assisted,Electroencephalography,Electroencephalography: methods,Humans,Image Interpretation,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Subtraction Technique},
  number = {18},
  pmid = {22553012}
}

@article{huth_jack_2016,
  title = {Natural Speech Reveals the Semantic Maps That Tile Human Cerebral Cortex},
  author = {Huth, Alexander G and Heer, Wendy A De and Griffiths, Thomas L and Theunissen, Fr{\'e}d{\'e}ric E and Jack, L},
  year = {2016},
  volume = {532},
  pages = {453--458},
  issn = {0028-0836},
  doi = {10.1038/nature17637},
  abstract = {The meaning of language is represented in regions of the cerebral cortex collectively known as the `semantic system'. However, little of the semantic system has been mapped comprehensively, and the semantic selectivity of most regions is unknown. Here we systematically map semantic selectivity across the cortex using voxel-wise modelling of functional MRI (fMRI) data collected while subjects listened to hours of narrative stories. We show that the semantic system is organized into intricate patterns that seem to be consistent across individuals. We then use a novel generative model to create a detailed semantic atlas. Our results suggest that most areas within the semantic system represent information about specific semantic domains, or groups of related concepts, and our atlas shows which domains are represented in each area. This study demonstrates that data-driven methods\textemdash commonplace in studies of human neuroanatomy and functional connectivity\textemdash provide a powerful and efficient means for mapping functional representations in the brain.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VSUZGDWR\\Huth et al. - 2016 - Natural speech reveals the semantic maps that tile human cerebral cortex.pdf},
  journal = {Nature},
  number = {7600},
  pmid = {27121839}
}

@article{hwang_komiyama_2019,
  title = {Corticostriatal {{Flow}} of {{Action Selection Bias}}},
  author = {Hwang, Eun Jung and Link, Trevor D. and Hu, Yvonne Yuling and Lu, Shan and Wang, Eric Hou-Jen and Lilascharoen, Varoth and Aronson, Sage and O'Neil, Keelin and Lim, Byung Kook and Komiyama, Takaki},
  year = {2019},
  month = dec,
  volume = {104},
  pages = {1126-1140.e6},
  issn = {08966273},
  doi = {10.1016/j.neuron.2019.09.028},
  abstract = {The posterior parietal cortex (PPC) performs many functions, including decision making and movement control. It remains unknown which input and output pathways of PPC support different functions. We addressed this issue in mice, focusing on PPC neurons projecting to the dorsal striatum (PPC-STR) and the posterior secondary motor cortex (PPCpM2). Projection-specific, retrograde labeling showed that PPC-STR and PPC-pM2 represent largely distinct subpopulations, with PPC-STR receiving stronger inputs from association areas and PPC-pM2 receiving stronger sensorimotor inputs. Two-photon calcium imaging during decision making revealed that the PPC-STR population encodes history-dependent choice bias more strongly than PPC-pM2 or general PPC populations. Furthermore, optogenetic inactivation of PPC-STR neurons or their terminals in STR decreased history-dependent bias, while inactivation of PPC-pM2 neurons altered movement kinematics. Therefore, PPC biases action selection through its STR projection while controlling movements through PPC-pM2 neurons. PPC may support multiple functions through parallel subpopulations, each with distinct input-output connectivity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LM2L5CYF\\Hwang et al. - 2019 - Corticostriatal Flow of Action Selection Bias.pdf},
  journal = {Neuron},
  language = {en},
  number = {6}
}

@article{hyafil_gutkin_2015,
  ids = {hyafilNeuralCrossFrequencyCoupling2015a},
  title = {Neural {{Cross}}-{{Frequency Coupling}}: {{Connecting Architectures}}, {{Mechanisms}}, and {{Functions}}},
  shorttitle = {Neural {{Cross}}-{{Frequency Coupling}}},
  author = {Hyafil, Alexandre and Giraud, Anne-Lise and Fontolan, Lorenzo and Gutkin, Boris},
  year = {2015},
  month = nov,
  volume = {38},
  pages = {725--740},
  issn = {01662236},
  doi = {10.1016/j.tins.2015.09.001},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\826ZZTYJ\\Hyafil et al. - 2015 - Neural Cross-Frequency Coupling Connecting Archit.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\G24X9A9N\\Hyafil et al. - 2015 - Neural Cross-Frequency Coupling Connecting Archit.pdf},
  journal = {Trends in Neurosciences},
  language = {en},
  number = {11}
}

@article{ikkai_curtis_2016,
  title = {Lateralization in {{Alpha}}-{{Band Oscillations Predicts}} the {{Locus}} and {{Spatial Distribution}} of {{Attention}}},
  author = {Ikkai, Akiko and Dandekar, Sangita and Curtis, Clayton E},
  year = {2016},
  doi = {10.1371/journal.pone.0154796},
  abstract = {Attending to a task-relevant location changes how neural activity oscillates in the alpha band (8-13Hz) in posterior visual cortical areas. However, a clear understanding of the relationships between top-down attention, changes in alpha oscillations in visual cortex, and attention performance are still poorly understood. Here, we tested the degree to which the posterior alpha power tracked the locus of attention, the distribution of attention, and how well the topography of alpha could predict the locus of attention. We recorded magnetoen-cephalographic (MEG) data while subjects performed an attention demanding visual discrimination task that dissociated the direction of attention from the direction of a saccade to indicate choice. On some trials, an endogenous cue predicted the target's location, while on others it contained no spatial information. When the target's location was cued, alpha power decreased in sensors over occipital cortex contralateral to the attended visual field. When the cue did not predict the target's location, alpha power again decreased in sensors over occipital cortex, but bilaterally, and increased in sensors over frontal cortex. Thus, the distribution and the topography of alpha reliably indicated the locus of covert attention. Together, these results suggest that alpha synchronization reflects changes in the excitability of populations of neurons whose receptive fields match the locus of attention. This is consistent with the hypothesis that alpha oscillations reflect the neural mechanisms by which top-down control of attention biases information processing and modulate the activity of neurons in visual cortex.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PTYBETLL\\Ikkai, Dandekar, Curtis - 2016 - Lateralization in Alpha-Band Oscillations Predicts the Locus and Spatial Distribution of Attention.pdf}
}

@article{ilg_ilg_2008,
  title = {The Role of Areas {{MT}} and {{MST}} in Coding of Visual Motion Underlying the Execution of Smooth Pursuit},
  author = {Ilg, Uwe J.},
  year = {2008},
  month = sep,
  volume = {48},
  pages = {2062--2069},
  issn = {00426989},
  doi = {10.1016/j.visres.2008.04.015},
  abstract = {What is the main purpose of visual motion processing? One very important aspect of motion processing is definitively the generation of smooth pursuit eye movements. These eye movements avoid motion blur of moving objects which would obstruct the analysis of the objects' visual details. However, these eye movements can only be executed if there is a moving target. So there is a very close and inseparable relationship between smooth pursuit and motion processing. The hub for visual motion processing is situated in the middle temporal (MT) and medial superior temporal (MST) area. Despite the undoubted importance of these areas for the generation of smooth pursuit or goal-directed behavior in general, it is important to keep in mind that motion processing in addition serves perceptual purposes such as object recognition, structure-from-motion detection, scene segmentation, self-motion estimation and depth perception. This review focuses at the beginning on pursuit-related activity recorded from MT and MST, subsequently extends the view to goal-directed hand movements, and finally addresses the possible contributions of these areas to motion perception.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QCH4JQ6P\\Ilg - 2008 - The role of areas MT and MST in coding of visual m.pdf},
  journal = {Vision Research},
  language = {en},
  number = {20}
}

@article{illing_brea_2019,
  title = {Biologically Plausible Deep Learning \textemdash{} {{But}} How Far Can We Go with Shallow Networks?},
  author = {Illing, Bernd and Gerstner, Wulfram and Brea, Johanni},
  year = {2019},
  month = oct,
  volume = {118},
  pages = {90--101},
  issn = {08936080},
  doi = {10.1016/j.neunet.2019.06.001},
  abstract = {Training deep neural networks with the error backpropagation algorithm is considered implausible from a biological perspective. Numerous recent publications suggest elaborate models for biologically plausible variants of deep learning, typically defining success as reaching around 98\% test accuracy on the MNIST data set. Here, we investigate how far we can go on digit (MNIST) and object (CIFAR10) classification with biologically plausible, local learning rules in a network with one hidden layer and a single readout layer. The hidden layer weights are either fixed (random or random Gabor filters) or trained with unsupervised methods (Principal/Independent Component Analysis or Sparse Coding) that can be implemented by local learning rules. The readout layer is trained with a supervised, local learning rule. We first implement these models with rate neurons. This comparison reveals, first, that unsupervised learning does not lead to better performance than fixed random projections or Gabor filters for large hidden layers. Second, networks with localized receptive fields perform significantly better than networks with all-to-all connectivity and can reach backpropagation performance on MNIST. We then implement two of the networks \textendash{} fixed, localized, random \& random Gabor filters in the hidden layer \textendash{} with spiking leaky integrate-and-fire neurons and spike timing dependent plasticity to train the readout layer. These spiking models achieve {$>$}98.2\% test accuracy on MNIST, which is close to the performance of rate networks with one hidden layer trained with backpropagation. The performance of our shallow network models is comparable to most current biologically plausible models of deep learning. Furthermore, our results with a shallow spiking network provide an important reference and suggest the use of data sets other than MNIST for testing the performance of future models of biologically plausible deep learning.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3YVFLY6J\\Illing et al. - 2019 - Biologically plausible deep learning — But how far.pdf},
  journal = {Neural Networks},
  language = {en}
}

@techreport{inglebert_debanne_2020,
  title = {Altered Spike Timing-Dependent Plasticity Rules in Physiological Calcium},
  author = {Inglebert, Yanis and Aljadeff, Johnatan and Brunel, Nicolas and Debanne, Dominique},
  year = {2020},
  month = mar,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.03.16.993675},
  abstract = {Like many forms of long-term synaptic plasticity, spike-timing-dependent plasticity (STDP) depends on intracellular Ca2+ signaling for its induction. Yet, all in vitro studies devoted to STDP used abnormally high external Ca2+ concentration. We measured STDP at the CA3-CA1 hippocampal synapses under different extracellular Ca2+ concentrations and found that the sign, shape and magnitude of plasticity strongly depend on Ca2+. A pre-post protocol that results in robust LTP in high Ca2+, yielded only LTD or no plasticity in the physiological Ca2+ range. LTP could be restored by either increasing the number of post-synaptic spikes or increasing the pairing frequency. A calcium-based plasticity model in which depression and potentiation depend on post-synaptic Ca2+ transients was found to fit quantitatively all the data, provided NMDA receptor-mediated non-linearities were implemented. In conclusion, STDP rule is profoundly altered in physiological Ca2+ but specific activity regimes restore a classical STDP profile.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WSRLYDTL\\Inglebert et al. - 2020 - Altered spike timing-dependent plasticity rules in.pdf},
  language = {en},
  type = {Preprint}
}

@article{inhoff_ranganath_2018,
  title = {Dynamic Integration of Conceptual Information during Learning},
  author = {Inhoff, Marika C and Libby, Laura A and Noguchi, Takao and Love, Bradley C and Ranganath, Charan},
  year = {2018},
  doi = {10.1101/280362},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MMQ6XFW3\\Inhoff et al. - 2018 - Dynamic integration of conceptual information during learning.pdf}
}

@article{insel_cuthbert_2015,
  title = {Brain Disorders? {{Precisely}}},
  author = {Insel, T R and Cuthbert, Bruce N},
  year = {2015},
  volume = {348},
  pages = {499--500},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aab2358},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MEHIGGM9\\Insel, Cuthbert - 2015 - Brain disorders Precisely.pdf},
  journal = {Science},
  number = {6234},
  pmid = {25931539}
}

@article{ishikawa_ikegaya_2020,
  title = {Locally Sequential Synaptic Reactivation during Hippocampal Ripples},
  author = {Ishikawa, Tomoe and Ikegaya, Yuji},
  year = {2020},
  month = feb,
  volume = {6},
  pages = {eaay1492},
  issn = {2375-2548},
  doi = {10.1126/sciadv.aay1492},
  abstract = {The sequential reactivation of memory-relevant neuronal ensembles during hippocampal sharp-wave (SW) ripple oscillations reflects cognitive processing. However, how a downstream neuron decodes this spatiotemporally organized activity remains unexplored. Using subcellular calcium imaging from CA1 pyramidal neurons in ex vivo hippocampal networks, we discovered that neighboring spines are activated serially along dendrites toward or away from cell bodies. Sequential spine activity was engaged repeatedly in different SWs in a complex manner. In a single SW event, multiple sequences appeared discretely in dendritic trees, but overall, sequences occurred preferentially in some dendritic branches. Thus, sequential replays of multineuronal spikes are distributed across several compartmentalized dendritic foci of a postsynaptic neuron, with their spatiotemporal features preserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\C3HGSLD6\\Ishikawa and Ikegaya - 2020 - Locally sequential synaptic reactivation during hi.pdf},
  journal = {Science Advances},
  language = {en},
  number = {7}
}

@article{issa_dombeck_2020,
  title = {Navigating {{Through Time}}: {{A Spatial Navigation Perspective}} on {{How}} the {{Brain May Encode Time}}},
  shorttitle = {Navigating {{Through Time}}},
  author = {Issa, John B. and Tocker, Gilad and Hasselmo, Michael E. and Heys, James G. and Dombeck, Daniel A.},
  year = {2020},
  month = jul,
  volume = {43},
  pages = {annurev-neuro-101419-011117},
  issn = {0147-006X, 1545-4126},
  doi = {10.1146/annurev-neuro-101419-011117},
  abstract = {Interval timing, which operates on timescales of seconds to minutes, is distributed across multiple brain regions and may use distinct circuit mechanisms as compared to millisecond timing and circadian rhythms. However, its study has proven difficult, as timing on this scale is deeply entangled with other behaviors. Several circuit and cellular mechanisms could generate sequential or ramping activity patterns that carry timing information. Here we propose that a productive approach is to draw parallels between interval timing and spatial navigation, where direct analogies can be made between the variables of interest and the mathematical operations necessitated. Along with designing experiments that isolate or disambiguate timing behavior from other variables, new techniques will facilitate studies that directly address the neural mechanisms that are responsible for interval timing.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6CUVXFC9\\Issa et al. - 2020 - Navigating Through Time A Spatial Navigation Pers.pdf},
  journal = {Annual Review of Neuroscience},
  language = {en},
  number = {1}
}

@article{ito_moser_2015,
  title = {A Prefrontal-Thalamo-Hippocampal Circuit for Goal-Directed Spatial Navigation},
  author = {Ito, Hiroshi T and Zhang, Sheng Jia and Witter, Menno P and Moser, Edvard I. and Moser, May Britt},
  year = {2015},
  volume = {522},
  pages = {50--55},
  issn = {14764687},
  doi = {10.1038/nature14396},
  abstract = {Spatial navigation requires information about the relationship between current and future positions. The activity of hippocampal neurons appears to reflect such a relationship, representing not only instantaneous position but also the path towards a goal location. However, how the hippocampus obtains information about goal direction is poorly understood. Here we report a prefrontal\textendash thalamic neural circuit that is required for hippocampal representation of routes or trajectories through the environment. Trajectory-dependent firing was observed in medial prefrontal cortex, the nucleus reuniens of the thalamus, and the CA1 region of the hippocampus in rats. Lesioning or optogenetic silencing of the nucleus reuniens substantially reduced trajectory-dependent CA1 firing. Trajectory-dependent activity was almost absent in CA3, which does not receive nucleus reuniens input. The data suggest that projections from medial prefrontal cortex, via the nucleus reuniens, are crucial for representation of the future path during goal-directed behaviour and point to the thalamus as a key node in networks for long-range communication between cortical regions involved in navigation. Hippocampal},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TKSCZIZS\\Ito et al. - Unknown - A prefrontal-thalamo-hippocampal circuit for goal-directed spatial navigation.pdf},
  journal = {Nature},
  number = {7554},
  pmid = {26017312}
}

@article{ito_moser_2018,
  title = {Supramammillary {{Nucleus Modulates Spike}}-{{Time Coordination}} in the {{Prefrontal}}-{{Thalamo}}-{{Hippocampal Circuit}} during {{Navigation}}},
  author = {Ito, Hiroshi T. and Moser, Edvard I. and Moser, May Britt},
  year = {2018},
  month = aug,
  volume = {99},
  pages = {576--587.e5},
  issn = {10974199},
  doi = {10.1016/j.neuron.2018.07.021},
  abstract = {During navigation, hippocampal spatial maps are thought to interact with action-planning systems in other regions of cortex. We here report a key role for spike-time coordination in functional coupling of the medial prefrontal cortex (mPFC) to the hippocampus through the thalamic nucleus reuniens (NR). When rats perform a T-maze alternation task, spikes of neurons in mPFC and NR exhibit enhanced coordination to the CA1 theta rhythm before the choice point on the maze. A similar coordination to CA1 theta rhythm was observed in neurons of the supramammillary nucleus (SUM). Optogenetic silencing of SUM neurons reduced the temporal coordination in the mPFC-NR-CA1 circuit. Following SUM inactivation, trajectory representations were impaired in both NR and CA1, but not in mPFC, indicating a failure in transmission of action plans from mPFC to the hippocampus. The findings identify theta-frequency spike-time coordination as a mechanism for gating of information flow in the mPFC-NR-CA1 circuit. Ito et al. show that the supramammillary nucleus in the hypothalamus is a key node to control theta-frequency spike-time coordination in the mPFC-NR-CA1 circuit. This coordination enhances the transfer of trajectory information from the prefrontal cortex to the hippocampus during route decisions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IMECXGTF\\Ito, Moser, Moser - 2018 - Supramammillary Nucleus Modulates Spike-Time Coordination in the Prefrontal-Thalamo-Hippocampal Circuit durin.pdf},
  journal = {Neuron},
  number = {3},
  pmid = {30092214}
}

@article{itti_itti_2004,
  title = {Realistic Avatar Eye and Head Animation Using a Neurobiological Model of Visual Attention},
  author = {Itti, Laurent},
  year = {2004},
  volume = {5200},
  pages = {64--78},
  issn = {0277786X},
  doi = {http://dx.doi.org/10.1117/12.512618},
  abstract = {We describe a neurobiological model of visual attention and eye/head movements in primates, and its application to the automatic animation of a realistic virtual human head watching an unconstrained variety of visual inputs. The bottom-up (image-based) attention model is based on the known neurophysiology of visual processing along the occipito-parietal pathway of the primate brain, while the eye/head movement model is derived from recordings in freely behaving Rhesus monkeys. The system is successful at autonomously saccading towards and tracking salient targets in a variety of video clips, including synthetic stimuli, real outdoors scenes and gaming console outputs. The resulting virtual human eye/head animation yields realistic rendering of the simulation results, both suggesting applicability of this approach to avatar animation and reinforcing the plausibility of the neural model.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SK5EVRVA\\Itti - 2004 - Realistic avatar eye and head animation using a neurobiological model of visual attention.pdf},
  journal = {Proceedings of SPIE},
  number = {1}
}

@article{iwase_mizuseki_2020,
  title = {Cell Type, Sub-Region, and Layer-Specific Speed Representation in the Hippocampal\textendash Entorhinal Circuit},
  author = {Iwase, Motosada and Kitanishi, Takuma and Mizuseki, Kenji},
  year = {2020},
  month = dec,
  volume = {10},
  pages = {1407},
  issn = {2045-2322},
  doi = {10.1038/s41598-020-58194-1},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WNAHQDUC\\Iwase et al. - 2020 - Cell type, sub-region, and layer-specific speed re.pdf},
  journal = {Scientific Reports},
  language = {en},
  number = {1}
}

@techreport{iyer_basu_2020,
  title = {A {{Spiking Neural Network Model}} for {{Category Learning}}},
  author = {Iyer, Laxmi R. and Basu, Arindam},
  year = {2020},
  month = jan,
  institution = {{Bioengineering}},
  doi = {10.1101/2020.01.23.916593},
  abstract = {The creation of useful categories from data is an important cognitive ability, and from the extensive research on categorization, it is now known that the brain has distinct systems for category learning. In this paper, we present the first spiking neural network (SNN) model of human category learning. Here categories are combinations of features - such categories are observed in the prefrontal cortex (PFC). The system follows an architecture commonly used to model the cortex - features are arranged in a topological 2D grid with short range excitatory connectivity and long range inhibitory connectivity - however, here, this architecture is used differently from other models to model higher level cognition. Earlier we presented an artificial neural network (ANN) model of category learning; however, here, a simpler model was adequate, as desired functionality emerges from the SNN dynamics. We identified the objectives that had to be fulfilled for the model to achieve the desired functionality, and performed a design space exploration (DSE) to identify the parameter range in which each of the objectives was fulfilled, and the parameter range for which the system exhibits good performance. Finally, we compared triphasic STDP (a variant of spike time dependant plasticity (STDP)) with standard STDP and observed that triphasic STDP exhibited quicker convergence.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QI5L3RXG\\Iyer and Basu - 2020 - A Spiking Neural Network Model for Category Learni.pdf},
  language = {en},
  type = {Preprint}
}

@article{izhikevich_edelman_2008,
  title = {Large-Scale Model of Mammalian Thalamocortical Systems},
  author = {Izhikevich, E. M. and Edelman, G. M.},
  year = {2008},
  month = mar,
  volume = {105},
  pages = {3593--3598},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.0712231105},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZBLNZSQS\\Izhikevich and Edelman - 2008 - Large-scale model of mammalian thalamocortical sys.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {9}
}

@article{izhikevich_izhikevich_2006,
  title = {Polychronization: {{Computation}} with {{Spikes}}},
  shorttitle = {Polychronization},
  author = {Izhikevich, Eugene M.},
  year = {2006},
  month = feb,
  volume = {18},
  pages = {245--282},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/089976606775093882},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XCFJZ8YZ\\Izhikevich - 2006 - Polychronization Computation with Spikes.pdf},
  journal = {Neural Computation},
  language = {en},
  number = {2}
}

@book{izhikevich_izhikevich_2007,
  title = {Dynamical Systems in Neuroscience},
  author = {Izhikevich, EM},
  year = {2007},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8FE4B89W\\Izhikevich - 2007 - Dynamical systems in neuroscience.pdf},
  isbn = {978-0-262-09043-8}
}

@article{izquierdo_cammarota_2006,
  title = {The Connection between the Hippocampal and the Striatal Memory Systems of the Brain: {{A}} Review of Recent Findings},
  shorttitle = {The Connection between the Hippocampal and the Striatal Memory Systems of the Brain},
  author = {Izquierdo, Iv{\'a}n and Bevilaqua, Lia R. M. and Rossato, Janine I. and Bonini, Juliana S. and Silva, Weber C. Da and Medina, Jorge H. and Cammarota, Mart{\'i}n},
  year = {2006},
  month = jun,
  volume = {10},
  pages = {113--121},
  issn = {1029-8428, 1476-3524},
  doi = {10.1007/BF03033240},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FUH7BV65\\Izquierdo et al. - 2006 - The connection between the hippocampal and the str.pdf},
  journal = {Neurotoxicity Research},
  language = {en},
  number = {2}
}

@book{jackman_jackman_2012,
  title = {Hierarchical {{Models}}},
  author = {Jackman, Simon},
  year = {2012},
  publisher = {{Elsevier Inc.}},
  doi = {10.1002/0470011815.b2a09021},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RJMGAJBD\\Jackman - 2012 - Hierarchical Models.pdf},
  isbn = {0-470-84907-X}
}

@article{jackson_woolgar_2018,
  title = {Adaptive Coding in the Human Brain: {{Distinct}} Object Features Are Encoded by Overlapping Voxels in Frontoparietal Cortex},
  author = {Jackson, Jade B. and Woolgar, Alexandra},
  year = {2018},
  volume = {108},
  pages = {25--34},
  issn = {19738102},
  doi = {10.1016/j.cortex.2018.07.006},
  abstract = {Our ability to flexibly switch between different tasks is a key component of cognitive control. Non-human primate (NHP) studies (e.g., Freedman, Riesenhuber, Poggio, \& Miller, 2001) have shown that prefrontal neurons are re-used across tasks, re-configuring their responses to code currently relevant information. In a similar vein, in the human brain, the ``multiple demand'' (MD) system is suggested to exert control by adjusting its responses, selectively processing information in line with our current goals (Duncan, 2010). However, whether the same or different resources (underlying neural populations) in the human brain are recruited to solve different tasks remains elusive. In the present study, we aimed to bridge the gap between the NHP and human literature by examining human functional imaging data at an intermediate level of resolution: quantifying the extent to which single voxels contributed to multiple neural codes. Participants alternated between two tasks requiring the selection of feature information from two distinct sets of objects. We examined whether neural codes for the relevant stimulus features in the two different tasks depended on the same or different voxels. In line with the electrophysiological literature, MD voxels were more likely to contribute to multiple neural codes than we predicted based on permutation tests. Comparatively, in the visual system the neural codes depended on distinct sets of voxels. Our data emphasise the flexibility of the MD regions to re-configure their responses and adaptively code relevant information across different tasks.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AQF8V9BT\\Jackson, Woolgar - 2018 - Adaptive coding in the human brain Distinct object features are encoded by overlapping voxels in frontoparieta.pdf},
  journal = {Cortex},
  keywords = {fmri,mvpa}
}

@article{jacob_nieder_2018,
  title = {Structuring of {{Abstract Working Memory Content}} by {{Fronto}}-Parietal {{Synchrony}} in {{Primate Cortex}}},
  author = {Jacob, Simon Nikolas and H{\"a}hnke, Daniel and Nieder, Andreas},
  year = {2018},
  month = aug,
  volume = {99},
  pages = {588-597.e5},
  issn = {08966273},
  doi = {10.1016/j.neuron.2018.07.025},
  abstract = {How is neuronal activity across distant brain regions orchestrated to allow multiple stimuli to be stored together in working memory, yet maintained separate for individual readout and protection from distractors? Using paired recordings in the prefrontal and parietal cortex of monkeys discriminating numbers of items (numerosities), we found that working memory content is structured by frequency-specific oscillatory synchrony. Parieto-frontal signaling in the beta band carried information about the most recent numerical input. Fronto-parietal coupling in the theta band differentiated between multiple memorized numerosities. Task-relevant and distracting stimuli were nested in spiking activity of single prefrontal neurons, but could be separated by reading out spikes at distinct phases of parietal theta oscillations. The strength of phase-locked, cross-regional memory coding predicted task performance. Frequency-specific communication channels in the fronto-parietal network could enable serial bottom-up and parallel top-down information transmission, providing an important mechanism to protect working memory from interference.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EM52XN8Y\\Jacob et al. - 2018 - Structuring of Abstract Working Memory Content by .pdf},
  journal = {Neuron},
  language = {en},
  number = {3}
}

@article{jaderberg_kavukcuoglu_2015,
  title = {Spatial {{Transformer Networks}}},
  author = {Jaderberg, Max and Simonyan, Karen and Zisserman, Andrew and Kavukcuoglu, Koray},
  year = {2015},
  month = jun,
  volume = {33},
  pages = {1242--1249},
  issn = {1087-0156},
  doi = {10.1038/nbt.3343},
  abstract = {Convolutional Neural Networks define an exceptionally powerful class of models, but are still limited by the lack of ability to be spatially invariant to the input data in a computationally and parameter efficient manner. In this work we introduce a new learnable module, the Spatial Transformer, which explicitly allows the spatial manipulation of data within the network. This differentiable module can be inserted into existing convolutional architectures, giving neural networks the ability to actively spatially transform feature maps, conditional on the feature map itself, without any extra training supervision or modification to the optimisation process. We show that the use of spatial transformers results in models which learn invariance to translation, scale, rotation and more generic warping, resulting in state-of-the-art performance on several benchmarks, and for a number of classes of transformations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\796TIYNX\\Jaderberg et al. - Unknown - Spatial Transformer Networks.pdf},
  journal = {Nature Biotechnology},
  number = {12},
  pmid = {26571099}
}

@article{jafarpour_penny_2013,
  title = {Population {{Level Inference}} for {{Multivariate MEG Analysis}}},
  author = {Jafarpour, Anna and Barnes, Gareth and Fuentemilla, Lluis and Duzel, Emrah and Penny, Will D},
  year = {2013},
  volume = {8},
  issn = {19326203},
  doi = {10.1371/journal.pone.0071305},
  abstract = {Multivariate analysis is a very general and powerful technique for analysing Magnetoencephalography (MEG) data. An outstanding problem however is how to make inferences that are consistent over a group of subjects as to whether there are condition-specific differences in data features, and what are those features that maximise these differences. Here we propose a solution based on Canonical Variates Analysis (CVA) model scoring at the subject level and random effects Bayesian model selection at the group level. We apply this approach to beamformer reconstructed MEG data in source space. CVA estimates those multivariate patterns of activation that correlate most highly with the experimental design; the order of a CVA model is then determined by the number of significant canonical vectors. Random effects Bayesian model comparison then provides machinery for inferring the optimal order over the group of subjects. Absence of a multivariate dependence is indicated by the null model being the most likely. This approach can also be applied to CVA models with a fixed number of canonical vectors but supplied with different feature sets. We illustrate the method by identifying feature sets based on variable-dimension MEG power spectra in the primary visual cortex and fusiform gyrus that are maximally discriminative of data epochs before versus after visual stimulation.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\K5ZCTCK3\\Jafarpour et al. - 2013 - Population Level Inference for Multivariate MEG Analysis.pdf},
  journal = {PLoS ONE},
  number = {8},
  pmid = {23940738}
}

@article{jamrozik_gentner_2020,
  title = {Relational Labeling Unlocks Inert Knowledge},
  author = {Jamrozik, Anja and Gentner, Dedre},
  year = {2020},
  month = mar,
  volume = {196},
  pages = {104146},
  issn = {00100277},
  doi = {10.1016/j.cognition.2019.104146},
  abstract = {Insightful solutions often come about by recalling a relevant prior situation\textemdash one that shares the same essential relational pattern as the current problem. Unfortunately, our memory retrievals often depend primarily on surface matches, rather than relational matches. For example, a person who is familiar with the idea of positive feedback in sound systems may fail to think of it in the context of global warming. We suggest that one reason for the failure of cross-domain relational retrieval is that relational information is typically encoded variably, in a context-dependent way. In contrast, the surface features of that context\textemdash such as objects, animals and characters\textemdash are encoded in a relatively stable way, and are therefore easier to retrieve across contexts. We propose that the use of relational language can serve to make situations' relational representations more uniform, thereby facilitating relational retrieval. In two studies, we find that providing relational labels for situations at encoding or at retrieval increased the likelihood of relational retrieval. In contrast, domain labels\textemdash labels that highlight situations' contextual features\textemdash did not reliably improve domain retrieval. We suggest that relational language allows people to retrieve knowledge that would otherwise remain inert and contributes to domain experts' insight.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\46U74CCS\\Jamrozik and Gentner - 2020 - Relational labeling unlocks inert knowledge.pdf},
  journal = {Cognition},
  language = {en}
}

@article{jankowski_omara_2013,
  title = {The Anterior Thalamus Provides a Subcortical Circuit Supporting Memory and Spatial Navigation},
  author = {Jankowski, Maciej M. and Ronnqvist, Kim C. and Tsanov, Marian and Vann, Seralynne D. and Wright, Nicholas F. and Erichsen, Jonathan T. and Aggleton, John P. and O'Mara, Shane M.},
  year = {2013},
  volume = {7},
  issn = {1662-5137},
  doi = {10.3389/fnsys.2013.00045},
  abstract = {The anterior thalamic nuclei (ATN), a central component of Papez' circuit, are generally assumed to be key constituents of the neural circuits responsible for certain categories of learning and memory. Supporting evidence for this contention is that damage to either of two brain regions, the medial temporal lobe and the medial diencephalon, is most consistently associated with anterograde amnesia. Within these respective regions, the hippocampal formation and the ATN (anteromedial, anteroventral, and anterodorsal) are the particular structures of interest. The extensive direct and indirect hippocampal-anterior thalamic interconnections and the presence of theta-modulated cells in both sites further support the hypothesis that these structures constitute a neuronal network crucial for memory and cognition. The major tool in understanding how the brain processes information is the analysis of neuronal output at each hierarchical level along the pathway of signal propagation coupled with neuroanatomical studies. Here, we discuss the electrophysiological properties of cells in the ATN with an emphasis on their role in spatial navigation. In addition, we describe neuroanatomical and functional relationships between the ATN and hippocampal formation.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\H5C6DH29\\Jankowski et al. - 2013 - The anterior thalamus provides a subcortical circu.pdf},
  journal = {Frontiers in Systems Neuroscience},
  language = {en}
}

@article{jankowski_wright_2014,
  title = {Nucleus Reuniens of the Thalamus Contains Head Direction Cells},
  author = {Jankowski, M M and Islam, M N and Wright, N F},
  year = {2014},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3NXSGL8K\\Jankowski, Islam, Wright - 2014 - Nucleus reuniens of the thalamus contains head direction cells.pdf},
  journal = {ELife}
}

@article{japee_ungerleider_2015,
  title = {A Role of Right Middle Frontal Gyrus in Reorienting of Attention: A Case Study},
  author = {Japee, Shruti and Holiday, Kelsey and Satyshur, Maureen D. and Mukai, Ikuko and Ungerleider, Leslie G.},
  year = {2015},
  volume = {9},
  pages = {1--16},
  issn = {1662-5137},
  doi = {10.3389/fnsys.2015.00023},
  abstract = {The right middle fontal gyrus (MFG) has been proposed to be a site of convergence of the dorsal and ventral attention networks, by serving as a circuit-breaker to interrupt ongoing endogenous attentional processes in the dorsal network and reorient attention to an exogenous stimulus. Here, we probed the contribution of the right MFG to both endogenous and exogenous attention by comparing performance on an orientation discrimination task of a patient with a right MFG resection and a group of healthy controls. On endogenously cued trials, participants were shown a central cue that predicted with 90\% accuracy the location of a subsequent peri-threshold Gabor patch stimulus. On exogenously cued trials, a cue appeared briefly at one of two peripheral locations, followed by a variable inter-stimulus interval (ISI; range 0-700 ms) and a Gabor patch in the same or opposite location as the cue. Behavioral data showed that for endogenous, and short ISI exogenous trials, valid cues facilitated responses compared to invalid cues, for both the patient and controls. However, at long ISIs, the patient exhibited difficulty in reverting to top-down attentional control, once the facilitatory effect of the exogenous cue had dissipated. When explicitly cued during long ISIs to attend to both stimulus locations, the patient was able to engage successfully in top-down control. This result indicates that the right MFG may play an important role in reorienting attention from exogenous to endogenous attentional control. Resting state fMRI data revealed that the right superior parietal lobule and right orbitofrontal cortex, showed significantly higher correlations with a left MFG seed region (a region tightly coupled with the right MFG in controls) in the patient relative to controls. We hypothesize that this paradoxical increase in cortical coupling represents a compensatory mechanism in the patient to offset the loss of function of the resected tissue in right prefrontal cortex.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4MDK984L\\Japee et al. - 2015 - A role of right middle frontal gyrus in reorienting of attention a case study.pdf},
  journal = {Frontiers in Systems Neuroscience},
  keywords = {dorsal attention netwo,dorsal attention network,endogenous attention,exogenous attention,frontal lobe tumor resection,reorienting of attention,resting state fmri,resting state fMRI,right middle frontal gyrus,ventral attention network},
  number = {March},
  pmid = {25784862}
}

@article{jaramillo_wang_2018,
  title = {Engagement of {{Pulvino}}-Cortical {{Feedforward}} and {{Feedback Pathways}} in {{Cognitive Computations Article Engagement}} of {{Pulvino}}-Cortical {{Feedforward}} and {{Feedback Pathways}} in {{Cognitive Computations}}},
  author = {Jaramillo, Jorge and Mejias, Jorge F and Correspondence, Xiao-Jing Wang and Wang, Xiao-Jing},
  year = {2018},
  volume = {101},
  pages = {1--16},
  doi = {10.1016/j.neuron.2018.11.023},
  abstract = {Highlights d Pulvino-cortical pathways modulate attention, working memory, and decision making d The pulvinar controls the effective connectivity within and across cortical areas d A plastic cortico-TRN-pulvinar circuit can estimate decision confidence d The pulvinar can regulate frequency-dependent and hierarchical cortical interactions In Brief Very little is known about the function of the thalamus beyond relaying sensory information to the cortex. Jaramillo et al. present a biologically based model of pulvino-cortical interactions and provide a unified account of the pulvinar's computational role across cognitive tasks. SUMMARY Computational modeling of brain mechanisms of cognition has largely focused on the cortex, but recent experiments have shown that higher-order nuclei of the thalamus participate in major cognitive functions and are implicated in psychiatric disorders. Here, we show that a pulvino-cortical circuit model, composed of the pulvinar and two cortical areas, captures several physiological and behavioral observations related to the macaque pulvinar. Effective connections between the two cortical areas are gated by the pulvinar, allowing the pulvinar to shift the operation regime of these areas during atten-tional processing and working memory and resolve conflict in decision making. Furthermore, cortico-pulvinar projections that engage the thalamic retic-ular nucleus enable the pulvinar to estimate decision confidence. Finally, feedforward and feedback pul-vino-cortical pathways participate in frequency-dependent inter-areal interactions that modify the relative hierarchical positions of cortical areas. Overall , our model suggests that the pulvinar provides crucial contextual modulation to cortical computations associated with cognition.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5LQUB38R\\Jaramillo et al. - 2018 - Engagement of Pulvino-cortical Feedforward and Feedback Pathways in Cognitive Computations Article Engagement.pdf},
  journal = {Neuron},
  keywords = {attention,attractor dynamics,confidence,cortex,decision making,hierarchy,oscillations,pulvinar,thalamic reticular nucleus,working-memory}
}

@article{jaramillo_wang_2019,
  title = {Engagement of {{Pulvino}}-Cortical {{Feedforward}} and {{Feedback Pathways}} in {{Cognitive Computations}}},
  author = {Jaramillo, Jorge and Mejias, Jorge F and Wang, Xiao-Jing},
  year = {2019},
  pages = {26},
  abstract = {Computational modeling of brain mechanisms of cognition has largely focused on the cortex, but recent experiments have shown that higher-order nuclei of the thalamus participate in major cognitive functions and are implicated in psychiatric disorders. Here, we show that a pulvino-cortical circuit model, composed of the pulvinar and two cortical areas, captures several physiological and behavioral observations related to the macaque pulvinar. Effective connections between the two cortical areas are gated by the pulvinar, allowing the pulvinar to shift the operation regime of these areas during attentional processing and working memory and resolve conflict in decision making. Furthermore, corticopulvinar projections that engage the thalamic reticular nucleus enable the pulvinar to estimate decision confidence. Finally, feedforward and feedback pulvino-cortical pathways participate in frequencydependent inter-areal interactions that modify the relative hierarchical positions of cortical areas. Overall, our model suggests that the pulvinar provides crucial contextual modulation to cortical computations associated with cognition.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZVPJMYAU\\Jaramillo - Engagement of Pulvino-cortical Feedforward and Fee.pdf},
  language = {en}
}

@article{jas_gramfort_2017,
  title = {Autoreject: {{Automated}} Artifact Rejection for {{MEG}} and {{EEG}} Data},
  author = {Jas, Mainak and Engemann, Denis A and Bekhti, Yousra and Raimondo, Federico and Gramfort, Alexandre},
  year = {2017},
  volume = {159},
  pages = {417--429},
  issn = {10959572},
  doi = {10.1016/j.neuroimage.2017.06.030},
  abstract = {We present an automated algorithm for unified rejection and repair of bad trials in magnetoencephalography (MEG) and electroencephalography (EEG) signals. Our method capitalizes on cross-validation in conjunction with a robust evaluation metric to estimate the optimal peak-to-peak threshold \textendash{} a quantity commonly used for identifying bad trials in M/EEG. This approach is then extended to a more sophisticated algorithm which estimates this threshold for each sensor yielding trial-wise bad sensors. Depending on the number of bad sensors, the trial is then repaired by interpolation or by excluding it from subsequent analysis. All steps of the algorithm are fully automated thus lending itself to the name Autoreject. In order to assess the practical significance of the algorithm, we conducted extensive validation and comparisons with state-of-the-art methods on four public datasets containing MEG and EEG recordings from more than 200 subjects. The comparisons include purely qualitative efforts as well as quantitatively benchmarking against human supervised and semi-automated preprocessing pipelines. The algorithm allowed us to automate the preprocessing of MEG data from the Human Connectome Project (HCP) going up to the computation of the evoked responses. The automated nature of our method minimizes the burden of human inspection, hence supporting scalability and reliability demanded by data analysis in modern neuroscience.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JR54FMRU\\Jas et al. - Unknown - Autoreject Automated artifact rejection for MEG and EEG data.pdf},
  journal = {NeuroImage},
  keywords = {Automated analysis,Cross-validation,Electroencephalogram (EEG),Human Connectome Project (HCP),Magnetoencephalography (MEG),Preprocessing,Statistical learning},
  pmid = {28645840}
}

@article{jas_gramfort_2018,
  title = {A {{Reproducible MEG}}/{{EEG Group Study With}} the {{MNE Software}}: {{Recommendations}}, {{Quality Assessments}}, and {{Good Practices}}},
  author = {Jas, Mainak and Larson, Eric and Engemann, Denis A. and Lepp{\"a}kangas, Jaakko and Taulu, Samu and H{\"a}m{\"a}l{\"a}inen, Matti and Gramfort, Alexandre},
  year = {2018},
  volume = {12},
  pages = {1--18},
  issn = {1662-453X},
  doi = {10.3389/fnins.2018.00530},
  abstract = {Cognitive neuroscience questions are commonly tested with experiments that involve a cohort of subjects. The cohort can consist of a handful of subjects for small studies to hundreds or thousands of subjects in open datasets. While there exist various online resources to get started with the analysis of magnetoencephalography (MEG) or electroencephalography (EEG) data, such educational materials are usually restricted to the analysis of a single subject. This is in part because data from larger group studies are harder to share, but also analyses of such data often require subject-specific decisions which are hard to document. This work presents the results obtained by the reanalysis of an open dataset from Wakeman and Henson (2015) using the MNE software package. The analysis covers preprocessing steps, quality assurance steps, sensor space analysis of evoked responses, source localization, and statistics in both sensor and source space. Results with possible alternative strategies are presented and discussed at different stages such as the use of high-pass filtering versus baseline correction, tSSS vs. SSS, the use of a minimum norm inverse vs. LCMV beamformer, and the use of univariate or multivariate statistics. This aims to provide a comparative study of different stages of M/EEG analysis pipeline on the same dataset, with open access to all of the scripts necessary to reproduce this analysis.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3NY97TLJ\\Jas et al. - 2018 - A Reproducible MEGEEG Group Study With the MNE Software Recommendations, Quality Assessments, and Good Practices(2).pdf},
  journal = {Frontiers in Neuroscience},
  keywords = {eeg,electroencephalography (EEG),magnetoencephalograp,magnetoencephalography,meg,neuroimaging,python,software},
  number = {August}
}

@article{jayachandran_jayachandran_2019,
  title = {Prefrontal {{Pathways Provide Top}}-{{Down Control}} of {{Memory}} for {{Sequences}} of {{Events}}},
  author = {Jayachandran, Maanasa},
  year = {2019},
  pages = {22},
  abstract = {We remember our lives as sequences of events, but it is unclear how these memories are controlled during retrieval. In rats, the medial prefrontal cortex (mPFC) is positioned to influence sequence memory through extensive top-down inputs to regions heavily interconnected with the hippocampus, notably the nucleus reuniens of the thalamus (RE) and perirhinal cortex (PER). Here, we used an hM4Di synapticsilencing approach to test our hypothesis that specific mPFC/RE and mPFC/PER projections regulate sequence memory retrieval. First, we found non-overlapping populations of mPFC cells project to RE and PER. Second, suppressing mPFC activity impaired sequence memory. Third, inhibiting mPFC/RE and mPFC/PER pathways effectively abolished sequence memory. Finally, a sequential lag analysis showed that the mPFC/RE pathway contributes to a working memory retrieval strategy, whereas the mPFC/PER pathway supports a temporal context memory retrieval strategy. These findings demonstrate that mPFC/RE and mPFC/ PER pathways serve as top-down mechanisms that control distinct sequence memory retrieval strategies.},
  language = {en}
}

@article{jayakumar_knierim_2019,
  title = {Recalibration of Path Integration in Hippocampal Place Cells},
  author = {Jayakumar, Ravikrishnan P. and Madhav, Manu S. and Savelli, Francesco and Blair, Hugh T. and Cowan, Noah J. and Knierim, James J.},
  year = {2019},
  month = feb,
  volume = {566},
  pages = {533--537},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/s41586-019-0939-3},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\G5QXTV6E\\Jayakumar et al. - 2019 - Recalibration of path integration in hippocampal p.pdf},
  journal = {Nature},
  language = {en},
  number = {7745}
}

@article{jeewajee_burgess_2014,
  title = {Theta Phase Precession of Grid and Place Cell Firing in Open Environments.},
  author = {Jeewajee, A and Barry, C and Douchamps, V and Manson, D and Lever, C and Burgess, Neil},
  year = {2014},
  volume = {369},
  pages = {20120532},
  issn = {1471-2970},
  doi = {10.1098/rstb.2012.0532},
  abstract = {Place and grid cells in the rodent hippocampal formation tend to fire spikes at successively earlier phases relative to the local field potential theta rhythm as the animal runs through the cell's firing field on a linear track. However, this 'phase precession' effect is less well characterized during foraging in two-dimensional open field environments. Here, we mapped runs through the firing fields onto a unit circle to pool data from multiple runs. We asked which of seven behavioural and physiological variables show the best circular-linear correlation with the theta phase of spikes from place cells in hippocampal area CA1 and from grid cells from superficial layers of medial entorhinal cortex. The best correlate was the distance to the firing field peak projected onto the animal's current running direction. This was significantly stronger than other correlates, such as instantaneous firing rate and time-in-field, but similar in strength to correlates with other measures of distance travelled through the firing field. Phase precession was stronger in place cells than grid cells overall, and robust phase precession was seen in traversals through firing field peripheries (although somewhat less than in traversals through the centre), consistent with phase coding of displacement along the current direction. This type of phase coding, of place field distance ahead of or behind the animal, may be useful for allowing calculation of goal directions during navigation.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7AI55H3V\\Jeewajee et al. - 2014 - Theta phase precession of grid and place cell firing in open environments.pdf},
  journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
  number = {December 2013},
  pmid = {24366140}
}

@article{jefferson_salat_2015,
  title = {Gray \& White Matter Tissue Contrast Differentiates {{Mild Cognitive Impairment}} Converters from Non-Converters},
  author = {Jefferson, Angela L. and Gifford, Katherine A. and Damon, Stephen and Chapman, G. William and Liu, Dandan and Sparling, Jamie and Dobromyslin, Vitaly and Salat, David},
  year = {2015},
  month = jun,
  volume = {9},
  pages = {141--148},
  issn = {1931-7557, 1931-7565},
  doi = {10.1007/s11682-014-9291-2},
  copyright = {All rights reserved},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\R938H2E9\\for the Alzheimer’s Disease Neuroimaging Initiative et al. - 2015 - Gray & white matter tissue contrast differentiates.pdf},
  journal = {Brain Imaging and Behavior},
  language = {en},
  number = {2}
}

@article{jennings_deisseroth_2019,
  title = {Interacting Neural Ensembles in Orbitofrontal Cortex for Social and Feeding Behaviour},
  author = {Jennings, Joshua H. and Kim, Christina K. and Marshel, James H. and Raffiee, Misha and Ye, Li and Quirin, Sean and Pak, Sally and Ramakrishnan, Charu and Deisseroth, Karl},
  year = {2019},
  month = jan,
  volume = {565},
  pages = {645--649},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/s41586-018-0866-8},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IQH7R8AI\\Jennings et al. - 2019 - Interacting neural ensembles in orbitofrontal cort.pdf},
  journal = {Nature},
  language = {en},
  number = {7741}
}

@article{jensen_bonnefond_2013,
  title = {Prefrontal Alpha- and Beta-Band Oscillations Are Involved in Rule Selection},
  author = {Jensen, Ole and Bonnefond, Mathilde},
  year = {2013},
  volume = {17},
  pages = {10--12},
  issn = {13646613},
  doi = {10.1016/j.tics.2012.11.002},
  abstract = {A recent study in monkeys reports that oscillatory neuronal synchronization between ensembles of prefrontal neurons is involved in rule selection. The study demonstrates that beta-band synchronization (19-40. Hz) reflects the selection of a rule, whereas alpha-band synchronization (6-16. Hz) reflects the active inhibition of a not-to-be-applied rule. ?? 2012 Elsevier Ltd.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NQ5EAI6D\\Jensen, Bonnefond - 2013 - Prefrontal alpha- and beta-band oscillations are involved in rule selection.pdf},
  journal = {Trends in Cognitive Sciences},
  number = {1},
  pmid = {23176827}
}

@article{jensen_bonnefond_2014,
  title = {Temporal Coding Organized by Coupled Alpha and Gamma Oscillations Prioritize Visual Processing},
  author = {Jensen, Ole and Gips, Bart and Bergmann, Til Ole and Bonnefond, Mathilde},
  year = {2014},
  month = jul,
  volume = {37},
  pages = {357--369},
  issn = {01662236},
  doi = {10.1016/j.tins.2014.04.001},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YNG5IRSI\\Jensen et al. - 2014 - Temporal coding organized by coupled alpha and gam.pdf},
  journal = {Trends in Neurosciences},
  language = {en},
  number = {7}
}

@article{ji_ji_2014,
  title = {Generalized {{Strategies}} for {{Path Integration}} Using {{Neural Oscillators}}},
  author = {Ji, Xiang},
  year = {2014},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LA3SDP4G\\Ji - 2014 - Generalized Strategies for Path Integration using Neural Oscillators.pdf}
}

@article{jia_benson_2020,
  title = {Neural {{Jump Stochastic Differential Equations}}},
  author = {Jia, Junteng and Benson, Austin R.},
  year = {2020},
  month = jan,
  abstract = {Many time series are effectively generated by a combination of deterministic continuous flows along with discrete jumps sparked by stochastic events. However, we usually do not have the equation of motion describing the flows, or how they are affected by jumps. To this end, we introduce Neural Jump Stochastic Differential Equations that provide a data-driven approach to learn continuous and discrete dynamic behavior, i.e., hybrid systems that both flow and jump. Our approach extends the framework of Neural Ordinary Differential Equations with a stochastic process term that models discrete events. We then model temporal point processes with a piecewise-continuous latent trajectory, where the discontinuities are caused by stochastic events whose conditional intensity depends on the latent state. We demonstrate the predictive capabilities of our model on a range of synthetic and real-world marked point process datasets, including classical point processes (such as Hawkes processes), awards on Stack Overflow, medical records, and earthquake monitoring.},
  archivePrefix = {arXiv},
  eprint = {1905.10403},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QMFUS3XQ\\Jia and Benson - 2020 - Neural Jump Stochastic Differential Equations.pdf},
  journal = {arXiv:1905.10403 [cs, stat]},
  language = {en},
  primaryClass = {cs, stat}
}

@article{jiang_egner_2015,
  title = {An Insula-Frontostriatal Network Mediates Flexible Cognitive Control by Adaptively Predicting Changing Control Demands},
  author = {Jiang, Jiefeng and Beck, Jeffrey and Heller, Katherine and Egner, Tobias},
  year = {2015},
  volume = {6},
  pages = {1--11},
  issn = {20411723},
  doi = {10.1038/ncomms9165},
  abstract = {The anterior cingulate and lateral prefrontal cortices have been implicated in implementing context-appropriate attentional control, but the learning mechanisms underlying our ability to flexibly adapt the control settings to changing environments remain poorly understood. Here we show that human adjustments to varying control demands are captured by a reinforcement learner with a flexible, volatility-driven learning rate. Using model-based functional magnetic resonance imaging, we demonstrate that volatility of control demand is estimated by the anterior insula, which in turn optimizes the prediction of forthcoming demand in the caudate nucleus. The caudate's prediction of control demand subsequently guides the implementation of proactive and reactive attentional control in dorsal anterior cingulate and dorsolateral prefrontal cortices. These data enhance our understanding of the neuro-computational mechanisms of adaptive behaviour by connecting the classic cingulate-prefrontal cognitive control network to a subcortical control-learning mechanism that infers future demands by flexibly integrating remote and recent past experiences.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2JYK5ZFG\\Jiang et al. - 2015 - An insula-frontostriatal network mediates flexible cognitive control by adaptively predicting changing control dem.pdf},
  journal = {Nature Communications},
  number = {May},
  pmid = {26391305}
}

@article{jiang_finn_2019,
  title = {Language as an {{Abstraction}} for {{Hierarchical Deep Reinforcement Learning}}},
  author = {Jiang, Yiding and Gu, Shixiang and Murphy, Kevin and Finn, Chelsea},
  year = {2019},
  month = jun,
  abstract = {Solving complex, temporally-extended tasks is a long-standing problem in reinforcement learning (RL). We hypothesize that one critical element of solving such problems is the notion of compositionality. With the ability to learn concepts and sub-skills that can be composed to solve longer tasks, i.e. hierarchical RL, we can acquire temporally-extended behaviors. However, acquiring effective yet general abstractions for hierarchical RL is remarkably challenging. In this paper, we propose to use language as the abstraction, as it provides unique compositional structure, enabling fast learning and combinatorial generalization, while retaining tremendous flexibility, making it suitable for a variety of problems. Our approach learns an instruction-following low-level policy and a high-level policy that can reuse abstractions across tasks, in essence, permitting agents to reason using structured language. To study compositional task learning, we introduce an open-source object interaction environment built using the MuJoCo physics engine and the CLEVR engine. We find that, using our approach, agents can learn to solve to diverse, temporally-extended tasks such as object sorting and multi-object rearrangement, including from raw pixel observations. Our analysis find that the compositional nature of language is critical for learning diverse sub-skills and systematically generalizing to new sub-skills in comparison to non-compositional abstractions that use the same supervision.},
  archivePrefix = {arXiv},
  eprint = {1906.07343},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RJBWI7LP\\Jiang_et_al_2019_Language_as_an_Abstraction_for_Hierarchical_Deep_Reinforcement_Learning.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\7YCN4PUX\\1906.html},
  journal = {arXiv:1906.07343 [cs, stat]},
  primaryClass = {cs, stat}
}

@article{jiang_vangaal_2015,
  title = {{{EEG}} Neural Oscillatory Dynamics Reveal Semantic and Response Conflict at Difference Levels of Conflict Awareness},
  author = {Jiang, Jun and Zhang, Qinglin and Van Gaal, Simon},
  year = {2015},
  volume = {5},
  pages = {12008},
  issn = {2045-2322},
  doi = {10.1038/srep12008},
  abstract = {Although previous work has shown that conflict can be detected in the absence of awareness, it is unknown how different sources of conflict (i.e., semantic, response) are processed in the human brain and whether these processes are differently modulated by conflict awareness. To explore this issue, we extracted oscillatory power dynamics from electroencephalographic (EEG) data recorded while human participants performed a modified version of the Stroop task. Crucially, in this task conflict awareness was manipulated by masking a conflict-inducing color word preceding a color patch target. We isolated semantic from response conflict by introducing four color words/patches, of which two were matched to the same response. We observed that both semantic as well as response conflict were associated with mid-frontal theta-band and parietal alpha-band power modulations, irrespective of the level of conflict awareness (high vs. low), although awareness of conflict increased these conflict-related power dynamics. These results show that both semantic and response conflict can be processed in the human brain and suggest that the neural oscillatory mechanisms in EEG reflect mainly "domain general" conflict processing mechanisms, instead of conflict source specific effects.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5HQHEX7V\\Jiang, Zhang, Van Gaal - 2015 - EEG neural oscillatory dynamics reveal semantic and response conflict at difference levels of conflict a.pdf},
  journal = {Scientific Reports},
  number = {1},
  pmid = {26169473}
}

@article{jin_arnsten_2017,
  title = {{{mGluR2}}/3 Mechanisms in Primate Dorsolateral Prefrontal Cortex: Evidence for Both Presynaptic and Postsynaptic Actions},
  shorttitle = {{{mGluR2}}/3 Mechanisms in Primate Dorsolateral Prefrontal Cortex},
  author = {Jin, L E and Wang, M and Yang, S-T and Yang, Y and Galvin, V C and Lightbourne, T C and Ottenheimer, D and Zhong, Q and Stein, J and Raja, A and Paspalas, C D and Arnsten, A F T},
  year = {2017},
  month = nov,
  volume = {22},
  pages = {1615--1625},
  issn = {1359-4184, 1476-5578},
  doi = {10.1038/mp.2016.129},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MD7BGFJ7\\Jin et al. - 2017 - mGluR23 mechanisms in primate dorsolateral prefro.pdf},
  journal = {Molecular Psychiatry},
  language = {en},
  number = {11}
}

@article{jirsa_muller_2013,
  title = {Cross-Frequency Coupling in Real and Virtual Brain Networks},
  author = {Jirsa, Viktor and M{\"u}ller, Viktor},
  year = {2013},
  volume = {7},
  issn = {1662-5188},
  doi = {10.3389/fncom.2013.00078},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MWDIWTH6\\Jirsa and Müller - 2013 - Cross-frequency coupling in real and virtual brain.pdf},
  journal = {Frontiers in Computational Neuroscience},
  language = {en}
}

@article{john_barbas_2018,
  title = {Visual {{Attention Deficits}} in {{Schizophrenia Can Arise From Inhibitory Dysfunction}} in {{Thalamus}} or {{Cortex}}},
  author = {John, Yohan J. and Zikopoulos, Basilis and Bullock, Daniel and Barbas, Helen},
  year = {2018},
  month = dec,
  volume = {2},
  pages = {223--257},
  issn = {2379-6227},
  doi = {10.1162/cpsy_a_00023},
  abstract = {Schizophrenia is associated with diverse cognitive deficits, including disorders of attention-related oculomotor behavior. At the structural level, schizophrenia is associated with abnormal inhibitory control in the circuit linking cortex and thalamus. We developed a spiking neural network model that demonstrates how dysfunctional inhibition can degrade attentive gaze control. Our model revealed that perturbations of two functionally distinct classes of cortical inhibitory neurons, or of the inhibitory thalamic reticular nucleus, disrupted processing vital for sustained attention to a stimulus, leading to distractibility. Because perturbation at each circuit node led to comparable but qualitatively distinct disruptions in attentive tracking or fixation, our findings support the search for new eye movement metrics that may index distinct underlying neural defects. Moreover, because the cortico-thalamic circuit is a common motif across sensory, association, and motor systems, the model and extensions can be broadly applied to study normal function and the neural bases of other cognitive deficits in schizophrenia.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KXQIECJI\\John et al. - 2018 - Visual Attention Deficits in Schizophrenia Can Ari.pdf},
  journal = {Computational Psychiatry},
  language = {en}
}

@article{john_erdi_2014,
  title = {Anxiolytic Drugs and Altered Hippocampal Theta Rhythms: The Quantitative Systems Pharmacological Approach.},
  author = {John, Tibin and Kiss, Tam{\'a}s and Lever, Colin and {\'E}rdi, P{\'e}ter},
  year = {2014},
  volume = {25},
  pages = {20--37},
  issn = {1361-6536},
  doi = {10.3109/0954898X.2013.880003},
  abstract = {The spirit of systems pharmacology was adopted to study the possible mechanisms of anxiolytic drugs on hippocampal electric patterns. The frequency of the hippocampal theta rhythm increases linearly with the intensity of electrical stimulation to the brainstem. The reduction of mean theta frequency in this paradigm predicts the clinical efficacy of anxiolytic drugs. The purpose of this study was to investigate the mechanisms by which anxiolytics produce their characteristic effects on the slope and intercept of the stimulus-frequency relationship of hippocampal theta. A network of neuron populations that generates septo-hippocampal theta rhythm was modeled using a compartmental modeling technique. The influence of cellular and synaptic parameters on network frequency was studied. Results show that halving the rate of rise and fall of pyramidal hyperpolarization-activated (Ih) conductance lowers nPO elicited theta frequency at low levels of stimulation. Results also suggest that increasing the decay time constant of inhibitory post-synaptic current can reduce the frequency of low nPO stimulation elicited theta rhythm, while maximal synaptic conductance of GABA-mediated synapses has little effect on frequency. Given their similar effect on network dynamics as by known anxiolytics, these parameter manipulations may mimic or predict the biophysical manifestations of anxiolytic action within the septo-hippocampal system.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MC3R24M6\\John et al. - 2014 - Anxiolytic drugs and altered hippocampal theta rhythms the quantitative systems pharmacological approach.pdf},
  journal = {Network},
  keywords = {anxiolytic,Hippocampus,Hippocampus: drug effects,Hippocampus: physiology,Models,Neural Networks (Computer),Neurological,Theta Rhythm,Theta Rhythm: drug effects,Theta Rhythm: physiology},
  number = {1-2},
  pmid = {24571096}
}

@article{john_prelec_2012,
  title = {Measuring the {{Prevalence}} of {{Questionable Research Practices With Incentives}} for {{Truth Telling}}},
  author = {John, L K and Loewenstein, G and Prelec, D},
  year = {2012},
  volume = {23},
  pages = {524--532},
  issn = {0956-7976},
  doi = {10.1177/0956797611430953},
  abstract = {Cases of clear scientific misconduct have received significant media attention recently, but less flagrantly questionable research practices may be more prevalent and, ultimately, more damaging to the academic enterprise. Using an anonymous elicitation format supplemented by incentives for honest reporting, we surveyed over 2,000 psychologists about their involvement in questionable research practices. The impact of truth-telling incentives on self-admissions of questionable research practices was positive, and this impact was greater for practices that respondents judged to be less defensible. Combining three different estimation methods, we found that the percentage of respondents who have engaged in questionable practices was surprisingly high. This finding suggests that some questionable practices may constitute the prevailing research norm.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NUSX6BND\\John, Loewenstein, Prelec - 2012 - Measuring the Prevalence of Questionable Research Practices With Incentives for Truth Telling.pdf},
  journal = {Psychological Science},
  keywords = {disclosure,judgment,methodology,professional standards,received 5,revision accepted 10,scientific misconduct have received},
  number = {5},
  pmid = {22508865}
}

@article{johnson_dickson_2007,
  title = {Integrating Hippocampus and Striatum in Decision-Making {{This}} Review Comes from a Themed Issue on {{Neurobiology}} of {{Behaviour Edited}}},
  author = {Johnson, Adam and Aa Van Der Meer, Matthijs and Redish, A David and Moser, Edvard and Dickson, Barry},
  year = {2007},
  volume = {17},
  pages = {692--697},
  doi = {10.1016/j.conb.2008.01.003},
  abstract = {Learning and memory and navigation literatures emphasize interactions between multiple memory systems: a flexible, planning-based system and a rigid, cached-value system. This has profound implications for decision-making. Recent conceptualizations of flexible decision-making employ prospection and projection arising from a network involving the hippocampus. Recent recordings from rodent hippocampus in decision-making situations have found transient forward-shifted representations. Evaluation of that prediction and subsequent action-selection probably occurs downstream (e.g. in orbitofrontal cortex, in ventral and dorsomedial striatum). Classically, striatum has been identified as a crucial component of the less-flexible, incremental system. Current evidence, however, suggests that striatum is involved in both flexible and stimulus\textendash response decision-making, with dorsolateral striatum involved in stimulus\textendash response strategies and ventral and dorsomedial striatum involved in goal-directed strategies.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IG9X87FB\\Johnson et al. - 2007 - Integrating hippocampus and striatum in decision-making This review comes from a themed issue on Neurobiology of.pdf},
  journal = {Current Opinion in Neurobiology}
}

@article{johnson_ofen_2018,
  title = {Direct Brain Recordings Reveal Prefrontal Cortex Dynamics of Memory Development},
  author = {Johnson, E L and Tang, L and Yin, Q and Asano, E and Ofen, N},
  year = {2018},
  month = dec,
  volume = {4},
  pages = {eaat3702},
  issn = {2375-2548},
  doi = {10.1126/sciadv.aat3702},
  abstract = {Prevailing theories link prefrontal cortex (PFC) maturation to the development of declarative memory. However, the precise spatiotemporal correlates of memory formation in the developing brain are not known. We provide rare intracranial evidence that the spatiotemporal propagation of frontal activity supports memory formation in children. Seventeen subjects (6.2 to 19.4 years) studied visual scenes in preparation for a recognition memory test while undergoing direct cortical monitoring. Earlier PFC activity predicted greater accuracy, and subsecond deviations in activity flow between subregions predicted memory formation. Activity flow between inferior and precentral sites was refined during adolescence, partially explaining gains in memory. In contrast, middle frontal activity predicted memory independent of age. These findings show with subsecond temporal precision that the developing PFC links scene perception and memory formation and underscore the role of the PFC in supporting memory development.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9IRSWPLD\\Johnson et al. - 2018 - Direct brain recordings reveal prefrontal cortex dynamics of memory development.pdf},
  journal = {Science Advances},
  number = {12}
}

@article{johnson_redish_2005,
  title = {Reconstruction of the Postsubiculum Head Direction Signal from Neural Ensembles.},
  author = {Johnson, Adam and Seeland, Kelsey and Redish, a David},
  year = {2005},
  month = jan,
  volume = {15},
  pages = {86--96},
  issn = {1050-9631},
  doi = {10.1002/hipo.20033},
  abstract = {Head direction cells change their firing rates as a function of the orientation of an animal within an environment. Typically, these cells display a unimodal tuning curve with maximal firing at the cell's preferred direction. As different cells have different preferred directions, the population of cells has been hypothesized to represent the orientation of the animal within the environment. Previous research has shown that pairs of simultaneously recorded head direction cells respond similarly to cue manipulations, suggesting that a population of head direction cells acts in concert to represent the animal's orientation within its environment. Ensembles of head direction cells were recorded from the postsubiculum from rats foraging in an open field. Directional responses of each cell were quantified by the nonparametric Watson's U2 statistic, a measure which makes no explicit assumptions of tuning curve shape. Directionally responsive cells were then used to reconstruct each animal's orientation within the open field using population vector, optimal-linear estimator, and Bayesian methods. The results indicated that postsubiculum contained a complete representation of the animal's orientation. The internal consistency of a neural ensemble can be assessed by comparing the ensemble activity to the expected activity given the reconstructed orientation. This has been termed the "coherency" of the neural ensemble. Reconstruction error decreased as the coherency of the orientation representation increased, indicating that coherency could be used to measure a level of confidence in the representation quality. Because coherency is a linear measure dependent only on internal variables, coherency may be a behaviorally relevant measure used to ascertain the animal's confidence in its representation of orientation.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2634QX4W\\Johnson, Seeland, Redish - 2005 - Reconstruction of the postsubiculum head direction signal from neural ensembles.pdf},
  journal = {Hippocampus},
  keywords = {Animals,Bayes Theorem,Head Movements,Head Movements: physiology,Hippocampus,Hippocampus: anatomy {\&} histology,Hippocampus: anatomy \& histology,Hippocampus: physiology,Inbred BN,Inbred F344,Male,Models,Nerve Net,Nerve Net: anatomy {\&} histology,Nerve Net: anatomy \& histology,Nerve Net: physiology,Neural Pathways,Neural Pathways: anatomy {\&} histology,Neural Pathways: anatomy \& histology,Neural Pathways: physiology,Neurological,Neurons,Neurons: physiology,Orientation,Orientation: physiology,Rats,Space Perception,Space Perception: physiology,Synaptic Transmission,Synaptic Transmission: physiology},
  number = {1},
  pmid = {15390162}
}

@article{johnson_redish_2009,
  title = {Looking for Cognition in the Structure within the Noise},
  author = {Johnson, Adam and Fenton, Andr?? A and Kentros, Cliff and Redish, A David},
  year = {2009},
  volume = {13},
  pages = {55--64},
  issn = {13646613},
  doi = {10.1016/j.tics.2008.11.005},
  abstract = {Neural activity in the mammalian CNS is determined by both observable processes, such as sensory stimuli or motor output, and covert, internal cognitive processes that cannot be directly observed. We propose methods to identify these cognitive processes by examining the covert structure within the apparent 'noise' in spike trains. Contemporary analyses of neural codes include encoding (tuning curves derived from spike trains and behavioral, sensory or motor variables), decoding (reconstructing behavioral, sensory or motor variables from spike trains and hypothesized tuning curves) and generative models (predicting the spike trains from hypothesized encoding models and decoded variables). We review examples of each of these processes in hippocampal activity, and propose a general methodology to examine cognitive processes via the identification of dynamic changes in covert variables. ?? 2008 Elsevier Ltd. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\M9Z9PVT9\\Johnson et al. - 2009 - Looking for cognition in the structure within the noise.pdf},
  journal = {Trends in Cognitive Sciences},
  number = {2},
  pmid = {19135406}
}

@article{johnson-laird_johnson-laird_1999,
  title = {Deductive Reasoning.},
  author = {{Johnson-Laird}, P N},
  year = {1999},
  volume = {50},
  pages = {109--135},
  issn = {0066-4308},
  doi = {10.1146/annurev.psych.50.1.109},
  abstract = {This chapter describes the main accounts of deductive competence, which explain what is computed in carrying out deductions. It argues that people have a modicum of competence, which is useful in daily life and a prerequisite for acquiring logical expertise. It outlines the three main sorts of theory of deductive performance, which explain how people make deductions: They rely on factual knowledge, formal rules, or mental models. It reviews recent experimental studies of deductive reasoning in order to help readers to assess these theories of performance.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CEGF7FDY\\Johnson-Laird - 1999 - Deductive reasoning.pdf},
  journal = {Annual review of psychology},
  keywords = {deduction,logic,mental models,rules of inference,thinking},
  pmid = {15012459}
}

@article{johnston_everling_2019,
  title = {Alpha-Oscillations Modulate Preparatory Activity in Marmoset Area {{8Ad}}},
  author = {Johnston, Kevin and Ma, Liya and Schaeffer, Lauren and Everling, Stefan},
  year = {2019},
  month = jan,
  pages = {2703--18},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.2703-18.2019},
  abstract = {Cognitive control often requires suppression of prepotent stimulus-driven responses in favour of less potent alternatives. Suppression of prepotent saccades has been shown to require proactive inhibition in the frontoparietal saccade network. Electrophysiological evidence in macaque monkeys has revealed neural correlates of such inhibition in this network, however the interlaminar instantiation of inhibitory processes remains poorly understood as these areas lie deep within sulci in macaques, rendering them inaccessible to laminar recordings. Here we addressed this gap by exploiting the mostly lissencephalic cortex of the common marmoset (Callithrix jacchus). We inserted linear electrode arrays into areas 8Ad \textemdash{} the putative marmoset frontal eye field - and lateral intraparietal area (LIP) of two male marmosets, and recorded neural activity during performance of a task comprised of alternating blocks of trials requiring a saccade either toward a large, high-luminance stimulus or the inhibition of this prepotent response in favour of a saccade toward a small, low-luminance stimulus. We observed prominent task-dependent activity in both alpha/gamma bands of the local field potential and discharge rates of single neurons in area 8Ad during a prestimulus task epoch in which the animals had been instructed which of these two tasks to perform but prior to peripheral stimulus onset. These data are consistent with a model in which rhythmic alpha-band activity in deeper layers inhibits spiking in upper layers to support proactive inhibitory saccade control. SIGNIFICANCE STATEMENT Failures to inhibit automatic saccadic responses are a hallmark of many neuropsychiatric disorders. How this process is implemented across the cortical layers in the frontoparietal saccade network remains unknown, as many of the areas are inaccessible to laminar recordings in macaques. Here we investigated laminar neural activity in marmoset monkeys which have a smooth cortex. Monkeys were required either to generate or inhibit a prepotent saccade response. In area 8Ad, the putative frontal eye field in marmosets, rhythmic alpha-band activity (9-14 Hz) was higher in deeper layers and spiking activity was lower in upper layers when the animals were instructed to suppress a saccade towards a peripheral stimulus. Reduced alpha power during task preparation may be the underlying common neural basis of a saccade suppression deficit.},
  copyright = {Copyright \textcopyright{} 2019 the authors},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5K4CZ6JD\\Johnston et al. - 2019 - Alpha-oscillations modulate preparatory activity i.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\8H8AGCR8\\JNEUROSCI.2703-18.html},
  journal = {Journal of Neuroscience},
  language = {en},
  pmid = {30651331}
}

@article{jones_canas_2010,
  title = {Permalink {{Integrating Reinforcement Learning}} with {{Models}} of {{Representation Learning}}},
  author = {Jones, Matt and Canas, Fabian},
  year = {2010},
  volume = {32},
  abstract = {Reinforcement learning (RL) shows great promise as a model of learning in complex, dynamic tasks, for both humans and artificial systems. However, the effectiveness of RL models depends strongly on the choice of state representation, because this determines how knowledge is generalized among states. We introduce a framework for integrating psychological mechanisms of representation learning that allows RL to autonomously adapt its representation to suit its needs and thereby speed learning. One such model is formalized, based on learned selective attention among stimulus dimensions. The model significantly outperforms standard RL models and provides a good fit to human data.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\H67AF76Y\\Jones, Canas - 2010 - Permalink Integrating Reinforcement Learning with Models of Representation Learning.pdf},
  keywords = {attention,generalization,Reinforcement learning},
  number = {32}
}

@article{jones_dennis_2015,
  title = {Models of {{Semantic Memory}}},
  author = {Jones, Michael N. and Willits, Jon and Dennis, Simon},
  year = {2015},
  pages = {232--254},
  doi = {10.1093/oxfordhb/9780199957996.013.11},
  abstract = {Meaning is a fundamental component of nearly all aspects of human cognition, but formal models of semantic memory have classically lagged behind many other areas of cognition. However, computational models of semantic memory have seen a surge of progress in the last two decades, advancing our knowledge of how meaning is constructed from experience, how knowledge is represented and used, and what processes are likely to be culprit in disorders characterized by semantic impairment. This chapter provides an overview of several recent clusters of models and trends in the literature, including modern connectionist and distributional models of semantic memory, and contemporary advances in grounding semantic models with perceptual information and models of compositional semantics. Several common lessons have emerged from both the connectionist and distributional literatures, and we attempt to synthesize these themes to better focus future developments in semantic modeling.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TWDVK9QC\\Jones, Willits, Dennis - 2015 - Models of Semantic Memory.pdf},
  journal = {Oxford Handbook of Mathematical and Computational Psychology},
  keywords = {cognitive model,concepts,connectionist network,distributional semantics,latent semantic analysis,semantic memory,semantic space model}
}

@article{jones_dzhafarov_2014,
  title = {Unfalsifiability and Mutual Translatability of Major Modeling Schemes for Choice Reaction Time.},
  author = {Jones, Matt and Dzhafarov, Ehtibar N},
  year = {2014},
  volume = {121},
  pages = {1--32},
  issn = {1939-1471},
  doi = {10.1037/a0034190},
  abstract = {[Correction Notice: An Erratum for this article was reported in Vol 121(1) of Psychological Review (see record 2014-03591-005). The link to supplemental material was missing. All versions of this article have been corrected.] Much current research on speeded choice utilizes models in which the response is triggered by a stochastic process crossing a deterministic threshold. This article focuses on 2 such model classes, 1 based on continuous-time diffusion and the other on linear ballistic accumulation (LBA). Both models assume random variability in growth rates and in other model components across trials. We show that if the form of this variability is unconstrained, the models can exactly match any possible pattern of response probabilities and response time distributions. Thus, the explanatory or predictive content of these models is determined not by their structural assumptions but, rather, by distributional assumptions (e.g., Gaussian distributions) that are traditionally regarded as implementation details. Selective influence assumptions (i.e., which experimental manipulations affect which model parameters) are shown to have no restrictive effect, except for the theoretically questionable assumption that speed-accuracy instructions do not affect growth rates. The 2nd contribution of this article concerns translation of falsifiable models between universal modeling languages. Specifically, we translate the predictions of the diffusion and LBA models (with their parametric and selective influence assumptions intact) into the Grice modeling framework, in which accumulation processes are deterministic and thresholds are random variables. The Grice framework is also known to reproduce any possible pattern of response probabilities and times, and hence it can be used as a common language for comparing models. It is found that only a few simple properties of empirical data are necessary predictions of the diffusion and LBA models.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\98XUPQJQ\\Jones, Dzhafarov - 2014 - Unfalsifiability and mutual translatability of major modeling schemes for choice reaction time.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\XHIJRRRP\\Jones, Dzhafarov - 2014 - Unfalsifiability and mutual translatability of major modeling schemes for choice reaction time(2).pdf},
  journal = {Psychological Review},
  keywords = {choice reaction time,diffusion model,grice framework,Grice framework,linear ballistic accumulator,model,model falsifiability},
  number = {1},
  pmid = {24079307}
}

@article{jones_jones_2016,
  title = {Duality {{Between Feature}} and {{Similarity Models}}, {{Based}} on the {{Reproducing}}-{{Kernel Hilbert Space}}},
  author = {Jones, Matt},
  year = {2016},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ERJTK62J\\Jones - 2016 - Duality Between Feature and Similarity Models, Based on the Reproducing-Kernel Hilbert Space.pdf}
}

@article{jones_jones_2016a,
  title = {When Brain Rhythms Aren't 'Rhythmic': Implication for Their Mechanisms and Meaning},
  author = {Jones, Stephanie R},
  year = {2016},
  volume = {40},
  pages = {72--80},
  doi = {10.1016/j.conb.2016.06.010},
  abstract = {Rhythms are a prominent signature of brain activity. Their expression is correlated with numerous examples of healthy information processing and their fluctuations are a marker of disease states. Yet, their causal or epiphenomenal role in brain function is still highly debated. We review recent studies showing brain rhythms are not always 'rhythmic', by which we mean representative of repeated cycles of activity. Rather, high power and continuous rhythms in averaged signals can represent brief transient events on single trials whose density accumulates in the average. We also review evidence showing time-domain signals with vastly different waveforms can exhibit identical spectral-domain frequency and power. Further, non-oscillatory waveform feature can create spurious high spectral power. Knowledge of these possibilities is essential when interpreting rhythms and is easily missed without considering pre-processed data. Lastly, we discuss how these findings suggest new directions to pursue in our quest to discover the mechanism and meaning of brain rhythms.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XJWRZZ7M\\Jones - 2016 - When brain rhythms aren't 'rhythmic' implication for their mechanisms and meaning.pdf},
  journal = {Current Opinion in Neurobiology}
}

@incollection{jones_jones_2017,
  title = {The {{Diffusion Model}} of {{Speeded Choice}}, from a {{Rational Perspective}}},
  author = {Jones, Matt},
  year = {2017},
  abstract = {This chapter considers tasks in which an experimental subject must make a binary decision, such as a perceptual discrimination or a semantic or mnemonic judgment. For some examples, a character could be presented on a monitor and the subject must decide whether it is red or green, or a letter or a number; or a string of letters is presented and the subject must decide whether it is a word or not; or a word is presented and the subject must decide whether it was part of a previously studied list or not. We are interested in both the probability that the subject will give the correct answer and the response time (RT) of whatever answer the subject gives. Our aim is to develop formal, mathematical models of this type of task that make predictions for response probability and RT. This chapter will begin by following the historical progression of models developed in the literature, from signal-detection models to random walk models to diffusion models, before presenting some new variations and results regarding the last of these. All of the models considered here are based on the idea of evidence sam-pling. The assumption is that the subject, in perceiving the stimulus, observes or calculates some sort of information that bears on the correct answer. In a color discrimination task, this information would presumably concern the wavelength of the light coming from the stimulus, originating in the subject's photoreceptors and further processed in visual cortex, for example in red-green opponent-process cells. In a recognition memory task, the information would come from comparing the stimulus to memory, perhaps retrieving an explicit memory of the item from the study phase, or perhaps generating a continuous-valued familiarity signal. For present purposes, we will not be concerned with the specific nature of this information or how it is computed. Instead, the focus will be on how the observations, once obtained, are used to generate a response in the binary decision task. Under this view, the problem facing the subject is to determine the relative support that the observed information lends to the two responses. The models considered here take a normative approach to this problem, treating it as one of statistical inference. Under this approach, each stimulus category (i.e., correct 1 response) is associated with a hypothesis. For example, hypothesis H 1 could be the that the stimulus is red (Category 1), and hypothesis H 2 could be that the stimulus is green (Category 2). The subject's goal is to use the observations to infer which hypothesis is probably correct and to select the corresponding response. More specifically, the models here take a Bayesian approach, using the likelihood of the observations under each hypothesis to determine a posterior belief in which hypothesis is correct, which in turn drives decision making.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RR4IPXEZ\\Jones - 2017 - The Diffusion Model of Speeded Choice, from a Rational Perspective.pdf}
}

@article{jones_love_2011,
  title = {Bayesian Fundamentalism or Enlightenment? {{On}} the Explanatory Status and Theoretical Contributions of {{Bayesian}} Models of Cognition.},
  author = {Jones, Matt and Love, Bradley C},
  year = {2011},
  volume = {34},
  pages = {169--188},
  issn = {0140-525X},
  doi = {10.1017/S0140525X10003134},
  abstract = {The prominence of Bayesian modeling of cognition has increased recently largely because of mathematical advances in specifying and deriving predictions from complex probabilistic models. Much of this research aims to demonstrate that cognitive behavior can be explained from rational principles alone, without recourse to psychological or neurological processes and representations. We note commonalities between this rational approach and other movements in psychology - namely, Behaviorism and evolutionary psychology - that set aside mechanistic explanations or make use of optimality assumptions. Through these comparisons, we identify a number of challenges that limit the rational program's potential contribution to psychological theory. Specifically, rational Bayesian models are significantly unconstrained, both because they are uninformed by a wide range of process-level data and because their assumptions about the environment are generally not grounded in empirical measurement. The psychological implications of most Bayesian models are also unclear. Bayesian inference itself is conceptually trivial, but strong assumptions are often embedded in the hypothesis sets and the approximation algorithms used to derive model predictions, without a clear delineation between psychological commitments and implementational details. Comparing multiple Bayesian models of the same task is rare, as is the realization that many Bayesian models recapitulate existing (mechanistic level) theories. Despite the expressive power of current Bayesian models, we argue they must be developed in conjunction with mechanistic considerations to offer substantive explanations of cognition. We lay out several means for such an integration, which take into account the representations on which Bayesian inference operates, as well as the algorithms and heuristics that carry it out. We argue this unification will better facilitate lasting contributions to psychological theory, avoiding the pitfalls that have plagued previous theoretical movements.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UYMMLFCC\\Jones, Love - 2011 - Bayesian fundamentalism or enlightenment On the explanatory status and theoretical contributions of Bayesian models.pdf},
  journal = {The Behavioral and brain sciences},
  keywords = {bayesian modeling,cognitive processing,levels of analysis,rational analysis,representation},
  number = {4},
  pmid = {21864419}
}

@article{jones_wilson_2005,
  title = {Theta {{Rhythms Coordinate Hippocampal}}\textendash{{Prefrontal Interactions}} in a {{Spatial Memory Task}}},
  author = {Jones, Matthew W and Wilson, Matthew A},
  editor = {Morris, Richard},
  year = {2005},
  month = nov,
  volume = {3},
  pages = {e402},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.0030402},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4FM28G2F\\Jones and Wilson - 2005 - Theta Rhythms Coordinate Hippocampal–Prefrontal In.pdf},
  journal = {PLoS Biology},
  language = {en},
  number = {12}
}

@article{jonikaitis_moore_2019,
  title = {The Interdependence of Attention, Working Memory and Gaze Control: Behavior and Neural Circuitry},
  shorttitle = {The Interdependence of Attention, Working Memory and Gaze Control},
  author = {Jonikaitis, Donatas and Moore, Tirin},
  year = {2019},
  month = oct,
  volume = {29},
  pages = {126--134},
  issn = {2352250X},
  doi = {10.1016/j.copsyc.2019.01.012},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VHNV658B\\Jonikaitis and Moore - 2019 - The interdependence of attention, working memory a.pdf},
  journal = {Current Opinion in Psychology},
  language = {en}
}

@article{jonker_ranganath_2018,
  title = {Neural Reactivation in Parietal Cortex Enhances Memory for Episodically Linked Information},
  author = {Jonker, Tanya R. and {Dimsdale-Zucker}, Halle and Ritchey, Maureen and Clarke, Alex and Ranganath, Charan},
  year = {2018},
  issn = {0027-8424},
  doi = {10.1073/pnas.1800006115},
  abstract = {The cytochrome P450 (CYP) enzyme system is involved in the metabolism and elimination of numerous widely used drugs. The capacity of this system varies from one person to another, leading to variable drug excretion rates and intersubject differences in the final serum drug concentrations. For this reason, therapeutic response and side-effects vary widely between patients treated with the same dose of drug. The intersubject variability in metabolic rate is largely determined by genetic factors. Some CYP enzymes, including CYP2D6 and CYP2C19, are genetically polymorphic. Several mutant alleles have been described, Environmental factors such as smoking, diet and co-administration of medications might also influence the CYP enzyme activity. By the use of genotyping or phenotyping methods every individual can be classified as either a poor, an intermediate, an extensive or an ultrarapid metabolizer. If this could be performed prior to drug therapy, the knowledge could be applied to drug selection and dose adjustment in order to reach therapeutic serum drug levels.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\J3KEJVB2\\Jonker et al. - 2018 - Neural reactivation in parietal cortex enhances memory for episodically linked information.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  pmid = {10586308}
}

@article{jordan_morrison_2019,
  title = {A {{Closed}}-{{Loop Toolchain}} for {{Neural Network Simulations}} of {{Learning Autonomous Agents}}},
  author = {Jordan, Jakob and Weidel, Philipp and Morrison, Abigail},
  year = {2019},
  month = aug,
  volume = {13},
  pages = {46},
  issn = {1662-5188},
  doi = {10.3389/fncom.2019.00046},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Z3N9T8SS\\Jordan et al. - 2019 - A Closed-Loop Toolchain for Neural Network Simulat.pdf},
  journal = {Frontiers in Computational Neuroscience},
  language = {en}
}

@inproceedings{joshi_betke_2018,
  title = {Context-{{Sensitive Prediction}} of {{Facial Expressivity Using Multimodal Hierarchical Bayesian Neural Networks}}},
  booktitle = {2018 13th {{IEEE International Conference}} on {{Automatic Face Gesture Recognition}} ({{FG}} 2018)},
  author = {Joshi, A. and Ghosh, S. and Gunnery, S. and {Tickle-Degnen}, L. and Sclaroff, S. and Betke, M.},
  year = {2018},
  month = may,
  pages = {278--285},
  doi = {10.1109/FG.2018.00048},
  abstract = {Objective automated affect analysis systems can be applied to quantify the progression of symptoms in neurodegenerative diseases such as Parkinson's Disease (PD). PD hampers the ability of patients to emote by decreasing the mobility of their facial musculature, a phenomenon known as ``facial masking.'' In this work, we focus on building a system that can predict an accurate score of active facial expressivity in people suffering from Parkinson's disease using features extracted from both video and audio. An ideal automated system should be able to mimic the ability of human experts to take into account contextual information while making these predictions. For example, patients exhibit different emotions with varying intensities when speaking about positive and negative experiences. We utilize a hierarchical Bayesian neural network framework to enable the learning of model parameters that subtly adapt to pre-defined notions of context, such as the gender of the patient or the valence of the expressed sentiment. We evaluate our formulation on a dataset of 772 20-second video clips of Parkinson's disease patients and demonstrate that training a context-specific hierarchical Bayesian framework yields an improvement in model performance in both multiclass classification and regression settings compared to baseline models trained on all data pooled together.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WV55HGXN\\Joshi et al_2018_Context-Sensitive Prediction of Facial Expressivity Using Multimodal.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\Y2UXLHDC\\8373841.html}
}

@article{ju_gaussier_2020,
  title = {A Model of Path Integration and Representation of Spatial Context in the Retrosplenial Cortex},
  author = {Ju, Mingda and Gaussier, Philippe},
  year = {2020},
  month = apr,
  volume = {114},
  pages = {303--313},
  issn = {0340-1200, 1432-0770},
  doi = {10.1007/s00422-020-00833-x},
  abstract = {Inspired by recent biological experiments, we simulate animals moving in different environments (open space, spiral mazes and on a treadmill) to test the performances of a simple model of the retrosplenial cortex (RSC) acting as a path integration (PI) and as a categorization mechanism. The connection between the hippocampus, RSC and the entorhinal cortex is revealed through a novel perspective. We suppose that the path integration is performed by the information coming from RSC. Grid cells in the entorhinal cortex then can be built as the result of a modulo projection of RSC activity. In our model, PI is performed by a 1D field of neurons acting as a simple low-pass filter of head direction (HD) cells modulated by the linear velocity of the animal. Our paper focuses on the constraints on the HD cells shape for a good approximation of PI. Recording of neurons on our 1D PI field shows these neurons would not be intuitively interpreted as performing PI. Using inputs coming from a narrow neighbouring projection of our PI field creates place cell-like activities in the RSC when the mouse runs on the treadmill. This can be the result of local self-organizing maps representing blobs of neurons in the RSC (e.g. cortical columns). Other simulations show that accessing the whole PI field would induce place cells whatever the environment is. Since this property is not observed, we conclude that the categorization neurons in the RSC should have access to only a small fraction of the PI field.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\G4JQAU3M\\Ju and Gaussier - 2020 - A model of path integration and representation of .pdf},
  journal = {Biological Cybernetics},
  language = {en},
  number = {2}
}

@article{julian_epstein_2018,
  title = {The {{Neurocognitive Basis}} of {{Spatial Reorientation}}},
  author = {Julian, Joshua B and Keinath, Alexandra T and Marchette, Steven A and Epstein, Russell A},
  year = {2018},
  volume = {28},
  pages = {R1059--R1073},
  doi = {10.1016/j.cub.2018.04.057},
  abstract = {The ability to recover one's bearings when lost is a skill that is fundamental for spatial navigation. We review the cognitive and neural mechanisms that underlie this ability, with the aim of linking together previously disparate findings from animal behavior, human psychology, electrophysiology, and cognitive neuroscience. Behavioral work suggests that reorientation involves two key abilities: first, the recovery of a spatial reference frame (a cognitive map) that is appropriate to the current environment; and second, the determination of one's heading and location relative to that reference frame. Electrophysiological recording studies, primarily in rodents, have revealed potential correlates of these operations in place, grid, border/boundary, and head-direction cells in the hippocampal formation. Cognitive neuroscience studies, primarily in humans, suggest that the perceptual inputs necessary for these operations are processed by neocortical regions such as the retrosplenial complex, occipital place area and parahippocampal place area, with the retrosplenial complex mediating spatial transformations between the local environment and the recovered spatial reference frame, the occipital place area supporting perception of local boundaries, and the parahippocampal place area processing visual information that is essential for identification of the local spatial context. By combining results across these various literatures, we converge on a unified account of reorientation that bridges the cognitive and neural domains. Introduction At some point in our lives, all of us have had the unsettling experience of losing our spatial bearings. Perhaps we had come up from a subway station onto a busy street and did not know which way we were facing. Perhaps we had taken a walk in the woods and lost track of where we were. In situations like these, unless we are aided by another person or a navigational device such as a compass or global positioning system, we must look out at the world and use perceptual information to figure out where we are and which way we are facing. In other words, we must spatially reorient ourselves. How do we accomplish this? And what are the neural systems involved? The experience of being lost underscores the fact that we are spatially oriented much of the time-but not always. This psychological distinction between orientation and disorientation implies the existence of an internal representation of large-scale navigable space that we use to keep track of our current spatial situation. Such a representation is referred to as a cognitive map. In its strongest form, a cognitive map could be a Euclidean coordinate system [1,2], although less rigid forms of spatial knowledge, such as graph-like representations [3-5], are also possible. When we are disoriented, we no longer know where we are or which way we are facing on the map, and when we are misoriented, we have plotted our map location or heading inaccurately. There are two ways that an oriented navigator can update their map coordinates as they move around the world. Path integration , sometimes called dead reckoning, involves the use of idiothetic cues, such as vestibular information, motor efference copies, proprioceptive signals, and optic flow, to actively update},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SRV8JGFD\\Julian et al. - 2018 - The Neurocognitive Basis of Spatial Reorientation.pdf},
  journal = {Current Biology}
}

@article{kachergis_hommel_2014,
  title = {A Continuous Time Neural Model for Sequential Action},
  author = {Kachergis, G and Wyatte, D and O'Reilly, Randall C and {de Kleijn}, R and Hommel, B},
  year = {2014},
  pages = {1--8},
  issn = {1471-2970},
  doi = {10.1098/rstb.2013.0623},
  abstract = {Action selection, planning and execution are continuous processes that evolve over time, responding to perceptual feedback as well as evolving top-down constraints. Existing models of routine sequential action (e.g. coffee- or pancake-making) generally fall into one of two classes: hierarchical models that include hand-built task representations, or heterarchical models that must learn to represent hierarchy via temporal context, but thus far lack goal-orientedness. We present a biologically motivated model of the latter class that, because it is situated in the Leabra neural architecture, affords an opportunity to include both unsupervised and goal-directed learning mechanisms. Moreover, we embed this neurocomputational model in the theoretical framework of the theory of event coding (TEC), which posits that actions and perceptions share a common representation with bidirectional associations between the two. Thus, in this view, not only does perception select actions (along with task context), but actions are also used to generate perceptions (i.e. intended effects). We propose a neural model that implements TEC to carry out sequential action control in hierarchically structured tasks such as coffee-making. Unlike traditional feedforward discrete-time neural network models, which use static percepts to generate static outputs, our biological model accepts continuous-time inputs and likewise generates non-stationary outputs, making short-timescale dynamic predictions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\66YGAQND\\Kachergis et al. - 2014 - A continuous time neural model for sequential action.pdf},
  journal = {Submitted to Philosophical Transactions of the Royal Society B},
  keywords = {behaviour,cognition},
  number = {January 2016},
  pmid = {25267830}
}

@article{kadmon_ganguli_2020,
  title = {Predictive Coding in Balanced Neural Networks with Noise, Chaos and Delays},
  author = {Kadmon, Jonathan and Timcheck, Jonathan and Ganguli, Surya},
  year = {2020},
  month = jun,
  abstract = {Biological neural networks face a formidable task: performing reliable computations in the face of intrinsic stochasticity in individual neurons, imprecisely specified synaptic connectivity, and nonnegligible delays in synaptic transmission. A common approach to combatting such biological heterogeneity involves averaging over large redundant networks of \$N\$ neurons resulting in coding errors that decrease classically as \$1/\textbackslash sqrt\{N\}\$. Recent work demonstrated a novel mechanism whereby recurrent spiking networks could efficiently encode dynamic stimuli, achieving a superclassical scaling in which coding errors decrease as \$1/N\$. This specific mechanism involved two key ideas: predictive coding, and a tight balance, or cancellation between strong feedforward inputs and strong recurrent feedback. However, the theoretical principles governing the efficacy of balanced predictive coding and its robustness to noise, synaptic weight heterogeneity and communication delays remain poorly understood. To discover such principles, we introduce an analytically tractable model of balanced predictive coding, in which the degree of balance and the degree of weight disorder can be dissociated unlike in previous balanced network models, and we develop a mean field theory of coding accuracy. Overall, our work provides and solves a general theoretical framework for dissecting the differential contributions neural noise, synaptic disorder, chaos, synaptic delays, and balance to the fidelity of predictive neural codes, reveals the fundamental role that balance plays in achieving superclassical scaling, and unifies previously disparate models in theoretical neuroscience.},
  archivePrefix = {arXiv},
  eprint = {2006.14178},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VY3J4ECB\\kadmon_ganguli_2020.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\GVSMJEBJ\\2006.html},
  journal = {arXiv:2006.14178 [cond-mat, q-bio, stat]},
  keywords = {Condensed Matter - Disordered Systems and Neural Networks,Quantitative Biology - Neurons and Cognition,Statistics - Machine Learning},
  primaryClass = {cond-mat, q-bio, stat}
}

@article{kadmon_ganguli_2020a,
  title = {Predictive Coding in Balanced Neural Networks with Noise, Chaos and Delays},
  author = {Kadmon, Jonathan and Timcheck, Jonathan and Ganguli, Surya},
  year = {2020},
  month = jun,
  abstract = {Biological neural networks face a formidable task: performing reliable computations in the face of intrinsic stochasticity in individual neurons, imprecisely specified synaptic connectivity, and nonnegligible delays in synaptic transmission. A common approach to combatting such biological heterogeneity involves averaging over large redundant networks of \$N\$ neurons resulting in coding errors that decrease classically as \$1/\textbackslash sqrt\{N\}\$. Recent work demonstrated a novel mechanism whereby recurrent spiking networks could efficiently encode dynamic stimuli, achieving a superclassical scaling in which coding errors decrease as \$1/N\$. This specific mechanism involved two key ideas: predictive coding, and a tight balance, or cancellation between strong feedforward inputs and strong recurrent feedback. However, the theoretical principles governing the efficacy of balanced predictive coding and its robustness to noise, synaptic weight heterogeneity and communication delays remain poorly understood. To discover such principles, we introduce an analytically tractable model of balanced predictive coding, in which the degree of balance and the degree of weight disorder can be dissociated unlike in previous balanced network models, and we develop a mean field theory of coding accuracy. Overall, our work provides and solves a general theoretical framework for dissecting the differential contributions neural noise, synaptic disorder, chaos, synaptic delays, and balance to the fidelity of predictive neural codes, reveals the fundamental role that balance plays in achieving superclassical scaling, and unifies previously disparate models in theoretical neuroscience.},
  archivePrefix = {arXiv},
  eprint = {2006.14178},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AJND8RDJ\\kadmon_ganguli_2020a.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\BTVNFRPU\\2006.html},
  journal = {arXiv:2006.14178 [cond-mat, q-bio, stat]},
  keywords = {Condensed Matter - Disordered Systems and Neural Networks,Quantitative Biology - Neurons and Cognition,Statistics - Machine Learning},
  primaryClass = {cond-mat, q-bio, stat}
}

@article{kaji_eliasmith_2018,
  title = {Evaluating the Psychological Plausibility of Word2vec and {{GloVe}} Distributional Semantic Models},
  author = {Kaji, Ivana and Eliasmith, Chris},
  year = {2018},
  doi = {10.13140/RG.2.2.25289.60004},
  abstract = {The representation of semantic knowledge poses a central modelling decision in many models of cognitive phenomena. However, not all such representations reflect properties ob-served in human semantic networks. Here, we evaluate the psychological plausibility of two distributional semantic mod-els widely used in natural language processing: word2vec and GloVe. We use these models to construct directed and undi-rected semantic networks and compare them to networks of hu-man association norms using a set of graph-theoretic analyses. Our results show that all such networks display small-world characteristics, while only undirected networks show similar degree distributions to those in the human semantic network. Directed networks also exhibit a hierarchical organization that is reminiscent of the human semantic network.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\W2G29BCC\\Kaji, Eliasmith - 2018 - Evaluating the psychological plausibility of word2vec and GloVe distributional semantic models.pdf},
  keywords = {distributional semantic models,free association norms,network analysis,semantic spaces},
  number = {August}
}

@article{kajikawa_schroeder_2011,
  title = {How Local Is the Local Field Potential?},
  author = {Kajikawa, Y and Schroeder, C E},
  year = {2011},
  volume = {72},
  pages = {847--858},
  doi = {10.1016/j.neuron.2011.09.029.How},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TNTU4NRV\\Kajikawa, Schroeder - 2011 - How local is the local field potential.pdf},
  journal = {Neuron},
  number = {5}
}

@article{kalfas_vogels_2018,
  title = {Representations of Regular and Irregular Shapes by Deep {{Convolutional Neural Networks}}, Monkey Inferotemporal Neurons and Human Judgments},
  author = {Kalfas, Ioannis ID and Vinken, Kasper ID and Vogels, Rufin ID},
  year = {2018},
  doi = {10.1371/journal.pcbi.1006557},
  abstract = {Recent studies suggest that deep Convolutional Neural Network (CNN) models show higher representational similarity, compared to any other existing object recognition models, with macaque inferior temporal (IT) cortical responses, human ventral stream fMRI activations and human object recognition. These studies employed natural images of objects. A long research tradition employed abstract shapes to probe the selectivity of IT neurons. If CNN models provide a realistic model of IT responses, then they should capture the IT selectivity for such shapes. Here, we compare the activations of CNN units to a stimulus set of 2D regular and irregular shapes with the response selectivity of macaque IT neurons and with human similarity judgements. The shape set consisted of regular shapes that differed in nonaccidental properties, and irregular, asymmetrical shapes with curved or straight boundaries. We found that deep CNNs (Alexnet, VGG-16 and VGG-19) that were trained to classify natural images show response modulations to these shapes that were similar to those of IT neurons. Untrained CNNs with the same architecture than trained CNNs, but with random weights, demonstrated a poorer similarity than CNNs trained in classification. The difference between the trained and untrained CNNs emerged at the deep convolutional layers, where the similarity between the shape-related response modulations of IT neurons and the trained CNNs was high. Unlike IT neurons, human similarity judgements of the same shapes correlated best with the last layers of the trained CNNs. In particular, these deepest layers showed an enhanced sensitivity for straight versus curved irregular shapes, similar to that shown in human shape judgments. In conclusion, the representations of abstract shape similarity are highly comparable between macaque IT neurons and deep convolutional layers of CNNs that were trained to classify natural images, while human shape similarity judgments correlate better with the deepest layers. PLOS Computational Biology | https://doi.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AWDPKEJD\\Kalfas, Vinken, Vogels - 2018 - Representations of regular and irregular shapes by deep Convolutional Neural Networks, monkey inferotemp.pdf}
}

@article{kaminski_wrobel_2012,
  title = {Beta Band Oscillations Engagement in Human Alertness Process},
  author = {Kami{\'n}ski, Jan and Brzezicka, Aneta and Gola, Mateusz and Wr{\'o}bel, Andrzej},
  year = {2012},
  month = jul,
  volume = {85},
  pages = {125--128},
  issn = {01678760},
  doi = {10.1016/j.ijpsycho.2011.11.006},
  abstract = {We previously showed that neuronal activity in beta frequency might serve as a carrier for attentional arousal within the visual system of cat. In the present study, we adopted the animal paradigm for anticipatory attention to study alertness-related changes of beta activity in human subjects. The results indicated that increased alertness, manifested by faster responses to target visual stimuli, is accompanied by higher EEG activation in beta band.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TWVNQG5Q\\Kamiński et al. - 2012 - Beta band oscillations engagement in human alertne.pdf},
  journal = {International Journal of Psychophysiology},
  language = {en},
  number = {1}
}

@article{kampa_stuart_2006,
  title = {Cortical Feed-Forward Networks for Binding Different Streams of Sensory Information},
  author = {Kampa, Bj{\"o}rn M and Letzkus, Johannes J and Stuart, Greg J},
  year = {2006},
  volume = {9},
  pages = {1472--1473},
  issn = {10976256},
  doi = {10.1038/nn1798},
  abstract = {Different streams of sensory information are transmitted to the cortex where they are merged into a percept in a process often termed `binding.' Using recordings from triplets of rat cortical layer 2/3 and layer 5 pyramidal neurons, we show that specific subnetworks within layer 5 receive input from different layer 2/3 subnetworks. This cortical microarchitecture may represent a mechanism that enables the main output of the cortex (layer 5) to bind different features of a sensory stimulus.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IVAEF3ZB\\Kampa, Letzkus, Stuart - Unknown - Cortical feed-forward networks for binding different streams of sensory information.pdf},
  journal = {Nature Neuroscience},
  number = {12},
  pmid = {17099707}
}

@article{kang_kocsis_2015,
  title = {Theta-Rhythmic Drive between Medial Septum and Hippocampus in Slow Wave Sleep and Microarousal: {{A Granger}} Causality Analysis},
  author = {Kang, Daesung and Ding, Mingzhou and Topchiy, Irina and Shifflett, Lauren and Kocsis, Bernat},
  year = {2015},
  pages = {jn.00542.2015},
  issn = {0022-3077},
  doi = {10.1152/jn.00542.2015},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\F7PQ58DP\\Kang et al. - 2015 - Theta-rhythmic drive between medial septum and hippocampus in slow wave sleep and microarousal A Granger causality.pdf},
  journal = {Journal of Neurophysiology}
}

@article{kang_pearce_2010,
  title = {{{NIH Public Access}}},
  author = {Kang, Ping and Liao, Mingxiang and Wester, Michael R and Leeder, J Steven and Pearce, Robin E},
  year = {2010},
  volume = {36},
  pages = {490--499},
  issn = {1946-6242},
  doi = {10.1124/dmd.107.016501.CYP3A4-Mediated},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5X58QMHH\\Kang et al. - 2010 - NIH Public Access.pdf},
  journal = {Ratio},
  keywords = {entorhinal cortex,existence of multiple memory,fmri,for the temporary storage,including working,memory,research has demonstrated the,scopolamine,sustained activity,systems},
  number = {3},
  pmid = {20371490}
}

@article{karayanidis_forstmann_2010,
  title = {Advance Preparation in Task-Switching: {{Converging}} Evidence from Behavioral, Brain Activation, and Model-Based Approaches},
  author = {Karayanidis, Frini and Jamadar, Sharna and Ruge, Hannes and Phillips, Natalie and Heathcote, Andrew and Forstmann, Birte U.},
  year = {2010},
  volume = {1},
  pages = {1--13},
  issn = {16641078},
  doi = {10.3389/fpsyg.2010.00025},
  abstract = {Recent research has taken advantage of the temporal and spatial resolution of event-related brain potentials (ERPs) and functional magnetic resonance imaging (fMRI) to identify the time course and neural circuitry of preparatory processes required to switch between different tasks. Here we overview some key findings contributing to understanding strategic processes in advance preparation. Findings from these methodologies are compatible with advance preparation conceptualized as a set of processes activated for both switch and repeat trials, but with substantial variability as a function of individual differences and task requirements. We then highlight new approaches that attempt to capitalize on this variability to link behavior and brain activation patterns. One approach examines correlations among behavioral, ERP and fMRI measures. A second "model-based" approach accounts for differences in preparatory processes by estimating quantitative model parameters that reflect latent psychological processes. We argue that integration of behavioral and neuroscientific methodologies is key to understanding the complex nature of advance preparation in task-switching.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\URHXSEC9\\Karayanidis et al. - 2010 - Advance preparation in task-switching Converging evidence from behavioral, brain activation, and model-based.pdf},
  journal = {Frontiers in Psychology},
  keywords = {Erp,Evidence accumulation models,Fmri,Task-switching},
  number = {JUL},
  pmid = {21833196}
}

@article{kasabov_kasabov_2019,
  title = {Spiking Neural Networks for Deep Learning and Knowledge Representation: {{Editorial}}},
  shorttitle = {Spiking Neural Networks for Deep Learning and Knowledge Representation},
  author = {Kasabov, Nikola K.},
  year = {2019},
  month = nov,
  volume = {119},
  pages = {341--342},
  issn = {08936080},
  doi = {10.1016/j.neunet.2019.08.019},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\K3QBPH2U\\Kasabov - 2019 - Spiking neural networks for deep learning and know.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\YBGKESDY\\Kasabov - 2019 - Spiking neural networks for deep learning and know.pdf},
  journal = {Neural Networks},
  language = {en}
}

@book{kass_brown_2014,
  title = {Springer {{Series}} in {{Statistics Analysis}} of {{Neural Data}}},
  author = {Kass, Robert E and Eden, Uri T and Brown, Emery N},
  year = {2014},
  doi = {10.1007/978-1-4614-9602-1},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\X6ERGN9Z\\Kass, Eden, Brown - Unknown - Springer Series in Statistics Analysis of Neural Data.pdf},
  isbn = {978-1-4614-9601-4}
}

@article{kaufmann_westlye_2018,
  title = {Genetics of Brain Age Suggest an Overlap with Common Brain Disorders},
  author = {Kaufmann, Tobias and {van der Meer}, Dennis and Doan, Nhat Trung and Schwarz, Emanuel and Lund, Martina J. and Agartz, Ingrid and {Aln{\textbackslash}a es}, Dag and Barch, Deanna M and {Baur-Streubel}, Ramona and Bertolino, Alessandro and Bettella, Francesco and Beyer, Mona K and B{\o}en, Erlend and Borgwardt, Stefan and Brandt, Christine L and Buitelaar, Jan and Celius, Elisabeth G. and Cervenka, Simon and Conzelmann, Annette and {C{\'o}rdova-Palomera}, Aldo and Dale, Anders M. and {de Quervain}, Dominique J.-F. and Carlo, Pasquale Di and Djurovic, Srdjan and D{\o}rum, Erlend S. and Eisenacher, Sarah and Elvsashagen, Torbj{\o}rn and Espeseth, Thomas and {Fatouros-Bergman}, Helena and Flyckt, Lena and Franke, Barbara and Frei, Oleksandr and Haatveit, Beathe and Haberg, Asta K. and Harbo, Hanne F. and Hartman, Catharina A. and Heslenfeld, Dirk and Hoekstra, Pieter J. and H{\o}gest{\o}l, Einar A. and Jernigan, Terry and Jonassen, Rune and J{\"o}nsson, Erik G. and (KASP), Karolinska Schizophrenia Project and Kirsch, Peter and Kloszewska, Iwona and Kolskar, Knut-Kristian and Landr{\o}, Nils Inge and Hellard, Stephanie Le and Lesch, Klaus-Peter and Lovestone, Simon and Lundervold, Arvid and Lundervold, Astri J. and Maglanoc, Luigi A. and Malt, Ulrik F. and Mecocci, Patrizia and Melle, Ingrid and {Meyer-Lindenberg}, Andreas and Moberget, Torgeir and Norbom, Linn B. and Nordvik, Jan Egil and Nyberg, Lars and Oosterlaan, Jaap and Papalino, Marco and Papassotiropoulos, Andreas and Pauli, Paul and Pergola, Giulio and Persson, Karin and Richard, Genevi{\`e}ve and Rokicki, Jaroslav and Sanders, Anne-Marthe and {Selb{\textbackslash}a ek}, Geir and Shadrin, Alexey A. and Smeland, Olav B. and Soininen, Hilkka and Sowa, Piotr and Steen, Vidar M. and Tsolaki, Magda and Ulrichsen, Kristine M. and Vellas, Bruno and Wang, Lei and Westman, Eric and Ziegler, Georg C. and Zink, Mathias and Andreassen, Ole A. and Westlye, Lars T.},
  year = {2018},
  volume = {17},
  pages = {303164},
  doi = {10.1101/303164},
  abstract = {Numerous genetic and environmental factors contribute to psychiatric disorders and other brain disorders. Common risk factors likely converge on biological pathways regulating the optimization of brain structure and function across the lifespan. Here, using structural magnetic resonance imaging and machine learning, we estimated the gap between brain age and chronological age in 36,891 individuals aged 3 to 96 years, including individuals with different brain disorders. We show that several disorders are associated with accentuated brain aging, with strongest effects in schizophrenia, multiple sclerosis and dementia, and document differential regional patterns of brain age gaps between disorders. In 16,269 healthy adult individuals, we show that brain age gap is heritable with a polygenic architecture overlapping those observed in common brain disorders. Our results identify brain age gap as a genetically modulated trait that offers a window into shared and distinct mechanisms in different brain disorders.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RSI7AI4W\\Kaufmann et al. - Unknown - Genetics of Brain Age Suggest Overlap with Common Brain Disorders.pdf},
  journal = {bioRxiv}
}

@article{kay_frank_2020,
  title = {Constant {{Sub}}-Second {{Cycling}} between {{Representations}} of {{Possible Futures}} in the {{Hippocampus}}},
  author = {Kay, Kenneth and Chung, Jason E. and Sosa, Marielena and Schor, Jonathan S. and Karlsson, Mattias P. and Larkin, Margaret C. and Liu, Daniel F. and Frank, Loren M.},
  year = {2020},
  month = feb,
  volume = {180},
  pages = {552-567.e25},
  issn = {00928674},
  doi = {10.1016/j.cell.2020.01.014},
  abstract = {Cognitive faculties such as imagination, planning, and decision-making entail the ability to represent hypothetical experience. Crucially, animal behavior in natural settings implies that the brain can represent hypothetical future experience not only quickly but also constantly over time, as external events continually unfold. To determine how this is possible, we recorded neural activity in the hippocampus of rats navigating a maze with multiple spatial paths. We found neural activity encoding two possible future scenarios (two upcoming maze paths) in constant alternation at 8 Hz: one scenario per \$125-ms cycle. Further, we found that the underlying dynamics of cycling (both inter- and intra-cycle dynamics) generalized across qualitatively different representational correlates (location and direction). Notably, cycling occurred across moving behaviors, including during running. These findings identify a general dynamic process capable of quickly and continually representing hypothetical experience, including that of multiple possible futures.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\76Z6VMDN\\Kay et al. - 2020 - Constant Sub-second Cycling between Representation.pdf},
  journal = {Cell},
  language = {en},
  number = {3}
}

@article{keane_gong_2015,
  title = {Propagating {{Waves Can Explain Irregular Neural Dynamics}}},
  author = {Keane, Adam and Gong, Pulin},
  year = {2015},
  volume = {35},
  pages = {1591--1605},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.1669-14.2015},
  abstract = {Cortical neurons in vivo fire quite irregularly. Previous studies about the origin of such irregular neural dynamics have given rise to two major models: a balanced excitation and inhibition model, and a model of highly synchronized synaptic inputs. To elucidate the network mechanisms underlying synchronized synaptic inputs and account for irregular neural dynamics, we investigate a spatially extended, conductance-based spiking neural network model. We show that propagating wave patterns with complex dynamics emerge from the network model. These waves sweep past neurons, to which they provide highly synchronized synaptic inputs. On the other hand, these patterns only emerge from the network with balanced excitation and inhibition; our model therefore reconciles the two major models of irregular neural dynamics. We further demonstrate that the collective dynamics of propagating wave patterns provides a mechanistic explanation for a range of irregular neural dynamics, including the variability of spike timing, slow firing rate fluctuations, and correlated membrane potential fluctuations. In addition, in our model, the distributions of synaptic conductance and membrane potential are non-Gaussian, consistent with recent experimental data obtained using whole-cell recordings. Our work therefore relates the propagating waves that have been widely observed in the brain to irregular neural dynamics. These results demonstrate that neural firing activity, although appearing highly disordered at the single-neuron level, can form dynamical coherent structures, such as propagating waves at the population level.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WAZ5A9N5\\Keane, Gong - 2015 - Propagating Waves Can Explain Irregular Neural Dynamics.pdf},
  journal = {Journal of Neuroscience},
  keywords = {balanced excitation and inhibition,cerebral cortex,computer simulation,cross-correlation,propagating waves,synchrony},
  number = {4},
  pmid = {25632135}
}

@article{keele_yee_1988,
  title = {Tests of a {{Temporal Theory}} of {{Attentional Binding}}},
  author = {Keele, Steven W. and Cohen, Asher and Ivry, Richard and Liotti, Mario and Yee, Penny},
  year = {1988},
  volume = {14},
  pages = {444--452},
  issn = {00961523},
  doi = {10.1037/0096-1523.14.3.444},
  abstract = {Different features of stimuli present in the field of view appear to be registered in different cortical maps. How, then, are the features that come from the same object bound together rather than mistakenly assembled with features coming from other simultaneously present objects? One theory supposes that an attentional mechanism intercepts input coming from particular retinal locations at a way station prior to parsing of the features from the same object. Any enhancement (or facilitation) at that stage will cause all the features from that object to be modified simultaneously in the downstream registers. The imposed temporal synchronicity serves as the essential binding cue. Five experiments provided no support for the theory. There is no tendency for synchronicity of features to cause binding unless the features come from the same location. Location, rather than temporal synchronicity, appears to be the essential cue for binding.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\B4DCTFMF\\Keele et al. - 1988 - Tests of a Temporal Theory of Attentional Binding.pdf},
  journal = {Journal of Experimental Psychology: Human Perception and Performance},
  number = {3},
  pmid = {2971772}
}

@article{keeler_robbins_2014,
  title = {Functional Implications of Dopamine {{D1}} vs. {{D2}} Receptors: {{A}} 'prepare and Select' Model of the Striatal Direct vs. Indirect Pathways},
  author = {Keeler, J F and Pretsell, D O and Robbins, T W},
  year = {2014},
  volume = {282},
  pages = {156--175},
  issn = {18737544},
  doi = {10.1016/j.neuroscience.2014.07.021},
  abstract = {The functions of the D1- and D2-dopamine receptors in the basal ganglia have remained somewhat enigmatic, with a number of competing theories relating to the interactions of the 'direct' and 'indirect pathways'. Computational models have been good at simulating properties of the system, but are typically divorced from the underlying neural architecture. In this article we propose a new model which re-addresses response selection at the level of the basal ganglia. At the core of this response selection system the D1 DA receptor-expressing striatal pathways 'prepare' the set of possible appropriate responses. The D2DR-expressing striatal pathways then shape and 'select' from this initial response set framework.This article is part of a Special Issue entitled: Ventral Tegmentum \{\&\} Dopamine. ?? 2014 .},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\I5QL6HEB\\Keeler, Pretsell, Robbins - 2014 - Functional implications of dopamine D1 vs. D2 receptors A 'prepare and select' model of the striatal.pdf},
  journal = {Neuroscience},
  keywords = {Basal ganglia,D1 receptor,D2 receptor,Direct and indirect pathways,Dopamine,Striatum},
  pmid = {25062777}
}

@article{keinath_brandon_2020,
  title = {{{DG}}\textendash{{CA3}} Circuitry Mediates Hippocampal Representations of Latent Information},
  author = {Keinath, Alexandra T. and {Nieto-Posadas}, Andr{\'e}s and Robinson, Jennifer C. and Brandon, Mark P.},
  year = {2020},
  month = jun,
  volume = {11},
  pages = {1--9},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-16825-1},
  abstract = {Survival in complex environments necessitates a flexible navigation system that incorporates memory of recent behavior and associations. Yet, how the hippocampal spatial circuit represents latent information independent of sensory inputs and future goals has not been determined. To address this, we image the activity of large ensembles in subregion CA1 via wide-field fluorescent microscopy during a novel behavioral paradigm. Our results demonstrate that latent information is represented through reliable firing rate changes during unconstrained navigation. We then hypothesize that the representation of latent information in CA1 is mediated by pattern separation/completion processes instantiated upstream within the dentate gyrus (DG) and CA3 subregions. Indeed, CA3 ensemble recordings reveal an analogous code for latent information. Moreover, selective chemogenetic inactivation of DG\textendash CA3 circuitry completely and reversibly abolishes the CA1 representation of latent information. These results reveal a causal and specific role of DG\textendash CA3 circuitry in the maintenance of latent information within the hippocampus. Keinath et al. show that information about the recent past is represented in the hippocampus through changes in firing rates in the absence of task demands. This representation is eliminated when DG\textendash CA3 circuitry is inhibited.},
  copyright = {2020 The Author(s)},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FF32MZ4G\\keinath_brandon_2020.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\E958VFJF\\s41467-020-16825-1.html},
  journal = {Nature Communications},
  language = {en},
  number = {1}
}

@article{keller_mrsic-flogel_2018,
  title = {Perspective {{Predictive Processing}}: {{A Canonical Cortical Computation}}},
  author = {Keller, Georg B and {Mrsic-Flogel}, Thomas D},
  year = {2018},
  doi = {10.1016/j.neuron.2018.10.003},
  abstract = {This perspective describes predictive processing as a computational framework for understanding cortical function in the context of emerging evidence, with a focus on sensory processing. We discuss how the pre-dictive processing framework may be implemented at the level of cortical circuits and how its implementation could be falsified experimentally. Lastly, we summarize the general implications of predictive processing on cortical function in healthy and diseased states.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FGNSI3N5\\Keller, Mrsic-Flogel - 2018 - Perspective Predictive Processing A Canonical Cortical Computation.pdf}
}

@article{keller_scanziani_2020,
  title = {Feedback Generates a Second Receptive Field in Neurons of the Visual Cortex},
  author = {Keller, Andreas J. and Roth, Morgane M. and Scanziani, Massimo},
  year = {2020},
  month = may,
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/s41586-020-2319-4},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\A89WG8TU\\Keller et al. - 2020 - Feedback generates a second receptive field in neu.pdf},
  journal = {Nature},
  language = {en}
}

@article{kemere_frank_2013,
  title = {Rapid and Continuous Modulation of Hippocampal Network State during Exploration of New Places.},
  author = {Kemere, Caleb and Carr, Margaret F and Karlsson, Mattias P and Frank, Loren M},
  year = {2013},
  volume = {8},
  pages = {e73114},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0073114},
  abstract = {Hippocampal information processing is often described as two-state, with a place cell state during movement and a reactivation state during stillness. Relatively little is known about how the network transitions between these different patterns of activity during exploration. Here we show that hippocampal network changes quickly and continuously as animals explore and become familiar with initially novel places. We measured the relationship between moment-by-moment changes in behavior and information flow through hippocampal output area CA1 in rats. We examined local field potential (LFP) patterns, evoked potentials and ensemble spiking and found evidence suggestive of a smooth transition from strong CA3 drive of CA1 activity at low speeds to entorhinal cortical drive of CA1 activity at higher speeds. These changes occurred with changes in behavior on a timescale of less than a second, suggesting a continuous modulation of information processing in the hippocampal circuit as a function of behavioral state.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UDN9JVZS\\Kemere et al. - 2013 - Rapid and continuous modulation of hippocampal network state during exploration of new places.pdf},
  journal = {PloS one},
  keywords = {Animal,Animal: physiology,Animals,Behavior,Brain Waves,Brain Waves: physiology,CA1 Region,CA3 Region,Evoked Potentials,Evoked Potentials: physiology,Exploratory Behavior,Exploratory Behavior: physiology,Hippocampal,Hippocampal: cytology,Hippocampal: physiology,Learning,Learning: physiology,Male,Nerve Net,Nerve Net: cytology,Nerve Net: physiology,Neurons,Neurons: cytology,Rats,Time Factors},
  number = {9},
  pmid = {24023818}
}

@article{kempter_vanhemmen_1999,
  title = {Hebbian Learning and Spiking Neurons},
  author = {Kempter, Richard and Gerstner, Wulfram and {van Hemmen}, J},
  year = {1999},
  month = apr,
  volume = {59},
  pages = {4498--4514},
  issn = {1063-651X},
  doi = {10.1103/PhysRevE.59.4498},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VSDV43ZH\\Kempter, Gerstner, van Hemmen - 1999 - Hebbian learning and spiking neurons.pdf},
  journal = {Physical Review E},
  number = {4}
}

@article{kennerley_wallis_2011,
  title = {Double Dissociation of Value Computations in Orbitofrontal and Anterior Cingulate Neurons},
  author = {Kennerley, Steven W and J Behrens, Timothy E and Wallis, Jonathan D},
  year = {2011},
  volume = {14},
  doi = {10.1038/nn.2961},
  abstract = {Prefrontal cortex (PFC) supports optimal and rational decision-making. Damage to areas such as orbitofrontal cortex (OFC), ante-rior cingulate cortex (ACC) and lateral prefrontal cortex (LPFC) is associated with severe decision-making impairments 1\textendash 8 , impairments not typically found with damage outside PFC. This implies that PFC neurons must support value computations that are essential for decision-making. However, although anatomical subdivisions within the PFC appear specialized in their function when examined with circumscribed lesions 2,4,5 or functional magnetic resonance imag-ing 9\textendash 12 , such regional dissociations have rarely been described in the underlying neuronal activity. Similar determinants of an outcome's subjective value can be found in the firing rates of neurons in ACC, OFC and LPFC 13\textendash 26 . Although there is a technical reason for this apparent discrepancy\textemdash{} very few studies have simultaneously recorded single neurons from multiple PFC areas to identify regional specialization\textemdash there is also a more fundamental difficulty in uncovering such regional dissociations: the firing rates of PFC neurons show substantial heterogeneity even within a PFC subregion 27 . This heterogeneity is evident in two forms. First, neurons recorded millimeters (or less) from each other may encode different features of the decision process 28 : neurons encode different parameters that influence the value of the choice (for exam-ple, reward size or type; delay, risk, effort associated with obtaining reward) 13,15,17,22\textendash 24 , or neuronal activity may be modulated by differ-ent trial events (for example, choice, movement, outcome) 15,25 . Second, and potentially more problematic, neurons that encode the same value parameter often do so with opponent encoding schemes: while one neuron may increase firing rate as a function of value, its neighbor may increase firing rate as value decreases 15,17,19,21,23\textendash 25,29\textendash 31 . This feature of PFC neurons is in stark contrast to activity measured, for example, in dopamine neurons, which encode reward and reward prediction error at predictable times, using a unified coding scheme 32\textendash 34 . Such heterogeneity of prefrontal coding makes it particularly important to examine the activity of single neurons but has rendered it difficult to dissociate regional patterns of PFC neuronal firing according to qualitative, rather than simply quantitative, differences. To address this issue, we simultaneously recorded the activity of single neurons in ACC, LPFC and OFC while monkeys (Macaca mulatta) made choices that varied in both the cost and benefit of a decision. We report two clear functional dissociations between PFC areas. First, a subpopulation of ACC neurons showed two unique features that distinguish these neurons from other value coding neurons: (i) at choice, these ACC neurons encoded all decision variables using a unified coding scheme of positive valence, and (ii) these same neu-rons also encoded reward prediction errors. Such activity was absent in OFC and LPFC. Second, we show that neurons in OFC, but not ACC, encode the value of current choices relative to the recent his-tory of choice values. RESULTS We trained two subjects to choose between pairs of pictures associated with different probabilities or sizes of reward, or different physical effort (cost) to obtain reward (Fig. 1) 15,25 . In each trial the two stimuli varied along only one decision variable; hence, there was always a correct choice. Trials from each decision variable were intermixed and randomly selected. Behavioral analyses revealed 15 that both subjects performed at a high level, choosing the more valuable out-come on 98\% of the trials. We report neuronal activity from 257, 140 and 213 neurons located in LPFC, OFC and ACC, respectively (see Online Methods and Supplementary Fig. 1 for recording locations).},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RJWIKA8J\\Kennerley, J Behrens, Wallis - 2011 - Double dissociation of value computations in orbitofrontal and anterior cingulate neurons.pdf},
  journal = {Nature Neuroscience},
  number = {12}
}

@article{keren_schuller_2017,
  title = {Convolutional {{RNN}}: An {{Enhanced Model}} for {{Extracting Features}} from {{Sequential Data}}},
  shorttitle = {Convolutional {{RNN}}},
  author = {Keren, Gil and Schuller, Bj{\"o}rn},
  year = {2017},
  month = jul,
  abstract = {Traditional convolutional layers extract features from patches of data by applying a non-linearity on an affine function of the input. We propose a model that enhances this feature extraction process for the case of sequential data, by feeding patches of the data into a recurrent neural network and using the outputs or hidden states of the recurrent units to compute the extracted features. By doing so, we exploit the fact that a window containing a few frames of the sequential data is a sequence itself and this additional structure might encapsulate valuable information. In addition, we allow for more steps of computation in the feature extraction process, which is potentially beneficial as an affine function followed by a non-linearity can result in too simple features. Using our convolutional recurrent layers we obtain an improvement in performance in two audio classification tasks, compared to traditional convolutional layers. Tensorflow code for the convolutional recurrent layers is publicly available in https://github.com/cruvadom/Convolutional-RNN.},
  archivePrefix = {arXiv},
  eprint = {1602.05875},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KBWC6THL\\Keren and Schuller - 2017 - Convolutional RNN an Enhanced Model for Extractin.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\4SYM7EEI\\1602.html},
  journal = {arXiv:1602.05875 [cs, stat]},
  primaryClass = {cs, stat}
}

@article{ketz_curran_2014,
  title = {Classification Aided Analysis of Oscillatory Signatures in Controlled Retrieval},
  author = {a Ketz, Nicholas and O'Reilly, Randall C and Curran, Tim},
  year = {2014},
  volume = {85},
  pages = {749--760},
  issn = {10959572},
  doi = {10.1016/j.neuroimage.2013.06.077},
  abstract = {Control processes are critical for both facilitating and suppressing memory retrieval, but these processes are not well understood. The current work, inspired by a similar fMRI design (Detre et al., in press), used a modified Think/No-Think(TNT) paradigm to investigate the neural signatures of volition over enhancing and suppressing memory retrieval. Previous studies have shown memory enhancement when well-learned stimulus pairs are restudied in cued recall ("Recall or think of studied pair item"), and degradation when restudied with cued suppression ("Avoid thinking of studied pair item"). We used category-based (faces vs. scenes) multivariate classification of electroencephalography signals to determine if individual target items were successfully retrieved or suppressed. A logistic regression based on classifier output determined that retrieval activation during the cued recall/suppression period was a predictor for subsequent memory. Labeling trials with this internal measure, as opposed to their nominal Think vs. No-Think condition, revealed the classic TNT pattern of enhanced memory for successful cued-retrieval and degraded memory for cued-suppression. This classification process enabled a more selective investigation into the time-frequency signatures of control over retrieval. Comparing controlled retrieval vs. controlled suppression, results showed more prominent Theta oscillations (3 to 8. Hz) in controlled retrieval. Beta oscillations (12 to 30. Hz) were involved in high levels of both controlled retrieval and suppression, suggesting it may have a more general control-related role. These results suggest unique roles for these frequency bands in retrieval processes. \textcopyright{} 2013 Elsevier Inc.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WIITVTR3\\Ketz, O'Reilly, Curran - 2014 - Classification aided analysis of oscillatory signatures in controlled retrieval.pdf},
  journal = {NeuroImage},
  keywords = {Beta,Classification,Control,eeg,Memory,Oscillations},
  pmid = {23845425}
}

@article{ketz_oreilly_2013,
  title = {Theta {{Coordinated Error}}-{{Driven Learning}} in the {{Hippocampus}}},
  author = {a Ketz, Nicholas and Morkonda, Srinimisha G. and O'Reilly, Randall C},
  year = {2013},
  volume = {9},
  pages = {e1003067},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1003067},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DBT76VA9\\Ketz, Morkonda, O'Reilly - 2013 - Theta Coordinated Error-Driven Learning in the Hippocampus(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\PKKYI365\\Ketz, Morkonda, O'Reilly - 2013 - Theta Coordinated Error-Driven Learning in the Hippocampus.pdf},
  journal = {PLoS Computational Biology},
  number = {6}
}

@article{ketz_oreilly_2015,
  title = {Thalamic Pathways Underlying Prefrontal Cortex-Medial Temporal Lobe Oscillatory Interactions},
  author = {Ketz, Nicholas A and Jensen, Ole and O'reilly, Randall C},
  year = {2015},
  volume = {38},
  doi = {10.1016/j.tins.2014.09.007},
  abstract = {As focus shifts to large-scale network interactions involved in memory, it is becoming increasingly clear that oscillatory dynamics are critically involved. A number of studies have shown a negative correlation between memory retrieval in alpha and beta power, and a positive correlation between retrieval and theta power. In this opinion article, we suggest three thalamic sub-regions responsible for the coordination of oscillatory activity and the facilitation of memory processes. Specifically, the medial dorsal nucleus is related to changes in beta synchrony, the pulvinar is responsible for alpha synchro-ny, and the anterior thalamus is related to theta synchro-ny. These pathways may be modulated via frontal control, and changes in oscillations could be used to track the engagement of underlying memory systems. Memory and thalamo-cortical networks Although everyone acknowledges that memory encoding and retrieval are not isolated functions of any one brain area [1,2], there are many challenges in moving beyond the traditional studies focusing on individual regions (e.g., concentrating on the prominent role of the hippocampus) to obtain insight into the nature of network-level dynamics. Fortunately, recent studies increasingly support the idea that oscillatory dynamics in multiple brain regions are associated with different aspects of memory encoding and retrieval [3-5], thus providing an important tool for further investigating these network-level dynamics (see Glossary). These studies have generally found a consistent relationship between several frequency bands and successful encoding or retrieval of experiences: namely, that oscillato-ry power within the alpha (8-12 Hz) and beta (13-30 Hz) frequency bands generally decrease with these memory processes, while theta (3-8 Hz) and gamma (30-100+ Hz) bands increase in the regions directly involved in the memory operations. The critical next step is to understand why these relationships exist, and what they tell us about the larger functional organization of memory systems in the brain. The central hypothesis advanced here is that different nuclei in the thalamus play a critical role in coordinating processing across different brain areas, and that these different thalamic circuits have characteristic oscillatory dynamics [6-10]. First order thalamic nuclei serve as a relay for sensory information into the neocortex, while higher order thalamic regions might serve a modulatory role in sensory processing. These nuclei receive extensive feedback projections from cortex-forming thalamo-cortical circuits. In this article, we show how a range of data on neural oscillations correlating with task performance can be explained in terms of the unique functional contributions of three different thalamically-defined circuits, with corresponding oscillatory signatures (in the alpha, beta, and theta bands). Furthermore, these thalamic networks provide different channels by which task-driven top-down control signals from the prefrontal cortex (PFC) can potentially shape memory processes [11-14]. Based on our previous work in this domain [15-17], two memory systems have informed our Three Circuit Model (Figure 1). The straightforward mapping of our theory based on lesion studies, neuroimaging, and thalamic con-nectivity would suggest that familiarity-based processing in the extra-hippocampal medial temporal lobe (MTL) Opinion Glossary Cross-frequency coupling: modulations of characteristics (e.g., power, phase) of oscillations in one frequency range that vary as a function of another frequency. For example spectral power in the gamma range is often seen to correlate with the phase of slow oscillations. Frequency bands: groupings of neural oscillations witnessed in EEG, MEG, or local field potentials. These bands, both clinically and functionally defined, show correlations between behavior and changes in oscillatory power within a given frequency band. A common definition of these bands are: delta-1-4 Hz, theta-4-8 Hz, alpha-8-12 Hz, beta-12-30 Hz, and gamma 30-100+ Hz. Neural oscillation: rhythmic synaptic activity of neuronal ensembles that is generated by intrinsic neural mechanisms of excitation and inhibition. Oscillations discussed in the current text are often originating from the influence of pacemaker like brain regions which have an architecture able to support these dynamics, and are measured in intracranial local field potentials and surface EEG/MEG. Power: is the square of the amplitude (i.e., deviation from zero) of the activity in a given frequency band. In the Fourier transform of a time varying signal, power in a given frequency range reflects the overall contribution of those oscillations to the total signal averaged over time. Synchronization: Quantified using various metrics (e.g., coherence, phase lag index, etc.), is generally used here as a measure derived from the Fourier transform of a given pair of time varying signals, which mainly reflects the frequency-dependent consistency of the phase angle between those signals. In short, power can provide a coarse measure of magnitude and temporal consistency of neuronal firing within a given region, while synchronization considers the interaction of two or more regions [72]. 0166-2236/},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2JUXT3YG\\Ketz, Jensen, O'Reilly - 2015 - Thalamic pathways underlying prefrontal cortex-medial temporal lobe oscillatory interactions.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\FKMFE4U8\\Ketz, Jensen, O'reilly - 2015 - Thalamic pathways underlying prefrontal cortex-medial temporal lobe oscillatory interactions.pdf},
  journal = {Trends in Neurosciences},
  number = {1}
}

@article{khaligh-razavi_kriegeskorte_2017,
  title = {Fixed versus Mixed {{RSA}}:??{{Explaining}} Visual Representations by Fixed and Mixed Feature Sets from Shallow and Deep Computational Models},
  author = {{Khaligh-Razavi}, Seyed Mahdi and Henriksson, Linda and Kay, Kendrick and Kriegeskorte, Nikolaus},
  year = {2017},
  volume = {76},
  pages = {184--197},
  issn = {10960880},
  doi = {10.1016/j.jmp.2016.10.007},
  abstract = {Studies of the primate visual system have begun to test a wide range of complex computational object-vision models. Realistic models have many parameters, which in practice cannot be fitted using the limited amounts of brain-activity data typically available. Task performance optimization (e.g. using backpropagation to train neural networks) provides major constraints for fitting parameters and discovering nonlinear representational features appropriate for the task (e.g. object classification). Model representations can be compared to brain representations in terms of the representational dissimilarities they predict for an image set. This method, called representational similarity analysis (RSA), enables us to test the representational feature space as is (fixed RSA) or to fit a linear transformation that mixes the nonlinear model features so as to best explain a cortical area's representational space (mixed RSA). Like voxel/population-receptive-field modelling, mixed RSA uses a training set (different stimuli) to fit one weight per model feature and response channel (voxels here), so as to best predict the response profile across images for each response channel. We analysed response patterns elicited by natural images, which were measured with functional magnetic resonance imaging (fMRI). We found that early visual areas were best accounted for by shallow models, such as a Gabor wavelet pyramid (GWP). The GWP model performed similarly with and without mixing, suggesting that the original features already approximated the representational space, obviating the need for mixing. However, a higher ventral-stream visual representation (lateral occipital region) was best explained by the higher layers of a deep convolutional network and mixing of its feature set was essential for this model to explain the representation. We suspect that mixing was essential because the convolutional network had been trained to discriminate a set of 1000 categories, whose frequencies in the training set did not match their frequencies in natural experience or their behavioural importance. The latter factors might determine the representational prominence of semantic dimensions in higher-level ventral-stream areas. Our results demonstrate the benefits of testing both the specific representational hypothesis expressed by a model's original feature space and the hypothesis space generated by linear transformations of that feature space.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PW547ULB\\Khaligh-Razavi et al. - 2017 - Fixed versus mixed RSAExplaining visual representations by fixed and mixed feature sets from shallow and.pdf},
  journal = {Journal of Mathematical Psychology},
  keywords = {Deep convolutional networks,Mixed RSA,Object-vision models,Representational similarity analysis}
}

@article{khan_hofer_2018,
  title = {Contextual Signals in Visual Cortex},
  author = {Khan, Adil G. and Hofer, Sonja B.},
  year = {2018},
  volume = {52},
  pages = {131--138},
  issn = {18736882},
  doi = {10.1016/j.conb.2018.05.003},
  abstract = {Vision is an active process. What we perceive strongly depends on our actions, intentions and expectations. During visual processing, these internal signals therefore need to be integrated with the visual information from the retina. The mechanisms of how this is achieved by the visual system are still poorly understood. Advances in recording and manipulating neuronal activity in specific cell types and axonal projections together with tools for circuit tracing are beginning to shed light on the neuronal circuit mechanisms of how internal, contextual signals shape sensory representations. Here we review recent work, primarily in mice, that has advanced our understanding of these processes, focusing on contextual signals related to locomotion, behavioural relevance and predictions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JEAR9S2B\\Khan, Hofer - 2018 - Contextual signals in visual cortex.pdf},
  journal = {Current Opinion in Neurobiology},
  pmid = {29883940}
}

@article{kheradpisheh_masquelier_2018,
  title = {{{STDP}}-Based Spiking Deep Convolutional Neural Networks for Object Recognition},
  author = {Kheradpisheh, Saeed Reza and Ganjtabesh, Mohammad and Thorpe, Simon J. and Masquelier, Timoth{\'e}e},
  year = {2018},
  volume = {99},
  pages = {56--67},
  issn = {18792782},
  doi = {10.1016/j.neunet.2017.12.005},
  abstract = {Previous studies have shown that spike-timing-dependent plasticity (STDP) can be used in spiking neural networks (SNN) to extract visual features of low or intermediate complexity in an unsupervised manner. These studies, however, used relatively shallow architectures, and only one layer was trainable. Another line of research has demonstrated \textendash{} using rate-based neural networks trained with back-propagation \textendash{} that having many layers increases the recognition robustness, an approach known as deep learning. We thus designed a deep SNN, comprising several convolutional (trainable with STDP) and pooling layers. We used a temporal coding scheme where the most strongly activated neurons fire first, and less activated neurons fire later or not at all. The network was exposed to natural images. Thanks to STDP, neurons progressively learned features corresponding to prototypical patterns that were both salient and frequent. Only a few tens of examples per category were required and no label was needed. After learning, the complexity of the extracted features increased along the hierarchy, from edge detectors in the first layer to object prototypes in the last layer. Coding was very sparse, with only a few thousands spikes per image, and in some cases the object category could be reasonably well inferred from the activity of a single higher-order neuron. More generally, the activity of a few hundreds of such neurons contained robust category information, as demonstrated using a classifier on Caltech 101, ETH-80, and MNIST databases. We also demonstrate the superiority of STDP over other unsupervised techniques such as random crops (HMAX) or auto-encoders. Taken together, our results suggest that the combination of STDP with latency coding may be a key to understanding the way that the primate visual system learns, its remarkable processing speed and its low energy consumption. These mechanisms are also interesting for artificial vision systems, particularly for hardware solutions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4AQPHDZM\\Kheradpisheh et al. - 2018 - STDP-based spiking deep convolutional neural networks for object recognition.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\IJS4BYY7\\Kheradpisheh et al. - 2018 - STDP-based spiking deep convolutional neural netwo.pdf},
  journal = {Neural Networks},
  keywords = {Deep learning,Object recognition,Spiking neural network,STDP,Temporal coding},
  pmid = {29328958}
}

@article{khodagholy_buzsaki_2014,
  title = {{{NeuroGrid}} : Recording Action Potentials from the Surface of the Brain},
  author = {Khodagholy, Dion and Gelinas, Jennifer N and Thesen, Thomas and Doyle, Werner and Devinsky, Orrin and Malliaras, George G and Buzs{\'a}ki, Gy{\"o}rgy},
  year = {2014},
  volume = {18},
  pages = {310--316},
  doi = {10.1038/nn.3905},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QNTTYGSZ\\Khodagholy et al. - 2014 - NeuroGrid recording action potentials from the surface of the brain.pdf},
  journal = {Nature neuroscience},
  number = {2}
}

@article{kiebel_friston_2009,
  title = {Dynamic Causal Modeling for {{EEG}} and {{MEG}}},
  author = {Kiebel, Stefan J. and Garrido, Marta I. and Moran, Rosalyn and Chen, Chun-Chuan and Friston, Karl J.},
  year = {2009},
  month = jun,
  volume = {30},
  pages = {1866--1876},
  issn = {10659471},
  doi = {10.1002/hbm.20775},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CMZ7ZCCM\\Kiebel et al. - 2009 - Dynamic causal modeling for EEG and MEG.pdf},
  journal = {Human Brain Mapping},
  keywords = {Bayesian analysis,eeg,MEG,network model},
  number = {6}
}

@article{kiebel_holmes_2006,
  title = {The {{General Linear Model}}},
  author = {Kiebel, S J and Holmes, A P},
  year = {2006},
  pages = {101--125},
  doi = {10.1016/B978-0-12-372560-8.50008-5},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LWA83QUU\\Kiebel, Holmes - 2006 - The General Linear Model.pdf},
  journal = {STATISTICAL PARAMETRIC MAPPING: The Analysis of Functional Brain Images}
}

@article{kilgard_merzenich_1998,
  title = {Cortical Map Reorganization Enabled by Nucleus Basalis Activity.},
  author = {Kilgard, M P and Merzenich, M M},
  year = {1998},
  month = mar,
  volume = {279},
  pages = {1714--1718},
  issn = {0036-8075},
  abstract = {Little is known about the mechanisms that allow the cortex to selectively improve the neural representations of behaviorally important stimuli while ignoring irrelevant stimuli. Diffuse neuromodulatory systems may facilitate cortical plasticity by acting as teachers to mark important stimuli. This study demonstrates that episodic electrical stimulation of the nucleus basalis, paired with an auditory stimulus, results in a massive progressive reorganization of the primary auditory cortex in the adult rat. Receptive field sizes can be narrowed, broadened, or left unaltered depending on specific parameters of the acoustic stimulus paired with nucleus basalis activation. This differential plasticity parallels the receptive field remodeling that results from different types of behavioral training. This result suggests that input characteristics may be able to drive appropriate alterations of receptive fields independently of explicit knowledge of the task. These findings also suggest that the basal forebrain plays an active instructional role in representational plasticity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GGFWNYUF\\Kilgard, Merzenich - 1998 - Cortical map reorganization enabled by nucleus basalis activity.pdf},
  journal = {Science (New York, N.Y.)},
  keywords = {Animals,Auditory Cortex,Auditory Cortex: physiology,Basal Ganglia,Basal Ganglia: physiology,Brain Mapping,Conditioning (Psychology),Electric Stimulation,Neuronal Plasticity,Neurons,Neurons: physiology,Prosencephalon,Prosencephalon: physiology,Rats},
  number = {5357},
  pmid = {9497289}
}

@article{killian_buffalo_2018,
  title = {Grid Cells Map the Visual World},
  author = {Killian, Nathaniel J. and Buffalo, Elizabeth A.},
  year = {2018},
  issn = {1097-6256},
  doi = {10.1038/s41593-017-0062-4},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DGZM5FS3\\Killian, Buffalo - 2018 - Grid cells map the visual world.pdf},
  journal = {Nature Neuroscience}
}

@article{kim_brown_2011,
  title = {A {{Granger}} Causality Measure for Point Process Models of Ensemble Neural Spiking Activity},
  author = {Kim, Sanggyun and Putrino, David and Ghosh, Soumya and Brown, Emery N},
  year = {2011},
  volume = {7},
  issn = {1553734X},
  doi = {10.1371/journal.pcbi.1001110},
  abstract = {The ability to identify directional interactions that occur among multiple neurons in the brain is crucial to an understanding of how groups of neurons cooperate in order to generate specific brain functions. However, an optimal method of assessing these interactions has not been established. Granger causality has proven to be an effective method for the analysis of the directional interactions between multiple sets of continuous-valued data, but cannot be applied to neural spike train recordings due to their discrete nature. This paper proposes a point process framework that enables Granger causality to be applied to point process data such as neural spike trains. The proposed framework uses the point process likelihood function to relate a neuron's spiking probability to possible covariates, such as its own spiking history and the concurrent activity of simultaneously recorded neurons. Granger causality is assessed based on the relative reduction of the point process likelihood of one neuron obtained excluding one of its covariates compared to the likelihood obtained using all of its covariates. The method was tested on simulated data, and then applied to neural activity recorded from the primary motor cortex (MI) of a Felis catus subject. The interactions present in the simulated data were predicted with a high degree of accuracy, and when applied to the real neural data, the proposed method identified causal relationships between many of the recorded neurons. This paper proposes a novel method that successfully applies Granger causality to point process data, and has the potential to provide unique physiological insights when applied to neural spike trains.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PWHEUEJV\\Kim et al. - 2011 - A Granger causality measure for point process models of ensemble neural spiking activity.pdf},
  journal = {PLoS Computational Biology},
  number = {3},
  pmid = {21455283}
}

@article{kim_chow_2018,
  title = {Learning Recurrent Dynamics in Spiking Networks},
  author = {Kim, Christopher M and Chow, Carson C},
  year = {2018},
  volume = {7e37124},
  pages = {28},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UH77C22X\\Kim and Chow - Learning recurrent dynamics in spiking networks.pdf},
  journal = {eLife},
  language = {en}
}

@article{kim_gilley_2013,
  title = {Neural {{Mechanisms}} of {{Rapid Sensitivity}} to {{Syntactic Anomaly}}},
  author = {Kim, Albert E and Gilley, Phillip M},
  year = {2013},
  volume = {4},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2013.00045},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DYMC4GTV\\Kim, Gilley - 2013 - Neural mechanisms of rapid sensitivity to syntactic anomaly.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\UKIVP2GK\\Kim, Gilley - 2013 - Neural Mechanisms of Rapid Sensitivity to Syntactic Anomaly.pdf},
  journal = {Frontiers in Psychology},
  keywords = {Anticipatory,N170,Occipital temporal cortex,P1,Posterior cingulate,Prediction,Sentence comprehension,Syntactic},
  number = {January 2016}
}

@article{kim_osterhout_2005,
  title = {The Independence of Combinatory Semantic Processing: {{Evidence}} from Event-Related Potentials},
  author = {Kim, Albert and Osterhout, Lee},
  year = {2005},
  volume = {52},
  pages = {205--225},
  issn = {0749596X},
  doi = {10.1016/j.jml.2004.10.002},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\K9AB98MI\\Kim, Osterhout - 2005 - The independence of combinatory semantic processing Evidence from event-related potentials(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\LK8WU26N\\Kim, Osterhout - 2005 - The independence of combinatory semantic processing Evidence from event-related potentials.pdf},
  journal = {Journal of Memory and Language},
  keywords = {clauses,combina-,erps,ERPs,into larger representational units,language comprehension involves combining,n400,N400,p600,P600,psycholinguistic investigation of such,semantics,Semantics,sentence processing,Sentence processing,such as phrases and,syntax,Syntax,thematic roles,Thematic roles},
  number = {2}
}

@article{kim_russek_2012,
  title = {Brain-Derived Neurotrophic Factor Uses {{CREB}} and {{Egr3}} to Regulate {{NMDA}} Receptor Levels in Cortical Neurons.},
  author = {Kim, Julia H and Roberts, Daniel S and Hu, Yinghui and Lau, Garrick C and {Brooks-Kayal}, Amy R and Farb, David H and Russek, Shelley J},
  year = {2012},
  month = jan,
  volume = {120},
  pages = {210--219},
  issn = {1471-4159},
  doi = {10.1111/j.1471-4159.2011.07555.x},
  abstract = {Regulation of gene expression via brain-derived neurotrophic factor (BDNF) is critical to the development of the nervous system and may well underlie cognitive performance throughout life. We now describe a mechanism by which BDNF can exert its effects on postsynaptic receptor populations that may have relevance to both the normal and diseased brain where BDNF levels either rise or fall in association with changes in excitatory neurotransmission. Increased levels of NMDA receptors (NMDARs) occur in rat cortical neurons via synthesis of new NMDA receptor 1 (NR1) subunits. The majority of synthesis is controlled by binding of cAMP response element binding protein (CREB) and early growth response factor 3 (Egr3) to the core NR1 promoter (NR1-p) region. BDNF-mediated NR1 transcription depends upon induction of the mitogen-activated protein kinase (MAPK) pathway through activation of the TrK-B receptor. Taken together with the fact that NMDAR activation stimulates BDNF synthesis, our results uncover a feed-forward gene regulatory network that may enhance excitatory neurotransmission to change neuronal behavior over time.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GBWW6G8S\\Kim et al. - 2012 - Brain-derived neurotrophic factor uses CREB and Egr3 to regulate NMDA receptor levels in cortical neurons.pdf},
  journal = {Journal of neurochemistry},
  keywords = {Animals,Brain-Derived Neurotrophic Factor,Brain-Derived Neurotrophic Factor: pharmacology,Cells,Cerebral Cortex,Cerebral Cortex: cytology,Chromatin Immunoprecipitation,CREB-Binding Protein,CREB-Binding Protein: metabolism,Cultured,Electrophoretic Mobility Shift Assay,Embryo,Enzyme Inhibitors,Enzyme Inhibitors: pharmacology,Ether-A-Go-Go Potassium Channels,Ether-A-Go-Go Potassium Channels: genetics,Ether-A-Go-Go Potassium Channels: metabolism,Gene Expression Regulation,Gene Expression Regulation: drug effects,Gene Expression Regulation: physiology,Humans,Luminescent Proteins,Luminescent Proteins: genetics,Mammalian,MAP Kinase Kinase Kinases,MAP Kinase Kinase Kinases: metabolism,Neurons,Neurons: drug effects,Neurons: metabolism,nmda,Phosphorylation,Phosphorylation: drug effects,Protein Binding,Protein Binding: drug effects,Rats,Receptor,Receptors,Serine,Serine: metabolism,Signal Transduction,Signal Transduction: drug effects,Tetradecanoylphorbol Acetate,Tetradecanoylphorbol Acetate: pharmacology,Transfection,trkB,trkB: metabolism},
  number = {2},
  pmid = {22035109}
}

@techreport{kim_sejnowski_2020,
  title = {Strong Inhibitory Signaling Underlies Stable Temporal Dynamics and Working Memory in Spiking Neural Networks},
  author = {Kim, Robert and Sejnowski, Terrence J.},
  year = {2020},
  month = feb,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.02.11.944751},
  abstract = {Cortical neurons process information on multiple timescales, and areas important for working memory (WM) contain neurons capable of integrating information over a long timescale. However, the underlying mechanisms for the emergence of neuronal timescales stable enough to support WM are unclear. By analyzing a spiking recurrent neural network (RNN) model trained on a WM task and activity of single neurons in the primate prefrontal cortex, we show that the temporal properties of our model and the neural data are remarkably similar. Dissecting our RNN model revealed strong inhibitory-to-inhibitory connections underlying a disinhibitory microcircuit as a critical component for long neuronal timescales and WM maintenance. We also found that enhancing inhibitory-to-inhibitory connections led to more stable temporal dynamics and improved task performance. Finally, we show that a network with such microcircuitry can perform other tasks without disrupting its pre-existing timescale architecture, suggesting that strong inhibitory signaling underlies a flexible WM network.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UQPZ4VMF\\Kim and Sejnowski - 2020 - Strong inhibitory signaling underlies stable tempo.pdf},
  language = {en},
  type = {Preprint}
}

@article{kingma_dhariwal_2018,
  title = {Glow: {{Generative Flow}} with {{Invertible}} 1x1 {{Convolutions}}},
  author = {Kingma, Diederik P and Dhariwal, Prafulla},
  year = {2018},
  abstract = {Flow-based generative models (Dinh et al., 2014) are conceptually attractive due to tractability of the exact log-likelihood, tractability of exact latent-variable inference, and parallelizability of both training and synthesis. In this paper we propose Glow, a simple type of generative flow using an invertible 1x1 convolution. Using our method we demonstrate a significant improvement in log-likelihood on standard benchmarks. Perhaps most strikingly, we demonstrate that a generative model optimized towards the plain log-likelihood objective is capable of efficient realistic-looking synthesis and manipulation of large images. The code for our model is available at https://github.com/openai/glow},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QW347LD9\\Kingma, Dhariwal, Francisco - Unknown - Glow Generative Flow with Invertible 1×1 Convolutions.pdf},
  journal = {arXiv}
}

@article{kingma_welling_2019,
  title = {An {{Introduction}} to {{Variational Autoencoders}}},
  author = {Kingma, Diederik P. and Welling, Max},
  year = {2019},
  volume = {12},
  pages = {307--392},
  issn = {1935-8237, 1935-8245},
  doi = {10.1561/2200000056},
  abstract = {Variational autoencoders provide a principled framework for learning deep latent-variable models and corresponding inference models. In this work, we provide an introduction to variational autoencoders and some important extensions.},
  archivePrefix = {arXiv},
  eprint = {1906.02691},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\V8UIAZAT\\Kingma and Welling - 2019 - An Introduction to Variational Autoencoders.pdf},
  journal = {Foundations and Trends\textregistered{} in Machine Learning},
  language = {en},
  number = {4}
}

@article{kinsky_correspondence_2018,
  title = {Hippocampal {{Place Fields Maintain}} a {{Coherent}} and {{Flexible Map}} across {{Long Timescales}}},
  author = {Kinsky, Nathaniel R and Sullivan, David W and Mau, William and Hasselmo, Michael E and Correspondence, Howard B Eichenbaum},
  year = {2018},
  doi = {10.1016/j.cub.2018.09.037},
  abstract = {Highlights d Mice use a stable place-field configuration, or coherent map, over long timescales d Mice employed coherent maps within the same arena and between different arenas d Random reorganization-global remapping-also occurred but was infrequent d Coherent map rotations between sessions could underlie instability},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\72LYBH57\\Kinsky et al. - 2018 - Hippocampal Place Fields Maintain a Coherent and Flexible Map across Long Timescales.pdf},
  keywords = {calcium imaging,hippocampus,memory,miniscope,place cells,remapping,stability}
}

@article{kirkpatrick_hadsell_2016,
  title = {Overcoming Catastrophic Forgetting in Neural Networks},
  author = {Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and {Grabska-Barwinska}, Agnieszka and Hassabis, Demis and Clopath, Claudia and Kumaran, Dharshan and Hadsell, Raia},
  year = {2016},
  volume = {114},
  issn = {0027-8424},
  doi = {10.1073/PNAS.1611835114},
  abstract = {The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Neural networks are not, in general, capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks which they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on the MNIST hand written digit dataset and by learning several Atari 2600 games sequentially.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\U8F3U4RN\\Kirkpatrick et al. - 2016 - Overcoming catastrophic forgetting in neural networks.pdf},
  journal = {arXiv preprint},
  number = {13},
  pmid = {28292907}
}

@article{kitanishi_hikida_2017,
  title = {Network Mechanisms of Hippocampal Laterality, Place Coding, and Goal-Directed Navigation},
  author = {Kitanishi, Takuma and Ito, Hiroshi T. and Hayashi, Yuichiro and Shinohara, Yoshiaki and Mizuseki, Kenji and Hikida, Takatoshi},
  year = {2017},
  month = mar,
  volume = {67},
  pages = {247--258},
  issn = {1880-6546, 1880-6562},
  doi = {10.1007/s12576-016-0502-z},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PBUUDM3L\\Kitanishi et al. - 2017 - Network mechanisms of hippocampal laterality, plac.pdf},
  journal = {The Journal of Physiological Sciences},
  language = {en},
  number = {2}
}

@article{klambauer_hochreiter_2017,
  title = {Self-{{Normalizing Neural Networks}}},
  author = {Klambauer, G{\"u}nter and Unterthiner, Thomas and Mayr, Andreas and Hochreiter, Sepp},
  year = {2017},
  issn = {10495258},
  doi = {1706.02515},
  abstract = {Deep Learning has revolutionized vision via convolutional neural networks (CNNs) and natural language processing via recurrent neural networks (RNNs). However, success stories of Deep Learning with standard feed-forward neural networks (FNNs) are rare. FNNs that perform well are typically shallow and, therefore cannot exploit many levels of abstract representations. We introduce self-normalizing neural networks (SNNs) to enable high-level abstract representations. While batch normalization requires explicit normalization, neuron activations of SNNs automatically converge towards zero mean and unit variance. The activation function of SNNs are "scaled exponential linear units" (SELUs), which induce self-normalizing properties. Using the Banach fixed-point theorem, we prove that activations close to zero mean and unit variance that are propagated through many network layers will converge towards zero mean and unit variance \textendash{} even under the presence of noise and perturbations. This convergence property of SNNs allows to (1) train deep networks with many layers, (2) employ strong regularization, and (3) to make learning highly robust. Furthermore, for activations not close to unit variance, we prove an upper and lower bound on the variance, thus, vanishing and exploding gradients are impossible. We compared SNNs on (a) 121 tasks from the UCI machine learning repository, on (b) drug discovery benchmarks, and on (c) astronomy tasks with standard FNNs and other machine learning methods such as random forests and support vector machines. SNNs significantly outperformed all competing FNN methods at 121 UCI tasks, outperformed all competing methods at the Tox21 dataset, and set a new record at an astronomy data set. The winning SNN architectures are often very deep. Implementations are available at: github.com/bioinf-jku/SNNs.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\97PND8L2\\Klambauer et al. - Unknown - Self-Normalizing Neural Networks.pdf}
}

@article{klaus_costa_2017,
  title = {The {{Spatiotemporal Organization}} of the {{Striatum Encodes Action Space}}.},
  author = {Klaus, A and Artins, GJ and Paixao, VB and Zhou, P and Paninski, L and Costa, Rui M.},
  year = {2017},
  volume = {95},
  pages = {1171--1180},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2017.08.015},
  abstract = {Activity in striatal direct- and indirect-pathway spiny projection neurons (SPNs) is critical for proper movement. However, little is known about the spatiotemporal organization of this activity. We investigated the spatiotemporal organization of SPN ensemble activity in mice during self-paced, natural movements using microendoscopic imaging. Activity in both pathways showed predominantly local but also some long-range correlations. Using a novel approach to cluster and quantify behaviors based on continuous accelerometer and video data, we found that SPN ensembles active during specific actions were spatially closer and more correlated overall. Furthermore, similarity between different actions corresponded to the similarity between SPN ensemble patterns, irrespective of movement speed. Consistently, the accuracy of decoding behavior from SPN ensemble patterns was directly related to the dissimilarity between behavioral clusters. These results identify a predominantly local, but not spatially compact, organization of direct- and indirect-pathway SPN activity that maps action space independently of movement speed.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KXPWFNGU\\Klaus et al. - 2017 - The Spatiotemporal Organization of the Striatum Encodes Action Space.pdf},
  journal = {Neuron.},
  number = {5},
  pmid = {28858619}
}

@article{klavir_yizhar_2017,
  title = {Manipulating Fear Associations via Optogenetic Modulation of Amygdala Inputs to Prefrontal Cortex},
  author = {Klavir, Oded and Prigge, Matthias and Sarel, Ayelet and Paz, Rony and Yizhar, Ofer},
  year = {2017},
  volume = {20},
  issn = {1097-6256},
  doi = {10.1038/nn.4523},
  abstract = {Fear-related disorders are thought to reflect strong and persistent fear memories. The basolateral amygdala (BLA) and the medial prefrontal cortex (mPFC) form strong reciprocal synaptic connections that play a key role in acquisition and extinction of fear memories. While synaptic contacts of BLA cells onto mPFC neurons are likely to play a crucial role in this process, the BLA connects with several additional nuclei within the fear circuit that could relay fear-associated information to the mPFC, and the contribution of direct monosynaptic BLA\textendash mPFC inputs is not yet clear. Here we establish an optogenetic stimulation protocol that induces synaptic depression in BLA\textendash mPFC synapses. In behaving mice, optogenetic high-frequency stimulation of BLA inputs to mPFC interfered with retention of cued associations, attenuated previously acquired cue-associated responses in mPFC neurons and facilitated extinction. Our findings demonstrate the contribution of BLA inputs to mPFC in forming and maintaining cued fear associations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MH6UHF4A\\Klavir et al. - 2017 - Manipulating fear associations via optogenetic modulation of amygdala inputs to prefrontal cortex.pdf},
  journal = {Nature Neuroscience},
  number = {6},
  pmid = {28288126}
}

@article{kleiner_niehorster_2007,
  title = {What's New in {{Psychtoolbox}}-3?},
  author = {Kleiner, Mario and Brainard, David H and Pelli, Denis G and Broussard, Christopher and Wolf, Tobias and Niehorster, Diederick},
  year = {2007},
  volume = {36},
  pages = {S14},
  issn = {0301-0066},
  doi = {10.1068/v070821},
  abstract = {Psychophysics Toolbox version 3 is a collaboratively developed free set of MATLAB (and GNU/ Octave) functions for vision research. It is available for Apple Mac OS X, Microsoft Windows, and GNU/Linux. It makes it easy to synthesize and show accurately controlled visual stimuli and interact with the observer in a general-purpose programming environment. It has about two thousand active users, an active forum (about 4 messages/day), and is highly cited (more than 400 papers) (see http://psychtoolbox.org). Psychtoolbox-3, although maintaining a large degree of backward compatibility with its predecessor Psychtoolbox-2, implements a new drawing model based on OpenGL, a new high-precision sound output system, and many other improvements. This presentation introduces the new OpenGL concepts and how to take advantage of the new stimulus presentation model. New features simplify development of code for stimulus presenta- tion and response collection. Many of the new features are demonstrated during the presentation and there are opportunities for questions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZL3LCMMH\\Kleiner et al. - 2007 - What's new in Psychtoolbox-3.pdf},
  journal = {Perception},
  pmid = {12345678}
}

@techreport{kleinman_kao_2019,
  title = {Recurrent Neural Network Models of Multi-Area Computation Underlying Decision-Making},
  author = {Kleinman, Michael and Chandrasekaran, Chandramouli and Kao, Jonathan C.},
  year = {2019},
  month = oct,
  institution = {{Neuroscience}},
  doi = {10.1101/798553},
  abstract = {Cognition emerges from the coordination of computations in multiple brain areas. However, elucidating these coordinated computations within and across brain regions is challenging because intra- and inter-areal connectivity are typically unknown. Testable hypotheses about these interactions are also generally unavailable. To study coordinated computation, we trained multi-area recurrent neural networks (RNNs) to discriminate the dominant color of a checkerboard and output decision variables reflecting a direction decision, a task previously used to investigate decision-related dynamics in dorsal premotor cortex (PMd) of monkeys. We found that multi-area RNNs, as opposed to single RNNs, reproduced the decision-related dynamics observed in PMd during this task. The RNN solved this task by a novel mechanism in which RNN dynamics integrated color information on an axis subsequently readout by an orthogonal direction axis. Direction information was selectively propagated through preferential alignment with the inter-areal connections, while the color information was filtered. These results suggest that cortex uses modular computation to generate minimal but sufficient representations of task information, selectively filtering unnecessary information between areas. Finally, we leverage multi-area RNNs to produce experimentally testable hypotheses for computations that occur within and across multiple brain areas, enabling new insights into distributed computation in neural systems.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YLV2PU7C\\Kleinman et al. - 2019 - Recurrent neural network models of multi-area comp.pdf},
  language = {en},
  type = {Preprint}
}

@article{klimesch_klimesch_2012,
  title = {Alpha-Band Oscillations, Attention, and Controlled Access to Stored Information},
  author = {Klimesch, Wolfgang},
  year = {2012},
  volume = {16},
  pages = {606--617},
  issn = {13646613},
  doi = {10.1016/j.tics.2012.10.007},
  abstract = {Alpha-band oscillations are the dominant oscillations in the human brain and recent evidence suggests that they have an inhibitory function. Nonetheless, there is little doubt that alpha-band oscillations also play an active role in information processing. In this article, I suggest that alpha-band oscillations have two roles (inhibition and timing) that are closely linked to two fundamental functions of attention (suppression and selection), which enable controlled knowledge access and semantic orientation (the ability to be consciously oriented in time, space, and context). As such, alpha-band oscillations reflect one of the most basic cognitive processes and can also be shown to play a key role in the coalescence of brain activity in different frequencies. ?? 2012 Elsevier Ltd.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\T8IS78XG\\Klimesch - 2012 - Alpha-band oscillations, attention, and controlled access to stored information.pdf},
  journal = {Trends in Cognitive Sciences},
  number = {12},
  pmid = {23141428}
}

@article{klink_alonso_1997,
  title = {Muscarinic Modulation of the Oscillatory and Repetitive Firing Properties of Entorhinal Cortex Layer {{II}} Neurons.},
  author = {Klink, R and Alonso, a},
  year = {1997},
  volume = {77},
  pages = {1813--1828},
  issn = {0022-3077},
  abstract = {Neurons in layer II of the entorhinal cortex (EC) are key elements in the temporal lobe memory system because they integrate and transfer into the hippocampal formation convergent sensory input from the entire cortical mantle. EC layer II also receives a profuse cholinergic innervation from the basal forebrain that promotes oscillatory dynamics in the EC network and may also implement memory function. To understand the cellular basis of cholinergic actions in EC, we investigated by intracellular recording in an in vitro rat brain slice preparation the muscarinic modulation of the electroresponsive properties of the two distinct classes of medial EC layer II projection neurons, the stellate cells (SCs) and non-SCs. In both SCs and non-SCs, muscarinic receptor activation with carbachol (CCh, 10-50 microM) caused atropine-sensitive (300 nM) membrane depolarization. In SCs, the CCh-induced membrane depolarization was associated with subthreshold membrane potential oscillations and "spike cluster" discharge, which are typically expressed by these cells on depolarization. CCh, however, caused a decrease of the dominant frequency of the membrane potential oscillations from 9.2 +/- 1.1 (SD) Hz to 6.3 +/- 1.1 Hz, as well as a decrease of the intracluster firing frequency from 18.1 +/- 1.7 Hz to 13.6 +/- 1.3 Hz. In addition, spike cluster discharge was less robust, and the cells tended to shift into tonic firing during CCh. In contrast to SCs, in non-SCs, CCh drastically affected firing behavior by promoting the development of voltage-dependent, long-duration (1-5 s) slow bursts of action potentials that could repeat rhythmically at slow frequencies (0.2-0.5 Hz). Concomitantly, the slow afterhyperpolarization (sAHP) was replaced by long-lasting plateau postdepolarizations. In both SCs and non-SCs, CCh also produced conspicuous changes on the action potential waveform and its afterpotentials. Notably, CCh significantly decreased spike amplitude and rate of rise, which suggests muscarinic modulation of a voltage-dependent Na+ conductance. Finally, we also observed that whereas CCh abolished the sAHP in both SCs and non-SCs, the membrane-permeant analogues of adenosine 3',5'-cyclic monophosphate, 8-(4-chlorophenylthio)-adenosine-cyclic monophosphate and 8-bromo-adenosine-cyclic-monophosphate, abolished the sAHP in SCs but not in non-SCs. The data demonstrate that cholinergic modulation further differentiates the intrinsic electroresponsiveness of SCs and non-SCs, and add support to the presence of two parallel processing systems in medial EC layer II that could thereby differentially influence their hippocampal targets. The results also indicate an important role for the cholinergic system in tuning the oscillatory dynamics of entorhinal neurons.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7IWABLNW\\Klink, Alonso - 1997 - Muscarinic modulation of the oscillatory and repetitive firing properties of entorhinal cortex layer II neurons.pdf},
  journal = {Journal of neurophysiology},
  pmid = {9114238}
}

@article{klink_alonso_1997a,
  title = {Ionic Mechanisms of Muscarinic Depolarization in Entorhinal Cortex Layer {{II}} Neurons.},
  author = {Klink, R and Alonso, a},
  year = {1997},
  volume = {77},
  pages = {1829--1843},
  issn = {0022-3077},
  abstract = {The mechanisms underlying direct muscarinic depolarizing responses in the stellate cells (SCs) and non-SCs of medial entorhinal cortex layer II were investigated in tissue slices by intracellular recording and pressure-pulse applications of carbachol (CCh). Subthreshold CCh depolarizations were largely potentiated in amplitude and duration when paired with a short DC depolarization that triggered cell firing. During Na+ conductance block, CCh depolarizations were also potentiated by a brief DC depolarization that allowed Ca2+ influx and the potentiation was more robust in non-SCs than in SCs. Also, in non-SCs, CCh depolarizations could be accompanied by spikelike voltage oscillations at a slow frequency. In both SCs and non-SCs, the voltage-current (V-I) relations were similarly affected by CCh, which caused a shift to the left of the steady-state V-I relations over the entire voltage range and an increase in apparent slope input resistance at potentials positive to about -70 mV. CCh responses potentiated by Ca2+ influx demonstrated a selective increase in slope input resistance at potentials positive to about -75 mV in relation to the nonpotentiated responses. K+ conductance block with intracellular injection of Cs+ (3 M) and extracellular Ba2+ (1 mM) neither abolished CCh depolarizations nor resulted in any qualitatively distinct effect of CCh on the V-I relations. CCh depolarizations were also undiminished by block of the time-dependent inward rectifier Ih, with extracellular Cs . However, CCh depolarizations were abolished during Ca2+ conductance block with low-Ca2+ (0.5 mM) solutions containing Cd2+, Co2+, or Mn2+, as well as by intracellular Ca2+ chelation with bis-(o-aminophenoxy)-N,N,N',N'-tetraacetic acid. Inhibition of the Na+-K+ ATPase with strophanthidin resulted in larger CCh depolarizations. On the other hand, when NaCl was replaced by N-methyl-D-glucamine, CCh depolarizations were largely diminished. CCh responses were blocked by 0.8 microM pirenzepine, whereas hexahydro-sila-difenidolhydrochloride,p-fluoroanalog (p-F-HHSiD) and himbacine were only effective antagonists at 5- to 10-fold larger concentrations. Our data are consistent with CCh depolarizations being mediated in both SCs and non-SCs by m1 receptor activation of a Ca2+-dependent cationic conductance largely permeable to Na+. Activation of this conductance is potentiated in a voltage-dependent manner by activity triggering Ca2+ influx. This property implements a Hebbian-like mechanism whereby muscarinic receptor activation may only be translated into substantial membrane depolarization if coupled to postsynaptic cell activity. Such a mechanism could be highly significant in light of the role of the entorhinal cortex in learning and memory as well as in pathologies such as temporal lobe epilepsy.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\A37YYNMD\\Klink, Alonso - 1997 - Ionic mechanisms of muscarinic depolarization in entorhinal cortex layer II neurons.pdf},
  journal = {Journal of neurophysiology},
  pmid = {9114239}
}

@article{klukas_fiete_2019,
  title = {Flexible Representation and Memory of Higher-Dimensional Cognitive Variables with Grid Cells},
  author = {Klukas, Mirko and Lewis, Marcus and Fiete, Ila},
  year = {2019},
  month = mar,
  doi = {10.1101/578641},
  abstract = {Grid cell representations are simultaneously flexible and powerful yet rigid and constrained: On one hand, they can encode spatial or a variety of non-spatial cognitive variables (Constantinescu et al., 2016; Killian et al., 2012), with remarkable capacity, integration, and error correction properties (Fiete et al., 2008; Sreenivasan and Fiete, 2011; Mathis et al., 2012). On the other, states within each grid module are confined to a fixed two-dimensional (2D) set across time, environment, encoded variable (Yoon et al., 2013, 2016), behavioral states including sleep (Gardner et al., 2017; Trettel et al., 2017), with the inherent lowdimensionality etched directly into the physical topography of the circuit (Heys et al., 2014; Gu et al., 2018). The restriction to 2D states seemingly imposes a severe limit on the representation of general cognitive variables of dimension greater than two by grid cells. We show here that a set of grid cell modules, each with only 2D responses, can generate unambiguous and high-capacity representations of variables in much higher-dimensional spaces. Specifically, M grid modules can represent variables of arbitrary dimension up to 2M , with a capacity exponential in M . The idea generalizes our understanding of the 2D grid code as capable of flexible reconfiguration to generate unique high-capacity metric codes and memory states for representation and algebra in higher-dimensional vector spaces, without costly higher-dimensional grid-like responses in individual cells.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TUKBGWSU\\Klukas et al. - 2019 - Flexible representation and memory of higher-dimen.pdf},
  journal = {bioRxiv},
  language = {en}
}

@article{knierim_zhang_2012,
  title = {Attractor {{Dynamics}} of {{Spatially Correlated Neural Activity}} in the {{Limbic System}}},
  author = {Knierim, James J and Zhang, Kechen},
  year = {2012},
  volume = {35},
  pages = {267--285},
  issn = {0147-006X},
  doi = {10.1146/annurev-neuro-062111-150351},
  abstract = {Attractor networks are a popular computational construct used to model different brain systems. These networks allow elegant computations that are thought to represent a number of aspects of brain function. Although there is good reason to believe that the brain displays attractor dynamics, it has proven difficult to test experimentally whether any particular attractor architecture resides in any particular brain circuit. We review models and experimental evidence for three systems in the rat brain that are presumed to be components of the rat's navigational and memory system. Head-direction cells have been modeled as a ring attractor, grid cells as a plane attractor, and place cells both as a plane attractor and as a point attractor. Whereas the models have proven to be extremely useful conceptual tools, the experimental evidence in their favor, although intriguing, is still mostly circumstantial.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LY5SP3YH\\Knierim, Zhang - 2012 - Attractor Dynamics of Spatially Correlated Neural Activity in the Limbic System.pdf},
  journal = {Annual Review of Neuroscience},
  keywords = {head-direction cell,hippocampus,medial entorhinal cortex,place cell},
  number = {1},
  pmid = {22462545}
}

@article{knudsen_knudsen_2018,
  title = {Neural {{Circuits That Mediate Selective Attention}}: {{A Comparative Perspective}}},
  author = {Knudsen, Eric I},
  year = {2018},
  issn = {01662236},
  doi = {10.1016/j.tins.2018.06.006},
  abstract = {Selective attention is central to cognition. Dramatic advances have been made in understanding the neural circuits that mediate selective attention. Forebrain networks, most elaborated in primates, control all forms of attention based on task demands and the physical salience of stimuli. These networks contain circuits that distribute top-down signals to sensory processing areas and enhance information processing in those areas. A midbrain network, most elaborated in birds, controls spatial attention. It contains circuits that continuously compute the highest priority stimulus location and route sensory information from the selected location to forebrain networks that make cognitive decisions. The identification of these circuits, their functions and mechanisms represent a major advance in our understanding of how the vertebrate brain mediates selective attention.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UN5PQ3IH\\Knudsen - 2018 - Feature Review Neural Circuits That Mediate Selective Attention A Comparative Perspective.pdf},
  journal = {Trends in Neurosciences},
  keywords = {cognition,mechanisms of attention,visual attention},
  pmid = {30075867}
}

@article{koay_tank_2019,
  title = {Neural {{Correlates}} of {{Cognition}} in {{Primary Visual}} versus {{Neighboring Posterior Cortices}} during {{Visual Evidence}}-{{Accumulation}}-Based {{Navigation}}},
  author = {Koay, Sue Ann and Thiberge, Stephan Y. and Brody, Carlos D. and Tank, David W.},
  year = {2019},
  month = mar,
  doi = {10.1101/568766},
  abstract = {Studies of perceptual decision-making have often assumed that the main role of sensory cortices is to provide sensory input to downstream processes that accumulate and drive behavioral decisions. We performed a systematic comparison of neural activity in primary visual (V1) to secondary visual and retrosplenial cortices, as mice performed a task where they should accumulate pulsatile visual cues through time to inform a navigational decision. Even in V1, only a small fraction of neurons had sensory-like responses to cues. Instead, in all areas neurons were sequentially active, and contained information ranging from sensory to cognitive, including cue timings, evidence, place/time, decision and reward outcome. Per-cue sensory responses were amplitude-modulated by various cognitive quantities, notably accumulated evidence. This inspired a multiplicative feedback-loop circuit hypothesis that proposes a more intricate role of sensory areas in the accumulation process, and furthermore explains a surprising observation that perceptual discrimination deviates from Weber-Fechner Law.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3ZDF622T\\Koay et al. - 2019 - Neural Correlates of Cognition in Primary Visual v.pdf},
  journal = {bioRxiv},
  language = {en}
}

@article{kobak_machens_2016,
  title = {Demixed Principal Component Analysis of Neural Population Data},
  author = {Kobak, Dmitry and Brendel, Wieland and Constantinidis, Christos and Feierstein, Claudia E and Kepecs, Adam and Mainen, Zachary F and Qi, Xue Lian and Romo, Ranulfo and Uchida, Naoshige and Machens, Christian K},
  year = {2016},
  volume = {5},
  pages = {1--36},
  issn = {2050084X},
  doi = {10.7554/eLife.10989},
  abstract = {Neurons in higher cortical areas, such as the prefrontal cortex, are often tuned to a variety of sensory and motor variables, and are therefore said to display mixed selectivity. This complexity of single neuron responses can obscure what information these areas represent and how it is represented. Here we demonstrate the advantages of a new dimensionality reduction technique, demixed principal component analysis (dPCA), that decomposes population activity into a few components. In addition to systematically capturing the majority of the variance of the data, dPCA also exposes the dependence of the neural representation on task parameters such as stimuli, decisions, or rewards. To illustrate our method we reanalyze population data from four datasets comprising different species, different cortical areas and different experimental tasks. In each case, dPCA provides a concise way of visualizing the data that summarizes the task-dependent features of the population response in a single figure.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BLJ6SCE2\\Kobak et al. - 2016 - Demixed principal component analysis of neural population data(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\FI7QFVNJ\\Kobak et al. - 2016 - Demixed principal component analysis of neural population data.pdf},
  journal = {eLife},
  number = {APRIL2016},
  pmid = {27067378}
}

@article{kocsis_kaminski_2006,
  title = {Dynamic Changes in the Direction of the Theta Rhythmic Drive between Supramammillary Nucleus and the Septohippocampal System},
  author = {Kocsis, Bernat and Kaminski, Maciej},
  year = {2006},
  volume = {16},
  pages = {531--540},
  issn = {10509631},
  doi = {10.1002/hipo.20180},
  abstract = {Neurons in the supramammillary nucleus (SUM) of urethane-anesthetized rats fire rhythmically in synchrony with hippocampal theta rhythm. As these neurons project to the septum and hippocampus, it is generally assumed that their role is to mediate ascending activation, leading to the hippocampal theta rhythm. However, the connections between SUM and the septohippocampal system are reciprocal; there is strong evidence that theta remains in the hippocampus after SUM lesions and in the SUM after lesioning the medial septum. The present study examines the dynamics of coupling between rhythmic discharge in the SUM and hippocampal field potential oscillations, using the directionality information carried by the two signals. Using directed transfer function analysis, we demonstrate that during sensory-elicited theta rhythm and also during short episodes of theta acceleration of spontaneous oscillations, the spike train of a subpopulation of SUM neurons contains information predicting future variations in rhythmic field potentials in the hippocampus. In contrast, during slow spontaneous theta rhythm, it is the SUM spike signal that can be predicted from the preceding segment of the electrical signal recorded in the hippocampus. These findings indicate that, in the anesthetized rat, SUM neurons effectively drive theta oscillations in the hippocampus during epochs of sensory-elicited theta rhythm and short episodes of theta acceleration, whereas spontaneous slow theta in the SUM is controlled by descending input from the septohippocampal system. Thus, in certain states, rhythmically firing SUM neurons function to accelerate the septal theta oscillator, and in others, they are entrained by a superordinate oscillatory network. \textcopyright{} 2006 Wiley-Liss Inc.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3NVX449H\\Kocsis, Kaminski - 2006 - Dynamic changes in the direction of the theta rhythmic drive between supramammillary nucleus and the septohipp.pdf},
  journal = {Hippocampus},
  keywords = {Directed transfer function,Electroencephalogram,Hippocampus,Neuronal oscillations,Spike train},
  number = {6},
  pmid = {17598147}
}

@article{koechlin_jubault_2006,
  title = {Broca's {{Area}} and the {{Hierarchical Organization}} of {{Human Behavior}}},
  author = {Koechlin, Etienne and Jubault, Thomas},
  year = {2006},
  volume = {50},
  pages = {963--974},
  issn = {08966273},
  doi = {10.1016/j.neuron.2006.05.017},
  abstract = {The prefrontal cortex subserves executive control, i.e., the organization of action or thought in relation to internal goals. This brain region hosts a system of executive processes extending from premotor to the most anterior prefrontal regions that governs the temporal organization of behavior. Little is known, however, about the prefrontal executive system involved in the hierarchical organization of behavior. Here, we show using magnetic resonance imaging in humans that the posterior portion of the prefrontal cortex, including Broca's area and its homolog in the right hemisphere, contains a system of executive processes that control start and end states and the nesting of functional segments that combine in hierarchically organized action plans. Our results indicate that Broca's area and its right homolog process hierarchically structured behaviors regardless of their temporal organization, suggesting a fundamental segregation between prefrontal executive systems involved in the hierarchical and temporal organization of goal-directed behaviors. \textcopyright{} 2006 Elsevier Inc. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BVR4VIT9\\Koechlin, Jubault - 2006 - Broca's Area and the Hierarchical Organization of Human Behavior.pdf},
  journal = {Neuron},
  keywords = {SYSNEURO},
  number = {6},
  pmid = {16772176}
}

@article{koechlin_summerfield_2007,
  title = {An Information Theoretical Approach to Prefrontal Executive Function},
  author = {Koechlin, Etienne and Summerfield, Christopher},
  year = {2007},
  volume = {11},
  pages = {229--235},
  issn = {13646613},
  doi = {10.1016/j.tics.2007.04.005},
  abstract = {The prefrontal cortex subserves executive control - that is, the ability to select actions or thoughts in relation to internal goals. Here, we propose a theory that draws upon concepts from information theory to describe the architecture of executive control in the lateral prefrontal cortex. Supported by evidence from brain imaging in human subjects, the model proposes that action selection is guided by hierarchically ordered control signals, processed in a network of brain regions organized along the anterior-posterior axis of the lateral prefrontal cortex. The theory clarifies how executive control can operate as a unitary function, despite the requirement that information be integrated across multiple distinct, functionally specialized prefrontal regions. ?? 2007 Elsevier Ltd. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5SS7QK26\\Koechlin, Summerfield - 2007 - An information theoretical approach to prefrontal executive function.pdf},
  journal = {Trends in Cognitive Sciences},
  number = {6},
  pmid = {17475536}
}

@article{koelsch_friston_2019,
  title = {Predictive {{Processes}} and the {{Peculiar Case}} of {{Music}}},
  author = {Koelsch, Stefan and Vuust, Peter and Friston, Karl},
  year = {2019},
  month = jan,
  volume = {23},
  pages = {63--77},
  issn = {13646613},
  doi = {10.1016/j.tics.2018.10.006},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\C6II6VGS\\Koelsch et al. - 2019 - Predictive Processes and the Peculiar Case of Musi.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {1}
}

@article{koene_hasselmo_2007,
  title = {First-in-First-out Item Replacement in a Model of Short-Term Memory Based on Persistent Spiking.},
  author = {a Koene, Randal and Hasselmo, Michael E},
  year = {2007},
  month = aug,
  volume = {17},
  pages = {1766--1781},
  issn = {1047-3211},
  doi = {10.1093/cercor/bhl088},
  abstract = {Persistent neuronal firing has been modeled in relation to observed brain rhythms, especially to theta oscillations recorded in behaving animals. Models of short-term memory that are based on such persistent firing properties of specific neurons can meet the requirements of spike-timing-dependent potentiation of synaptic strengths during the encoding of a temporal sequence of spike patterns. We show that such a spiking buffer can be simulated with integrate-and-fire neurons that include a leak current even when different numbers of spikes represent successive items. We propose a mechanism that successfully replaces items in the buffer in first-in-first-out (FIFO) order when the distribution of spike density in a theta cycle is asymmetric, as found in experimental data. We predict effects on the function and capacity of the buffer model caused by changes in modeled theta cycle duration, the timing of input to the buffer, the strength of recurrent inhibition, and the strength and timing of after-hyperpolarization and after-depolarization (ADP). Shifts of input timing or changes in ADP parameters can enable the reverse-order buffering of items, with FIFO replacement in a full buffer. As noise increases, the simulated buffer provides robust output that may underlie episodic encoding.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2ERSLCZA\\Koene, Hasselmo - 2007 - First-in-first-out item replacement in a model of short-term memory based on persistent spiking.pdf},
  journal = {Cerebral cortex (New York, N.Y. : 1991)},
  keywords = {Algorithms,Calcium Channels,Calcium Channels: physiology,Computer Simulation,Electrophysiology,Entorhinal Cortex,Entorhinal Cortex: cytology,Entorhinal Cortex: physiology,Humans,Interneurons,Interneurons: physiology,Membrane Potentials,Membrane Potentials: physiology,Memory,Models,Neurological,Noise,Pyramidal Cells,Pyramidal Cells: physiology,Short-Term,Short-Term: physiology,Statistical,Synapses,Synapses: physiology,Synaptic Transmission,Synaptic Transmission: physiology,Theta Rhythm},
  number = {8},
  pmid = {17030561}
}

@article{kohn_yu_2020,
  title = {Principles of {{Corticocortical Communication}}: {{Proposed Schemes}} and {{Design Considerations}}},
  shorttitle = {Principles of {{Corticocortical Communication}}},
  author = {Kohn, Adam and Jasper, Anna I. and Semedo, Jo{\~a}o D. and Gokcen, Evren and Machens, Christian K. and Yu, Byron M.},
  year = {2020},
  month = sep,
  volume = {43},
  pages = {725--737},
  issn = {01662236},
  doi = {10.1016/j.tins.2020.07.001},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EN3GUQ7W\\Kohn et al. - 2020 - Principles of Corticocortical Communication Propo.pdf},
  journal = {Trends in Neurosciences},
  language = {en},
  number = {9}
}

@article{kohonen_kohonen_1982,
  title = {Self-Organized Formation of Topologically Correct Feature Maps},
  author = {Kohonen, Teuvo},
  year = {1982},
  volume = {69},
  pages = {59--69},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RGLXDUVI\\Kohonen - 1982 - Self-organized formation of topologically correct feature maps.pdf},
  journal = {Biological cybernetics}
}

@article{koivo_koivo_2008,
  title = {{{NEURAL NETWORKS}} : {{Basics}} Using {{MATLAB Neural Network Toolbox By}}},
  author = {Koivo, Heikki N},
  year = {2008},
  pages = {1--59},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CBJVGYJY\\Koivo - 2008 - NEURAL NETWORKS Basics using MATLAB Neural Network Toolbox By.pdf},
  journal = {Neural Networks}
}

@article{kok_turk-browne_2019,
  title = {Content-Based Dissociation of Hippocampal Involvement in Prediction},
  author = {Kok, Peter and Rait, Lindsay I. and {Turk-Browne}, Nicholas B.},
  year = {2019},
  month = mar,
  doi = {10.1101/568303},
  abstract = {It has recently become clear that one of the key functions of the hippocampus is to predict future inputs. In line with this, previous research has revealed prediction-related signals in the hippocampus for complex visual objects, such as fractals and abstract shapes. Based on this, it has been suggested that the hippocampus may generate perceptual expectations, especially when relying on rapidly learned predictive associations between arbitrary stimuli. However, it is currently unknown whether the hippocampus implements general-purpose computations that subserve all associative predictions, regardless of stimulus properties, or whether the involvement of the hippocampus is stimulus-dependent. To investigate this, we exposed male and female human participants to complex auditory cues predicting either the shape of a complex object (Experiment 1) or the orientation of a simple line grating (Experiment 2). We measured brain activity using highresolution functional magnetic resonance imaging (fMRI), in combination with inverted encoding models to reconstruct shape and orientation representations in visual cortex and the hippocampus. Our results revealed that expectations about shape and orientation evoked distinct representations in the hippocampus. For complex shapes, the hippocampus represented which shape was expected, potentially serving as a source of top-down predictions. In contrast, for simple gratings, the hippocampus represented only unexpected orientations, more reminiscent of a prediction error. We discuss several potential explanations for this dissociation, concluding that the computational role of the hippocampus in predictive processing depends upon the nature and complexity of stimuli.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3GA447TW\\Kok et al. - 2019 - Content-based dissociation of hippocampal involvem.pdf},
  journal = {bioRxiv},
  language = {en}
}

@book{koller_friedman_2009,
  title = {Probabilistic Graphical Models: Principles and Techniques},
  shorttitle = {Probabilistic Graphical Models},
  author = {Koller, Daphne and Friedman, Nir},
  year = {2009},
  publisher = {{MIT Press}},
  address = {{Cambridge, MA}},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\F3W8LB23\\Koller and Friedman - 2009 - Probabilistic graphical models principles and tec.pdf},
  isbn = {978-0-262-01319-2},
  language = {en},
  lccn = {QA279.5 .K65 2009},
  series = {Adaptive Computation and Machine Learning}
}

@article{kolling_rushworth_2016,
  title = {Value, Search, Persistence and Model Updating in Anterior Cingulate Cortex},
  author = {Kolling, Nils and Wittmann, Marco K and Behrens, Tim E J and Boorman, Erie D and Mars, Rogier B and Rushworth, Matthew F S},
  year = {2016},
  volume = {19},
  pages = {1280--1285},
  issn = {1097-6256},
  doi = {10.1038/nn.4382},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UXXUCWNN\\Kolling et al. - 2016 - Value, search, persistence and model updating in anterior cingulate cortex.pdf},
  journal = {Nature Neuroscience},
  number = {10},
  pmid = {27669988}
}

@article{komer_eliasmith_,
  title = {Efficient Navigation Using a Scalable, Biologically Inspired Spatial Representation},
  author = {Komer, Brent and Eliasmith, Chris},
  pages = {7},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\X7BVINLY\\Komer and Eliasmith - Efﬁcient navigation using a scalable, biologically.pdf},
  language = {en}
}

@article{kondgen_giugliano_2008,
  title = {The {{Dynamical Response Properties}} of {{Neocortical Neurons}} to {{Temporally Modulated Noisy Inputs In Vitro}}},
  author = {K{\"o}ndgen, Harold and Geisler, Caroline and Fusi, Stefano and Wang, Xiao-Jing and L{\"u}scher, Hans-Rudolf and Giugliano, Michele},
  year = {2008},
  month = sep,
  volume = {18},
  pages = {2086--2097},
  issn = {1460-2199, 1047-3211},
  doi = {10.1093/cercor/bhm235},
  abstract = {To achieve their goal of realizing fast and energy-efficient learning, neuromorphic systems require computationally powerful models that obey the constraints imposed by a physical implementation of neural network structure and dynamics, such as the inevitability of relaxation times or the locality of plasticity. In this work, we provide a first-principles derivation of a mechanistic model for cortical computation based on the premise of "neuronal least action". The resulting time-continuous neuron and synapse dynamics realize gradient-descent learning through error backpropagation both in supervised and in reinforcement learning scenarios. In particular, the derived equations of motion reproduce well-established microscopic phenomena such as neuronal leaky integration of afferent signals, while enabling synaptic learning using only locally available information. Our principled framework can thus serve as a starting point for hardware-focused models of highly efficient time-continuous learning.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DZAG39ZS\\Köndgen et al. - 2008 - The Dynamical Response Properties of Neocortical N.pdf},
  journal = {Cerebral Cortex},
  language = {en},
  number = {9}
}

@article{konidaris_lozano-perez_2018,
  title = {From {{Skills}} to {{Symbols}}: {{Learning Symbolic Representations}} for {{Abstract High}}-{{Level Planning}}},
  author = {Konidaris, George and Kaelbling, Leslie Pack and {Lozano-Perez}, Tomas},
  year = {2018},
  volume = {6117},
  pages = {215--289},
  abstract = {We consider the problem of constructing abstract representations for planning in high-dimensional, continuous environments. We assume an agent equipped with a collection of high-level actions, and construct representations provably capable of evaluating plans composed of sequences of those actions. We first consider the deterministic planning case, and show that the relevant computa-tion involves set operations performed over sets of states. We define the specific collection of sets that is necessary and sufficient for planning, and use them to construct a grounded abstract symbolic representation that is provably suitable for deterministic planning. The resulting representation can be expressed in PDDL, a canonical high-level planning do-main language; we construct such a representation for the Playroom domain and solve it in milliseconds using an off-the-shelf planner. We then consider probabilistic planning, which we show requires generalizing from sets of states to distributions over states. We identify the specific distributions required for planning, and use them to construct a grounded abstract symbolic representation that correctly estimates the expected reward and probability of success of any plan. In addition, we show that learning the relevant probability distributions corresponds to specific instances of probabilistic density estimation and probabilistic classification. We construct an agent that autonomously learns the correct abstract representation of a computer game domain, and rapidly solves it. Finally, we apply these techniques to create a physical robot system that autonomously learns its own symbolic representation of a mobile manipulation task directly from senso-rimotor data\textemdash point clouds, map locations, and joint angles\textemdash and then plans using that representation. Together, these results establish a principled link between high-level actions and abstract representations, a concrete theoretical foundation for constructing abstract representations with provable properties, and a practical mechanism for autonomously learning abstract high-level representations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AKYNMLH6\\Konidaris, Kaelbling, Lozano-Perez - 2018 - From Skills to Symbols Learning Symbolic Representations for Abstract High-Level Planning.pdf},
  journal = {Journal of Artificial Intelligence Research},
  number = {118}
}

@article{konkel_konkel_2009,
  title = {Relational Memory and the Hippocampus: {{Representations}} and Methods},
  shorttitle = {Relational Memory and the Hippocampus},
  author = {Konkel, Alex},
  year = {2009},
  month = sep,
  volume = {3},
  pages = {166--174},
  issn = {16624548, 1662453X},
  doi = {10.3389/neuro.01.023.2009},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JA8MGIJJ\\Konkel - 2009 - Relational memory and the hippocampus Representat.pdf},
  journal = {Frontiers in Neuroscience},
  language = {en},
  number = {2}
}

@article{kool_gershman_2009,
  title = {Competition and {{Cooperation Between Multiple Reinforcement Learning Systems}}},
  author = {Kool, Wouter and Cushman, Fiery A and Gershman, Samuel J},
  year = {2009},
  abstract = {Most psychological research on reinforcement learning has depicted two systems locked in battle for control of behavior: a flexible but computationally expensive " model-based " system and an inflexible but cheap " model-free " system. However, the complete picture is more complex, with the two systems cooperating in myriad ways. We focus on two issues at the frontier of this research program. First, how is the conflict between these systems adjudicated? Second, how can the systems be combined to harness the relative strengths of each? This chapter reviews recent work on competition and cooperation between the two systems, highlighting the computational principles that govern different forms of interaction. As you leave work each day, how do you choose a route home? Prominent dual-system accounts posit two distinct cognitive systems that solve this task in different ways On the one hand, you could decide your route home by relying on habit. Since you have successfully taken one particular route to your house many times, this route has been ingrained into your motor system, and can be executed quickly and automatically. Habits are useful because they make often-repeated behavior efficient and automatized; however, they are also inflexible and therefore more likely to produce errors. For example, consider the case where your significant other asked you to buy some toilet paper on your way back home. In this case, it would be better to suppress the habitual route and engage in goal-directed control. This involves the recall of the alternate goal (picking up toilet paper), and planning a new route that goes past the convenience store, using an internal model (" cognitive map ") of the environment. Goal-directed planning is useful because it is more flexible and consequently more accurate than relying on habit. However, it also carries significant computational costs (Gershman \& Daw, 2012). These two systems are typically theorized as competitors, vying for control of behavior. A major goal of modern decision research is understanding how control is allocated between the two systems. We will attempt to summarize and extend this line of research. Yet, the two systems may also interact cooperatively. For example, you might learn a habit to check traffic reports before you leave work, because this facilitates planning an optimal route. Moreover, the act of " checking " could involve elements of goal-directed planning\textemdash for instance, searching for radio stations\textemdash even if initiated out of habit. These illustrate just two forms of cooperation: habitual actions can support effective goal pursuit, and even drive the selection of goals themselves.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\98LBBS4W\\Kool, Cushman, Gershman - 2009 - Competition and Cooperation Between Multiple Reinforcement Learning Systems.pdf}
}

@article{kopell_kramer_2011,
  title = {Neuronal Assembly Dynamics in the Beta1 Frequency Range Permits Short-Term Memory},
  author = {Kopell, N. and Whittington, M. A. and Kramer, M. A.},
  year = {2011},
  volume = {108},
  pages = {3779--3784},
  issn = {0027-8424},
  doi = {10.1073/pnas.1019676108},
  abstract = {Cell assemblies have long been thought to be associated with brain rhythms, notably the gamma rhythm. Here, we use a computational model to show that the beta1 frequency band, as found in rat association cortex, has properties complementary to the gamma band for the creation and manipulation of cell assemblies. We focus on the ability of the beta1 rhythm to respond differently to familiar and novel stimuli, and to provide a framework for combining the two. Simulations predict that assemblies of superficial layer pyramidal cells can be maintained in the absence of continuing input or synaptic plasticity. Instead, the formation of these assemblies relies on the nesting of activity within a beta1 rhythm. In addition, cells receiving further input after assembly formation produce coexistent spiking activity, unlike the competitive spiking activity characteristic of assembly formation with gamma rhythms.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZXNUHU25\\Kopell, Whittington, Kramer - 2011 - Neuronal assembly dynamics in the beta1 frequency range permits short-term memory.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  number = {9},
  pmid = {21321198}
}

@article{kopell_tort_2010,
  title = {Gamma and {{Theta Rhythms}} in {{Biophysical Models}} of {{Hippocampal Circuits}}},
  author = {Kopell, N and B{\"o}rgers, C and Pervouchine, D and Malerba, P and Tort, A},
  year = {2010},
  doi = {10.1007/978-1-4419-0996-1},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SNIQYXD3\\Kopell et al. - Unknown - Gamma and Theta Rhythms in Biophysical Models of Hippocampal Circuits.pdf}
}

@article{kopell_traub_2000,
  title = {Gamma Rhythms and Beta Rhythms Have Different Synchronization Properties.},
  author = {Kopell, Nancy and Ermentrout, G B and a Whittington, M and Traub, R D},
  year = {2000},
  month = feb,
  volume = {97},
  pages = {1867--1872},
  issn = {0027-8424},
  abstract = {Experimental and modeling efforts suggest that rhythms in the CA1 region of the hippocampus that are in the beta range (12-29 Hz) have a different dynamical structure than that of gamma (30-70 Hz). We use a simplified model to show that the different rhythms employ different dynamical mechanisms to synchronize, based on different ionic currents. The beta frequency is able to synchronize over long conduction delays (corresponding to signals traveling a significant distance in the brain) that apparently cannot be tolerated by gamma rhythms. The synchronization properties are consistent with data suggesting that gamma rhythms are used for relatively local computations whereas beta rhythms are used for higher level interactions involving more distant structures.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\85BKYEJM\\Kopell et al. - 2000 - Gamma rhythms and beta rhythms have different synchronization properties.pdf},
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  keywords = {Animals,Cortical Synchronization,Electroencephalography,Hippocampus,Hippocampus: physiology,Models,Neurological},
  number = {4},
  pmid = {10677548}
}

@article{koppe_durstewitz_2019,
  title = {Identifying Nonlinear Dynamical Systems via Generative Recurrent Neural Networks with Applications to {{fMRI}}},
  author = {Koppe, Georgia and Toutounji, Hazem and Kirsch, Peter and Lis, Stefanie and Durstewitz, Daniel},
  editor = {Isik, Leyla},
  year = {2019},
  month = aug,
  volume = {15},
  pages = {e1007263},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1007263},
  abstract = {A major tenet in theoretical neuroscience is that cognitive and behavioral processes are ultimately implemented in terms of the neural system dynamics. Accordingly, a major aim for the analysis of neurophysiological measurements should lie in the identification of the computational dynamics underlying task processing. Here we advance a state space model (SSM) based on generative piecewise-linear recurrent neural networks (PLRNN) to assess dynamics from neuroimaging data. In contrast to many other nonlinear time series models which have been proposed for reconstructing latent dynamics, our model is easily interpretable in neural terms, amenable to systematic dynamical systems analysis of the resulting set of equations, and can straightforwardly be transformed into an equivalent continuoustime dynamical system. The major contributions of this paper are the introduction of a new observation model suitable for functional magnetic resonance imaging (fMRI) coupled to the latent PLRNN, an efficient stepwise training procedure that forces the latent model to capture the `true' underlying dynamics rather than just fitting (or predicting) the observations, and of an empirical measure based on the Kullback-Leibler divergence to evaluate from empirical time series how well this goal of approximating the underlying dynamics has been achieved. We validate and illustrate the power of our approach on simulated `ground-truth' dynamical systems as well as on experimental fMRI time series, and demonstrate that the learnt dynamics harbors task-related nonlinear structure that a linear dynamical model fails to capture. Given that fMRI is one of the most common techniques for measuring brain activity non-invasively in human subjects, this approach may provide a novel step toward analyzing aberrant (nonlinear) dynamics for clinical assessment or neuroscientific research.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5TI8LT9K\\Koppe et al. - 2019 - Identifying nonlinear dynamical systems via genera.pdf},
  journal = {PLOS Computational Biology},
  language = {en},
  number = {8}
}

@article{kording_konig_2001a,
  ids = {rding\_nig\_a},
  title = {Supervised and {{Unsupervised Learning}} with {{Two Sites}} of {{Synaptic Integration}}},
  author = {Kording, Konrad P and Konig, Peter},
  year = {2001},
  pages = {9},
  abstract = {Many learning rules for neural networks derive from abstract objective functions. The weights in those networks are typically optimized utilizing gradient ascent on the objective function. In those networks each neuron needs to store two variables. One variable, called activity, contains the bottom-up sensory-fugal information involved in the core signal processing. The other variable typically describes the derivative of the objective function with respect to the cell's activity and is exclusively used for learning. This variable allows the objective function's derivative to be calculated with respect to each weight and thus the weight update. Although this approach is widely used, the mapping of such two variables onto physiology is unclear, and these learning algorithms are often considered biologically unrealistic. However, recent research on the properties of cortical pyramidal neurons shows that these cells have at least two sites of synaptic integration, the basal and the apical dendrite, and are thus appropriately described by at least two variables. Here we discuss whether these results could constitute a physiological basis for the described abstract learning rules. As examples we demonstrate an implementation of the backpropagation of error algorithm and a specific self-supervised learning algorithm using these principles. Thus, compared to standard, one-integration-site neurons, it is possible to incorporate interesting properties in neural networks that are inspired by physiology with a modest increase of complexity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VZJTEL3S\\Rding and Nig - Supervised and Unsupervised Learning with Two Site.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\YKJTL5IP\\Rding and Nig - Supervised and Unsupervised Learning with Two Site.pdf},
  journal = {Journal of Computational Neuroscience},
  language = {en}
}

@article{koren_deneve_2017,
  title = {Computational {{Account}} of {{Spontaneous Activity}} as a {{Signature}} of {{Predictive Coding}}},
  author = {Koren, Veronika and Den{\`e}ve, Sophie},
  editor = {Blackwell, Kim T.},
  year = {2017},
  month = jan,
  volume = {13},
  pages = {e1005355},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1005355},
  abstract = {Spontaneous activity is commonly observed in a variety of cortical states. Experimental evidence suggested that neural assemblies undergo slow oscillations with Up ad Down states even when the network is isolated from the rest of the brain. Here we show that these spontaneous events can be generated by the recurrent connections within the network and understood as signatures of neural circuits that are correcting their internal representation. A noiseless spiking neural network can represent its input signals most accurately when excitatory and inhibitory currents are as strong and as tightly balanced as possible. However, in the presence of realistic neural noise and synaptic delays, this may result in prohibitively large spike counts. An optimal working regime can be found by considering terms that control firing rates in the objective function from which the network is derived and then minimizing simultaneously the coding error and the cost of neural activity. In biological terms, this is equivalent to tuning neural thresholds and after-spike hyperpolarization. In suboptimal working regimes, we observe spontaneous activity even in the absence of feed-forward inputs. In an all-to-all randomly connected network, the entire population is involved in Up states. In spatially organized networks with local connectivity, Up states spread through local connections between neurons of similar selectivity and take the form of a traveling wave. Up states are observed for a wide range of parameters and have similar statistical properties in both active and quiescent state. In the optimal working regime, Up states are vanishing, leaving place to asynchronous activity, suggesting that this working regime is a signature of maximally efficient coding. Although they result in a massive increase in the firing activity, the read-out of spontaneous Up states is in fact orthogonal to the stimulus representation, therefore interfering minimally with the network function.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KI5CTQZU\\Koren and Denève - 2017 - Computational Account of Spontaneous Activity as a.pdf},
  journal = {PLOS Computational Biology},
  language = {en},
  number = {1}
}

@article{korzeniewska_crone_2008,
  title = {Dynamics of Event-Related Causality in Brain Electrical Activity},
  author = {Korzeniewska, Anna and Crainiceanu, Ciprian M and Ku{\'s}, Rafa{\textbackslash}l and Franaszczuk, Piotr J and Crone, Nathan E},
  year = {2008},
  volume = {29},
  pages = {1170--1192},
  issn = {10659471},
  doi = {10.1002/hbm.20458},
  abstract = {A new method (Event-Related Causality, ERC) is proposed for the investigation of functional interactions between brain regions during cognitive processing. ERC estimates the direction, intensity, spectral content, and temporal course of brain activity propagation within a cortical network. ERC is based upon the short-time directed transfer function (SDTF), which is measured in short EEG epochs during multiple trials of a cognitive task, as well as the direct directed transfer function (dDTF), which distinguishes direct interactions between brain regions from indirect interactions via brain regions. ERC uses new statistical methods for comparing estimates of causal interactions during prestimulus "baseline" epochs and during poststimulus "activated" epochs in order to estimate event-related increases and decreases in the functional interactions between cortical network components during cognitive tasks. The utility of the ERC approach is demonstrated through its application to human electrocorticographic recordings (ECoG) of a simple language task. ERC analyses of these ECoG recordings reveal frequency-dependent interactions, particularly in high gamma (\textbackslash textgreater60 Hz) frequencies, between brain regions known to participate in the recorded language task, and the temporal evolution of these interactions is consistent with the putative processing stages of this task. The method may be a useful tool for investigating the dynamics of causal interactions between various brain regions during cognitive task performance.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GMTCSXJL\\Korzeniewska et al. - 2008 - Dynamics of event-related causality in brain electrical activity.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\SVPUGV7B\\korzeniewska_et_al_2008_dynamics_of_event-related_causality_in_brain_electrical_activity.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\9JML3VDD\\hbm.html},
  journal = {Human Brain Mapping},
  keywords = {Brain mapping,Cortical synchronization,eeg,Important,Language,Multivariate analysis,Neural network,Neural transmission,Signal processing},
  number = {10},
  pmid = {17712784}
}

@article{kosiorek_hinton_2019,
  title = {Stacked {{Capsule Autoencoders}}},
  author = {Kosiorek, Adam R. and Sabour, Sara and Teh, Yee Whye and Hinton, Geoffrey E.},
  year = {2019},
  month = jun,
  abstract = {An object can be seen as a geometrically organized set of interrelated parts. A system that makes explicit use of these geometric relationships to recognize objects should be naturally robust to changes in viewpoint, because the intrinsic geometric relationships are viewpoint-invariant. We describe an unsupervised version of capsule networks, in which a neural encoder, which looks at all of the parts, is used to infer the presence and poses of object capsules. The encoder is trained by backpropagating through a decoder, which predicts the pose of each already discovered part using a mixture of pose predictions. The parts are discovered directly from an image, in a similar manner, by using a neural encoder, which infers parts and their affine transformations. The corresponding decoder models each image pixel as a mixture of predictions made by affine-transformed parts. We learn object- and their part-capsules on unlabeled data, and then cluster the vectors of presences of object capsules. When told the names of these clusters, we achieve state-of-the-art results for unsupervised classification on SVHN (55\%) and near state-of-the-art on MNIST (98.5\%).},
  archivePrefix = {arXiv},
  eprint = {1906.06818},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ICX8IIG2\\Kosiorek et al. - 2019 - Stacked Capsule Autoencoders.pdf},
  journal = {arXiv:1906.06818 [cs, stat]},
  language = {en},
  primaryClass = {cs, stat}
}

@article{koster_kartner_2016,
  title = {Infants {{Understand Others Needs}}},
  author = {{Ko ster}, M and Ohmer, X and Nguyen, T D and {Ka rtner}, J},
  year = {2016},
  volume = {27},
  pages = {0956797615627426----},
  issn = {0956-7976},
  doi = {10.1177/0956797615627426},
  abstract = {Infants begin to help other individuals in the second year of life. However, it is still unclear whether early helping behavior is based on an understanding of other individuals needs and is thus motivated prosocially. In the present eye-tracking study, 9- to 18-month-old infants (N = 71) saw a character in need of help, unable to reach its goal because of an obstacle, and a second character that was able to achieve a goal on its own. When a third individual (a helper) initiated an action, the infants expected the helper to help the character in need (as indicated during the anticipatory-looking and violation-of-expectation phases). Their prosocial understanding did not differ between age groups and was not related to their helping behavior (measured in two behavioral tasks). Thus, infants understand other individuals needs even before they start to help others themselves. This indicates that early helping may indeed be motivated prosocially and raises the question of which other competences underlie the ontogeny of helping behavior.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2KNEY856\\Ko ster et al. - 2016 - Infants Understand Others Needs.pdf},
  journal = {Psychological Science},
  number = {4}
}

@article{koster_kumaran_2018,
  title = {Big-{{Loop Recurrence}} within the {{Hippocampal System Supports Integration}} of {{Information}} across {{Episodes}}},
  author = {Koster, Raphael and Chadwick, Martin J and Chen, Yi and Hassabis, Demis and Kumaran, Dharshan},
  year = {2018},
  doi = {10.1016/j.neuron.2018.08.009},
  abstract = {Highlights d How we are able to integrate information across multiple episodes remains unknown d We show that recirculation of hippocampal output as a new input mediates this process d Results support computational models of big-loop recurrence within the hippocampus d This provides a unifying hippocampal algorithm for episodic memory and integration Correspondence rkoster@google.com (R.K.), mjchadwick@google.com (M.J.C.), dkumaran@google.com (D.K.) In Brief The hippocampus is central for storing distinct episodes, while also supporting integration across related episodes. Using ultra-high-resolution fMRI, Koster et al. provide evidence for a core computational principle (big-loop recurrence) that can account for these apparently conflicting hippocampal roles. Koster et al.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5JIEA2XI\\Koster et al. - 2018 - Big-Loop Recurrence within the Hippocampal System Supports Integration of Information across Episodes.pdf},
  keywords = {fmri,hippocampus,mvpa,paired-associate inference task}
}

@article{koyama_kass_2009,
  title = {Bayesian Decoding of Neural Spike Trains},
  author = {Koyama, Shinsuke and Eden, Uri T and Brown, Emery N. and Kass, Robert E.},
  year = {2009},
  month = jul,
  volume = {62},
  pages = {37--59},
  issn = {0020-3157},
  doi = {10.1007/s10463-009-0249-x},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8NV2VFU9\\Koyama et al. - 2009 - Bayesian decoding of neural spike trains.pdf},
  journal = {Annals of the Institute of Statistical Mathematics},
  number = {1}
}

@techreport{kozachkov_miller_2020,
  title = {Achieving Stable Dynamics in Neural Circuits},
  author = {Kozachkov, Leo and Lundqvist, Mikael and Slotine, Jean-Jacques and Miller, Earl K.},
  year = {2020},
  month = jan,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.01.17.910174},
  abstract = {1           Abstract           The brain consists of many interconnected networks with time-varying, partially autonomous activity. There are multiple sources of noise and variation yet activity has to eventually converge to a stable, reproducible state (or sequence of states) for its computations to make sense. We approached this problem from a control-theory perspective by applying contraction analysis to recurrent neural networks. This allowed us to find mechanisms for achieving stability in multiple connected networks with biologically realistic dynamics, including synaptic plasticity and time-varying inputs. These mechanisms included inhibitory Hebbian plasticity, excitatory anti-Hebbian plasticity, synaptic sparsity and excitatory-inhibitory balance. Our findings shed light on how stable computations might be achieved despite biological complexity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3VKFF267\\Kozachkov et al. - 2020 - Achieving stable dynamics in neural circuits.pdf},
  language = {en},
  type = {Preprint}
}

@book{kramer_eden_2016,
  title = {Case Studies in Neural Data Analysis: A Guide for the Practicing Neuroscientist},
  shorttitle = {Case Studies in Neural Data Analysis},
  author = {Kramer, Mark A. and Eden, Uri T.},
  year = {2016},
  publisher = {{The MIT Press}},
  address = {{Cambridge, Massachusetts}},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\STBXQG4K\\Kramer and Eden - 2016 - Case studies in neural data analysis a guide for .pdf},
  isbn = {978-0-262-52937-2},
  keywords = {Neural analyzers,Neuropsychological tests},
  language = {en},
  lccn = {QP357.5 .K69 2016},
  series = {Computational Neuroscience Series}
}

@article{kramer_kopell_2008,
  title = {Rhythm {{Generation}} through {{Period Concatenation}} in {{Rat Somatosensory Cortex}}},
  author = {Kramer, Mark A. and Roopun, Anita K. and Carracedo, Lucy M. and Traub, Roger D. and Whittington, Miles A. and Kopell, Nancy J.},
  editor = {Friston, Karl J.},
  year = {2008},
  month = sep,
  volume = {4},
  pages = {e1000169},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1000169},
  abstract = {Rhythmic voltage oscillations resulting from the summed activity of neuronal populations occur in many nervous systems. Contemporary observations suggest that coexistent oscillations interact and, in time, may switch in dominance. We recently reported an example of these interactions recorded from in vitro preparations of rat somatosensory cortex. We found that following an initial interval of coexistent gamma (,25 ms period) and beta2 (,40 ms period) rhythms in the superficial and deep cortical layers, respectively, a transition to a synchronous beta1 (,65 ms period) rhythm in all cortical layers occurred. We proposed that the switch to beta1 activity resulted from the novel mechanism of period concatenation of the faster rhythms: gamma period (25 ms)+beta2 period (40 ms) = beta1 period (65 ms). In this article, we investigate in greater detail the fundamental mechanisms of the beta1 rhythm. To do so we describe additional in vitro experiments that constrain a biologically realistic, yet simplified, computational model of the activity. We use the model to suggest that the dynamic building blocks (or motifs) of the gamma and beta2 rhythms combine to produce a beta1 oscillation that exhibits crossfrequency interactions. Through the combined approach of in vitro experiments and mathematical modeling we isolate the specific components that promote or destroy each rhythm. We propose that mechanisms vital to establishing the beta1 oscillation include strengthened connections between a population of deep layer intrinsically bursting cells and a transition from antidromic to orthodromic spike generation in these cells. We conclude that neural activity in the superficial and deep cortical layers may temporally combine to generate a slower oscillation.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\289IU9Z9\\Kramer et al. - 2008 - Rhythm Generation through Period Concatenation in .PDF},
  journal = {PLoS Computational Biology},
  language = {en},
  number = {9}
}

@phdthesis{kramer_kramer_2005,
  title = {Nonlinear {{Dynamics}} and {{Neural Systems}}: {{Synchronization}} and {{Modeling}}},
  author = {Kramer, Mark Alan},
  year = {2005},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PCNZEIY6\\Kramer - 2005 - Nonlinear Dynamics and Neural Systems Synchronization and Modeling.pdf},
  school = {University of California, Berkeley},
  type = {{{PhD Thesis}}}
}

@article{kraus_eichenbaum_2015,
  title = {During Running in Place, Grid Cells Integrate Elapsed Time and Distance Run},
  author = {Kraus, Benjamin J and Brandon, Mark P. and Robinson II, Robert J. and a. Connerney, Michael and Hasselmo, Michael E and Eichenbaum, Howard B},
  year = {2015},
  volume = {88},
  pages = {578--589},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2015.09.031},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YV9ZXGBZ\\Kraus et al. - 2015 - During running in place, grid cells integrate elapsed time and distance run.pdf},
  journal = {Neuron},
  number = {3}
}

@article{kraus_hasselmo_2013,
  title = {Hippocampal "Time Cells": Time versus Path Integration.},
  author = {Kraus, Benjamin J and Robinson, Robert J and a White, John and Eichenbaum, Howard B and Hasselmo, Michael E},
  year = {2013},
  month = jun,
  volume = {78},
  pages = {1090--101},
  issn = {1097-4199},
  doi = {10.1016/j.neuron.2013.04.015},
  abstract = {Recent studies have reported the existence of hippocampal "time cells," neurons that fire at particular moments during periods when behavior and location are relatively constant. However, an alternative explanation of apparent time coding is that hippocampal neurons "path integrate" to encode the distance an animal has traveled. Here, we examined hippocampal neuronal firing patterns as rats ran in place on a treadmill, thus "clamping" behavior and location, while we varied the treadmill speed to distinguish time elapsed from distance traveled. Hippocampal neurons were strongly influenced by time and distance, and less so by minor variations in location. Furthermore, the activity of different neurons reflected integration over time and distance to varying extents, with most neurons strongly influenced by both factors and some significantly influenced by only time or distance. Thus, hippocampal neuronal networks captured both the organization of time and distance in a situation where these dimensions dominated an ongoing experience.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WH6NPHIU\\Kraus et al. - 2013 - Hippocampal time cells time versus path integration.pdf},
  journal = {Neuron},
  keywords = {Animals,Hippocampus,Hippocampus: cytology,Hippocampus: physiology,Long-Evans,Male,Maze Learning,Maze Learning: physiology,Motor Activity,Motor Activity: physiology,Neural Pathways,Neural Pathways: cytology,Neural Pathways: physiology,Rats,Space Perception,Space Perception: physiology,Time Factors},
  number = {6},
  pmid = {23707613}
}

@article{krause_walker_2017,
  title = {The Sleep-Deprived Human Brain},
  author = {Krause, Adam J. and Simon, Eti Ben and Mander, Bryce A. and Greer, Stephanie M. and Saletin, Jared M. and {Goldstein-Piekarski}, Andrea N. and Walker, Matthew P.},
  year = {2017},
  month = may,
  volume = {18},
  pages = {404--418},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn.2017.55},
  abstract = {How does a lack of sleep affect our brains? In contrast to the benefits of sleep, frameworks exploring the impact of sleep loss are relatively lacking. Importantly, the effects of sleep deprivation (SD) do not simply reflect the absence of sleep and the benefits attributed to it; rather, they reflect the consequences of several additional factors, including extended wakefulness. With a focus on neuroimaging studies, we review the consequences of SD on attention and working memory, positive and negative emotion, and hippocampal learning. We explore how this evidence informs our mechanistic understanding of the known changes in cognition and emotion associated with SD, and the insights it provides regarding clinical conditions associated with sleep disruption.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\26HYA4A7\\Krause et al. - 2017 - The sleep-deprived human brain.pdf},
  journal = {Nature Reviews Neuroscience},
  language = {en},
  number = {7}
}

@article{kreiman_serre_2020,
  title = {Beyond the Feedforward Sweep: Feedback Computations in the Visual Cortex},
  shorttitle = {Beyond the Feedforward Sweep},
  author = {Kreiman, Gabriel and Serre, Thomas},
  year = {2020},
  month = mar,
  volume = {1464},
  pages = {222--241},
  issn = {0077-8923, 1749-6632},
  doi = {10.1111/nyas.14320},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\G2R3IGKJ\\Kreiman and Serre - 2020 - Beyond the feedforward sweep feedback computation.pdf},
  journal = {Annals of the New York Academy of Sciences},
  language = {en},
  number = {1}
}

@article{kreitzer_zurwerra_2014,
  title = {Striatal {{Plasticity}} and {{Basal Ganglia Circuit Function}}},
  author = {Kreitzer, Anatol C and Malenka, Robert C and Lerner, Talia N and Kreitzer, Anatol C and Hikosaka, Okihide and Isoda, Masaki and Qiu, Mei-Hong and Chen, Michael C and Huang, Zhi-Li and Lu, Jun and Carter, Matthew E and Yizhar, Ofer and Chikahisa, Sachiko and Nguyen, Hieu and Adamantidis, Antoine and Nishino, Seiji and Deisseroth, Karl and {de Lecea}, Luis and Calabresi, Paolo and Picconi, Barbara and Tozzi, Alessandro and Ghiglieri, Veronica and Di Filippo, Massimiliano and Ishikawa, Masago and Kenny, Paul J and Kusters, J and Zurwerra, Didier},
  year = {2014},
  volume = {13},
  pages = {13},
  issn = {1097-6256},
  doi = {10.1016/j.conb.2011.01.005},
  abstract = {The cerebral cortex and basal ganglia (BG) form a neural circuit that is disrupted in disorders such as Parkinson's disease. We found that neuronal activity (c-Fos) in the BG followed cortical activity, i.e., high in arousal state and low in sleep state. To determine if cortical activity is necessary for BG activity, we administered atropine to rats to induce a dissociative state resulting in slow-wave electroencephalography but hyperactive motor behaviors. Atropine blocked c-Fos expression in the cortex and BG, despite high c-Fos expression in the sub-cortical arousal neuronal groups and thalamus, indicating that cortical activity is required for BG activation. To identify which glutamate receptors in the BG that mediate cortical inputs, we injected ketamine [N-methyl-d-aspartate (NMDA) receptor antagonist] and 6-cyano-nitroquinoxaline-2, 3-dione (CNQX, a non-NMDA receptor antagonist). Systemic ketamine and CNQX administration revealed that NMDA receptors mediated subthalamic nucleus (STN) input to internal globus pallidus (GPi) and substantia nigra pars reticulata (SNr), while non-NMDA receptor mediated cortical input to the STN. Both types of glutamate receptors were involved in mediating cortical input to the striatum. Dorsal striatal (caudoputamen, CPu) dopamine depletion by 6-hydroxydopamine resulted in reduced activity of the CPu, globus pallidus externa (GPe), and STN but increased activity of the GPi, SNr, and putative layer V neurons in the motor cortex. Our results reveal that the cortical activity is necessary for BG activity and clarifies the pathways and properties of the BG-cortical network and their putative role in the pathophysiology of BG disorders.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2TT36WNH\\Kreitzer et al. - 2014 - Striatal Plasticity and Basal Ganglia Circuit Function.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\STQDCFMU\\Kreitzer et al. - 2014 - Striatal Plasticity and Basal Ganglia Circuit Function.pdf},
  journal = {Nature Neuroscience},
  keywords = {arousal,atropine,basal ganglia,c-fos,c-Fos,cerebral cortex,rat},
  number = {4},
  pmid = {21333525}
}

@article{kriegeskorte_bandettini_2008,
  title = {Representational Similarity Analysis - Connecting the Branches of Systems Neuroscience.},
  author = {Kriegeskorte, Nikolaus and Mur, Marieke and a. Bandettini, Peter},
  year = {2008},
  volume = {2},
  pages = {4},
  issn = {1662-5137},
  doi = {10.3389/neuro.06.004.2008},
  abstract = {A FUNDAMENTAL CHALLENGE FOR SYSTEMS NEUROSCIENCE IS TO QUANTITATIVELY RELATE ITS THREE MAJOR BRANCHES OF RESEARCH: brain-activity measurement, behavioral measurement, and computational modeling. Using measured brain-activity patterns to evaluate computational network models is complicated by the need to define the correspondency between the units of the model and the channels of the brain-activity data, e.g., single-cell recordings or voxels from functional magnetic resonance imaging (fMRI). Similar correspondency problems complicate relating activity patterns between different modalities of brain-activity measurement (e.g., fMRI and invasive or scalp electrophysiology), and between subjects and species. In order to bridge these divides, we suggest abstracting from the activity patterns themselves and computing representational dissimilarity matrices (RDMs), which characterize the information carried by a given representation in a brain or model. Building on a rich psychological and mathematical literature on similarity analysis, we propose a new experimental and data-analytical framework called representational similarity analysis (RSA), in which multi-channel measures of neural activity are quantitatively related to each other and to computational theory and behavior by comparing RDMs. We demonstrate RSA by relating representations of visual objects as measured with fMRI in early visual cortex and the fusiform face area to computational models spanning a wide range of complexities. The RDMs are simultaneously related via second-level application of multidimensional scaling and tested using randomization and bootstrap techniques. We discuss the broad potential of RSA, including novel approaches to experimental design, and argue that these ideas, which have deep roots in psychology and neuroscience, will allow the integrated quantitative analysis of data from all three branches, thus contributing to a more unified systems neuroscience.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\N2AWDX5T\\Kriegeskorte, Mur, Bandettini - 2008 - Representational similarity analysis - connecting the branches of systems neuroscience.pdf},
  journal = {Frontiers in systems neuroscience},
  keywords = {computational modeling,electrophysiology,fmri,population code,representation,similarity},
  number = {November},
  pmid = {19104670}
}

@article{kriegeskorte_douglas_2018,
  title = {Cognitive Computational Neuroscience},
  author = {Kriegeskorte, Nikolaus and Douglas, Pamela K},
  year = {2018},
  issn = {1097-6256},
  doi = {10.1038/s41593-018-0210-5},
  abstract = {To learn how cognition is implemented in the brain, we must build computational models that can perform cognitive tasks, and test such models with brain and behavioral experiments. Cognitive science has developed computational models that decompose cognition into functional components. Computational neuroscience has modeled how interacting neurons can implement elementary components of cognition. It is time to assemble the pieces of the puzzle of brain computation and to better integrate these separate disciplines. Modern technologies enable us to measure and manipulate brain activity in unprecedentedly rich ways in animals and humans. However, experiments will yield theoretical insight only when employed to test brain-computational models. Here we review recent work in the intersection of cognitive science, computational neuroscience and artificial intelligence. Computational models that mimic brain information processing during perceptual, cognitive and control tasks are beginning to be developed and tested with brain and behavioral data.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KCCUNQYL\\Kriegeskorte, Douglas - Unknown - Cognitive computational neuroscience(3).pdf},
  journal = {Nature Neuroscience},
  pmid = {29500078}
}

@article{kriete_oreilly_2013,
  title = {Indirection and Symbol-like Processing in the Prefrontal Cortex and Basal Ganglia},
  author = {Kriete, T. and Noelle, D. C. and Cohen, J. D. and O'Reilly, Randall C},
  year = {2013},
  volume = {110},
  pages = {16390--16395},
  issn = {0027-8424},
  doi = {10.1073/pnas.1303547110},
  abstract = {The ability to flexibly, rapidly, and accurately perform novel tasks is a hallmark of human behavior. In our everyday lives we are often faced with arbitrary instructions that we must understand and follow, and we are able to do so with remarkable ease. It has frequently been argued that this ability relies on symbol processing, which depends critically on the ability to represent variables and bind them to arbitrary values. Whereas symbol processing is a fundamental feature of all computer systems, it remains a mystery whether and how this ability is carried out by the brain. Here, we provide an example of how the structure and functioning of the prefrontal cortex/basal ganglia working memory system can support variable binding, through a form of indirection (akin to a pointer in computer science). We show how indirection enables the system to flexibly generalize its behavior substantially beyond its direct experience (i.e., systematicity). We argue that this provides a biologically plausible mechanism that approximates a key component of symbol processing, exhibiting both the flexibility, but also some of the limitations, that are associated with this ability in humans.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\G2BQVVIE\\Kriete et al. - 2013 - Indirection and symbol-like processing in the prefrontal cortex and basal ganglia(3).pdf},
  journal = {Proceedings of the National Academy of Sciences},
  keywords = {Basal Ganglia,Basal Ganglia: physiology,Cognition,Cognition: physiology,Humans,Models,Neurological,Neurons,Neurons: metabolism,Prefrontal Cortex,Prefrontal Cortex: physiology,Symbolism},
  number = {41},
  pmid = {24062434}
}

@article{krishnagopal_krishnagopal_,
  title = {{{UNCOVERING PATTERNS IN COMPLEX DATA WITH RESERVOIR COMPUTING AND NETWORK ANALYTICS}}: {{A DYNAMICAL SYSTEMS APPROACH}}},
  author = {Krishnagopal, Sanjukta},
  pages = {149},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9MS5YW3P\\Krishnagopal - UNCOVERING PATTERNS IN COMPLEX DATA WITH RESERVOIR.pdf},
  language = {en}
}

@article{kropff_moser_2015,
  title = {Speed Cells in the Medial Entorhinal Cortex},
  author = {Kropff, Emilio and Carmichael, James E and Moser, May-Britt and Moser, Edvard I},
  year = {2015},
  issn = {0028-0836},
  doi = {10.1038/nature14622},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZUU7887G\\Kropff et al. - 2015 - Speed cells in the medial entorhinal cortex.pdf},
  journal = {Nature}
}

@article{krotov_hopfield_2020,
  title = {Large {{Associative Memory Problem}} in {{Neurobiology}} and {{Machine Learning}}},
  author = {Krotov, Dmitry and Hopfield, John},
  year = {2020},
  month = aug,
  abstract = {Dense Associative Memories or modern Hopfield networks permit storage and reliable retrieval of an exponentially large (in the dimension of feature space) number of memories. At the same time, their naive implementation is non-biological, since it seemingly requires the existence of many-body synaptic junctions between the neurons. We show that these models are effective descriptions of a more microscopic (written in terms of biological degrees of freedom) theory that has additional (hidden) neurons and only requires two-body interactions between them. For this reason our proposed microscopic theory is a valid model of large associative memory with a degree of biological plausibility. The dynamics of our network and its reduced dimensional equivalent both minimize energy (Lyapunov) functions. When certain dynamical variables (hidden neurons) are integrated out from our microscopic theory, one can recover many of the models that were previously discussed in the literature, e.g. the model presented in ''Hopfield Networks is All You Need'' paper. We also provide an alternative derivation of the energy function and the update rule proposed in the aforementioned paper and clarify the relationships between various models of this class.},
  archivePrefix = {arXiv},
  eprint = {2008.06996},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UV45D6UF\\krotov_hopfield_2020.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\KNNYLJN6\\2008.html},
  journal = {arXiv:2008.06996 [q-bio]},
  keywords = {Quantitative Biology - Neurons and Cognition},
  primaryClass = {q-bio}
}

@techreport{kruijne_olivers_2019,
  title = {Flexible Working Memory through Selective Gating and Attentional Tagging},
  author = {Kruijne, Wouter and Bohte, Sander M. and Roelfsema, Pieter R. and Olivers, Christian N. L.},
  year = {2019},
  month = nov,
  institution = {{Neuroscience}},
  doi = {10.1101/846675},
  abstract = {Working memory is essential for intelligent behavior as it serves to guide behavior of humans and nonhuman primates when task-relevant stimuli are no longer present to the senses. Moreover, complex tasks often require that multiple working memory representations can be flexibly and independently maintained, prioritized, and updated according to changing task demands. Thus far, neural network models of working memory have been unable to offer an integrative account of how such control mechanisms are implemented in the brain and how they can be acquired in a biologically plausible manner. Here, we present WorkMATe, a neural network architecture that models cognitive control over working memory content and learns the appropriate control operations needed to solve complex working memory tasks. Key components of the model include a gated memory circuit that is controlled by internal actions, encoding sensory information through untrained connections, and a neural circuit that matches sensory inputs to memory content. The network is trained by means of a biologically plausible reinforcement learning rule that relies on attentional feedback and reward prediction errors to guide synaptic updates. We demonstrate that the model successfully acquires policies to solve classical working memory tasks, such as delayed match-to-sample and delayed pro-saccade/antisaccade tasks. In addition, the model solves much more complex tasks including the hierarchical 12-AX task or the ABAB ordered recognition task, which both demand an agent to independently store and updated multiple items separately in memory. Furthermore, the control strategies that the model acquires for these tasks subsequently generalize to new task contexts with novel stimuli. As such, WorkMATe provides a new solution for the neural implementation of flexible memory control.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XNFIKV86\\Kruijne et al. - 2019 - Flexible working memory through selective gating a.pdf},
  language = {en},
  type = {Preprint}
}

@article{krumin_shoham_2010,
  title = {Multivariate {{Autoregressive Modeling}} and {{Granger Causality Analysis}} of {{Multiple Spike Trains}}},
  author = {Krumin, Michael and Shoham, Shy},
  year = {2010},
  volume = {2010},
  pages = {1--9},
  issn = {1687-5265},
  doi = {10.1155/2010/752428},
  abstract = {\textbackslash textlessp\textbackslash textgreaterRecent years have seen the emergence of microelectrode arrays and optical methods allowing simultaneous recording of spiking activity from populations of neurons in various parts of the nervous system. The analysis of multiple neural spike train data could benefit significantly from existing methods for multivariate time-series analysis which have proven to be very powerful in the modeling and analysis of continuous neural signals like EEG signals. However, those methods have not generally been well adapted to point processes. Here, we use our recent results on correlation distortions in multivariate Linear-Nonlinear-Poisson spiking neuron models to derive generalized Yule-Walker-type equations for fitting ``hidden'' Multivariate Autoregressive models. We use this new framework to perform Granger causality analysis in order to extract the directed information flow pattern in networks of simulated spiking neurons. We discuss the relative merits and limitations of the new method.\textbackslash textless/p\textbackslash textgreater},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\45EMTIU8\\Krumin, Shoham - 2010 - Multivariate Autoregressive Modeling and Granger Causality Analysis of Multiple Spike Trains.pdf},
  journal = {Computational Intelligence and Neuroscience},
  pmid = {20454705}
}

@article{krupic_okeefe_2015,
  title = {Grid Cell Symmetry Is Shaped by Environmental Geometry},
  author = {Krupic, Julija and Bauza, Marius and Burton, Stephen and Barry, Caswell and O'Keefe, John},
  year = {2015},
  volume = {518},
  pages = {232--235},
  issn = {0028-0836},
  doi = {10.1038/nature14153},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PMCVGWLU\\Krupic et al. - 2015 - Grid cell symmetry is shaped by environmental geometry.pdf},
  journal = {Nature},
  number = {7538}
}

@article{kruskal_lieber_2015,
  title = {Beyond the {{Patch Clamp}}: {{Nanotechnologies}} for {{Intracellular Recording}}},
  author = {Kruskal, Peter B and Jiang, Zhe and Gao, Teng and Lieber, Charles M},
  year = {2015},
  volume = {86},
  pages = {21--24},
  issn = {08966273},
  doi = {10.1016/j.neuron.2015.01.004},
  abstract = {The patch clamp is a fundamental tool for neuroscientists, offering insights that have shaped our understand- ing of the brain. Advances in nanotechnology suggest that the next generation of recording methods is now within reach.We discuss the complexity and future promise of applying nanoscience to neural recording.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZEL3UW3A\\Kruskal et al. - 2015 - Beyond the Patch Clamp Nanotechnologies for Intracellular Recording.pdf},
  journal = {Neuron},
  number = {1},
  pmid = {25856481}
}

@article{kuehn_sereno_2018,
  title = {Modelling the {{Human Cortex}} in {{Three Dimensions}}},
  author = {Kuehn, Esther and Sereno, Martin I.},
  year = {2018},
  month = dec,
  volume = {22},
  pages = {1073--1075},
  issn = {1879307X},
  doi = {10.1016/j.tics.2018.08.010},
  abstract = {In cognitive neuroscience, brain-behaviour relationships are usually mapped onto a 2D cortical sheet. Cortical layers are a critical but often ignored third dimension of human cortical function. Improved resolution has put us on the threshold of beginning to image human cognition in three dimensions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2IXFSRAX\\Kuehn, Sereno - 2018 - Modelling the Human Cortex in Three Dimensions.pdf},
  journal = {Trends in Cognitive Sciences},
  keywords = {laminar modelling,MRI,multisensory integration,ultra-high field imaging},
  number = {12},
  pmid = {30236490}
}

@article{kuhlmann_cook_2018,
  title = {Epilepsyecosystem.Org: Crowd-Sourcing Reproducible Seizure Prediction with Long-Term Human Intracranial {{EEG}}},
  author = {Kuhlmann, Levin and Karoly, Philippa and Freestone, Dean R and Brinkmann, Benjamin H and Temko, Andriy and Barachant, Alexandre and Li, Feng and Titericz, Gilberto and Lang, Brian W and Lavery, Daniel and Roman, Kelly and Broadhead, Derek and Dobson, Scott and Jones, Gareth and Tang, Qingnan and Ivanenko, Irina and Panichev, Oleg and Proix, Timoth{\'e}e and N{\'a}hl{\'i}k, Michal and Grunberg, Daniel B and Reuben, Chip and Worrell, Gregory and Litt, Brian and Liley, David T J and Grayden, David B and Cook, Mark J},
  year = {2018},
  issn = {0006-8950},
  doi = {10.1093/brain/awy210},
  abstract = {Accurate seizure prediction will transform epilepsy management by offering warnings to patients or triggering interventions. However, state-of-the-art algorithm design relies on accessing adequate long-term data. Crowd-sourcing ecosystems leverage quality data to enable cost-effective, rapid development of predictive algorithms. A crowd-sourcing ecosystem for seizure prediction is presented involving an international competition, a follow-up held-out data evaluation, and an online platform, Epilepsyecosystem.org, for yielding further improvements in prediction performance. Crowd-sourced algorithms were obtained via the 'Melbourne-University AES-MathWorks-NIH Seizure Prediction Challenge' conducted at kaggle.com. Long-term continuous intracranial electroencephalography (iEEG) data (442 days of recordings and 211 lead seizures per patient) from prediction-resistant patients who had the lowest seizure prediction performances from the NeuroVista Seizure Advisory System clinical trial were analysed. Contestants (646 individuals in 478 teams) from around the world developed algorithms to distinguish between 10-min inter-seizure versus pre-seizure data clips. Over 10 000 algorithms were submitted. The top algorithms as determined by using the contest data were evaluated on a much larger held-out dataset. The data and top algorithms are available online for further investigation and development. The top performing contest entry scored 0.81 area under the classification curve. The performance reduced by only 6.7\% on held-out data. Many other teams also showed high prediction reproducibility. Pseudo-prospective evaluation demonstrated that many algorithms, when used alone or weighted by circadian information, performed better than the benchmarks, including an average increase in sensitivity of 1.9 times the original clinical trial sensitivity for matched time in warning. These results indicate that clinically-relevant seizure prediction is possible in a wider range of patients than previously thought possible. Moreover, different algorithms performed best for different patients, supporting the use of patient-specific algorithms and long-term monitoring. The crowd-sourcing ecosystem for seizure prediction will enable further worldwide community study of the data to yield greater improvements in prediction performance by way of competition, collaboration and synergism.10.1093/brain/awy210\_video1awy210media15817489051001.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8DXPNYED\\Kuhlmann et al. - 2018 - Epilepsyecosystem.org crowd-sourcing reproducible seizure prediction with long-term human intracranial EEG.pdf},
  journal = {Brain},
  keywords = {epilepsy,iEEG = intracranial electroencephalography,intracranial EEG,Open Data Ecosystem for the Neurosciences Abbrevia,refractory epilepsy,ROC = receiver operating characteristic,seizure prediction},
  pmid = {30101347}
}

@techreport{kuljis_barth_2020,
  title = {Transient and Layer-Specific Reduction in Neocortical {{PV}} Inhibition during Sensory Association Learning},
  author = {Kuljis, Dika A. and Park, Eunsol and Myal, Stephanie E. and Clopath, Claudia and Barth, Alison L.},
  year = {2020},
  month = apr,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.04.24.059865},
  abstract = {Abstract           Sensory and motor learning reorganizes neocortical circuitry, particularly manifested in the strength of excitatory synapses. Prior studies suggest reduced inhibition can facilitate glutamatergic synapse plasticity during learning, but the role of specific inhibitory neurons in this process has not been well-documented. Here we investigate whether inhibition from parvalbumin (PV)-expressing neurons is altered in primary somatosensory cortex in mice trained in a whisker-based reward-association task. Anatomical and electrophysiological analyses show PV input to L2/3, but not L5, pyramidal (Pyr) neurons is rapidly suppressed during early stages of sensory training, effects that are reversed after longer training periods. Importantly, sensory stimulation without reward does not alter PV-mediated inhibition. Computational modeling indicates that reduced PV inhibition in L2/3 selectively enables an increase in translaminar recurrent activity, also observed during SAT. PV disinhibition in superficial layers of the neocortex may be one of the earliest changes in learning-dependent rewiring of the cortical column.                        Impact statement             Tactile learning is associated with reduced PV inhibition in superficial layers of somatosensory cortex. Modeling studies suggest that PV disinhibition can support prolonged recurrent activity initiated by thalamic input.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\86CYRCT9\\Kuljis et al. - 2020 - Transient and layer-specific reduction in neocorti.pdf},
  language = {en},
  type = {Preprint}
}

@article{kulkarni_gershman_2016,
  title = {Deep {{Successor Reinforcement Learning}}},
  author = {Kulkarni, Tejas D and Saeedi, Ardavan and Gautam, Simanta and Gershman, Samuel J},
  year = {2016},
  abstract = {Learning robust value functions given raw observations and rewards is now possible with model-free and model-based deep reinforcement learning algorithms. There is a third alternative, called Successor Representations (SR), which decomposes the value function into two components \textendash{} a reward predictor and a successor map. The successor map represents the expected future state occupancy from any given state and the reward predictor maps states to scalar rewards. The value function of a state can be computed as the inner product between the successor map and the reward weights. In this paper, we present DSR, which generalizes SR within an end-to-end deep reinforcement learning framework. DSR has several appealing properties including: increased sensitivity to distal reward changes due to factorization of reward and world dynamics, and the ability to extract bottleneck states (subgoals) given successor maps trained under a random policy. We show the efficacy of our approach on two diverse environments given raw pixel observations \textendash{} simple grid-world domains (MazeBase) and the Doom game engine.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4EHYPVIX\\Kulkarni et al. - Unknown - Deep Successor Reinforcement Learning.pdf},
  journal = {arXiv}
}

@techreport{kulkarni_hakim_2020,
  title = {Synchronization, Stochasticity and Phase Waves in Neuronal Networks with Spatially-Structured Connectivity},
  author = {Kulkarni, Anirudh and Ranft, Jonas and Hakim, Vincent},
  year = {2020},
  month = jun,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.06.04.134940},
  abstract = {Oscillations in the beta/low gamma range (10-45 Hz) are recorded in diverse neural structures. They have successfully been modeled as sparsely synchronized oscillations arising from reciprocal interactions between randomly connected excitatory (E) pyramidal cells and local interneurons (I). The synchronization of spatially distant oscillatory spiking E-I modules has been well studied in the rate model framework but less so for modules of spiking neurons. Here, we first show that previously proposed modifications of rate models provide a quantitative description of spiking E-I modules of Exponential Integrate-and-Fire (EIF) neurons. This allows us to analyze the dynamical regimes of sparsely synchronized oscillatory E-I modules connected by long-range excitatory interactions, for two modules, as well as for a chain of such modules. For modules with a large number of neurons ({$>$} 105), we obtain results similar to previously obtained ones based on the classic deterministic Wilson-Cowan rate model, with the added bonus that the results quantitatively describe simulations of spiking EIF neurons. However, for modules with a moderate ({$\sim$} 104) number of neurons, stochastic variations in the spike emission of neurons are important and need to be taken into account. On the one hand, they modify the oscillations in a way that tends to promote synchronization between different modules. On the other hand, independent fluctuations on different modules tend to disrupt synchronization. The correlations between distant oscillatory modules can be described by stochastic equations for the oscillator phases that have been intensely studied in other contexts. On shorter distances, we develop a description that also takes into account amplitude modes and that quantitatively accounts for our simulation data. Stochastic dephasing of neighboring modules produces transient phase gradients and the transient appearance of phase waves. We propose that these stochastically-induced phase waves provide an explanative framework for the observations of traveling waves in the cortex during beta oscillations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NE6I2NI6\\Kulkarni et al. - 2020 - Synchronization, stochasticity and phase waves in .pdf},
  language = {en},
  type = {Preprint}
}

@article{kulvicius_worgotter_2008,
  title = {Odor Supported Place Cell Model and Goal Navigation in Rodents},
  author = {Kulvicius, Tomas and Tamosiunaite, Minija and Ainge, James and Dudchenko, Paul and W{\"o}rg{\"o}tter, Florentin},
  year = {2008},
  volume = {25},
  pages = {481--500},
  issn = {09295313},
  doi = {10.1007/s10827-008-0090-x},
  abstract = {Experiments with rodents demonstrate that visual cues play an important role in the control of hippocampal place cells and spatial navigation. Nevertheless, rats may also rely on auditory, olfactory and somatosensory stimuli for orientation. It is also known that rats can track odors or self-generated scent marks to find a food source. Here we model odor supported place cells by using a simple feed-forward network and analyze the impact of olfactory cues on place cell formation and spatial navigation. The obtained place cells are used to solve a goal navigation task by a novel mechanism based on self-marking by odor patches combined with a Q-learning algorithm. We also analyze the impact of place cell remapping on goal directed behavior when switching between two environments. We emphasize the importance of olfactory cues in place cell formation and show that the utility of environmental and self-generated olfactory cues, together with a mixed navigation strategy, improves goal directed navigation.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MXREBDSX\\Kulvicius et al. - 2008 - Odor supported place cell model and goal navigation in rodents.pdf},
  journal = {Journal of Computational Neuroscience},
  keywords = {Place cell directionality,Q-learning,Reinforcement learning,Remapping,Self-marking navigation},
  number = {3},
  pmid = {18431616}
}

@article{kumaran_mcclelland_2016,
  title = {What {{Learning Systems}} Do {{Intelligent Agents Need}}? {{Complementary Learning Systems Theory Updated}}},
  author = {Kumaran, Dharshan and Hassabis, Demis and McClelland, James L},
  year = {2016},
  volume = {20},
  pages = {512--534},
  issn = {1879307X},
  doi = {10.1016/j.tics.2016.05.004},
  abstract = {We update complementary learning systems (CLS) theory, which holds that intelligent agents must possess two learning systems, instantiated in mammalians in neocortex and hippocampus. The first gradually acquires structured knowledge representations while the second quickly learns the specifics of individual experiences. We broaden the role of replay of hippocampal memories in the theory, noting that replay allows goal-dependent weighting of experience statistics. We also address recent challenges to the theory and extend it by showing that recurrent activation of hippocampal traces can support some forms of generalization and that neocortical learning can be rapid for information that is consistent with known structure. Finally, we note the relevance of the theory to the design of artificial intelligent agents, highlighting connections between neuroscience and machine learning.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\G6X686SP\\Kumaran, Hassabis, McClelland - 2016 - What Learning Systems do Intelligent Agents Need Complementary Learning Systems Theory Updated.pdf},
  journal = {Trends in Cognitive Sciences},
  keywords = {Artificial intelligence,Hippocampus,Learning,Memory},
  number = {7},
  pmid = {27315762}
}

@article{kumarasinghe_taylor_2020,
  title = {Deep Learning and Deep Knowledge Representation in {{Spiking Neural Networks}} for {{Brain}}-{{Computer Interfaces}}},
  author = {Kumarasinghe, Kaushalya and Kasabov, Nikola and Taylor, Denise},
  year = {2020},
  month = jan,
  volume = {121},
  pages = {169--185},
  issn = {08936080},
  doi = {10.1016/j.neunet.2019.08.029},
  abstract = {Objective: This paper argues that Brain-Inspired Spiking Neural Network (BI-SNN) architectures can learn and reveal deep in time-space functional and structural patterns from spatio-temporal data. These patterns can be represented as deep knowledge, in a partial case in the form of deep spatio-temporal rules. This is a promising direction for building new types of Brain-Computer Interfaces called BrainInspired Brain\textendash Computer Interfaces (BI-BCI). A theoretical framework and its experimental validation on deep knowledge extraction and representation using SNN are presented. Results: The proposed methodology was applied in a case study to extract deep knowledge of the functional and structural organisation of the brain's neural network during the execution of a Grasp and Lift task. The BI-BCI successfully extracted the neural trajectories that represent the dorsal and ventral visual information processing streams as well as its connection to the motor cortex in the brain. Deep spatiotemporal rules on functional and structural interaction of distinct brain areas were then used for event prediction in BI-BCI. Significance: The computational framework can be used for unveiling the topological patterns of the brain and such knowledge can be effectively used to enhance the state-of-the-art in BCI.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LGSNTTKB\\Kumarasinghe et al. - 2020 - Deep learning and deep knowledge representation in.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\ZP8Z98S8\\Kumarasinghe et al. - 2020 - Deep learning and deep knowledge representation in.pdf},
  journal = {Neural Networks},
  language = {en}
}

@article{kunda_goel_2013,
  title = {A Computational Model for Solving Problems from the {{Raven}}'s {{Progressive Matrices}} Intelligence Test Using Iconic Visual Representations},
  author = {Kunda, Maithilee and McGreggor, Keith and Goel, Ashok K},
  year = {2013},
  volume = {22-23},
  pages = {47--66},
  issn = {13890417},
  doi = {10.1016/j.cogsys.2012.08.001},
  abstract = {We describe a computational model for solving problems from Raven's Progressive Matrices (RPM), a family of standardized intelligence tests. Existing computational models for solving RPM problems generally reason over amodal propositional representations of test inputs. However, there is considerable evidence that humans can also apply imagery-based reasoning strategies to RPM problems, in which processes rooted in perception operate over modal representations of test inputs. In this paper, we present the " affine model," a computational model that simulates modal reasoning by using iconic visual representations together with affine and set transformations over these representations to solve a given RPM problem. Various configurations of the affine model successfully solve between 33 and 38 of the 60 problems on the Standard Progressive Matrices, which matches levels of performance for typically developing 9- to 11-year-old children. This suggests that, for at least a sizeable subset of RPM problems, it is not always necessary to extract amodal symbols in order to arrive at the correct answer, and iconic visual representations constitute a sufficient form of representation to successfully solve these problems. We intend for the affine model to serve as a complementary computational account to existing propositional models, which together may provide an integrated, dual-process account of human problem solving on the RPM. \textcopyright{} 2012 Elsevier B.V..},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZT92ZLBW\\Kunda, Mcgreggor, Goel - 2013 - A computational model for solving problems from the Raven's Progressive Matrices intelligence test using.pdf},
  journal = {Cognitive Systems Research},
  keywords = {analogy,Iconic representations,Intelligence tests,Mental imagery,Raven's Progressive Matrices}
}

@article{kunz_axmacher_2019,
  title = {Mesoscopic {{Neural Representations}} in {{Spatial Navigation}}},
  author = {Kunz, Lukas and Maidenbaum, Shachar and Chen, Dong and Wang, Liang and Jacobs, Joshua and Axmacher, Nikolai},
  year = {2019},
  month = jul,
  volume = {23},
  pages = {615--630},
  issn = {13646613},
  doi = {10.1016/j.tics.2019.04.011},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5854DF3V\\Kunz et al. - 2019 - Mesoscopic Neural Representations in Spatial Navig.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\J2F5M8QA\\Kunz et al. - 2019 - Mesoscopic Neural Representations in Spatial Navig.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {7}
}

@article{kushnir_deneve_2019,
  title = {Learning Temporal Structure of the Input with a Network of Integrate-and-Fire Neurons},
  author = {Kushnir, Lyudmila and Den{\`e}ve, Sophie},
  year = {2019},
  month = dec,
  abstract = {The task of the brain is to look for structure in the external input. We study a network of integrateand-fire neurons with several types of recurrent connections that learns the structure of its time-varying feedforward input by attempting to efficiently represent this input with spikes. The efficiency of the representation arises from incorporating the structure of the input into the decoder, which is implicit in the learned synaptic connectivity of the network. While in the original work of [Boerlin, Machens, Den`eve 2013] and [Brendel et al., 2017] the structure learned by the network to make the representation efficient was the low-dimensionality of the feedforward input, in the present work it is its temporal dynamics. The network achieves the efficiency by adjusting its synaptic weights in such a way, that for any neuron in the network, the recurrent input cancels the feedforward for most of the time. We show that if the only temporal structure that the input possesses is that it changes slowly on the time scale of neuronal integration, the dimensionality of the network dynamics is equal to the dimensionality of the input. However, if the input follows a linear differential equation of the first order, the efficiency of the representation can be increased by increasing the dimensionality of the network dynamics in comparison to the dimensionality of the input. If there is only one type of slow synaptic current in the network, the increase is two-fold, while if there are two types of slow synaptic currents that decay with different rates and whose amplitudes can be adjusted separately, it is advantageous to make the increase three-fold. We numerically simulate the network with synaptic weights that imply the most efficient input representation in the above cases. We also propose a learning rule by means of which the corresponding synaptic weights can be learned.},
  archivePrefix = {arXiv},
  eprint = {1912.10262},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\J4SZNQ8B\\Kushnir and Denève - 2019 - Learning temporal structure of the input with a ne.pdf},
  journal = {arXiv:1912.10262 [q-bio]},
  language = {en},
  primaryClass = {q-bio}
}

@article{kutter_nieder_2018,
  title = {Single {{Neurons}} in the {{Human Brain Encode Numbers Article Single Neurons}} in the {{Human Brain Encode Numbers}}},
  author = {Kutter, Esther F and Bostroem, Jan and Elger, Christian E and Mormann, Florian and Correspondence, Andreas Nieder and Nieder, Andreas},
  year = {2018},
  volume = {100},
  doi = {10.1016/j.neuron.2018.08.036},
  abstract = {Highlights d Single neurons in the human medial temporal lobe (MTL) encode numerical information d Numerosity and abstract numerals are encoded by distinct neuronal populations d Numerosity representation shows a distance effect; numerals are encoded categorically d Representation of symbolic numerals may evolve from numerosity representations In Brief Kutter et al. show how nonsymbolic and symbolic numerical quantity is encoded in the human brain by neurons of the medial temporal lobe. The data support the hypothesis that high-level human numerical abilities are rooted in biologically determined mechanisms.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KQP7JFVK\\Kutter et al. - 2018 - Single Neurons in the Human Brain Encode Numbers Article Single Neurons in the Human Brain Encode Numbers.pdf},
  journal = {Neuron}
}

@article{kuzovkin_aru_2018,
  title = {Activations of {{Deep Convolutional Neural Network}} Are {{Aligned}} with {{Gamma Band Activity}} of {{Human Visual Cortex}}},
  author = {Kuzovkin, Ilya and Vicente, Raul and Petton, Mathilde and Lachaux, Jean-Philippe and Baciu, Monica and Kahane, Philippe and Rheims, Sylvain and Vidal, Juan R. and Aru, Jaan},
  year = {2018},
  month = feb,
  pages = {133694},
  doi = {10.1101/133694},
  abstract = {Previous work demonstrated a direct correspondence between the hierarchy of the human visual areas and layers of deep convolutional neural networks (DCNN) trained on visual object recognition. We used DCNNs to investigate which frequency bands correlate with feature transformations of increasing complexity along the ventral visual pathway. By capitalizing on intracranial depth recordings from 100 patients and 11293 electrodes we assessed the alignment between the DCNN and signals at different frequency bands in different time windows. We found that gamma activity, especially in the lower spectrum (30-70 Hz), matched the increasing complexity of visual feature representations in the DCNN. These findings show that the activity of the DCNN captures the essential characteristics of biological object recognition not only in space and time, but also in the frequency domain. These results also demonstrate the potential that modern artificial intelligence algorithms have in advancing our understanding of the brain.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QUK7F9EL\\Kuzovkin et al. - 2018 - Activations of Deep Convolutional Neural Network are Aligned with Gamma Band Activity of Human Visual Cortex.pdf},
  journal = {bioRxiv}
}

@article{kveraga_bar_2007,
  title = {Top-down Predictions in the Cognitive Brain},
  author = {Kveraga, Kestutis and Ghuman, Avniel S. and Bar, Moshe},
  year = {2007},
  volume = {65},
  pages = {145--168},
  issn = {02782626},
  doi = {10.1016/j.bandc.2007.06.007},
  abstract = {The human brain is not a passive organ simply waiting to be activated by external stimuli. Instead, we propose that the brain continuously employs memory of past experiences to interpret sensory information and predict the immediately relevant future. The basic elements of this proposal include analogical mapping, associative representations and the generation of predictions. This review concentrates on visual recognition as the model system for developing and testing ideas about the role and mechanisms of top-down predictions in the brain. We cover relevant behavioral, computational and neural aspects, explore links to emotion and action preparation, and consider clinical implications for schizophrenia and dyslexia. We then discuss the extension of the general principles of this proposal to other cognitive domains. \textcopyright{} 2007 Elsevier Inc. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DPKMHPIB\\Kveraga, Ghuman, Bar - 2007 - Top-down predictions in the cognitive brain.pdf},
  journal = {Brain and Cognition},
  keywords = {Computational methods,Contextual facilitation,Magnetoencephalography,Magnocellular,Neuroimaging,Object recognition,Orbitofrontal cortex,Parvocellular,Priming,Synchrony,Vision,Visual pathways},
  number = {2},
  pmid = {17923222}
}

@inproceedings{kwisthout_rooij_2013,
  title = {Predictive Coding and the {{Bayesian}} Brain: {{Intractability}} Hurdles That Are yet to Be Overcome},
  shorttitle = {Predictive Coding and the {{Bayesian}} Brain},
  booktitle = {{{CogSci}}},
  author = {Kwisthout, Johan and van Rooij, Iris},
  year = {2013},
  abstract = {There is a growing body of evidence that the human brain may be organized according to principles of hierarchical predictive coding. A current conjecture in neuroscience is that a brain organized in this way can effectively and efficiently perform genuine Bayesian inferences. Given that many forms of cognition seem to be well characterized as Bayesian inferences, this conjecture has great import for cognitive science. It suggests that hierarchical predictive coding may provide a neurally plausible account of how forms of cognition that are modeled as Bayesian inference may be physically implemented in the brain. Yet, as we show in this paper, the jury is still out on whether or not the conjecture is really true. Specifically, we demonstrate that each key subcomputation invoked in hierarchical predictive coding potentially hides a computationally intractable problem. We identify ways in which computational modelers may or may not overcome these `intractability hurdles.'},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\96Z2C9M5\\Kwisthout and Rooij - 2013 - Predictive coding and the Bayesian brain Intracta.pdf}
}

@article{lachance_taube_2019,
  title = {A Sense of Space in Postrhinal Cortex},
  author = {LaChance, Patrick A and Todd, Travis P and Taube, Jeffrey S},
  year = {2019},
  pages = {12},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GKD78BQA\\LaChance et al. - 2019 - A sense of space in postrhinal cortex.pdf},
  language = {en}
}

@article{lacy_stark_2013,
  title = {The Neuroscience of Memory: Implications for the Courtroom},
  author = {Lacy, Joyce W and Stark, Craig E L},
  year = {2013},
  volume = {14},
  pages = {649--658},
  issn = {1471-0048},
  doi = {10.1038/nrn3563},
  abstract = {Nature Reviews Neuroscience 14, 649 (2013). doi:10.1038/nrn3563},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LHCHC5DE\\Lacy, Stark - 2013 - The neuroscience of memory implications for the courtroom.pdf},
  journal = {Nature Publishing Group},
  number = {9},
  pmid = {23942467}
}

@article{lake_gershman_2017,
  title = {Building Machines That Learn and Think like People},
  author = {Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.},
  year = {2017},
  month = nov,
  volume = {40},
  pages = {e253},
  issn = {0140-525X},
  doi = {10.1017/S0140525X16001837},
  abstract = {Recent progress in artificial intelligence has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats that of humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn and how they learn it. Specifically, we argue that these machines should (1) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (2) ground learning in intuitive theories of physics and psychology to support and enrich the knowledge that is learned; and (3) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes toward these goals that can combine the strengths of recent neural network advances with more structured cognitive models.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3YI9KPGR\\lake_et_al_2016_building_machines_that_learn_and_think_like_people.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\P2V7TX3Y\\Lake et al. - Unknown - Building Machines That Learn and Think Like People.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\TI3Z23A9\\Lake et al. - Unknown - Building Machines That Learn and Think Like People.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\U3HUQ8ZB\\Lake et al. - 2016 - Building Machines That Learn and Think Like People.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\J6Z3FJR7\\1604.html},
  journal = {Behavioral and Brain Sciences},
  pmid = {1000303116}
}

@article{lake_tenenbaum_2015,
  title = {Human-Level Concept Learning Throgh Probabilistic Program Induction},
  author = {Lake, Brenden M and Salakhutdinov, Ruslan and Tenenbaum, Joshua B},
  year = {2015},
  volume = {350},
  pages = {1332--1338},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4USXSJN5\\Lake, Salakhutdinov, Tenenbaum - 2015 - Human-level concept learning throgh probabilistic program induction.pdf},
  journal = {Science},
  number = {6266}
}

@article{lake_tenenbaum_2015a,
  title = {Human-Level Concept Learning through Probabilistic Program Induction},
  author = {Lake, Brenden M and Salakhutdinov, Ruslan and Tenenbaum, Joshua B},
  year = {2015},
  month = dec,
  volume = {350},
  pages = {1332--1338},
  issn = {10959203},
  doi = {10.1126/science.aab3050},
  abstract = {People learning new concepts can often generalize successfully from just a single example, yet machine learning algorithms typically require tens or hundreds of examples to perform with similar accuracy. People can also use learned concepts in richer ways than conventional algorithms\textemdash for action, imagination, and explanation.We present a computational model that captures these human learning abilities for a large class of simple visual concepts: handwritten characters from the world's alphabets. The model represents concepts as simple programs that best explain observed examples under a Bayesian criterion. On a challenging one-shot classification task, the model achieves human-level performance while outperforming recent deep learning approaches.We also present several ``visual Turing tests'' probing the model's creative generalization abilities, which in many cases are indistinguishable from human behavior.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KRBLDWR2\\Lake, Salakhutdinov, Tenenbaum - Unknown - Human-level concept learning through probabilistic program induction.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\WFYZRN3Z\\Lake, Salakhutdinov, Tenenbaum - 2018 - Human-level concept learning through probabilistic program induction Downloaded from.pdf},
  journal = {Science},
  number = {6266},
  pmid = {26659050}
}

@article{lambonralph_rogers_2016,
  title = {The Neural and Computational Bases of Semantic Cognition},
  author = {Lambon Ralph, Matthew A and Jefferies, Elizabeth and Patterson, Karalyn and Rogers, Timothy T},
  year = {2016},
  volume = {18},
  pages = {1--14},
  issn = {1471-003X},
  doi = {10.1038/nrn.2016.150},
  abstract = {Semantic cognition refers to our ability to use, manipulate and generalise knowledge that is acquired over the lifespan to support innumerable verbal and nonverbal behaviours. This Review summarizes key findings and issues arising from a decade of research into the neurocognitive and neurocomputational underpinnings of this ability, leading to a new framework that we term controlled semantic cognition (CSC). CSC offers solutions to long-standing queries in philosophy and cognitive science, and yields a convergent framework for understanding the neural and computational bases of healthy semantic cognition and its dysfunction in brain disorders.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5CP5Y548\\Lambon Ralph et al. - 2016 - The neural and computational bases of semantic cognition.pdf},
  journal = {Nature Reviews Neuroscience},
  keywords = {semantic memory},
  number = {1},
  pmid = {27881854}
}

@article{lample_charton_2019,
  title = {Deep {{Learning}} for {{Symbolic Mathematics}}},
  author = {Lample, Guillaume and Charton, Fran{\c c}ois},
  year = {2019},
  month = dec,
  abstract = {Neural networks have a reputation for being better at solving statistical or approximate problems than at performing calculations or working with symbolic data. In this paper, we show that they can be surprisingly good at more elaborated tasks in mathematics, such as symbolic integration and solving differential equations. We propose a syntax for representing mathematical problems, and methods for generating large datasets that can be used to train sequence-to-sequence models. We achieve results that outperform commercial Computer Algebra Systems such as Matlab or Mathematica.},
  archivePrefix = {arXiv},
  eprint = {1912.01412},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VELEB4LE\\Lample and Charton - 2019 - Deep Learning for Symbolic Mathematics.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\WNVCSG9H\\Lample and Charton - 2019 - Deep Learning for Symbolic Mathematics.pdf},
  journal = {arXiv:1912.01412 [cs]},
  language = {en},
  primaryClass = {cs}
}

@article{landisman_connors_1993,
  title = {Long-{{Term Modulation}} of {{Electrical Synapses}} in the {{Mammalian Thalamus}}},
  author = {Landisman, Carole E and Connors, Barry W},
  year = {1993},
  month = oct,
  volume = {262},
  pages = {679--685},
  issn = {0036-8075},
  abstract = {Sleep is characterized by synchronized events in billions of synaptically coupled neurons in thalamocortical systems. The activation of a series of neuromodulatory transmitter systems during awakening blocks low-frequency oscillations, induces fast rhythms, and allows the brain to recover full responsiveness. Analysis of cortical and thalamic networks at many levels, from molecules to single neurons to large neuronal assemblies, with a variety of techniques, ranging from intracellular recordings in vivo and in vitro to computer simulations, is beginning to yield insights into the mechanisms of the generation, modulation, and function of brain oscillations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\76QF9G86\\Landisman, Connors - 1993 - Long-Term Modulation of Electrical Synapses in the Mammalian Thalamus.pdf},
  journal = {Science},
  number = {5134}
}

@article{langtangen_langtangen_2016,
  title = {Solving Nonlinear {{ODE}} and {{PDE}} Problems},
  author = {Langtangen, Hans Petter},
  year = {2016},
  pages = {69},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TYJ8UDW8\\Langtangen - Solving nonlinear ODE and PDE problems.pdf},
  language = {en}
}

@article{lara_wallis_2015,
  title = {The {{Role}} of {{Prefrontal Cortex}} in {{Working Memory}}: {{A Mini Review}}},
  author = {Lara, Antonio H and Wallis, Jonathan D},
  year = {2015},
  volume = {9},
  issn = {1662-5137},
  doi = {10.3389/fnsys.2015.00173},
  abstract = {A prominent account of prefrontal cortex (PFC) function is that single neurons within the PFC maintain representations of task-relevant stimuli in working memory. Evidence for this view comes from studies in which subjects hold a stimulus across a delay lasting up to several seconds. Persistent elevated activity in the PFC has been observed in animal models as well as in humans performing these tasks. This persistent activity has been interpreted as evidence for the encoding of the stimulus itself in working memory. However, recent findings have posed a challenge to this notion. A number of recent studies have examined neural data from the PFC and posterior sensory areas, both at the single neuron level in primates, and at a larger scale in humans, and have failed to find encoding of stimulus information in the PFC during tasks with a substantial working memory component. Strong stimulus related information, however, was seen in posterior sensory areas. These results suggest that delay period activity in the PFC might be better understood not as a signature of memory storage per se, but as a top down signal that influences posterior sensory areas where the actual working memory representations are maintained.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VDNYH4HJ\\Lara, Wallis - 2015 - The Role of Prefrontal Cortex in Working Memory A Mini Review.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\Z4PD7CBI\\Lara, Wallis - 2015 - The Role of Prefrontal Cortex in Working Memory A Mini Review.pdf},
  journal = {Frontiers in Systems Neuroscience},
  keywords = {attention,executive function,frontoparietal network,prefrontal cortex,working-memory},
  pmid = {26733825}
}

@book{larkum_larkum_2013,
  title = {A Cellular Mechanism for Cortical Associations: {{An}} Organizing Principle for the Cerebral Cortex},
  author = {Larkum, Matthew},
  year = {2013},
  volume = {36},
  doi = {10.1016/j.tins.2012.11.006},
  abstract = {A basic feature of intelligent systems such as the cerebral cortex is the ability to freely associate aspects of perceived experience with an internal representation of the world and make predictions about the future. Here, a hypothesis is presented that the extraordinary performance of the cortex derives from an associative mechanism built in at the cellular level to the basic cortical neuronal unit: the pyramidal cell. The mechanism is robustly triggered by coincident input to opposite poles of the neuron, is exquisitely matched to the large- and fine-scale architecture of the cortex, and is tightly controlled by local microcircuits of inhibitory neurons targeting subcellular compartments. This article explores the experimental evidence and the implications for how the cortex operates. \textcopyright{} 2012 Elsevier Ltd.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GG9SJU6U\\Larkum - 2013 - A cellular mechanism for cortical associations An organizing principle for the cerebral cortex.pdf},
  isbn = {0166-2236},
  keywords = {Binding,Calcium spike,Dendrite,Feedback,Neocortex,Pyramidal neuron},
  pmid = {23273272}
}

@article{larocque_postle_2013,
  title = {Decoding Attended Information in Short-Term Memory: An {{EEG}} Study.},
  author = {LaRocque, Joshua J and a {Lewis-Peacock}, Jarrod and Drysdale, Andrew T and Oberauer, Klaus and Postle, Bradley R},
  year = {2013},
  volume = {25},
  pages = {127--142},
  issn = {1530-8898},
  doi = {10.1162/jocn_a_00305},
  abstract = {For decades it has been assumed that sustained, elevated neural activity\textendash the so-called active trace\textendash is the neural correlate of the short-term retention of information. However, a recent fMRI study has suggested that this activity may be more related to attention than to retention. Specifically, a multivariate pattern analysis failed to find evidence that information that was outside the focus of attention, but nonetheless in STM, was retained in an active state. Here, we replicate and extend this finding by querying the neural signatures of attended versus unattended information within STM with electroencephalograpy (EEG), a method sensitive to oscillatory neural activity to which the previous fMRI study was insensitive. We demonstrate that in the delay-period EEG activity, there is information only about memory items that are also in the focus of attention. Information about items outside the focus of attention is not detectable. This result converges with the fMRI findings to suggest that, contrary to conventional wisdom, an active memory trace may be unnecessary for the short-term retention of information.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UTWHWQDR\\LaRocque et al. - 2013 - Decoding attended information in short-term memory an EEG study.pdf},
  journal = {Journal of Cognitive Neuroscience},
  keywords = {Attention,Attention: physiology,Electroencephalography,Electroencephalography: instrumentation,Electroencephalography: methods,Female,Humans,Male,Memory,Neuropsychological Tests,Recognition (Psychology),Recognition (Psychology): physiology,Short-Term,Short-Term: physiology,Time Factors},
  number = {1},
  pmid = {23198894}
}

@article{larocque_wagner_2013,
  title = {Global Similarity and Pattern Separation in the Human Medial Temporal Lobe Predict Subsequent Memory},
  author = {LaRocque, K F and Smith, M E and Carr, V A and Witthoft, N and {Grill-Spector}, K and Wagner, A D},
  year = {2013},
  volume = {33},
  pages = {5466--5474},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.4293-12.2013},
  abstract = {Intense debate surrounds the role of medial temporal lobe (MTL) structures in recognition memory. Using high-resolution fMRI and analyses of pattern similarity in humans, we examined the encoding computations subserved by MTL subregions. Specifically, we tested the theory that MTL cortex supports memory by encoding overlapping representations, whereas hippocampus supports memory by encoding pattern-separated representations. Consistent with this view, the relationship between encoding pattern similarity and subsequent memory dissociated MTL cortex and hippocampus: later memory was predicted by greater across-item pattern similarity in perirhinal cortex and in parahippocampal cortex, but greater pattern distinctiveness in hippocampus. Additionally, by comparing neural patterns elicited by individual stimuli regardless of subsequent memory, we found that perirhinal cortex and parahippocampal cortex exhibited differential content sensitivity for multiple stimulus categories, whereas hippocampus failed to demonstrate content sensitivity. These data provide novel evidence that complementary MTL encoding computations subserve declarative memory.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ERN6JQEM\\LaRocque et al. - 2013 - Global similarity and pattern separation in the human medial temporal lobe predict subsequent memory.pdf},
  journal = {Journal of Neuroscience},
  keywords = {Computer-Assisted,Female,Humans,Image Processing,Magnetic Resonance Imaging,Male,Oxygen/blood,Pattern Recognition,Photic Stimulation,Recognition (Psychology)/*physiology,Temporal Lobe/blood supply/*physiology},
  number = {13},
  pmid = {23536062}
}

@article{latimer_pillow_2014,
  title = {Inferring Synaptic Conductances from Spike Trains under a Biophysically Inspired Point Process Model},
  author = {Latimer, Kenneth W and Chichilnisky, E. J. and Rieke, Fred and Pillow, Jonathan W},
  year = {2014},
  pages = {1--9},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TVX9B2TG\\Latimer et al. - 2014 - Inferring synaptic conductances from spike trains under a biophysically inspired point process model.pdf},
  journal = {Nips}
}

@article{lau_paton_2017,
  title = {The Many Worlds Hypothesis of Dopamine Prediction Error: Implications of a Parallel Circuit Architecture in the Basal Ganglia},
  shorttitle = {The Many Worlds Hypothesis of Dopamine Prediction Error},
  author = {Lau, Brian and Monteiro, Tiago and Paton, Joseph J},
  year = {2017},
  month = oct,
  volume = {46},
  pages = {241--247},
  issn = {09594388},
  doi = {10.1016/j.conb.2017.08.015},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VIECYH5N\\Lau et al. - 2017 - The many worlds hypothesis of dopamine prediction .pdf},
  journal = {Current Opinion in Neurobiology},
  language = {en}
}

@article{lau_so_2008,
  title = {Bayesian Mixture of Autoregressive Models},
  author = {Lau, John W. and So, Mike K.P.},
  year = {2008},
  month = sep,
  volume = {53},
  pages = {38--60},
  issn = {01679473},
  doi = {10.1016/j.csda.2008.06.001},
  abstract = {An infinite mixture of autoregressive models is developed. The unknown parameters in the mixture autoregressive model follow a mixture distribution, which is governed by a Dirichlet process prior. One main feature of our approach is the generalization of a finite mixture model by having the number of components unspecified. A Bayesian sampling scheme based on a weighted Chinese restaurant process is proposed to generate partitions of observations. Using the partitions, Bayesian prediction, while accounting for possible model uncertainty, determining the most probable number of mixture components, clustering of time series and outlier detection in time series, can be done. Numerical results from simulated and real data are presented to illustrate the methodology.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WX2RRPEQ\\Lau, So - 2008 - Computational Statistics and Data Analysis Bayesian mixture of autoregressive models.pdf},
  journal = {Computational Statistics \& Data Analysis},
  number = {1}
}

@article{lawrence_delangecorrespondence_2018,
  title = {Laminar {{Organization}} of {{Working Memory Signals}} in {{Human Visual Cortex Highlights}} d {{Early}} Visual Cortex Contains Item-Specific Working Memory Signals},
  author = {Lawrence, Samuel J D and Van Mourik, Tim and Kok, Peter and Koopmans, Peter J and Norris, David G and De Lange Correspondence, Floris P},
  year = {2018},
  volume = {28},
  doi = {10.1016/j.cub.2018.08.043},
  abstract = {In Brief Using high-field MRI, Lawrence et al. show that holding a visual item in working memory leads to top-down activation of the primary visual cortex. This activity is strongest in the agranular layers. These results provide new insights into how bottom-up and top-down signals are deployed in visual cortex.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KRX28L5U\\Lawrence et al. - 2018 - Laminar Organization of Working Memory Signals in Human Visual Cortex Highlights d Early visual cortex contains.pdf},
  journal = {Current Biology}
}

@article{lecun_hinton_2015,
  title = {Deep Learning},
  author = {Lecun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  year = {2015},
  volume = {521},
  pages = {436--444},
  issn = {14764687},
  doi = {10.1038/nature14539},
  abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YVDXXTPG\\Lecun, Bengio, Hinton - 2015 - Deep learning.pdf},
  journal = {Nature},
  number = {7553},
  pmid = {10463930}
}

@article{lee_bengio_2015,
  ids = {lee\_bengio\_2015a},
  title = {Difference {{Target Propagation}}},
  author = {Lee, Dong-Hyun and Zhang, Saizheng and Fischer, Asja and Bengio, Yoshua},
  year = {2015},
  abstract = {Back-propagation has been the workhorse of recent successes of deep learning but it relies on infinitesimal effects (partial derivatives) in order to per-form credit assignment. This could become a serious issue as one considers deeper and more non-linear functions, e.g., consider the extreme case of non-linearity where the relation between parameters and cost is actually discrete. In-spired by the biological implausibility of back-propagation, a few approaches have been proposed in the past that could play a similar credit assignment role. In this spirit, we explore a novel approach to credit assignment in deep networks that we call target propagation. The main idea is to compute targets rather than gradi-ents, at each layer. Like gradients, they are propagated backwards. In a way that is related but different from previously proposed proxies for back-propagation which rely on a backwards network with symmetric weights, target propagation relies on auto-encoders at each layer. Unlike back-propagation, it can be applied even when units exchange stochastic bits rather than real numbers. We show that a linear correction for the imperfectness of the auto-encoders, called difference target propagation, is very effective to make target propagation actually work, leading to results comparable to back-propagation for deep networks with dis-crete and continuous units and denoising auto-encoders and achieving state of the art for stochastic networks.},
  archivePrefix = {arXiv},
  eprint = {1412.7525},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GMW5RYYS\\Lee et al. - 2015 - Difference Target Propagation.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\LDQRXYID\\Lee et al. - Unknown - Difference Target Propagation.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\WH8HCIMY\\1412.html},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing}
}

@book{lee_hempstead_2018,
  title = {New {{Roles}} for an {{Ancient Factor}}},
  author = {Lee, Francis S. and Hempstead, Barbara L.},
  year = {2018},
  doi = {10.1016/j.tins.2018.08.012},
  abstract = {In 1996, Hyejin Kang and Erin Schuman, in search of new functions for the secreted growth factor brain-derived neurotrophic factor (BDNF), identified the protein synthesis requirement of BDNF in regulating synaptic plasticity. This landmark paper identified one of the first tractable pathways in the quest to dissect the complex process of synaptic remodeling and revealed the critical role for this neurotrophin in regulating long-term memory.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JBM8GRU8\\Lengyel - 2018 - The Redemption of Noise Inference with Neural Populations.pdf},
  isbn = {1006;9:14321438},
  keywords = {BDNF,long-term potentiation},
  pmid = {30219601}
}

@article{lee_knierim_2020,
  ids = {lee\_knierim\_2020a},
  title = {Parallel Processing Streams in the Hippocampus},
  author = {Lee, Heekyung and GoodSmith, Douglas and Knierim, James J},
  year = {2020},
  month = oct,
  volume = {64},
  pages = {127--134},
  issn = {09594388},
  doi = {10.1016/j.conb.2020.03.004},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EKI2G2QV\\Lee et al. - 2020 - Parallel processing streams in the hippocampus.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\KJJJ7NHT\\Lee et al. - 2020 - Parallel processing streams in the hippocampus.pdf},
  journal = {Current Opinion in Neurobiology},
  language = {en}
}

@article{lee_kopell_2013,
  title = {Top-{{Down Beta Rhythms Support Selective Attention}} via {{Interlaminar Interaction}}: {{A Model}}},
  author = {Lee, Jung H and Whittington, Miles A and Kopell, Nancy J},
  year = {2013},
  volume = {9},
  issn = {1553734X},
  doi = {10.1371/journal.pcbi.1003164},
  abstract = {Cortical rhythms have been thought to play crucial roles in our cognitive abilities. Rhythmic activity in the beta frequency band, around 20 Hz, has been reported in recent studies that focused on neural correlates of attention, indicating that top-down beta rhythms, generated in higher cognitive areas and delivered to earlier sensory areas, can support attentional gain modulation. To elucidate functional roles of beta rhythms and underlying mechanisms, we built a computational model of sensory cortical areas. Our simulation results show that top-down beta rhythms can activate ascending synaptic projections from L5 to L4 and L2/3, responsible for biased competition in superficial layers. In the simulation, slow-inhibitory interneurons are shown to resonate to the 20 Hz input and modulate the activity in superficial layers in an attention-related manner. The predicted critical roles of these cells in attentional gain provide a potential mechanism by which cholinergic drive can support selective attention.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\74HVIZXJ\\Lee, Whittington, Kopell - 2013 - Top-Down Beta Rhythms Support Selective Attention via Interlaminar Interaction A Model.pdf},
  journal = {PLoS Computational Biology},
  number = {8},
  pmid = {23950699}
}

@article{lee_lee_2012,
  title = {Hippocampal Place Fields Emerge upon Single-Cell Manipulation of Excitability during Behavior.},
  author = {Lee, Doyun and Lin, Bei-Jung and Lee, Albert K},
  year = {2012},
  month = aug,
  volume = {337},
  pages = {849--853},
  issn = {1095-9203},
  doi = {10.1126/science.1221489},
  abstract = {The origin of the spatial receptive fields of hippocampal place cells has not been established. A hippocampal CA1 pyramidal cell receives thousands of synaptic inputs, mostly from other spatially tuned neurons; however, how the postsynaptic neuron's cellular properties determine the response to these inputs during behavior is unknown. We discovered that, contrary to expectations from basic models of place cells and neuronal integration, a small, spatially uniform depolarization of the spatially untuned somatic membrane potential of a silent cell leads to the sudden and reversible emergence of a spatially tuned subthreshold response and place-field spiking. Such gating of inputs by postsynaptic neuronal excitability reveals a cellular mechanism for receptive field origin and may be critical for the formation of hippocampal memory representations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CLNQYNPB\\Lee, Lin, Lee - 2012 - Hippocampal place fields emerge upon single-cell manipulation of excitability during behavior.pdf},
  journal = {Science (New York, N.Y.)},
  keywords = {Animals,CA1 Region,Excitatory Postsynaptic Potentials,Hippocampal,Hippocampal: cytology,Hippocampal: physiology,Memory,Pyramidal Cells,Pyramidal Cells: physiology,Rats,Spatial Behavior,Synapses,Synapses: physiology},
  number = {6096},
  pmid = {22904011}
}

@article{lee_mumford_2003,
  title = {Hierarchical {{Bayesian}} Inference in the Visual Cortex},
  author = {Lee, Tai Sing and Mumford, David},
  year = {2003},
  month = jul,
  volume = {20},
  pages = {1434},
  issn = {1084-7529, 1520-8532},
  doi = {10.1364/JOSAA.20.001434},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RZARTAIW\\Lee and Mumford - 2003 - Hierarchical Bayesian inference in the visual cort.pdf},
  journal = {Journal of the Optical Society of America A},
  language = {en},
  number = {7}
}

@article{lee_pfeiffer_2016,
  title = {Training {{Deep Spiking Neural Networks Using Backpropagation}}},
  author = {Lee, Jun Haeng and Delbruck, Tobi and Pfeiffer, Michael},
  year = {2016},
  month = nov,
  volume = {10},
  issn = {1662-453X},
  doi = {10.3389/fnins.2016.00508},
  abstract = {Deep spiking neural networks (SNNs) hold the potential for improving the latency and energy efficiency of deep neural networks through data-driven event-based computation. However, training such networks is difficult due to the non-differentiable nature of spike events. In this paper, we introduce a novel technique, which treats the membrane potentials of spiking neurons as differentiable signals, where discontinuities at spike times are considered as noise. This enables an error backpropagation mechanism for deep SNNs that follows the same principles as in conventional deep networks, but works directly on spike signals and membrane potentials. Compared with previous methods relying on indirect training and conversion, our technique has the potential to capture the statistics of spikes more precisely. We evaluate the proposed framework on artificially generated events from the original MNIST handwritten digit benchmark, and also on the N-MNIST benchmark recorded with an event-based dynamic vision sensor, in which the proposed method reduces the error rate by a factor of more than three compared to the best previous SNN, and also achieves a higher accuracy than a conventional convolutional neural network (CNN) trained and tested on the same data. We demonstrate in the context of the MNIST task that thanks to their event-driven operation, deep SNNs (both fully connected and convolutional) trained with our method achieve accuracy equivalent with conventional neural networks. In the N-MNIST example, equivalent accuracy is achieved with about five times fewer computational operations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4QMKKCEE\\Lee et al. - 2016 - Training Deep Spiking Neural Networks Using Backpr.pdf},
  journal = {Frontiers in Neuroscience},
  language = {en}
}

@article{leech_cooper_2008,
  title = {Analogy as Relational Priming: {{A}} Developmental and Computational Perspective on the Origins of a Complex Cognitive Skill},
  author = {Leech, Robert and Mareschal, Denis and Cooper, Richard P},
  year = {2008},
  volume = {31},
  issn = {0140-525X},
  doi = {10.1017/S0140525X08004469},
  abstract = {The development of analogical reasoning has traditionally been understood in terms of theories of adult competence. This approach emphasizes structured representations and structure mapping. In contrast, we argue that by taking a developmental perspective, analogical reasoning can be viewed as the product of a substantially different cognitive ability - relational priming. To illustrate this, we present a computational (here connectionist) account where analogy arises gradually as a by-product of pattern completion in a recurrent network. Initial exposure to a situation primes a relation that can then be applied to a novel situation to make an analogy. Relations are represented as transformations between states. The network exhibits behaviors consistent with a broad range of key phenomena from the developmental literature, lending support to the appropriateness of this approach (using low-level cognitive mechanisms) for investigating a domain that has normally been the preserve of high-level models. Furthermore, we present an additional simulation that integrates the relational priming mechanism with deliberative controlled use of inhibition to demonstrate how the framework can be extended to complex analogical reasoning, such as the data from explicit mapping studies in the literature on adults. This account highlights how taking a developmental perspective constrains the theory construction and cognitive modeling processes in a way that differs substantially from that based purely on adult studies, and illustrates how a putative complex cognitive skill can emerge out of a simple mechanism.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PIW87BE2\\Leech, Mareschal, Cooper - 2008 - Analogy as relational priming A developmental and computational perspective on the origins of a comple.pdf},
  journal = {Behavioral and Brain Sciences},
  keywords = {analogy,cognitive development,connectionism,relational priming,transformation similarity},
  number = {04},
  pmid = {18662435}
}

@article{leeid_leeid_2018,
  title = {Ten Simple Rules for Documenting Scientific Software},
  author = {Leeid, Benjamin D},
  year = {2018},
  doi = {10.1371/journal.pcbi.1006561},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EFH7PIDH\\Leeid - 2018 - Ten simple rules for documenting scientific software.pdf}
}

@article{leheron_husain_2017,
  title = {The Anatomy of Apathy: A Neurocognitive Framework for Amotivated Behavior},
  author = {Le Heron, C and Apps., M A J and Husain, M},
  year = {2017},
  issn = {00283932},
  doi = {10.1016/j.neuropsychologia.2017.07.003},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WX38UXX4\\Le Heron, Apps., Husain - 2017 - The anatomy of apathy a neurocognitive framework for amotivated behavior.pdf},
  journal = {Neuropsychologia},
  keywords = {anterior cingulate,Apathy,Decision making,Motivation,Reward,Ventral striatum}
}

@article{leong_niv_2017,
  title = {Dynamic {{Interaction}} between {{Reinforcement Learning}} and {{Attention}} in {{Multidimensional Environments}}},
  author = {Leong, Yuan Chang and Radulescu, Angela and Daniel, Reka and DeWoskin, Vivian and Niv, Yael},
  year = {2017},
  issn = {10974199},
  doi = {10.1016/j.neuron.2016.12.040},
  abstract = {Little is known about the relationship between attention and learning during decision making. Using eye tracking and multivariate pattern analysis of fMRI data, we measured participants' dimensional attention as they performed a trial-and-error learning task in which only one of three stimulus dimensions was relevant for reward at any given time. Analysis of participants' choices revealed that attention biased both value computation during choice and value update during learning. Value signals in the ventromedial prefrontal cortex and prediction errors in the striatum were similarly biased by attention. In turn, participants' focus of attention was dynamically modulated by ongoing learning. Attentional switches across dimensions correlated with activity in a frontoparietal attention network, which showed enhanced connectivity with the ventromedial prefrontal cortex between switches. Our results suggest a bidirectional interaction between attention and learning: attention constrains learning to relevant dimensions of the environment, while we learn what to attend to via trial and error.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NSL8UA45\\Leong et al. - 2017 - Dynamic Interaction between Reinforcement Learning and Attention in Multidimensional Environments.pdf},
  journal = {Neuron},
  keywords = {attention,computational modeling,decision making,fmri,mvpa,prediction error,reinforcement learning,striatum,value,vmPFC},
  pmid = {28103483}
}

@article{lepage_eden_2011,
  title = {The Dependence of Spike Field Coherence on Expected Intensity.},
  author = {Lepage, Kyle Q and a Kramer, Mark and Eden, Uri T},
  year = {2011},
  month = sep,
  volume = {23},
  pages = {2209--41},
  issn = {1530-888X},
  doi = {10.1162/NECO_a_00169},
  abstract = {The coherence between neural spike trains and local-field potential recordings, called spike-field coherence, is of key importance in many neuroscience studies. In this work, aside from questions of estimator performance, we demonstrate that theoretical spike-field coherence for a broad class of spiking models depends on the expected rate of spiking. This rate dependence confounds the phase locking of spike events to field-potential oscillations with overall neuron activity and is demonstrated analytically, for a large class of stochastic models, and in simulation. Finally, the relationship between the spike-field coherence and the intensity field coherence is detailed analytically. This latter quantity is independent of neuron firing rate and, under commonly found conditions, is proportional to the probability that a neuron spikes at a specific phase of field oscillation. Hence, intensity field coherence is a rate-independent measure and a candidate on which to base the appropriate statistical inference of spike field synchrony.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TH57DN3U\\Lepage, Kramer, Eden - 2011 - The dependence of spike field coherence on expected intensity.pdf},
  journal = {Neural computation},
  keywords = {Algorithms,Models,Neurological,Neurons,Neurons: physiology},
  number = {9},
  pmid = {21671792}
}

@article{leroy_cheron_2017,
  title = {Short-Term {{EEG}} Dynamics and Neural Generators Evoked by Navigational Images},
  author = {Leroy, Axelle and Cevallos, Carlos and Cebolla, Ana-maria and Dan, Bernard and Cheron, Guy},
  year = {2017},
  pages = {1--26},
  doi = {10.1371/journal.pone.0178817},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\D4JEG3VU\\Leroy et al. - 2017 - Short-term EEG dynamics and neural generators evoked by navigational images.pdf},
  journal = {PloS one}
}

@article{lesaint_khamassi_2014,
  title = {Modelling {{Individual Differences}} in the {{Form}} of {{Pavlovian Conditioned Approach Responses}}: {{A Dual Learning Systems Approach}} with {{Factored Representations}}},
  author = {Lesaint, Florian and Sigaud, Olivier and Flagel, Shelly B and Robinson, Terry E and Khamassi, Mehdi},
  year = {2014},
  volume = {10},
  issn = {15537358},
  doi = {10.1371/journal.pcbi.1003466},
  abstract = {Reinforcement Learning has greatly influenced models of conditioning, providing powerful explanations of acquired behaviour and underlying physiological observations. However, in recent autoshaping experiments in rats, variation in the form of Pavlovian conditioned responses (CRs) and associated dopamine activity, have questioned the classical hypothesis that phasic dopamine activity corresponds to a reward prediction error-like signal arising from a classical Model-Free system, necessary for Pavlovian conditioning. Over the course of Pavlovian conditioning using food as the unconditioned stimulus (US), some rats (sign-trackers) come to approach and engage the conditioned stimulus (CS) itself - a lever - more and more avidly, whereas other rats (goal-trackers) learn to approach the location of food delivery upon CS presentation. Importantly, although both sign-trackers and goal-trackers learn the CS-US association equally well, only in sign-trackers does phasic dopamine activity show classical reward prediction error-like bursts. Furthermore, neither the acquisition nor the expression of a goal-tracking CR is dopamine-dependent. Here we present a computational model that can account for such individual variations. We show that a combination of a Model-Based system and a revised Model-Free system can account for the development of distinct CRs in rats. Moreover, we show that revising a classical Model-Free system to individually process stimuli by using factored representations can explain why classical dopaminergic patterns may be observed for some rats and not for others depending on the CR they develop. In addition, the model can account for other behavioural and pharmacological results obtained using the same, or similar, autoshaping procedures. Finally, the model makes it possible to draw a set of experimental predictions that may be verified in a modified experimental protocol. We suggest that further investigation of factored representations in computational neuroscience studies may be useful.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NFAJF8SZ\\Lesaint et al. - 2014 - Modelling Individual Differences in the Form of Pavlovian Conditioned Approach Responses A Dual Learning Systems.pdf},
  journal = {PLoS Computational Biology},
  number = {2},
  pmid = {24550719}
}

@article{leshinskaya_thompson-schill_2020,
  title = {Incidental Binding between Predictive Relations},
  author = {Leshinskaya, Anna and Bajaj, Mira and {Thompson-Schill}, Sharon L.},
  year = {2020},
  month = jun,
  volume = {199},
  pages = {104238},
  issn = {00100277},
  doi = {10.1016/j.cognition.2020.104238},
  abstract = {Knowledge of predictive relations is a core aspect of learning. Beyond individual relations, we also represent intuitive theories of the world, which include interrelated sets of relations. We asked whether individual predictive relations learned incidentally in the same context become associatively bound and whether they spontaneously influence later learning. Participants performed a cover task while watching three sequences of events. Each sequence contained the same set of events, but differed in how the events related to each other. The first two sequences each had two strong predictive relations (R1 \& R2, and R3 \& R4). The third contained either a consistent pairing of relations (R1 \& R2) or an inconsistent pairing (R1 \& R3). We found that participants' learning of the individual relations in the third sequence was affected by pairing consistency, suggesting the mind associates relations to each other as part of the intrinsic way it learns about the world. This was despite participants' minimal ability to verbally describe most of the relations they had learned. Thus, participants spontaneously developed the expectation that pairs of relations should cohere, and this affected their ability to learn new evidence. Such associative binding of relational information may help us build intuitive theories.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8N446YFE\\Leshinskaya et al. - 2020 - Incidental binding between predictive relations.pdf},
  journal = {Cognition},
  language = {en}
}

@article{leugering_pipa_2018,
  title = {A {{Unifying Framework}} of {{Synaptic}} and {{Intrinsic Plasticity}} in {{Neural Populations}}},
  author = {Leugering, Johannes and Pipa, Gordon},
  year = {2018},
  month = apr,
  volume = {30},
  pages = {945--986},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/neco_a_01057},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SPBQZ98U\\Leugering and Pipa - 2018 - A Unifying Framework of Synaptic and Intrinsic Pla.pdf},
  journal = {Neural Computation},
  language = {en},
  number = {4}
}

@article{leung_law_2020,
  title = {Phasic Modulation of Hippocampal Synaptic Plasticity by Theta Rhythm.},
  author = {Leung, L. Stan and Law, Clayton S. H.},
  year = {2020},
  month = jan,
  issn = {1939-0084, 0735-7044},
  doi = {10.1037/bne0000354},
  abstract = {Theta rhythm and long-term potentiation (LTP) are 2 remarkable discoveries. The theta rhythm is an oscillatory neural activity of 3\textendash 10 Hz in the hippocampus. LTP is implicated as a cellular basis of memory, but the function of theta oscillation in memory is not clear. This review suggests that theta rhythm bestows optimal conditions for hippocampal LTP and memory encoding. Theta rhythm in hippocampal CA1 is generated mainly by 2 oscillating dipoles\textemdash somatic-inhibition and phase-shifted, distal dendritic excitation, with a smaller contribution by rhythmic proximal (CA3) excitation and distal inhibition. Our recent study showed that LTP of the excitatory synapses on the basal or apical dendrites of CA1 pyramidal cells peaked twice in a theta cycle, at the rising (R) and the midcycle (M) phase of the theta rhythm recorded at the distal apical dendrites. In contrast, evoked population spike excitability peaked at a single phase near the midcycle. We infer that R and M peaks of LTP correspond to maximal dendritic depolarization and maximal somatic depolarization of CA1 pyramidal cells, respectively. A ϳ50\textdegree{} phase shift between LTP-versus-theta-phase functions suggests independent LTP at the basal and apical dendrites. It is argued that theta phase\textendash{} dependent LTP occurs under physiological conditions, by pairing presynaptic activity with oscillating postsynaptic depolarization. Place cells, showing intrinsic membrane potential oscillations, are ideal LTP participants. It is suggested that theta phase\textendash{} dependent LTP contributes to memory encoding, and disruption of either theta oscillation or LTP may disrupt memory in various neurological disorders, including epilepsy and Alzheimer's disease.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QCFHKRSH\\Leung and Law - 2020 - Phasic modulation of hippocampal synaptic plastici.pdf},
  journal = {Behavioral Neuroscience},
  language = {en}
}

@article{lever_burgess_2009,
  title = {Boundary Vector Cells in the Subiculum of the Hippocampal Formation.},
  author = {Lever, Colin and Burton, Stephen and Jeewajee, Ali and O'Keefe, John and Burgess, Neil},
  year = {2009},
  month = aug,
  volume = {29},
  pages = {9771--9777},
  issn = {1529-2401},
  doi = {10.1523/JNEUROSCI.1319-09.2009},
  abstract = {"Boundary vector cells" were predicted to exist by computational models of the environmental inputs underlying the spatial firing patterns of hippocampal place cells (O'Keefe and Burgess, 1996; Burgess et al., 2000; Hartley et al., 2000). Here, we report the existence of cells fulfilling this description in recordings from the subiculum of freely moving rats. These cells may contribute environmental information to place cell firing, complementing path integrative information. Their relationship to other cell types, including medial entorhinal "border cells," is discussed.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7SK995X7\\Lever et al. - 2009 - Boundary vector cells in the subiculum of the hippocampal formation.pdf},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  keywords = {Animals,Electrodes,Environment,Hippocampus,Hippocampus: cytology,Hippocampus: physiology,Implanted,Motor Activity,Motor Activity: physiology,Neurons,Neurons: cytology,Neurons: physiology,Rats,Space Perception,Space Perception: physiology,Time Factors},
  number = {31},
  pmid = {19657030}
}

@article{lever_burgess_2009a,
  title = {Hippocampal Theta Frequency, Novelty, and Behavior},
  author = {Lever, Colin and Jeewajee, Ali and Burton, Stephen and O'Keefe, John and Burgess, Neil},
  year = {2009},
  month = apr,
  volume = {19},
  pages = {409--410},
  issn = {10509631},
  doi = {10.1002/hipo.20557},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HF36FFTW\\Lever et al. - 2009 - Hippocampal theta frequency, novelty, and behavior.pdf},
  journal = {Hippocampus},
  number = {4}
}

@techreport{levichkina_vidyasagar_2020,
  title = {Dynamics of Coherent Activity between Cortical Areas Defines a Two-Stage Process of Selective Attention},
  author = {Levichkina, E. and Kermani, M. and Saalmann, Y.B. and Vidyasagar, T.R.},
  year = {2020},
  month = feb,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.02.09.940791},
  abstract = {ABSTRACT           Analysing a visual scene requires the brain to briefly keep in memory potentially relevant parts and then direct attention to their locations for detailed processing. To reveal the neuronal basis of the underlying working memory and top-down attention processes, we trained macaques to match two patterns presented with a delay between them. As the above processes are likely to require communication between brain regions, and the parietal cortex is involved in spatial attention, we simultaneously recorded neuronal activities from the interconnected parietal and middle temporal areas. We found that mnemonic information about the first pattern was retained in coherent oscillating activity between the areas in high-frequency bands, followed by coherent activity in low-frequency bands that mediate top-down attention on the relevant location.                        ONE SENTENCE SUMMARY             Gamma coherence allows retaining object features in a saliency map while lower frequency coherence facilitates attention.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XWT83DSK\\Levichkina et al. - 2020 - Dynamics of coherent activity between cortical are.pdf},
  language = {en},
  type = {Preprint}
}

@article{levy_desmond_1985,
  title = {The Rules of Elemental Synaptic Plasticity},
  author = {Levy, W B and Desmond, N L},
  year = {1985},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\M3QMISS4\\Levy, Desmond - 1985 - The rules of elemental synaptic plasticity.pdf},
  journal = {Synaptic modification, neuron selectivity, \{\textbackslash ldots\}}
}

@article{lewis_bastiaansen_2016,
  title = {A {{Predictive Coding Perspective}} on {{Beta Oscillations}} during {{Sentence}}-{{Level Language Comprehension}}},
  author = {Lewis, Ashley G. and Schoffelen, Jan-Mathijs and Schriefers, Herbert and Bastiaansen, Marcel},
  year = {2016},
  volume = {10},
  pages = {1--6},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2016.00085},
  abstract = {Oscillatory neural dynamics have been steadily receiving more attention as a robust and temporally precise signature of network activity related to language processing.We have recently proposed that oscillatory dynamics in the beta and gamma frequency ranges measured during sentence-level comprehension might be best explained from a predictive coding perspective. Under our proposal we related beta oscillations to both the maintenance/change of the neural network configuration responsible for the construction and representation of sentence-level meaning, and to top\textendash down predictions about upcoming linguistic input based on that sentence-level meaning. Here we zoom in on these particular aspects of our proposal, and discuss both old and new supporting evidence. Finally, we present some preliminary magnetoencephalography data from an experiment comparing Dutch subject- and object-relative clauses that was specifically designed to test our predictive coding framework. Initial results support the first of the two suggested roles for beta oscillations in sentence-level language comprehension.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7HM5J9ST\\Lewis et al. - 2016 - A Predictive Coding Perspective on Beta Oscillations during Sentence-Level Language Comprehension.pdf},
  journal = {Frontiers in Human Neuroscience},
  keywords = {beta,eeg,language comprehension,meg,neural oscillations,predictive coding},
  number = {March},
  pmid = {26973500}
}

@article{lewis_bates_2013,
  title = {The Long Reach of the Gene},
  author = {Lewis, Gary J. and Bates, Timothy C.},
  year = {2013},
  volume = {26},
  pages = {194--198},
  issn = {09528229},
  doi = {10.1162/jocn},
  abstract = {The negotiation of social order is intimately connected to the capacity to infer and track status relationships. Despite the foundational role of status in social cognition, we know little about how the brain constructs status from social interactions that display it. Although emerging cognitive neuroscience reveals that status judgments depend on the intraparietal sulcus, a brain region that supports the comparison of targets along a quantitative continuum, we present evidence that status judgments do not necessarily reduce to ranking targets along a quantitative continuum. The process of judging status also fits a social interdependence analysis. Consistent with third-party perceivers judging status by inferring whose goals are dictating the terms of the interaction and who is subordinating their desires to whom, status judgments were associated with increased recruitment of medial pFC and STS, brain regions implicated in mental state inference},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CASVXUX2\\Ciavarro et al. - 2013 - rTMS of Medial Parieto-occipital Cortex Interferes with Attentional Reorienting during Attention and Reaching T.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\E8Y3K7M2\\Lewis, Bates - 2013 - The long reach of the gene.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\E9YTR6E5\\Lewis, Bates - 2013 - The long reach of the gene(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\JU5J76J7\\Lewis, Bates - 2013 - The long reach of the gene(4).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\LRS66T4A\\Ciavarro et al. - 2013 - rTMS of Medial Parieto-occipital Cortex Interferes with Attentional Reorienting during Attention and Reachin(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\QJN88EIR\\Roy, Buschman, Miller - 2013 - PFC Neurons Reflect Categorical Decisions about Ambigious STimuli.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\XXBBPDN7\\Lewis, Bates - 2013 - The long reach of the gene(3).pdf},
  journal = {Psychologist},
  number = {3},
  pmid = {23647519}
}

@article{lewis-peacock_norman_2016,
  title = {Neural Evidence of the Strategic Choice between Working Memory and Episodic Memory in Prospective Remembering},
  author = {{Lewis-Peacock}, Jarrod A and Cohen, Jonathan D and Norman, Kenneth A},
  year = {2016},
  volume = {93},
  pages = {280--288},
  issn = {18733514},
  doi = {10.1016/j.neuropsychologia.2016.11.006},
  abstract = {Theories of prospective memory (PM) posit that it can be subserved either by working memory (WM) or episodic memory (EM). Testing and refining these multiprocess theories of PM requires a way of tracking participants' reliance on WM versus EM. Here we use multi-voxel pattern analysis (MVPA) to derive a trial-by-trial measure of WM use in prospective memory. We manipulated strategy demands by varying the degree of proactive interference (which impairs EM) and the memory load required to perform the secondary task (which impairs WM). For the condition in which participants were pushed to rely more on WM, our MVPA measures showed 1) greater WM use and 2) a trial-by-trial correlation between WM use and PM behavior. Finally, we also showed that MVPA measures of WM use are not redundant with other behavioral measures: in the condition in which participants were pushed more to rely on WM, using neural and behavioral measures together led to better prediction of PM accuracy than either measure on its own.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IF5GLQWZ\\Lewis-Peacock, Cohen, Norman - 2016 - Neural evidence of the strategic choice between working memory and episodic memory in prospective.pdf},
  journal = {Neuropsychologia},
  keywords = {Episodic memory,fmri,mvpa,Prospective memory,working-memory},
  number = {November}
}

@article{lewis-peacock_postle_2012,
  title = {Neural Evidence for a Distinction between Short-Term Memory and the Focus of Attention.},
  author = {{Lewis-Peacock}, Jarrod A and Drysdale, Andrew T and Oberauer, Klaus and Postle, Bradley R},
  year = {2012},
  volume = {24},
  pages = {61--79},
  issn = {1530-8898},
  doi = {10.1162/jocn_a_00140},
  abstract = {It is widely assumed that the short-term retention of information is accomplished via maintenance of an active neural trace. However, we demonstrate that memory can be preserved across a brief delay despite the apparent loss of sustained representations. Delay period activity may, in fact, reflect the focus of attention, rather than STM. We unconfounded attention and memory by causing external and internal shifts of attention away from items that were being actively retained. Multivariate pattern analysis of fMRI indicated that only items within the focus of attention elicited an active neural trace. Activity corresponding to representations of items outside the focus quickly dropped to baseline. Nevertheless, this information was remembered after a brief delay. Our data also show that refocusing attention toward a previously unattended memory item can reactivate its neural signature. The loss of sustained activity has long been thought to indicate a disruption of STM, but our results suggest that, even for small memory loads not exceeding the capacity limits of STM, the active maintenance of a stimulus representation may not be necessary for its short-term retention.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5UWBL5JQ\\Lewis-Peacock et al. - 2012 - Neural evidence for a distinction between short-term memory and the focus of attention.pdf},
  journal = {Journal of cognitive neuroscience},
  keywords = {Algorithms,associative learning,Attention,Attention: physiology,Cognition,Cognition: physiology,Data Interpretation,Female,Humans,Magnetic Resonance Imaging,Male,Memory,Photic Stimulation,Psychomotor Performance,Psychomotor Performance: physiology,Reaction Time,Reaction Time: physiology,Recognition (Psychology),Recognition (Psychology): physiology,Short-Term,Short-Term: physiology,Statistical},
  number = {1},
  pmid = {21955164}
}

@article{li_berger_2013,
  title = {Real-Time Prediction of Neuronal Population Spiking Activity Using {{FPGA}}.},
  author = {Li, Will X Y and Cheung, Ray C C and Chan, Rosa H M and Song, Dong and Berger, Theodore W},
  year = {2013},
  month = aug,
  volume = {7},
  pages = {489--498},
  issn = {1940-9990},
  doi = {10.1109/TBCAS.2012.2228261},
  abstract = {A field-programmable gate array (FPGA)-based hardware architecture is proposed and utilized for prediction of neuronal population firing activity. The hardware system adopts the multi-input multi-output (MIMO) generalized Laguerre-Volterra model (GLVM) structure to describe the nonlinear dynamic neural process of mammalian brain and can switch between the two important functions: estimation of GLVM coefficients and prediction of neuronal population spiking activity (model outputs). The model coefficients are first estimated using the in-sample training data; then the output is predicted using the out-of-sample testing data and the field estimated coefficients. Test results show that compared with previous software implementation of the generalized Laguerre-Volterra algorithm running on an Intel Core i7-2620M CPU, the FPGA-based hardware system can achieve up to 2.66\texttimes 10(3) speedup in doing model parameters estimation and 698.84 speedup in doing model output prediction. The proposed hardware platform will facilitate research on the highly nonlinear neural process of the mammal brain, and the cognitive neural prosthesis design.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FTUZHTZ6\\Li et al. - 2013 - Real-time prediction of neuronal population spiking activity using FPGA.pdf},
  journal = {IEEE transactions on biomedical circuits and systems},
  keywords = {Algorithms,Animals,Computer Systems,Electrodes,Electronics,Humans,Medical,Models,Neurological,Neurons,Neurons: physiology},
  number = {4},
  pmid = {23893208}
}

@article{li_frohlich_2017,
  title = {Unified Thalamic Model Generates Multiple Distinct Oscillations with State-Dependent Entrainment by Stimulation},
  author = {Li, Guoshi and Henriquez, Craig S. and Fr{\"o}hlich, Flavio},
  editor = {Gutkin, Boris S.},
  year = {2017},
  month = oct,
  volume = {13},
  pages = {e1005797},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1005797},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TTUCNSUS\\Li et al. - 2017 - Unified thalamic model generates multiple distinct.pdf},
  journal = {PLOS Computational Biology},
  language = {en},
  number = {10}
}

@article{li_lizier_2019,
  title = {Transitions in Information Processing Dynamics at the Whole-Brain Network Level Are Driven by Alterations in Neural Gain},
  author = {Li, Mike and Han, Yinuo and Aburn, Matthew J. and Breakspear, Michael and Poldrack, Russell A. and Shine, James M. and Lizier, Joseph T.},
  editor = {Cuntz, Hermann},
  year = {2019},
  month = oct,
  volume = {15},
  pages = {e1006957},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1006957},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CTGHZJZM\\Li et al. - 2019 - Transitions in information processing dynamics at .pdf},
  journal = {PLOS Computational Biology},
  language = {en},
  number = {10}
}

@techreport{li_sejnowski_2020,
  title = {Learning the Synaptic and Intrinsic Membrane Dynamics Underlying Working Memory in Spiking Neural Network Models},
  author = {Li, Yinghao and Kim, Robert and Sejnowski, Terrence J.},
  year = {2020},
  month = jun,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.06.11.147405},
  abstract = {Recurrent neural network (RNN) model trained to perform cognitive tasks is a useful computational tool for understanding how cortical circuits execute complex computations. However, these models are often composed of units that interact with one another using continuous signals and overlook parameters intrinsic to spiking neurons. Here, we developed a method to directly train not only synaptic-related variables but also membrane-related parameters of a spiking RNN model. Training our model on a wide range of cognitive tasks resulted in diverse yet task-specific synaptic and membrane parameters. We also show that fast membrane time constants and slow synaptic decay dynamics naturally emerge from our model when it is trained on tasks associated with working memory (WM). Further dissecting the optimized parameters revealed that fast membrane properties and slow synaptic dynamics are important for encoding stimuli and WM maintenance, respectively. This approach offers a unique window into how connectivity patterns and intrinsic neuronal properties contribute to complex dynamics in neural populations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HES3BRPB\\Li et al. - 2020 - Learning the synaptic and intrinsic membrane dynam.pdf},
  language = {en},
  type = {Preprint}
}

@techreport{li_sheynikhovich_2019,
  title = {Panoramic Visual Representation in the Dorsal Visual Pathway and Its Role in Reorientation},
  author = {Li, Tianyi and Arleo, Angelo and Sheynikhovich, Denis},
  year = {2019},
  month = nov,
  institution = {{Animal Behavior and Cognition}},
  doi = {10.1101/827667},
  abstract = {Abstract           While primates are primarily visual animals, how visual information is processed on its way to memory structures and contributes to the generation of visuospatial behaviors is poorly understood. Recent imaging data demonstrate the existence of scene-sensitive areas in the dorsal visual path that are likely to combine visual information from successive egocentric views, while behavioral evidence indicates the memory of surrounding visual space in extraretinal coordinates. The present work focuses on the computational nature of a panoramic representation that is proposed to link visual and mnemonic functions during natural behavior. In a spiking neural network model of the dorsal visual path it is shown how time-integration of spatial views can give rise to such a representation and how it can subsequently be used to perform memory-based spatial reorientation and visual search. More generally, the model predicts a common role of view-based allocentric memory storage in spatial and non-spatial mnemonic behaviors.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9VG6SN7Q\\Li et al. - 2019 - Panoramic visual representation in the dorsal visu.pdf},
  language = {en},
  type = {Preprint}
}

@article{li_wu_2020,
  ids = {li\_wu\_2020a},
  title = {Power-Efficient Neural Network with Artificial Dendrites},
  author = {Li, Xinyi and Tang, Jianshi and Zhang, Qingtian and Gao, Bin and Yang, J. Joshua and Song, Sen and Wu, Wei and Zhang, Wenqiang and Yao, Peng and Deng, Ning and Deng, Lei and Xie, Yuan and Qian, He and Wu, Huaqiang},
  year = {2020},
  month = jun,
  issn = {1748-3387, 1748-3395},
  doi = {10.1038/s41565-020-0722-5},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8KU6HZWM\\Li et al. - 2020 - Power-efficient neural network with artificial den.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\95FMPUGZ\\Li et al. - 2020 - Power-efficient neural network with artificial den.pdf},
  journal = {Nature Nanotechnology},
  language = {en}
}

@article{liao_poggio_2016,
  title = {Bridging the {{Gaps Between Residual Learning}}, {{Recurrent Neural Networks}} and {{Visual Cortex}}},
  author = {Liao, Qianli and Poggio, Tomaso},
  year = {2016},
  month = apr,
  abstract = {We discuss relations between Residual Networks (ResNet), Recurrent Neural Networks (RNNs) and the primate visual cortex. We begin with the observation that a shallow RNN is exactly equivalent to a very deep ResNet with weight sharing among the layers. A direct implementation of such a RNN, although having orders of magnitude fewer parameters, leads to a performance similar to the corresponding ResNet. We propose 1) a generalization of both RNN and ResNet architectures and 2) the conjecture that a class of moderately deep RNNs is a biologically-plausible model of the ventral stream in visual cortex. We demonstrate the effectiveness of the architectures by testing them on the CIFAR-10 dataset.},
  archivePrefix = {arXiv},
  eprint = {1604.03640},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FJHZYM2F\\Liao and Poggio - 2016 - Bridging the Gaps Between Residual Learning, Recur.pdf},
  journal = {arXiv:1604.03640 [cs]},
  language = {en},
  primaryClass = {cs}
}

@article{libby_ranganath_2014,
  title = {Medial {{Temporal Lobe Coding}} of {{Item}} and {{Spatial Information}} during {{Relational Binding}} in {{Working Memory}}},
  author = {Libby, Laura A and Hannula, Deborah E and Ranganath, Charan},
  year = {2014},
  volume = {34},
  pages = {14233--14242},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.0655-14.2014},
  abstract = {Several models have proposed that different medial temporal lobe (MTL) regions represent different kinds of information in the service of long-term memory. For instance, it has been proposed that perirhinal cortex (PRC), parahippocampal cortex (PHC), and hippocampus differentially support long-term memory for item information, spatial context, and item-context relations present during an event, respectively. Recent evidence has indicated that, in addition to long-term memory, MTL subregions may similarly contribute to processes that support the retention of complex spatial arrangements of objects across short delays. Here, we used functional magnetic resonance imaging and multivoxel pattern similarity analysis to investigate the extent to which human MTL regions independently code for object and spatial information, as well as the conjunction of this information, during working memory encoding and active maintenance. Voxel activity patterns in PRC, temporopolar cortex, and amygdala carried information about individual objects, whereas activity patterns in the PHC and posterior hippocampus carried information about the configuration of spatial locations that was to be remembered. Additionally, the integrity of multivoxel patterns in the right anterior hippocampus across encoding and delay periods was predictive of accurate short-term memory for object-location relationships. These results are consistent with parallel processing of item and spatial context information by PRC and PHC, respectively, and the binding of item and context by the hippocampus.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ICSE8EIV\\Libby et al. - 2014 - Medial Temporal Lobe Coding of Item and Spatial In.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\KXNJQVHM\\Libby, Hannula, Ranganath - 2014 - Medial Temporal Lobe Coding of Item and Spatial Information during Relational Binding in Working Memo.pdf},
  journal = {Journal of Neuroscience},
  keywords = {fmri,hippocampus,mvpa,parahippocampal,perirhinal,working-memory},
  number = {43},
  pmid = {25339737}
}

@article{liberty_tygert_2007,
  title = {Randomized Algorithms for the Low-Rank Approximation of Matrices.},
  author = {Liberty, Edo and Woolfe, Franco and Martinsson, Per-Gunnar and Rokhlin, Vladimir and Tygert, Mark},
  year = {2007},
  month = dec,
  volume = {104},
  pages = {20167--20172},
  issn = {1091-6490},
  doi = {10.1073/pnas.0709640104},
  abstract = {We describe two recently proposed randomized algorithms for the construction of low-rank approximations to matrices, and demonstrate their application (inter alia) to the evaluation of the singular value decompositions of numerically low-rank matrices. Being probabilistic, the schemes described here have a finite probability of failure; in most cases, this probability is rather negligible (10(-17) is a typical value). In many situations, the new procedures are considerably more efficient and reliable than the classical (deterministic) ones; they also parallelize naturally. We present several numerical examples to illustrate the performance of the schemes.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YI8DCLV2\\Liberty et al. - 2007 - Randomized algorithms for the low-rank approximation of matrices.pdf},
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  number = {51},
  pmid = {18056803}
}

@article{liebe_rainer_2012,
  title = {Theta Coupling between {{V4}} and Prefrontal Cortex Predicts Visual Short-Term Memory Performance},
  author = {Liebe, Stefanie and Hoerzer, Gregor M and Logothetis, Nikos K and Rainer, Gregor},
  year = {2012},
  volume = {15},
  pages = {456--462},
  issn = {1097-6256},
  doi = {10.1038/nn.3038},
  abstract = {Nature Neuroscience 15, 456 (2012). doi:10.1038/nn.3038},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZL9LJT7K\\Liebe et al. - 2012 - Theta coupling between V4 and prefrontal cortex predicts visual short-term memory performance.pdf},
  journal = {Nature Neuroscience},
  number = {3},
  pmid = {22286175}
}

@article{lignani_benfenati_2013,
  title = {Long-Term Optical Stimulation of Channelrhodopsin-Expressing Neurons to Study Network Plasticity.},
  author = {Lignani, Gabriele and Ferrea, Enrico and Difato, Francesco and Amar{\`u}, Jessica and Ferroni, Eleonora and Lugar{\`a}, Eleonora and Espinoza, Stefano and Gainetdinov, Raul R and Baldelli, Pietro and Benfenati, Fabio},
  year = {2013},
  month = jan,
  volume = {6},
  pages = {22},
  issn = {1662-5099},
  doi = {10.3389/fnmol.2013.00022},
  abstract = {Neuronal plasticity produces changes in excitability, synaptic transmission, and network architecture in response to external stimuli. Network adaptation to environmental conditions takes place in time scales ranging from few seconds to days, and modulates the entire network dynamics. To study the network response to defined long-term experimental protocols, we setup a system that combines optical and electrophysiological tools embedded in a cell incubator. Primary hippocampal neurons transduced with lentiviruses expressing channelrhodopsin-2/H134R were subjected to various photostimulation protocols in a time window in the order of days. To monitor the effects of light-induced gating of network activity, stimulated transduced neurons were simultaneously recorded using multi-electrode arrays (MEAs). The developed experimental model allows discerning short-term, long-lasting, and adaptive plasticity responses of the same neuronal network to distinct stimulation frequencies applied over different temporal windows.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6J4M2BI3\\Lignani et al. - 2013 - Long-term optical stimulation of channelrhodopsin-expressing neurons to study network plasticity.pdf},
  journal = {Frontiers in molecular neuroscience},
  keywords = {long-term recordings,network activity,network plasticity,optogenetic,optogenetics,primary neurons},
  number = {August},
  pmid = {23970852}
}

@article{liljeholm_odoherty_2012,
  title = {Contributions of the Striatum to Learning, Motivation, and Performance: An Associative Account},
  shorttitle = {Contributions of the Striatum to Learning, Motivation, and Performance},
  author = {Liljeholm, Mimi and O'Doherty, John P.},
  year = {2012},
  month = sep,
  volume = {16},
  pages = {467--475},
  issn = {13646613},
  doi = {10.1016/j.tics.2012.07.007},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YX4G9QCK\\Liljeholm and O’Doherty - 2012 - Contributions of the striatum to learning, motivat.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {9}
}

@article{lillicrap_akerman_2016,
  title = {{{ARTICLE Random}} Synaptic Feedback Weights Support Error Backpropagation for Deep Learning},
  author = {Lillicrap, Timothy P and Cownden, Daniel and Tweed, Douglas B and Akerman, Colin J},
  year = {2016},
  volume = {7},
  doi = {10.1038/ncomms13276},
  abstract = {The brain processes information through multiple layers of neurons. This deep architecture is representationally powerful, but complicates learning because it is difficult to identify the responsible neurons when a mistake is made. In machine learning, the backpropagation algorithm assigns blame by multiplying error signals with all the synaptic weights on each neuron's axon and further downstream. However, this involves a precise, symmetric backward connectivity pattern, which is thought to be impossible in the brain. Here we demonstrate that this strong architectural constraint is not required for effective error propagation. We present a surprisingly simple mechanism that assigns blame by multiplying errors by even random synaptic weights. This mechanism can transmit teaching signals across multiple layers of neurons and performs as effectively as backpropagation on a variety of tasks. Our results help reopen questions about how the brain could use error signals and dispel long-held assumptions about algorithmic constraints on learning.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9NUA82D8\\Lillicrap et al. - 2016 - ARTICLE Random synaptic feedback weights support error backpropagation for deep learning.pdf},
  journal = {Nature Publishing Group}
}

@article{lim_brunel_2015,
  title = {Inferring Learning Rules from Distributions of Firing Rates},
  author = {Lim, Sukbin and McKee, Jillian L and Woloszyn, Luke and Amit, Yali and Freedman, David J and Sheinberg, David L and Brunel, Nicolas},
  year = {2015},
  volume = {18},
  pages = {1--13},
  issn = {1097-6256},
  doi = {10.1038/nn.4158},
  abstract = {Information about external stimuli is thought to be stored in cortical circuits through experience-dependent modifications of synaptic connectivity. These modifications of network connectivity should lead to changes in neuronal activity as a particular stimulus is repeatedly encountered. Here we ask what plasticity rules are consistent with the differences in the statistics of the visual response to novel and familiar stimuli in inferior temporal cortex, an area underlying visual object recognition. We introduce a method that allows one to infer the dependence of the presumptive learning rule on postsynaptic firing rate, and we show that the inferred learning rule exhibits depression for low postsynaptic rates and potentiation for high rates. The threshold separating depression from potentiation is strongly correlated with both mean and s.d. of the firing rate distribution. Finally, we show that network models implementing a rule extracted from data show stable learning dynamics and lead to sparser representations of stimuli.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L87NDVIB\\Lim et al. - 2015 - Inferring learning rules from distributions of firing rates.pdf},
  journal = {Nature neuroscience},
  number = {12},
  pmid = {26523643}
}

@article{lim_roberts_2019,
  title = {Recurrent {{Neural Filters}}: {{Learning Independent Bayesian Filtering Steps}} for {{Time Series Prediction}}},
  shorttitle = {Recurrent {{Neural Filters}}},
  author = {Lim, Bryan and Zohren, Stefan and Roberts, Stephen},
  year = {2019},
  month = jan,
  abstract = {Despite the recent popularity of deep generative state space models, few comparisons have been made between network architectures and the inference steps of the Bayesian filtering framework \textendash{} with most models simultaneously approximating both state transition and update steps with a single recurrent neural network (RNN). In this paper, we introduce the Recurrent Neural Filter (RNF), a novel recurrent variational autoencoder architecture that learns distinct representations for each Bayesian filtering step, captured by a series of encoders and decoders. Testing this on three real-world time series datasets, we demonstrate that decoupling representations not only improves the accuracy of one-step-ahead forecasts while providing realistic uncertainty estimates, but also facilitates multistep prediction through the separation of encoder stages.},
  archivePrefix = {arXiv},
  eprint = {1901.08096},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XE7S47K3\\Lim et al. - 2019 - Recurrent Neural Filters Learning Independent Bay.pdf},
  journal = {arXiv:1901.08096 [cs, eess, stat]},
  language = {en},
  primaryClass = {cs, eess, stat}
}

@techreport{limbacher_legenstein_2020,
  title = {H-{{Mem}}: {{Harnessing}} Synaptic Plasticity with {{Hebbian Memory Networks}}},
  shorttitle = {H-{{Mem}}},
  author = {Limbacher, Thomas and Legenstein, Robert},
  year = {2020},
  month = jul,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.07.01.180372},
  abstract = {A             bstract                      The ability to base current computations on memories from the past is critical for many cognitive tasks such as story understanding. Hebbian-type synaptic plasticity is believed to underlie the retention of memories over medium and long time scales in the brain. However, it is unclear how such plasticity processes are integrated with computations in cortical networks. Here, we propose Hebbian Memory Networks (H-Mems), a simple neural network model that is built around a core hetero-associative network subject to Hebbian plasticity. We show that the network can be optimized to utilize the Hebbian plasticity processes for its computations. H-Mems can one-shot memorize associations between stimulus pairs and use these associations for decisions later on. Furthermore, they can solve demanding question-answering tasks on synthetic stories. Our study shows that neural network models are able to enrich their computations with memories through simple Hebbian plasticity processes.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\C66RDMV5\\Limbacher and Legenstein - 2020 - H-Mem Harnessing synaptic plasticity with Hebbian.pdf},
  language = {en},
  type = {Preprint}
}

@article{lin_gramann_2015,
  title = {{{EEG}} Correlates of Spatial Orientation in the Human Retrosplenial Complex},
  author = {Lin, C. T. and Chiu, T. C. and Gramann, K},
  year = {2015},
  volume = {120},
  pages = {123--132},
  issn = {10959572},
  doi = {10.1016/j.neuroimage.2015.07.009},
  abstract = {Studies on spatial navigation reliably demonstrate that the retrosplenial complex (RSC) plays a pivotal role for allocentric spatial information processing by transforming egocentric and allocentric spatial information into the respective other spatial reference frame (SRF). While more and more imaging studies investigate the role of the RSC in spatial tasks, high temporal resolution measures such as electroencephalography (EEG) are missing. To investigate the function of the RSC in spatial navigation with high temporal resolution we used EEG to analyze spectral perturbations during navigation based on allocentric and egocentric SRF. Participants performed a path integration task in a clearly structured virtual environment providing allothetic information. Continuous EEG recordings were decomposed by independent component analysis (ICA) with subsequent source reconstruction of independent time source series using equivalent dipole modeling. Time-frequency transformation was used to investigate reference frame-specific orientation processes during navigation as compared to a control condition with identical visual input but no orientation task. Our results demonstrate that navigation based on an egocentric reference frame recruited a network including the parietal, motor, and occipital cortices with dominant perturbations in the alpha band and theta modulation in frontal cortex. Allocentric navigation was accompanied by performance-related desynchronization of the 8-13. Hz frequency band and synchronization in the 12-14. Hz band in the RSC. The results support the claim that the retrosplenial complex is central to translating egocentric spatial information into allocentric reference frames. Modulations in different frequencies with different time courses in the RSC further provide first evidence of two distinct neural processes reflecting translation of spatial information based on distinct reference frames and the computation of heading changes.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CKR5TH4X\\Lin, Chiu, Gramann - 2015 - EEG correlates of spatial orientation in the human retrosplenial complex.pdf},
  journal = {NeuroImage},
  pmid = {26163801}
}

@article{lin_lega_2017,
  title = {Theta Band Power Increases in the Posterior Hippocampus Predict Successful Episodic Memory Encoding in Humans},
  author = {Lin, Jui Jui and Rugg, Michael and Das, Sandhitsu and Stein, Joel and Rizzuto, Daniel and Kahana, Michael and Lega, Bradley},
  year = {2017},
  pages = {1--14},
  issn = {10509631},
  doi = {10.1002/hipo.22751},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DCV4R5YJ\\Lin et al. - 2017 - Theta band power increases in the posterior hippocampus predict successful episodic memory encoding in humans.pdf},
  journal = {Hippocampus},
  keywords = {center for vital longevity,dallas,department of radiology,texas 75390,texas at dallas,university of},
  number = {June},
  pmid = {28608960}
}

@article{linderman_adams_2014,
  title = {A Framework for Studying Synaptic Plasticity with Neural Spike Train Data},
  author = {Linderman, Scott and Stock, Christopher H and Adams, Ryan P},
  year = {2014},
  pages = {2330--2338},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TYS6UIJ2\\Linderman, Stock, Adams - 2014 - A framework for studying synaptic plasticity with neural spike train data.pdf},
  journal = {Advances in Neural Information Processing Systems 27}
}

@article{linderman_johnson_2016,
  title = {Recurrent Switching Linear Dynamical Systems},
  author = {Linderman, Scott W. and Miller, Andrew C. and Adams, Ryan P. and Blei, David M. and Paninski, Liam and Johnson, Matthew J.},
  year = {2016},
  month = oct,
  abstract = {Many natural systems, such as neurons firing in the brain or basketball teams traversing a court, give rise to time series data with complex, nonlinear dynamics. We can gain insight into these systems by decomposing the data into segments that are each explained by simpler dynamic units. Building on switching linear dynamical systems (SLDS), we present a new model class that not only discovers these dynamical units, but also explains how their switching behavior depends on observations or continuous latent states. These ``recurrent'' switching linear dynamical systems provide further insight by discovering the conditions under which each unit is deployed, something that traditional SLDS models fail to do. We leverage recent algorithmic advances in approximate inference to make Bayesian inference in these models easy, fast, and scalable.},
  archivePrefix = {arXiv},
  eprint = {1610.08466},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\M3PUKU5E\\Linderman et al. - 2016 - Recurrent switching linear dynamical systems.pdf},
  journal = {arXiv:1610.08466 [stat]},
  language = {en},
  primaryClass = {stat}
}

@techreport{linderman_paninski_2019,
  title = {Hierarchical Recurrent State Space Models Reveal Discrete and Continuous Dynamics of Neural Activity in {{{\emph{C}}}}{\emph{. Elegans}}},
  author = {Linderman, Scott and Nichols, Annika and Blei, David and Zimmer, Manuel and Paninski, Liam},
  year = {2019},
  month = apr,
  institution = {{Neuroscience}},
  doi = {10.1101/621540},
  abstract = {Modern recording techniques enable large-scale measurements of neural activity in a variety of model organisms. The dynamics of neural activity shed light on how organisms process sensory information and generate motor behavior. Here, we study these dynamics using optical recordings of neural activity in the nematode C. elegans. To understand these data, we develop state space models that decompose neural time-series into segments with simple, linear dynamics. We incorporate these models into a hierarchical framework that combines partial recordings from many worms to learn shared structure, while still allowing for individual variability. This framework reveals latent states of population neural activity, along with the discrete behavioral states that govern dynamics in this state space. We find stochastic transition patterns between discrete states and see that transition probabilities are determined by both current brain activity and sensory cues. Our methods automatically recover transition times that closely match manual labels of different behaviors, such as forward crawling, reversals, and turns. Finally, the resulting model can simulate neural data, faithfully capturing salient patterns of whole brain dynamics seen in real data.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BNKATJJH\\Linderman et al. - 2019 - Hierarchical recurrent state space models reveal d.pdf},
  language = {en},
  type = {Preprint}
}

@article{lindsay_fusi_2017,
  title = {Hebbian {{Learning}} in a {{Random Network Captures Selectivity Properties}} of {{Prefrontal Cortex}}},
  author = {Lindsay, Grace W. and Rigotti, Mattia and Warden, Melissa R. and Miller, Earl K and Fusi, Stefano},
  year = {2017},
  pages = {1222--17},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.1222-17.2017},
  abstract = {Complex cognitive behaviors, such as context-switching and rule-following, are thought to be supported by prefrontal cortex (PFC). Neural activity in PFC must thus be specialized to specific tasks while retaining flexibility. Nonlinear 'mixed' selectivity is an important neurophysiological trait for enabling complex and context-dependent behaviors. Here we investigate (1) the extent to which PFC exhibits computationally-relevant properties such as mixed selectivity and (2) how such properties could arise via circuit mechanisms. We show that PFC cells recorded from male and female rhesus macaques during a complex task show a moderate level of specialization and structure that is not replicated by a model wherein cells receive random feedforward inputs. While random connectivity can be effective at generating mixed selectivity, the data shows significantly more mixed selectivity than predicted by a model with otherwise matched parameters. A simple Hebbian learning rule applied to the random connectivity, however, increases mixed selectivity and allows the model to match the data more accurately. To explain how learning achieves this, we provide analysis along with a clear geometric interpretation of the impact of learning on selectivity. After learning, the model also matches the data on measures of noise, response density, clustering, and the distribution of selectivities. Of two styles of Hebbian learning tested, the simpler and more biologically plausible option better matches the data. These modeling results give intuition about how neural properties important for cognition can arise in a circuit and make clear experimental predictions regarding how various measures of selectivity would evolve during animal training.Significance Statement: Prefrontal cortex (PFC) is a brain region believed to support the ability of animals to engage in complex behavior. How neurons in this area respond to stimuli\textemdash and in particular, to combinations of stimuli ("mixed selectivity")-is a topic of interest. Despite the fact that models with random feedforward connectivity are capable of creating computationally-relevant mixed selectivity, such a model does not match the levels of mixed selectivity seen in the data analyzed in this study. Adding simple Hebbian learning to the model increases mixed selectivity to the correct level and makes the model match the data on several other relevant measures. This study thus offers predictions on how mixed selectivity and other properties evolve with training.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\86XFYKED\\Lindsay et al. - 2017 - Hebbian Learning in a Random Network Captures Selectivity Properties of Prefrontal Cortex.pdf},
  journal = {The Journal of Neuroscience},
  pmid = {28986463}
}

@article{lindsay_garry_2004,
  title = {True {{Photographs}} and {{False Memories}}},
  author = {Lindsay, D. Stephen and Hagen, Lisa and Read, J. Don and Wade, Kimberley A. and Garry, Maryanne},
  year = {2004},
  month = mar,
  volume = {15},
  pages = {149--154},
  issn = {0956-7976, 1467-9280},
  doi = {10.1111/j.0956-7976.2004.01503002.x},
  abstract = {Some trauma-memory-oriented psychotherapists advise clients to review old family photo albums to cue suspected ``repressed'' memories of childhood sexual abuse. Old photos might cue long-forgotten memories, but when combined with other suggestive influences they might also contribute to false memories. We asked 45 undergraduates to work at remembering three school-related childhood events (two true events provided by parents and one pseudoevent). By random assignment, 23 subjects were also given their school classes' group photos from the years of the to-be-recalled events as memory cues. As predicted, the rate of false-memory reports was dramatically higher in the photo condition than in the no-photo condition. Indeed, the rate of false-memory reports in the photo condition was substantially higher than the rate in any previously published study.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\P5DLQ2K4\\Lindsay et al. - 2004 - True Photographs and False Memories.pdf},
  journal = {Psychological Science},
  language = {en},
  number = {3}
}

@techreport{lindsay_miller_2018,
  title = {How Biological Attention Mechanisms Improve Task Performance in a Large-Scale Visual System Model},
  author = {Lindsay, Grace W and Miller, Kenneth D},
  year = {2018},
  abstract = {How does attentional modulation of neural activity enhance performance? Here we use a deep convolutional neural network as a large-scale model of the visual system to address this question. We model the feature similarity gain model of attention, in which attentional modulation is applied according to neural stimulus tuning. Using a variety of visual tasks, we show that neural modulations of the kind and magnitude observed experimentally lead to performance changes of the kind and magnitude observed experimentally. We find that, at earlier layers, attention applied according to tuning does not successfully propagate through the network, and has a weaker impact on performance than attention applied according to values computed for optimally modulating higher areas. This raises the question of whether biological attention might be applied at least in part to optimize function rather than strictly according to tuning. We suggest a simple experiment to distinguish these alternatives.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XE7EA447\\Lindsay, Miller - Unknown - How biological attention mechanisms improve task performance in a large-scale visual system model.pdf}
}

@techreport{lisitsyn_ernst_2020,
  title = {Signal Transfer of Visual Stimuli to {{V4}} Occurs in Gamma-Rhythmic, Pulsed Information Packages},
  author = {Lisitsyn, Dmitriy and Grothe, Iris and Kreiter, Andreas K. and Ernst, Udo A.},
  year = {2020},
  month = feb,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.02.03.931956},
  abstract = {Selective visual attention allows the brain to focus on behaviorally relevant information while ignoring irrelevant signals. As a possible mechanism, routing by synchronization was proposed: neural populations sending attended signals align their gamma-rhythmic activities with receiving populations, such that spikes from the senders arrive at excitability peaks of the receivers, enhancing signal transfer. Conversely, the non-attended signals arrive unaligned to the receiver's oscillation, reducing signal transfer. Therefore, visual signals should be transferred through periodically pulsed information packages, resulting in a modulation of the stimulus content within the receiver's activity by its gamma phase and amplitude. To test this prediction, we quantified gamma phase-specific stimulus content within neural activity from area V4 of macaques performing a visual attention task. For the attended stimulus we find enhanced stimulus content reaching its maximum near excitability peaks, with effect magnitude increasing with oscillation amplitude, establishing a functional link between selective processing and gamma activity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\STWBF7EV\\Lisitsyn et al. - 2020 - Signal transfer of visual stimuli to V4 occurs in .pdf},
  language = {en},
  type = {Preprint}
}

@article{liu_behrens_2019,
  title = {Human {{Replay Spontaneously Reorganizes Experience}}},
  author = {Liu, Yunzhe and Dolan, Raymond J. and {Kurth-Nelson}, Zeb and Behrens, Timothy E.J.},
  year = {2019},
  month = jul,
  volume = {178},
  pages = {640-652.e14},
  issn = {00928674},
  doi = {10.1016/j.cell.2019.06.012},
  abstract = {Knowledge abstracted from previous experiences can be transferred to aid new learning. Here, we asked whether such abstract knowledge immediately guides the replay of new experiences. We first trained participants on a rule defining an ordering of objects and then presented a novel set of objects in a scrambled order. Across two studies, we observed that representations of these novel objects were reactivated during a subsequent rest. As in rodents, human ``replay'' events occurred in sequences accelerated in time, compared to actual experience, and reversed their direction after a reward. Notably, replay did not simply recapitulate visual experience, but followed instead a sequence implied by learned abstract knowledge. Furthermore, each replay contained more than sensory representations of the relevant objects. A sensory code of object representations was preceded 50 ms by a code factorized into sequence position and sequence identity. We argue that this factorized representation facilitates the generalization of a previously learned structure to new objects.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LXAGW7VS\\Liu et al. - 2019 - Human Replay Spontaneously Reorganizes Experience.pdf},
  journal = {Cell},
  language = {en},
  number = {3}
}

@article{liu_dragoi_2018,
  title = {Generative {{Predictive Codes}} by {{Multiplexed Hippocampal Neuronal Tuplets}}},
  author = {Liu, Kefei and Sibille, Jeremie and Dragoi, George},
  year = {2018},
  month = sep,
  volume = {99},
  pages = {1329-1341.e6},
  issn = {08966273},
  doi = {10.1016/j.neuron.2018.07.047},
  abstract = {Rapid internal representations are continuously formed based on single experiential episodes in space and time, but the neuronal ensemble mechanisms enabling rapid encoding without constraining the capacity for multiple distinct representations are unknown. We developed a probabilistic statistical model of hippocampal spontaneous sequential activity and revealed existence of an internal model of generative predictive codes for the regularities of multiple future novel spatial sequences. During navigation, the inferred difference between external stimuli and the internal model was encoded by emergence of intrinsic-unlikely, novel functional connections, which updated the model by preferentially potentiating post-experience. This internal model and these predictive codes depended on neuronal organization into inferred modules of short, highrepeat sequential neuronal ``tuplets'' operating as ``neuro-codons.'' We propose that flexible multiplexing of neuronal tuplets into repertoires of extended sequences vastly expands the capacity of hippocampal predictive codes, which could initiate topdown hierarchical cortical loops for spatial and mental navigation and rapid learning.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9EAPSMD6\\Liu et al. - 2018 - Generative Predictive Codes by Multiplexed Hippoca.pdf},
  journal = {Neuron},
  language = {en},
  number = {6}
}

@article{liu_dragoi_2019,
  title = {Preconfigured Patterns Are the Primary Driver of Offline Multi-Neuronal Sequence Replay},
  author = {Liu, Kefei and Sibille, Jeremie and Dragoi, George},
  year = {2019},
  month = mar,
  volume = {29},
  pages = {275--283},
  issn = {10509631},
  doi = {10.1002/hipo.23034},
  abstract = {Spontaneous neuronal ensemble activity in the hippocampus is believed to result from a combination of preconfigured internally generated dynamics and the unique patterns of activity driven by recent experience. Previous research has established that preconfigured sequential neuronal patterns (i.e., preplay) contribute to the expression of future place cell sequences, which in turn contribute to the sequential neuronal patterns expressed post-experience (i.e., replay). The relative contribution of preconfigured and of experience-related factors to replay and to overall sequential activity during post-run sleep is believed to be highly biased toward the recent run experience, despite never being tested directly. Here, we use multi-neuronal sequence analysis unbiased by firing rate to compute and directly compare the contributions of internally generated and of recent experience-driven factors to the sequential neuronal activity in post-run sleep in na\"ive adult rats. We find that multi-neuronal sequences during post-run sleep are dominantly contributed by the pre-run preconfigured patterns and to a much smaller extent by the place cell sequences and associated awake rest multi-neuronal sequences experienced during de novo run session, which are weakly and similarly correlated with pre- and post-run sleep multi-neuronal sequences. These findings indicate a robust default internal organization of the hippocampal network into sequential neuronal ensembles that withstands a de novo spatial experience and suggest that integration of novel information during de novo experience leading to lasting changes in sequential network patterns is much more subtle than previously assumed.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QP8KN9UT\\Liu et al. - 2019 - Preconfigured patterns are the primary driver of o.pdf},
  journal = {Hippocampus},
  language = {en},
  number = {3}
}

@article{liu_duyn_2012,
  title = {Finding Thalamic {{BOLD}} Correlates to Posterior Alpha {{EEG}}},
  author = {Liu, Zhongming and {de Zwart}, Jacco A. and Yao, Bing and {van Gelderen}, Peter and Kuo, Li-Wei and Duyn, Jeff H.},
  year = {2012},
  month = nov,
  volume = {63},
  pages = {1060--1069},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2012.08.025},
  abstract = {Oscillatory electrical brain activity in the alpha (8\textendash 13 Hz) band is a prominent feature of human electroencephalography (EEG) during alert wakefulness, and is commonly thought to arise primarily from the occipital and parietal parts of the cortex. While the thalamus is considered to play a supportive role in the generation and modulation of cortical alpha rhythms, its precise function remains controversial and incompletely understood. To address this, we evaluated the correlation between the blood oxygenation level dependent (BOLD) functional magnetic resonance imaging (fMRI) signals in the thalamus and the spontaneous modulation of posterior alpha rhythms based on EEG\textendash fMRI data acquired concurrently during an eyes-closed task-free condition. We observed both negative and positive correlations in the thalamus. The negative correlations were mostly seen within the visual thalamus, with a preference for the pulvinar over lateral geniculate nuclei. The positive correlations were found at the anterior and medial dorsal nuclei. Through functional connectivity analysis of the fMRI data, the pulvinar was found to be functionally associated with the same widespread cortical visual areas where the fMRI signals were negatively correlated with the posterior alpha modulation. In contrast, the dorsal nuclei were part of a distinct functional network that included brain stem, cingulate cortex and cerebellum. These observations are consistent with previous animal electrophysiology studies and the notion that the visual thalamus, and the pulvinar in particular, is intimately involved in the generation and spontaneous modulation of posterior alpha rhythms, facilitated by its reciprocal and widespread interaction with the cortical visual areas. We further postulate that the anterior and medial dorsal nuclei, being part of the ascending neuromodulatory system, may indirectly modulate cortical alpha rhythms by affecting vigilance and arousal levels.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RVEQU7RW\\Liu et al. - 2012 - Finding thalamic BOLD correlates to posterior alph.pdf},
  journal = {NeuroImage},
  language = {en},
  number = {3}
}

@techreport{liu_hasselmo_2019,
  title = {A Geometric Characterization of Population Coding in the Prefrontal Cortex and Hippocampus during a Paired-Associate Learning Task},
  author = {Liu, Yue and Brincat, Scott L and Miller, Earl K and Hasselmo, Michael E},
  year = {2019},
  month = mar,
  institution = {{Neuroscience}},
  doi = {10.1101/578849},
  abstract = {Large-scale neuronal recording techniques have enabled discoveries of population-level mechanisms for neural computation. However it is not clear how these mechanisms form by trial and error learning. In this paper we present an initial effort to characterize the population activity in monkey prefrontal cortex (PFC) and hippocampus (HPC) during the learning phase of a paired-associate task. To analyze the population data, we introduce the normalized distance, a dimensionless metric that describes the encoding of cognitive variables from the geometrical relationship among neural trajectories in state space. It is found that PFC exhibits a more sustained encoding of task-relevant variables whereas HPC only transiently encodes the identity of the stimuli. We also found partial evidence on the learning-dependent changes for some of the task variables. This study shows the feasibility of using normalized distance as a metric to characterize and compare population level encoding of task variables, and suggests further directions to explore the learning-dependent changes in the population activity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2V4TT99A\\Liu et al. - 2019 - A geometric characterization of population coding .pdf},
  language = {en},
  type = {Preprint}
}

@article{liu_hasselmo_2019a,
  title = {Neural Population Dynamics in Prefrontal Cortex and Hippocampus during Paired-Associate Learning},
  author = {Liu, Yue and Brincat, Scott L. and Miller, Earl K. and Hasselmo, Michael E.},
  year = {2019},
  month = mar,
  doi = {10.1101/578849},
  abstract = {Large-scale neuronal recording techniques have enabled discoveries of population-level mechanisms for neural computation. However it is not clear how these mechanisms form by trial and error learning. In this paper we present an initial effort to characterize the change of population activity in monkey prefrontal cortex (PFC) and hippocampus (HPC) during the learning phase of a paired-associate task. To analyze the population data, we introduce the normalized distance, a dimensionless metric that describes the encoding of cognitive variables from the geometrical relationship among neural trajectories in state space. It is found that PFC exhibits a more sustained encoding of task-relevant variables whereas HPC only transiently encodes the identity of the stimuli. Moreover, PFC and HPC also exhibit learningdependent changes for the encoding of some task variables. This study shows the feasibility of using normalized distance as a metric to characterize and compare population level encoding of task variables, and suggests further directions to explore the learning-dependent changes in the population activity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\P74LJRV2\\Liu et al. - 2019 - Neural population dynamics in prefrontal cortex an.pdf},
  journal = {bioRxiv},
  language = {en}
}

@article{liu_howard_2018,
  title = {A Neural Microcircuit Model for a Scalable Scale-Invariant Representation of Time},
  author = {Liu, Yue and Tiganj, Zoran and Hasselmo, Michael E and Howard, Marc W.},
  year = {2018},
  month = nov,
  pages = {327387},
  issn = {10509631},
  doi = {10.1002/hipo.22994},
  abstract = {Scale-invariant timing has been observed in a wide range of behavioral experiments. The firing properties of recently described time cells provide a possible neural substrate for scale-invariant behavior. Earlier neural circuit models do not produce scale-invariant neural sequences. In this paper we present a biologically detailed network model based on an earlier mathematical algorithm. The simulations incorporate exponentially decaying persistent firing maintained by the calcium-activated nonspecific (CAN) cationic current and a network structure given by the inverse Laplace transform to generate time cells with scale-invariant firing rates. This model provides the first biologically detailed neural circuit for generating scale-invariant time cells. The circuit that implements the inverse Laplace transform merely consists of off-center/on-surround receptive fields. Critically, rescaling temporal sequences can be accomplished simply via cortical gain control (changing the slope of the f-I curve).},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WBVQUAI9\\Liu et al. - 2018 - A neural microcircuit model for a scalable scale-invariant representation of time.pdf},
  journal = {Hippocampus},
  keywords = {boston,brain,center for memory and,center for systems neuroscience,massachusetts,university}
}

@article{liu_howard_2019,
  title = {Generation of Scale-Invariant Sequential Activity in Linear Recurrent Networks},
  author = {Liu, Yue and Howard, Marc W.},
  year = {2019},
  month = mar,
  doi = {10.1101/580522},
  abstract = {Sequential neural activity has been observed in many parts of the brain and has been proposed as a neural mechanism for memory. The natural world expresses temporal relationships at a wide range of scales. Because we cannot know the relevant scales a priori it is desirable that memory, and thus the generated sequences, are scale-invariant. Although recurrent neural network models have been proposed as a mechanism for generating sequences, the requirements for scale-invariant sequences are not known. This paper reports the constraints that enable a linear recurrent neural network model to generate scale-invariant sequential activity. A straightforward eigendecomposition analysis results in two independent conditions that are required for scale-invariance. First the eigenvalues of the network must be geometrically spaced. Second, the eigenvectors must be related to one another via translation. These constraints, along with considerations on initial conditions, provide a general recipe to build linear recurrent neural networks that support scale-invariant sequential activity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BDBKY6RG\\Liu and Howard - 2019 - Generation of scale-invariant sequential activity .pdf},
  journal = {bioRxiv},
  language = {en}
}

@book{liu_liu_2011,
  title = {Applications of {{Learning}} to {{Rank}}},
  author = {Liu, Tie-Yan},
  year = {2011},
  doi = {10.1561/1500000016},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BHDL3FUH\\Liu - 2011 - Applications of Learning to Rank.pdf},
  isbn = {978-3-642-14266-6}
}

@article{livneh_andermann_2020,
  title = {Estimation of {{Current}} and {{Future Physiological States}} in {{Insular Cortex}}},
  author = {Livneh, Yoav and Sugden, Arthur and Madara, Joseph C and Essner, Rachel A and Flores, Vanessa I and Andermann, Mark L},
  year = {2020},
  doi = {10.1016/j.neuron.2019.12.027},
  abstract = {Interoception, the sense of internal bodily signals, isessential for physiological homeostasis, cognition,and emotions. While human insular cortex (InsCtx)is implicated in interoception, the cellular and circuitmechanisms remain unclear. We imaged mouseInsCtx neurons during two physiological deficiencystates: hunger and thirst. InsCtx ongoing activity pat-terns reliably tracked the gradual return to homeosta-sis but not changes in behavior. Accordingly, whileartificial induction of hunger or thirst in sated micevia activation of specific hypothalamic neurons(AgRP or SFOGLUT) restored cue-evoked food- or wa-ter-seeking, InsCtx ongoing activity continued toreflect physiological satiety. During natural hungeror thirst, food or water cues rapidly and transientlyshifted InsCtx population activity to the futuresatiety-related pattern. During artificial hunger orthirst, food or water cues further shifted activitybeyondthe current satiety-related pattern. Togetherwith circuit-mapping experiments, these findingssuggest that InsCtx integrates visceral-sensory sig-nals of current physiological state with hypothala-mus-gated amygdala inputs that signal upcomingingestion of food or water to compute a predictionof future physiological state},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PNF3QML9\\Estimation of Current and Future Physiological Sta;C\:\\Users\\wchapman\\Zotero\\storage\\WYILIA9D\\S0896627319310931.html},
  language = {en}
}

@article{lobier_palva_2018,
  title = {High-Alpha Band Synchronization across Frontal, Parietal and Visual Cortex Mediates Behavioral and Neuronal Effects of Visuospatial Attention},
  author = {Lobier, Muriel and Palva, J Matias and Palva, Satu},
  year = {2018},
  doi = {10.1016/j.neuroimage.2017.10.044},
  abstract = {A B S T R A C T Visuospatial attention prioritizes processing of attended visual stimuli. It is characterized by lateralized alpha-band (8\textendash 14 Hz) amplitude suppression in visual cortex and increased neuronal activity in a network of frontal and parietal areas. It has remained unknown what mechanisms coordinate neuronal processing among fronto-parietal network and visual cortices and implement the attention-related modulations of alpha-band amplitudes and behavior. We investigated whether large-scale network synchronization could be such a mechanism. We recorded human cortical activity with magnetoencephalography (MEG) during a visuospatial attention task. We then identified the frequencies and anatomical networks of inter-areal phase synchronization from source localized MEG data. We found that visuospatial attention is associated with robust and sustained long-range synchronization of cortical oscillations exclusively in the high-alpha (10\textendash 14 Hz) frequency band. This synchro-nization connected frontal, parietal and visual regions and was observed concurrently with amplitude suppression of low-alpha (6\textendash 9 Hz) band oscillations in visual cortex. Furthermore, stronger high-alpha phase synchronization was associated with decreased reaction times to attended stimuli and larger suppression of alpha-band ampli-tudes. These results thus show that high-alpha band phase synchronization is functionally significant and could coordinate the neuronal communication underlying the implementation of visuospatial attention.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GZL55U6I\\Lobier, Palva, Palva - 2018 - High-alpha band synchronization across frontal, parietal and visual cortex mediates behavioral and neurona.pdf},
  keywords = {alpha,Attention,MEG,Oscillations,Synchronization}
}

@article{lobo_kasabov_2020,
  title = {Spiking {{Neural Networks}} and Online Learning: {{An}} Overview and Perspectives},
  shorttitle = {Spiking {{Neural Networks}} and Online Learning},
  author = {Lobo, Jesus L. and Del Ser, Javier and Bifet, Albert and Kasabov, Nikola},
  year = {2020},
  month = jan,
  volume = {121},
  pages = {88--100},
  issn = {08936080},
  doi = {10.1016/j.neunet.2019.09.004},
  abstract = {Applications that generate huge amounts of data in the form of fast streams are becoming increasingly prevalent, being therefore necessary to learn in an online manner. These conditions usually impose memory and processing time restrictions, and they often turn into evolving environments where a change may affect the input data distribution. Such a change causes that predictive models trained over these stream data become obsolete and do not adapt suitably to new distributions. Specially in these non-stationary scenarios, there is a pressing need for new algorithms that adapt to these changes as fast as possible, while maintaining good performance scores. Unfortunately, most off-theshelf classification models need to be retrained if they are used in changing environments, and fail to scale properly. Spiking Neural Networks have revealed themselves as one of the most successful approaches to model the behavior and learning potential of the brain, and exploit them to undertake practical online learning tasks. Besides, some specific flavors of Spiking Neural Networks can overcome the necessity of retraining after a drift occurs. This work intends to merge both fields by serving as a comprehensive overview, motivating further developments that embrace Spiking Neural Networks for online learning scenarios, and being a friendly entry point for non-experts.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4CR2XM44\\Lobo et al. - 2020 - Spiking Neural Networks and online learning An ov.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\HDYGAA6A\\Lobo et al. - 2020 - Spiking Neural Networks and online learning An ov.pdf},
  journal = {Neural Networks},
  language = {en}
}

@article{loesche_hasselhorn_2015,
  title = {How Knowing the Rules Affects Solving the {{Raven Advanced Progressive Matrices Test}}},
  author = {Loesche, Patrick and Wiley, Jennifer and Hasselhorn, Marcus},
  year = {2015},
  volume = {48},
  pages = {58--75},
  doi = {10.1016/j.intell.2014.10.004},
  abstract = {a r t i c l e i n f o a b s t r a c t The solution process underlying the Raven Advanced Progressive Matrices (RAPM) has been conceptualized to consist of two subprocesses: rule induction and goal management. Past research has also found a strong relation between measures of working memory capacity and performance on RAPM. The present research attempted to test whether the goal management subprocess is responsible for the relation between working memory capacity and RAPM, using a paradigm where the rules necessary to solve the problems were given to subjects, assuming that it would render rule induction unnecessary. Three experiments revealed that working memory capacity was still strongly related to RAPM performance in the given-rules condition, while in two experiments the correlation in the given-rules condition was significantly higher than in the no-rules condition. Experiment 4 revealed that giving the rules affected problem solving behavior. Evidence from eye tracking protocols suggested that participants in the given-rules condition were more likely to approach the problems with a constructive matching strategy. Two possible mechanisms are discussed that could both explain why providing participants with the rules might increase the relation between working memory capacity and RAPM performance.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PFN9SRVV\\Loesche, Wiley, Hasselhorn - 2015 - How knowing the rules affects solving the Raven Advanced Progressive Matrices Test.pdf},
  journal = {Intelligence},
  keywords = {Raven APM,Rule induction,Rule knowledge,working-memory}
}

@article{logo_logo_2012,
  title = {"{{Frequently Asked Questions}}},
  author = {{Logo}},
  year = {2012},
  pages = {1--12},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PU7D85LM\\Logo - 2012 - Frequently Asked Questions.pdf}
}

@article{logothetis_oeltermann_2001,
  title = {Neurophysiological Investigation of the Basis of the {{fMRI}} Signal},
  author = {Logothetis, Nikos K. and Pauls, Jon and Augath, Mark and Trinath, Torsten and Oeltermann, Axel},
  year = {2001},
  month = jul,
  volume = {412},
  pages = {150--157},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/35084005},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FK5EJFJ6\\Logothetis et al. - 2001 - Neurophysiological investigation of the basis of t.pdf},
  journal = {Nature},
  language = {en},
  number = {6843}
}

@article{london_hausser_2005,
  title = {{{DENDRITIC COMPUTATION}}},
  author = {London, Michael and H{\"a}usser, Michael},
  year = {2005},
  pages = {32},
  abstract = {One of the central questions in neuroscience is how particular tasks, or computations, are implemented by neural networks to generate behavior. The prevailing view has been that information processing in neural networks results primarily from the properties of synapses and the connectivity of neurons within the network, with the intrinsic excitability of single neurons playing a lesser role. As a consequence, the contribution of single neurons to computation in the brain has long been underestimated. Here we review recent work showing that neuronal dendrites exhibit a range of linear and nonlinear mechanisms that allow them to implement elementary computations. We discuss why these dendritic properties may be essential for the computations performed by the neuron and the network and provide theoretical and experimental examples to support this view.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FQDY7R8Z\\London and Häusser - 2005 - DENDRITIC COMPUTATION.pdf},
  language = {en}
}

@article{loonis_miller_2017,
  title = {Article {{A Meta}}-{{Analysis Suggests Different Neural Correlates}} for {{Implicit}} and {{Explicit Learning Article A Meta}}-{{Analysis Suggests Different Neural Correlates}}},
  author = {Loonis, Roman F. and Brincat, Scott L. and Antzoulatos, Evan G. and Miller, Earl K},
  year = {2017},
  month = oct,
  volume = {96},
  pages = {521--534.e7},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2017.09.032},
  abstract = {Summary A meta-analysis of non-human primates performing three different tasks (Object-Match, Category-Match, and Category-Saccade associations) revealed signatures of explicit and implicit learning. Performance improved equally following correct and error trials in the Match (explicit) tasks, but it improved more after correct trials in the Saccade (implicit) task, a signature of explicit versus implicit learning. Likewise, error-related negativity, a marker for error processing, was greater in the Match (explicit) tasks. All tasks showed an increase in alpha/beta (10\textendash 30 Hz) synchrony after correct choices. However, only the implicit task showed an increase in theta (3\textendash 7 Hz) synchrony after correct choices that decreased with learning. In contrast, in the explicit tasks, alpha/beta synchrony increased with learning and decreased thereafter. Our results suggest that explicit versus implicit learning engages different neural mechanisms that rely on different patterns of oscillatory synchrony.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AGFVPCHV\\Loonis et al. - 2017 - Article A Meta-Analysis Suggests Different Neural Correlates for Implicit and Explicit Learning Article A Meta-An.pdf},
  journal = {Neuron},
  keywords = {explicit,implicit,prefrontal cortex,reward learning,synchrony},
  number = {2}
}

@article{lopes_lopes_2010,
  title = {{{EEG}} - {{fMRI}}},
  author = {Lopes, Fernando},
  year = {2010},
  pages = {19--39},
  doi = {10.1007/978-3-540-87919-0},
  abstract = {Functional magnetic resonance imaging (fMRI) and electroencephalography (EEG) are very important and complementary modalities since fMRI offers high spatial resolution while EEG provides a direct measurement of neuronal activity with high temporal resolution. Interest in the integration of these two types of data is growing rapidly as it promises to yield important new insights into human brain activity, as has already occurred in the case of epilepsy. Indeed, it seems certain that integrated EEG-fMRI will play an increasing role in neuroscience and in the clinical study of various brain disorders. This book discusses in depth all aspects of EEG-fMRI, including physiological principles and technical and methodological issues such as EEG artefact reduction methods, image quality, and data analysis strategies. Detailed consideration is given to all potential applications, primarily in the fields of sleep research, cognitive neuroscience, and clinical neurology and psychiatry. All of the authors are recognized experts in the field, and the text is supported by numerous informative illustrations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\26MWG58N\\Lopes - 2010 - EEG - fMRI.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\UXRNHXRS\\Lopes - 2010 - EEG - fMRI(2).pdf}
}

@article{lopes-dos-santos_dupret_2018,
  title = {Parsing {{Hippocampal Theta Oscillations}} by {{Nested Spectral Components}} during {{Spatial Exploration}} and {{Memory}}-{{Guided Behavior}}},
  author = {{Lopes-dos-Santos}, V{\'i}tor and {van de Ven}, Gido M and Morley, Alexander and Trouche, St{\'e}phanie and {Campo-Urriza}, Natalia and Dupret, David},
  year = {2018},
  doi = {10.1016/j.neuron.2018.09.031},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\48ZLLAIK\\Lopes-dos-Santos et al. - 2018 - Parsing Hippocampal Theta Oscillations by Nested Spectral Components during Spatial Exploration and Mem.pdf}
}

@article{lopes-dos-santos_quianquiroga_2018,
  title = {Extracting Information from the Shape and Spatial Distribution of Evoked Potentials},
  author = {{Lopes-Dos-Santos}, V{\'i}tor and Rey, Hernan G and Navajas, Joaquin and Quian Quiroga, Rodrigo},
  year = {2018},
  volume = {296},
  pages = {12--22},
  doi = {10.1016/j.jneumeth.2017.12.014},
  abstract = {\textbullet{} A decoding approach for extracting and quantifying information from ERPs is proposed. \textbullet{} The proposed framework extracts more information than standard supervised approaches. \textbullet{} The method allows analysis of multichannel signals. a b s t r a c t Background: Over 90 years after its first recording, scalp electroencephalography (EEG) remains one of the most widely used techniques in human neuroscience research, in particular for the study of event-related potentials (ERPs). However, because of its low signal-to-noise ratio, extracting useful information from these signals continues to be a hard-technical challenge. Many studies focus on simple properties of the ERPs such as peaks, latencies, and slopes of signal deflections. New method: To overcome these limitations, we developed the Wavelet-Information method which uses wavelet decomposition, information theory, and a quantification based on single-trial decoding performance to extract information from evoked responses. Results: Using simulations and real data from four experiments, we show that the proposed approach outperforms standard supervised analyses based on peak amplitude estimation. Moreover, the method can extract information using the raw data from all recorded channels using no a priori knowledge or pre-processing steps. Comparison with existing method(s): We show that traditional approaches often disregard important fea-tures of the signal such as the shape of EEG waveforms. Also, other approaches often require some form of a priori knowledge for feature selection and lead to problems of multiple comparisons. Conclusions: This approach offers a new and complementary framework to design experiments that go beyond the traditional analyses of ERPs. Potentially, it allows a wide usage beyond basic research; such as for clinical diagnosis, brain-machine interfaces, and neurofeedback applications requiring single-trial analyses.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CBFA4GW9\\Lopes-Dos-Santos et al. - 2018 - Extracting information from the shape and spatial distribution of evoked potentials.pdf},
  journal = {Journal of Neuroscience Methods},
  keywords = {eeg,Event-related potentials}
}

@article{lopesdasilva_lopesdasilva_2013,
  title = {{{EEG}} and {{MEG}}: {{Relevance}} to Neuroscience},
  author = {{Lopes da Silva}, Fernando},
  year = {2013},
  volume = {80},
  pages = {1112--1128},
  issn = {08966273},
  doi = {10.1016/j.neuron.2013.10.017},
  abstract = {To understand dynamic cognitive processes, the high time resolution of EEG/MEG is invaluable. EEG/MEG signals can play an important role in providing measures of functional and effective connectivity in the brain. After a brief description of the foundations and basic methodological aspects of EEG/MEG signals, the relevance of the signals to obtain novel insights into the neuronal mechanisms underlying cognitive processes is surveyed, with emphasis on neuronal oscillations (ultra-slow, theta, alpha, beta, gamma, and HFOs) and combinations of oscillations. Three main functional roles of brain oscillations are put in evidence: (1) coding specific information, (2) setting and modulating brain attentional states, and (3) assuring the communication between neuronal populations such that specific dynamic workspaces may be created. The latter form the material core of cognitive functions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EP4J4VRP\\Lopes da Silva - 2013 - EEG and MEG Relevance to neuroscience.pdf},
  journal = {Neuron},
  number = {5},
  pmid = {24314724}
}

@article{lotter_cox_2017,
  title = {Deep {{Predictive Coding Networks}} for {{Video Prediction}} and {{Unsupervised Learning}}},
  author = {Lotter, William and Kreiman, Gabriel and Cox, David},
  year = {2017},
  month = feb,
  abstract = {While great strides have been made in using deep learning algorithms to solve supervised learning tasks, the problem of unsupervised learning - leveraging unlabeled examples to learn about the structure of a domain - remains a difficult unsolved challenge. Here, we explore prediction of future frames in a video sequence as an unsupervised learning rule for learning about the structure of the visual world. We describe a predictive neural network ("PredNet") architecture that is inspired by the concept of "predictive coding" from the neuroscience literature. These networks learn to predict future frames in a video sequence, with each layer in the network making local predictions and only forwarding deviations from those predictions to subsequent network layers. We show that these networks are able to robustly learn to predict the movement of synthetic (rendered) objects, and that in doing so, the networks learn internal representations that are useful for decoding latent object parameters (e.g. pose) that support object recognition with fewer training views. We also show that these networks can scale to complex natural image streams (car-mounted camera videos), capturing key aspects of both egocentric movement and the movement of objects in the visual scene, and the representation learned in this setting is useful for estimating the steering angle. Altogether, these results suggest that prediction represents a powerful framework for unsupervised learning, allowing for implicit learning of object and scene structure.},
  archivePrefix = {arXiv},
  eprint = {1605.08104},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9UN9CJPK\\lotter_cox_2017.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\368GL933\\1605.html},
  journal = {arXiv:1605.08104 [cs, q-bio]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition},
  primaryClass = {cs, q-bio}
}

@article{lotter_cox_2020,
  title = {A Neural Network Trained for Prediction Mimics Diverse Features of Biological Neurons and Perception},
  author = {Lotter, William and Kreiman, Gabriel and Cox, David},
  year = {2020},
  month = apr,
  volume = {2},
  pages = {210--219},
  issn = {2522-5839},
  doi = {10.1038/s42256-020-0170-9},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JG6HEJHH\\Lotter et al. - 2020 - A neural network trained for prediction mimics div.pdf},
  journal = {Nature Machine Intelligence},
  language = {en},
  number = {4}
}

@article{lovett-barron_losonczy_2014,
  title = {Dendritic Inhibition in the Hippocampus Supports Fear Learning.},
  author = {{Lovett-Barron}, Matthew and Kaifosh, Patrick and a Kheirbek, Mazen and Danielson, Nathan and Zaremba, Jeffrey D and Reardon, Thomas R and Turi, Gergely F and Hen, Ren{\'e} and Zemelman, Boris V and Losonczy, Attila},
  year = {2014},
  month = feb,
  volume = {343},
  pages = {857--863},
  issn = {1095-9203},
  doi = {10.1126/science.1247485},
  abstract = {Fear memories guide adaptive behavior in contexts associated with aversive events. The hippocampus forms a neural representation of the context that predicts aversive events. Representations of context incorporate multisensory features of the environment, but must somehow exclude sensory features of the aversive event itself. We investigated this selectivity using cell type-specific imaging and inactivation in hippocampal area CA1 of behaving mice. Aversive stimuli activated CA1 dendrite-targeting interneurons via cholinergic input, leading to inhibition of pyramidal cell distal dendrites receiving aversive sensory excitation from the entorhinal cortex. Inactivating dendrite-targeting interneurons during aversive stimuli increased CA1 pyramidal cell population responses and prevented fear learning. We propose subcortical activation of dendritic inhibition as a mechanism for exclusion of aversive stimuli from hippocampal contextual representations during fear learning.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\47WIX8V8\\Lovett-Barron et al. - 2014 - Dendritic inhibition in the hippocampus supports fear learning.pdf},
  journal = {Science (New York, N.Y.)},
  keywords = {amygdala,Animals,CA1 Region,Conditioning (Psychology),Dendrites,Dendrites: physiology,Fear,Fear: physiology,Glycine,Glycine: metabolism,Hippocampal,Hippocampal: cytology,Hippocampal: physiology,Hippocampus,Hippocampus: cytology,Hippocampus: physiology,Interneurons,Interneurons: metabolism,Interneurons: physiology,Learning,Learning: physiology,Mice,Neural Inhibition,Nicotinic,Nicotinic: metabolism,Receptors,Somatostatin,Somatostatin: metabolism},
  number = {6173},
  pmid = {24558155}
}

@article{lowe_rao_2016,
  title = {Modern {{Methods}} for {{Interrogating}} the {{Human Connectome}}},
  author = {Lowe, Mark J and Sakaie, Ken E and Beall, Erik B and Calhoun, Vince D and Bridwell, David A and Rubinov, Mikail and Rao, Stephen M},
  year = {2016},
  volume = {22},
  pages = {105--119},
  issn = {1355-6177},
  doi = {10.1017/S1355617716000060},
  abstract = {\{\textbackslash textless\}p\{\textbackslash textgreater\} \{\textbackslash textless\}bold\{\textbackslash textgreater\}Objectives:\{\textbackslash textless\}/bold\{\textbackslash textgreater\} Connectionist theories of brain function took hold with the seminal contributions of Norman Geschwind a half century ago. Modern neuroimaging techniques have expanded the scientific interest in the study of brain connectivity to include the intact as well as disordered brain. \{\textbackslash textless\}bold\{\textbackslash textgreater\}Methods:\{\textbackslash textless\}/bold\{\textbackslash textgreater\} In this review, we describe the most common techniques used to measure functional and structural connectivity, including resting state functional MRI, diffusion MRI, and electroencephalography and magnetoencephalography coherence. We also review the most common analytical approaches used for examining brain interconnectivity associated with these various imaging methods. \{\textbackslash textless\}bold\{\textbackslash textgreater\}Results:\{\textbackslash textless\}/bold\{\textbackslash textgreater\} This review presents a critical analysis of the assumptions, as well as methodological limitations, of each imaging and analysis approach. \{\textbackslash textless\}bold\{\textbackslash textgreater\}Conclusions:\{\textbackslash textless\}/bold\{\textbackslash textgreater\} The overall goal of this review is to provide the reader with an introduction to evaluating the scientific methods underlying investigations that probe the human connectome. ( \{\textbackslash textless\}italic\{\textbackslash textgreater\}JINS\{\textbackslash textless\}/italic\{\textbackslash textgreater\} , 2016, \{\textbackslash textless\}italic\{\textbackslash textgreater\}22\{\textbackslash textless\}/italic\{\textbackslash textgreater\} , 105\textendash 119) \{\textbackslash textless\}/p\{\textbackslash textgreater\}},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BCN2W4TE\\Lowe et al. - 2016 - Modern Methods for Interrogating the Human Connectome.pdf},
  journal = {Journal of the International Neuropsychological Society},
  keywords = {complex network analysis,diffusion mri,eeg,human connectome,independent components analysis,meg coherence,resting state fmri},
  number = {02}
}

@article{lowet_vandereerden_2018,
  title = {Microsaccade-Rhythmic Modulation of Neural Synchronization and Coding within and across Cortical Areas {{V1}} and {{V2}}},
  author = {Lowet, Eric and Gips, Bart and Roberts, Mark J. and Weerd, Peter De and Jensen, Ole and {van der Eerden}, Jan},
  year = {2018},
  volume = {11},
  pages = {e0154417},
  issn = {19326203},
  doi = {10.1371/journal.pone.0154417},
  abstract = {Converging evidence suggests close relationships between the action and social space representations. The concepts of peripersonal space, as defined by cognitive neuroscience, and interpersonal space, as defined by social psychology, refer to approximately the same spatial area surrounding our bodies. The aim of this study was thus to assess experimentally whether the peripersonal (PPS) and interpersonal space (IPS) represent a similar psychological entity. Were this true, they should share some functional features. Here we tested tool-use dependent plasticity, known to modulate PPS, but still unexplored in the IPS. Results from two experiments converge in showing that tool-use remapped the action-related PPS, measured by a Reaching-distance toward a confederate, but did not affect the social-related IPS, measured by a Comfort-distance task. These findings indicate that PPS and IPS rely on dissociable plastic mechanisms and suggest that, at least in the present experimental conditions, there is no full functional overlap between these two spatial representations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Y2YWW8A9\\Lowet et al. - 2018 - Microsaccade-rhythmic modulation of neural synchronization and coding within and across cortical areas V1 and V2.pdf},
  journal = {2PLOS Biology},
  number = {4},
  pmid = {27144720}
}

@article{lu_holyoak_2012,
  title = {Bayesian Analogy with Relational Transformations.},
  author = {Lu, Hongjing and Chen, Dawn and Holyoak, Keith J.},
  year = {2012},
  volume = {119},
  pages = {617--648},
  doi = {10.1037/a0028719},
  abstract = {How can humans acquire relational representations that enable analogical inference and other forms of high-level reasoning? Using comparative relations as a model domain, we explore the possibility that bottom-up learning mechanisms applied to objects coded as feature vectors can yield representations of relations sufficient to solve analogy problems. We introduce Bayesian analogy with relational transformations (BART) and apply the model to the task of learning first-order comparative relations (e.g., larger, smaller, fiercer, meeker) from a set of animal pairs. Inputs are coded by vectors of continuous-valued features, based either on human magnitude ratings, normed feature ratings (De Deyne et al., 2008), or outputs of the topics model (Griffiths, Steyvers, \& Tenenbaum, 2007). Bootstrapping from empirical priors, the model is able to induce first-order relations represented as probabilistic weight distributions, even when given positive examples only. These learned representations allow classification of novel instantiations of the relations and yield a symbolic distance effect of the sort obtained with both humans and other primates. BART then transforms its learned weight distributions by importance-guided mapping, thereby placing distinct dimensions into correspondence. These transformed representations allow BART to reliably solve 4-term analogies (e.g., larger:smaller::fiercer:meeker), a type of reasoning that is arguably specific to humans. Our results provide a proof-of-concept that structured analogies can be solved with representations induced from unstructured feature vectors by mechanisms that operate in a largely bottom-up fashion. We discuss potential implications for algorithmic and neural models of relational thinking, as well as for the evolution of abstract thought.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RCML4WK4\\Lu et al_2012_Bayesian analogy with relational transformations.pdf},
  journal = {Psychological review},
  keywords = {analogy},
  number = {3}
}

@article{lundqvist_lansner_2011,
  title = {Theta and {{Gamma Power Increases}} and {{Alpha}}/{{Beta Power Decreases}} with {{Memory Load}} in an {{Attractor Network Model}}},
  author = {Lundqvist, Mikael and Herman, Pawel and Lansner, Anders},
  year = {2011},
  month = oct,
  volume = {23},
  pages = {3008--3020},
  issn = {0898-929X, 1530-8898},
  doi = {10.1162/jocn_a_00029},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\B6IGERNM\\Lundqvist et al. - 2011 - Theta and Gamma Power Increases and AlphaBeta Pow.pdf},
  journal = {Journal of Cognitive Neuroscience},
  language = {en},
  number = {10}
}

@article{lundqvist_miller_2016,
  title = {Gamma and {{Beta Bursts Underlie Working Memory}}},
  author = {Lundqvist, Mikael and Rose, Jonas and Herman, Pawel and Brincat, Scott L L and Buschman, Timothy J J and Miller, Earl K K.},
  year = {2016},
  volume = {90},
  pages = {152--164},
  issn = {10974199},
  doi = {10.1016/j.neuron.2016.02.028},
  abstract = {Working memory is thought to result from sustained neuron spiking. However, computational models suggest complex dynamics with discrete oscillatory bursts. We analyzed local field potential (LFP) and spiking from the prefrontal cortex (PFC) of monkeys performing a working memory task. There were brief bursts of narrow-band gamma oscillations (45\textendash 100 Hz), varied in time and frequency, accompanying encoding and re-activation of sensory information. They appeared at a minority of recording sites associated with spiking reflecting the to-be-remembered items. Beta oscillations (20\textendash 35 Hz) also occurred in brief, variable bursts but reflected a default state interrupted by encoding and decoding. Only activity of neurons reflecting encoding/decoding correlated with changes in gamma burst rate. Thus, gamma bursts could gate access to, and prevent sensory interference with, working memory. This supports the hypothesis that working memory is manifested by discrete oscillatory dynamics and spiking, not sustained activity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\APMBTJZZ\\Lundqvist et al. - 2016 - Gamma and Beta Bursts Underlie Working Memory.pdf},
  journal = {Neuron},
  number = {1},
  pmid = {26996084}
}

@article{lundqvist_miller_2017,
  title = {Gamma and Beta Bursts during Working Memory Read-out Suggest Roles in Its Volitional Control},
  author = {Lundqvist, Mikael and Herman, Pawel and Warden, Melissa R and Brincat, Scott L and Miller, Earl K},
  year = {2017},
  pages = {122598},
  issn = {2041-1723},
  doi = {10.1101/122598},
  abstract = {Working memory (WM) activity is not as stationary or sustained as previously thought. There are brief bursts of gamma (55 to 120 Hz) and beta (20 to 35 Hz) oscillations, the former linked to stimulus information in spiking. We examine these dynamics in relation to read-out from WM, which is still not well understood. Monkeys held a sequence of two objects and had to decide if they matched a subsequent sequence. Changes in the balance of beta/gamma suggested their role in WM control. In anticipation of having to use an object for the match decision, there was an increase in spiking information about that object along with an increase in gamma and a decrease in beta. When an object was no longer needed, beta increased and gamma as well as spiking information about that object decreased. Deviations from these dynamics predicted behavioral errors. Thus, turning up or down beta could regulate gamma and the information in working memory.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PTQJCRMP\\Lundqvist et al. - 2017 - Gamma and beta bursts during working memory read-out suggest roles in its volitional control.pdf},
  journal = {bioRxiv},
  number = {2018}
}

@article{lundqvist_miller_2018,
  title = {Working {{Memory}}: {{Delay Activity}}, {{Yes}}! {{Persistent Activity}}? {{Maybe Not}}},
  shorttitle = {Working {{Memory}}},
  author = {Lundqvist, Mikael and Herman, Pawel and Miller, Earl K.},
  year = {2018},
  month = aug,
  volume = {38},
  pages = {7013--7019},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.2485-17.2018},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\76JZSVZ9\\Lundqvist et al. - 2018 - Working Memory Delay Activity, Yes! Persistent Ac.pdf},
  journal = {The Journal of Neuroscience},
  language = {en},
  number = {32}
}

@article{lundqvist_miller_2018a,
  title = {Gamma and Beta Bursts during Working Memory Readout Suggest Roles in Its Volitional Control},
  author = {Lundqvist, Mikael and Herman, Pawel and Warden, Melissa R and Brincat, Scott L and Miller, Earl K},
  year = {2018},
  volume = {9},
  issn = {20411723},
  doi = {10.1038/s41467-017-02791-8},
  abstract = {Working memory (WM) activity is not as stationary or sustained as previously thought. There are brief bursts of gamma ({$\sim$}50\textendash 120 Hz) and beta ({$\sim$}20\textendash 35 Hz) oscillations, the former linked to stimulus information in spiking. We examined these dynamics in relation to readout and control mechanisms of WM. Monkeys held sequences of two objects in WM to match to subsequent sequences. Changes in beta and gamma bursting suggested their distinct roles. In anticipation of having to use an object for the match decision, there was an increase in gamma and spiking information about that object and reduced beta bursting. This readout signal was only seen before relevant test objects, and was related to premotor activity. When the objects were no longer needed, beta increased and gamma decreased together with object spiking information. Deviations from these dynamics predicted behavioral errors. Thus, beta could regulate gamma and the information in WM.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IMNLNJTE\\Lundqvist et al. - 2017 - Gamma and beta bursts during working memory read-out suggest roles in its volitional control.pdf},
  journal = {Nature Communications},
  number = {1},
  pmid = {29374153}
}

@techreport{lundqvist_miller_2020,
  title = {Preservation and Changes in Oscillatory Dynamics across the Cortical Hierarchy},
  author = {Lundqvist, Mikael and Bastos, Andr{\'e} M. and Miller, Earl K.},
  year = {2020},
  month = feb,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.02.03.932533},
  abstract = {Theta (2-8 Hz), Alpha (8-12 Hz), beta (12-35 Hz) and gamma ({$>$}35 Hz) rhythms are ubiquitous in cortex. But there is little understanding of whether they have similar properties and functions in different cortical areas because they have rarely been compared across areas. We record neuronal spikes and local field potentials simultaneously at several levels of the cortical hierarchy in monkeys. Theta, alpha, beta and gamma oscillations had similar relationships to spiking activity in visual, parietal and prefrontal cortex. However, the frequencies in all bands increased up the cortical hierarchy. These results suggest that these rhythms have similar functions across cortex. We discuss how the increase in frequencies up the cortical hierarchy may help sculpt cortical flow and processing.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4LZ457UR\\Lundqvist et al. - 2020 - Preservation and changes in oscillatory dynamics a.pdf},
  language = {en},
  type = {Preprint}
}

@article{lupyan_mcclelland_2007,
  title = {Language {{Is Not Just}} for {{Talking Redundant Labels Facilitate Learning}} of {{Novel Categories}}},
  author = {Lupyan, Gary and Rakison, David H and Mcclelland, James L},
  year = {2007},
  abstract = {\textemdash In addition to having communicative functions, verbal labels may play a role in shaping concepts. Two experiments assessed whether the presence of labels affected category formation. Subjects learned to categorize ''aliens'' as those to be approached or those to be avoided. After accuracy feedback on each response was provided, a nonsense label was either presented or not. Providing nonsense category labels facilitated category learning even though the labels were redundant and all subjects had equivalent experience with supervised categorization of the stimuli. A followup study investigated differences between learning verbal and nonverbal associations and showed that learning a nonverbal association did not facilitate categorization. The findings show that labels make category distinctions more concrete and bear directly on the languageandthought debate.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PJQATUAK\\Lupyan, Rakison, Mcclelland - 2007 - Language Is Not Just for Talking Redundant Labels Facilitate Learning of Novel Categories.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\RPF43FNR\\Lupyan, Rakison, Mcclelland - 2007 - Language Is Not Just for Talking Redundant Labels Facilitate Learning of Novel Categories(2).pdf},
  journal = {Psychological Science}
}

@article{lupyan_thompson-schill_2012,
  title = {The Evocative Power of Words: Activation of Concepts by Verbal and Nonverbal Means.},
  author = {Lupyan, Gary and {Thompson-Schill}, Sharon L},
  year = {2012},
  volume = {141},
  pages = {170--186},
  issn = {1939-2222},
  doi = {10.1037/a0024904},
  abstract = {A major part of learning a language is learning to map spoken words onto objects in the environment. An open question is what are the consequences of this learning for cognition and perception? Here, we present a series of experiments that examine effects of verbal labels on the activation of conceptual information as measured through picture verification tasks. We find that verbal cues, such as the word "cat," lead to faster and more accurate verification of congruent objects and rejection of incongruent objects than do either nonverbal cues, such as the sound of a cat meowing, or words that do not directly refer to the object, such as the word "meowing." This label advantage does not arise from verbal labels being more familiar or easier to process than other cues, and it does extends to newly learned labels and sounds. Despite having equivalent facility in learning associations between novel objects and labels or sounds, conceptual information is activated more effectively through verbal means than through nonverbal means. Thus, rather than simply accessing nonverbal concepts, language activates aspects of a conceptual representation in a particularly effective way. We offer preliminary support that representations activated via verbal means are more categorical and show greater consistency between subjects. These results inform the understanding of how human cognition is shaped by language and hint at effects that different patterns of naming can have on conceptual structure.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Y5VYA9Q9\\Lupyan, Thompson-Schill - 2012 - The evocative power of words activation of concepts by verbal and nonverbal means.pdf},
  journal = {Journal of experimental psychology. General},
  keywords = {Communication,Concept Formation,Concept Formation: physiology,Cues,Female,Humans,Language,Male,Verbal Learning,Verbal Learning: physiology},
  number = {1},
  pmid = {21928923}
}

@article{lutz_davidson_2004,
  title = {Gamma {{Synchrony During Mental Practice}}},
  author = {Lutz, Antoine and Greischar, Lawrence L and Rawlings, Nancy B and Ricard, Matthieu and Davidson, Richard J},
  year = {2004},
  volume = {101},
  pages = {16369--16373},
  issn = {0027-8424},
  doi = {10.1073/pnas.0407401101},
  abstract = {Practitioners understand ``meditation,'' or mental training, to be a process of familiarization with one's own mental life leading to long-lasting changes in cognition and emotion. Little is known about this process and its impact on the brain. Here we find that long-term Buddhist practitioners self-induce sustained electroen- cephalographic high-amplitude gamma-band oscillations and phase-synchrony during meditation. These electroencephalogram patterns differ from those of controls, in particular over lateral frontoparietal electrodes. In addition, the ratio of gamma-band activity (25\textendash{} 42 Hz) to slow oscillatory activity (4 \textendash 13 Hz) is initially higher in the resting baseline before meditation for the practitio- ners than the controls over medial frontoparietal electrodes. This difference increases sharply during meditation over most of the scalp electrodes and remains higher than the initial baseline in the postmeditation baseline. These data suggest that mental training involves temporal integrative mechanisms and may induce short- term and long-term neural changes. Meditative Instruction. The st ate of unconditional lov ing-kindness and compassion is described as an ``unrestricted readiness and availabilit y to help liv ing beings.'' This practice does not require concentration on particular objects, memories, or images, al- though in other medit ations that are also part of their long-ter m training, practitioners focus on particular persons or groups of beings. Because ``benevolence and compassion per vades the mind as a way of being,'' this st ate is called ``pure compassion'' or ``nonreferential compassion'' (dmigs med snying rje in Ti- bet an). A week before the collection of the dat a, medit ative instr uctions were given to the control subjects, who were asked to practice daily for 1 h. The qualit y of their training was verbally assessed before EEG collection. During the training session, the control subjects were asked to think of someone they care about, such as their parents or beloved, and to let their mind be invaded by a feeling of love or compassion (by imagining a sad situation},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9ZDFKITP\\Lutz et al. - 2004 - Gamma Synchrony During Mental Practice.pdf},
  journal = {Pnas},
  number = {46},
  pmid = {15534199}
}

@article{luz_latham_2012,
  title = {Balancing {{Feed}}-{{Forward Excitation}} and {{Inhibition}} via {{Hebbian Inhibitory Synaptic Plasticity}}},
  author = {Luz, Yotam and Shamir, Maoz and Latham, Peter E},
  year = {2012},
  volume = {8},
  doi = {10.1371/journal.pcbi.1002334},
  abstract = {It has been suggested that excitatory and inhibitory inputs to cortical cells are balanced, and that this balance is important for the highly irregular firing observed in the cortex. There are two hypotheses as to the origin of this balance. One assumes that it results from a stable solution of the recurrent neuronal dynamics. This model can account for a balance of steady state excitation and inhibition without fine tuning of parameters, but not for transient inputs. The second hypothesis suggests that the feed forward excitatory and inhibitory inputs to a postsynaptic cell are already balanced. This latter hypothesis thus does account for the balance of transient inputs. However, it remains unclear what mechanism underlies the fine tuning required for balancing feed forward excitatory and inhibitory inputs. Here we investigated whether inhibitory synaptic plasticity is responsible for the balance of transient feed forward excitation and inhibition. We address this issue in the framework of a model characterizing the stochastic dynamics of temporally anti-symmetric Hebbian spike timing dependent plasticity of feed forward excitatory and inhibitory synaptic inputs to a single post-synaptic cell. Our analysis shows that inhibitory Hebbian plasticity generates 'negative feedback' that balances excitation and inhibition, which contrasts with the 'positive feedback' of excitatory Hebbian synaptic plasticity. As a result, this balance may increase the sensitivity of the learning dynamics to the correlation structure of the excitatory inputs.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6YRKQSYA\\Luz, Shamir, Latham - 2012 - Balancing Feed-Forward Excitation and Inhibition via Hebbian Inhibitory Synaptic Plasticity.pdf},
  journal = {PLoS Comput Biol},
  number = {1}
}

@article{lyamzin_benucci_2018,
  title = {Accepted {{Manuscript Title}}: {{The}} Mouse Posterior Parietal Cortex: Anatomy and Functions {{The}} Mouse Posterior Parietal Cortex: Anatomy and Functions},
  author = {Lyamzin, Dmitry and Benucci, Andrea},
  year = {2018},
  doi = {10.1016/j.neures.2018.10.008},
  abstract = {Highlights  A review of the literature on the mouse parietal cortex (PPC) is proposed  The discussion focuses on the anatomy and function of PPC  The role of PPC for single-and multimodal stimulus encoding is discussed  PPC role in navigation and choice-related activity is also reviewed Abstract In recent years, the number of studies on decision-making in mice has increased dramatically. Many of these studies focus on the posterior parietal cortex (PPC), an area that has been implicated in sensory and multisensory processing, navigation, motion planning, and decision-making. In this review we summarize recent anatomical and functional studies of mouse PPC. First, we make a note of the existing variability in the nomenclature and its anatomical localization. Based on the commonalities across different studies we then describe the connectivity of PPC and discuss its place within several functional brain networks. In view of the examined connectivity, we go on to discuss the role of PPC for the encoding of single-modality and multimodal stimuli as well as its role in navigation. Finally, we summarize the literature on the choice-related activity: we discuss the variety of behavioral protocols and sensory modalities used in these studies, and we note that the response properties of PPC and its causal involvement in decision-making may depend substantially on these conditions. We conclude that, although more research should be devoted to creating a more complete and consistent image of the mouse PPC, this area should rightfully be considered a convenient model system for a circuit-level understanding of the mammalian parietal cortex.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9MV7A4YB\\Lyamzin, Benucci - 2018 - Accepted Manuscript Title The mouse posterior parietal cortex anatomy and functions The mouse posterior pariet.pdf},
  journal = {Neuroscience Research}
}

@article{macdonald_eichenbaum_2011,
  title = {Hippocampal "Time Cells" Bridge the Gap in Memory for Discontiguous Events},
  author = {MacDonald, Christopher J. and Lepage, Kyle Q. and Eden, Uri T and Eichenbaum, Howard B},
  year = {2011},
  volume = {71},
  pages = {737--749},
  issn = {08966273},
  doi = {10.1016/j.neuron.2011.07.012},
  abstract = {The hippocampus is critical to remembering the flow of events in distinct experiences and, in doing so, bridges temporal gaps between discontiguous events. Here, we report a robust hippocampal representation of sequence memories, highlighted by "time cells" that encode successive moments during an empty temporal gap between the key events, while also encoding location and ongoing behavior. Furthermore, just as most place cells "remap" when a salient spatial cue is altered, most time cells form qualitatively different representations (" retime") when the main temporal parameter is altered. Hippocampal neurons also differentially encode the key events and disambiguate different event sequences to compose unique, temporally organized representations of specific experiences. These findings suggest that hippocampal neural ensembles segment temporally organized memories much the same as they represent locations of important events in spatially defined environments. ?? 2011 Elsevier Inc.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4FS68927\\MacDonald et al. - 2011 - Hippocampal time cells bridge the gap in memory for discontiguous events(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\W3MJA7E5\\MacDonald et al. - 2011 - Hippocampal time cells bridge the gap in memory for discontiguous events.pdf},
  journal = {Neuron},
  number = {4},
  pmid = {21867888}
}

@article{machamer_craver_2000,
  title = {Thinking about {{Mechanisms}}},
  author = {Machamer, Peter and Darden, Lindley and Craver, Carl F},
  year = {2000},
  volume = {67},
  pages = {1--25},
  issn = {0031-8248},
  doi = {10.1086/392759},
  abstract = {The concept of mechanism is analyzed in terms of entities and activities, organized such that they are productive of regular changes. Examples show how mechanisms work in neurobiology and molecular biology. Thinking in terms of mechanisms provides a new framework for addressing many traditional philosophical issues: causality, laws, expla- nation, reduction, and scientific change.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PDYHQC3F\\Machamer, Darden, Craver - 2000 - Thinking about Mechanisms.pdf},
  journal = {Philosophy of Science},
  number = {1},
  pmid = {18649878}
}

@article{mackie_mackie_2015,
  title = {How {{Hard Do You Want}} to {{Work}}?: {{How}} the {{ACC Influences Motivation}}},
  author = {Mackie, Prescott},
  year = {2015},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YL5DZFNX\\Mackie - 2015 - How Hard Do You Want to Work How the ACC Influences Motivation.pdf}
}

@techreport{mackwood_sprekeler_2020,
  title = {Learning Excitatory-Inhibitory Neuronal Assemblies in Recurrent Networks},
  author = {Mackwood, Owen and Naumann, Laura B. and Sprekeler, Henning},
  year = {2020},
  month = apr,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.03.30.016352},
  abstract = {Abstract           In sensory circuits with poor feature topography, stimulus-specific feedback inhibition necessitates carefully tuned synaptic circuitry. Recent experimental data from mouse primary visual cortex (V1) show that synapses between pyramidal neurons and parvalbumin-expressing (PV) inhibitory interneurons tend to be stronger for neurons that respond to similar stimulus features. The mechanism that underlies the formation of such excitatory-inhibitory (E/I) assemblies is unresolved. Here, we show that activity-dependent synaptic plasticity on input and output synapses of PV interneurons generates a circuit structure that is consistent with mouse V1. Using a computational model, we show that both forms of plasticity must act synergistically to form the observed E/I assemblies. Once established, these assemblies produce a stimulus-specific competition between pyramidal neurons. Our model suggests that activity-dependent plasticity can enable inhibitory circuits to actively shape cortical computations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YGITQJYU\\Mackwood et al. - 2020 - Learning excitatory-inhibitory neuronal assemblies.pdf},
  language = {en},
  type = {Preprint}
}

@article{maes_clopath_2020,
  title = {Learning Spatiotemporal Signals Using a Recurrent Spiking Network That Discretizes Time},
  author = {Maes, Amadeus and Barahona, Mauricio and Clopath, Claudia},
  editor = {Richards, Blake A.},
  year = {2020},
  month = jan,
  volume = {16},
  pages = {e1007606},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1007606},
  abstract = {Learning to produce spatiotemporal sequences is a common task that the brain has to solve. The same neural substrate may be used by the brain to produce different sequential behaviours. The way the brain learns and encodes such tasks remains unknown as current computational models do not typically use realistic biologically-plausible learning. Here, we propose a model where a spiking recurrent network of excitatory and inhibitory biophysical neurons drives a read-out layer: the dynamics of the driver recurrent network is trained to encode time which is then mapped through the read-out neurons to encode another dimension, such as space or a phase. Different spatiotemporal patterns can be learned and encoded through the synaptic weights to the read-out neurons that follow common Hebbian learning rules. We demonstrate that the model is able to learn spatiotemporal dynamics on time scales that are behaviourally relevant and we show that the learned sequences are robustly replayed during a regime of spontaneous activity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Z2Z4D9LC\\Maes et al. - 2020 - Learning spatiotemporal signals using a recurrent .pdf},
  journal = {PLOS Computational Biology},
  language = {en},
  number = {1}
}

@article{maes_iordanova_2019,
  title = {Causal Evidence Supporting the Proposal That Dopamine Transients Function as a Temporal Difference Prediction Error},
  author = {Maes, Etienne Jp and Sharpe, Melissa J and Gardner, Matthew PH and Chang, Chun Yun and Schoenbaum, Geoffrey and Iordanova, Mihaela D},
  year = {2019},
  doi = {10.1101/520965},
  abstract = {Reward-evoked dopamine is well-established as a prediction error. However the central tenet of temporal difference accounts-that similar transients evoked by reward-predictive cues also function as errors-remains untested. To address this, we used two phenomena, second-order conditioning and blocking, in order to examine the role of dopamine in prediction error versus reward prediction. We show that optogenetically-shunting dopamine activity at the start of a reward-predicting cue prevents second-order conditioning without affecting blocking. These results support temporal difference accounts by providing causal evidence that cue-evoked dopamine transients function as prediction errors.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7RAS8ZFC\\Maes et al. - Unknown - Causal evidence supporting the proposal that dopamine transients function as a temporal difference prediction er.pdf},
  journal = {bioRxiv}
}

@article{magazzini_singh_2018,
  title = {Spatial Attention Modulates Visual Gamma Oscillations across the Human Ventral Stream},
  author = {Magazzini, Lorenzo and Singh, Krish D},
  year = {2018},
  doi = {10.1016/j.neuroimage.2017.10.069},
  abstract = {A B S T R A C T Oscillatory synchronization in the gamma frequency range has been proposed as a neuronal mechanism to pri-oritize processing of relevant stimuli over competing ones. Recent studies in animals found that selective spatial attention enhanced gamma-band synchronization in high-order visual areas (V4) and increased the gamma peak frequency in V1. The existence of such mechanisms in the human visual system is yet to be fully demonstrated. In this study, we used MEG, in combination with an optimised stimulus design, to record visual gamma oscillations from human early visual cortex, while participants performed a visuospatial attention cueing task. First, we reconstructed virtual sensors in V1/V2, where gamma oscillations were strongly induced by visual stimulation alone. Second, following the results of a statistical comparison between conditions of attention, we reconstructed cortical activity also in inferior occipital-temporal regions (V4). The results indicated that gamma amplitude was modulated by spatial attention across the cortical hierarchy, both in the early visual cortex and in higher-order regions of the ventral visual pathway. In contrast, we found no evidence for an increase in the gamma peak frequency in V1/V2 with attention. The gamma response tended to peak earlier in V1/V2 than in V4 by approximately 70 ms, consistent with a feed-forward role of gamma-band activity in propagating sensory rep-resentations across the visual cortical hierarchy. Together, these findings suggest that differences in experimental design or methodology can account for the inconsistencies in previous animal and human studies. Furthermore, our results are in line with the hypothesis of enhanced gamma-band synchronization as an attentional mechanism in the human visual cortex.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YXIBQIN3\\Magazzini, Singh - 2018 - Spatial attention modulates visual gamma oscillations across the human ventral stream.pdf},
  keywords = {Gamma peak frequency,Magnetoencephalography,Ventral visual stream,Visual gamma oscillations,Visuospatial attention}
}

@article{magee_grienberger_2020,
  title = {Synaptic {{Plasticity Forms}} and {{Functions}}},
  author = {Magee, Jeffrey C. and Grienberger, Christine},
  year = {2020},
  month = jul,
  volume = {43},
  pages = {annurev-neuro-090919-022842},
  issn = {0147-006X, 1545-4126},
  doi = {10.1146/annurev-neuro-090919-022842},
  abstract = {Synaptic plasticity, the activity-dependent change in neuronal connection strength, has long been considered an important component of learning and memory. Computational and engineering work corroborate the power of learning through the directed adjustment of connection weights. Here we review the fundamental elements of four broadly categorized forms of synaptic plasticity and discuss their functional capabilities and limitations. Although standard, correlation-based, Hebbian synaptic plasticity has been the primary focus of neuroscientists for decades, it is inherently limited. Three-factor plasticity rules supplement Hebbian forms with neuromodulation and eligibility traces, while true supervised types go even further by adding objectives and instructive signals. Finally, a recently discovered hippocampal form of synaptic plasticity combines the above elements, while leaving behind the primary Hebbian requirement. We suggest that the effort to determine the neural basis of adaptive behavior could benefit from renewed experimental and theoretical investigation of more powerful directed types of synaptic plasticity.             Expected final online publication date for the Annual Review of Neuroscience, Volume 43 is July 8, 2020. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BS8YABIX\\Magee and Grienberger - 2020 - Synaptic Plasticity Forms and Functions.pdf},
  journal = {Annual Review of Neuroscience},
  language = {en},
  number = {1}
}

@article{mainen_sejnowski_1995,
  title = {Reliability of Spike Timing in Neocortical Neurons},
  author = {Mainen, Z. and Sejnowski, T.},
  year = {1995},
  month = jun,
  volume = {268},
  pages = {1503--1506},
  issn = {0036-8075},
  doi = {10.1126/science.7770778},
  abstract = {It is not known whether the variability of neural activity in the cerebral cortex carries information or reflects noisy underlying mechanisms. In an examination of the reliability of spike generation using recordings from neurons in rat neocortical slices, the precision of spike timing was found to depend on stimulus transients. Constant stimuli led to imprecise spike trains, whereas stimuli with fluctuations resembling synaptic activity produced spike trains with timing reproducible to less than 1 millisecond. These data suggest a low intrinsic noise level in spike generation, which could allow cortical neurons to accurately transform synaptic input into spike sequences, supporting a possible role for spike timing in the processing of cortical information by the neocortex.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DXEPKDF5\\Mainen, Sejnowski - Unknown - Reliability of Spike Timing in Neocortical Circuits.pdf},
  journal = {Science},
  number = {5216}
}

@article{makeig_sejnowski_1996,
  title = {Independent {{Component Analysis}} of {{Electroencephalographic Data}}},
  author = {Makeig, Scott and J. Bell., Anthony and Jung, Tzyy-Ping and Sejnowski, Terrence J},
  year = {1996},
  volume = {8},
  pages = {145--151},
  issn = {10495258},
  doi = {10.1109/ICOSP.2002.1180091},
  abstract = {The electroencephalogram (EEG) is a non-invasive measure of brain electrical activity recorded as changes in potential difference between points on the human scalp. Because of volume conduction through cerebrospinal fluid, skull and scalp, EEG data collected from any point on the scalp includes activity from processes occurring within a large brain volume.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\U5R7M3PG\\Makeig et al. - 1996 - Independent Component Analysis of Electroencephalographic Data.pdf},
  journal = {Advances in Neural Information Processing Systems},
  pmid = {14622887}
}

@article{makino_mchugh_2019,
  title = {Physiological {{Signature}} of {{Memory Age}} in the {{Prefrontal}}-{{Hippocampal Circuit}}},
  author = {Makino, Yuichi and Polygalov, Denis and Bola{\~n}os, Federico and Benucci, Andrea and McHugh, Thomas J.},
  year = {2019},
  month = dec,
  volume = {29},
  pages = {3835-3846.e5},
  issn = {22111247},
  doi = {10.1016/j.celrep.2019.11.075},
  abstract = {The long-term storage of episodic memory requires communication between prefrontal cortex and hippocampus. However, how consolidation alters dynamic interactions between these regions during subsequent recall remains unexplored. Here we perform simultaneous electrophysiological recordings from anterior cingulate cortex (ACC) and hippocampal CA1 in mice during recall of recent and remote contextual fear memory. We find that, in contrast to recent memory, remote memory recall is accompanied by increased ACC-CA1 synchronization at multiple frequency bands. The augmented ACC-CA1 interaction is associated with strengthened coupling among distally spaced CA1 neurons, suggesting an ACC-driven organization of a sparse code. This robust shift in physiology permits a support vector machine classifier to accurately determine memory age on the basis of the ACC-CA1 synchronization pattern. Our findings reveal that memory consolidation alters the dynamic coupling of the prefrontal-hippocampal circuit and results in a physiological signature of memory age.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\R48KBE5U\\Makino et al. - 2019 - Physiological Signature of Memory Age in the Prefr.pdf},
  journal = {Cell Reports},
  language = {en},
  number = {12}
}

@article{malagon-vina_klausberger_2018,
  title = {Fluid Network Dynamics in the Prefrontal Cortex during Multiple Strategy Switching},
  author = {{Malagon-Vina}, Hugo and Ciocchi, Stephane and Passecker, Johannes and Dorffner, Georg and Klausberger, Thomas},
  year = {2018},
  volume = {9},
  pages = {309},
  issn = {2041-1723},
  doi = {10.1038/s41467-017-02764-x},
  abstract = {Coordinated shifts of neuronal activity in the prefrontal cortex are associated with strategy adaptations in behavioural tasks, when animals switch from following one rule to another. However, network dynamics related to multiple-rule changes are scarcely known. We show how firing rates of individual neurons in the prelimbic and cingulate cortex correlate with the performance of rats trained to change their navigation multiple times according to allocentric and egocentric strategies. The concerted population activity exhibits a stable firing during the performance of one rule but shifted to another neuronal firing state when a new rule is learnt. Interestingly, when the same rule is presented a second time within the same session, neuronal firing does not revert back to the original neuronal firing state, but a new activity-state is formed. Our data indicate that neuronal firing of prefrontal cortical neurons repre-sents changes in strategy and task-performance rather than specific strategies or rules.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MNXUUGJI\\Malagon-Vina et al. - 2018 - Fluid network dynamics in the prefrontal cortex during multiple strategy switching.pdf},
  journal = {Nature Communications},
  number = {1}
}

@article{mallory_giocomo_2018,
  title = {Grid Scale Drives the Scale and Long-Term Stability of Place Maps},
  author = {Mallory, Caitlin S. and Hardcastle, Kiah and Bant, Jason S. and Giocomo, Lisa M.},
  year = {2018},
  pages = {1},
  issn = {1097-6256},
  doi = {10.1038/s41593-017-0055-3},
  abstract = {Medial entorhinal cortex (MEC) grid cells fire at regular spatial intervals and project to the hippocampus, where place cells are active in spatially restricted locations. One feature of the grid population is the increase in grid spatial scale along the dorsal\textendash ventral MEC axis. However, the difficulty in perturbing grid scale without impacting the properties of other functionally defined MEC cell types has obscured how grid scale influences hippocampal coding and spatial memory. Here we use a targeted viral approach to knock out HCN1 channels selectively in MEC, causing the grid scale to expand while leaving other MEC spatial and velocity signals intact. Grid scale expansion resulted in place scale expansion in fields located far from environmental boundaries, reduced long-term place field stability and impaired spatial learning. These observations, combined with simulations of a grid-to-place cell model and position decoding of place cells, illuminate how grid scale impacts place coding and spatial memory.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IFR434Z9\\Mallory et al. - 2018 - Grid scale drives the scale and long-term stability of place maps.pdf},
  journal = {Nature Neuroscience},
  keywords = {Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences}
}

@article{manohar_husain_2019,
  title = {Neural Mechanisms of Attending to Items in Working Memory},
  author = {Manohar, Sanjay G. and Zokaei, Nahid and Fallon, Sean J. and Vogels, Tim P. and Husain, Masud},
  year = {2019},
  month = jun,
  volume = {101},
  pages = {1--12},
  issn = {01497634},
  doi = {10.1016/j.neubiorev.2019.03.017},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Y6R7M3PZ\\Manohar et al. - 2019 - Neural mechanisms of attending to items in working.pdf},
  journal = {Neuroscience \& Biobehavioral Reviews},
  language = {en}
}

@article{mante_newsome_2013,
  title = {Context-Dependent Computation by Recurrent Dynamics in Prefrontal Cortex},
  author = {Mante, Valerio and Sussillo, David and Shenoy, Krishna V. and Newsome, William T.},
  year = {2013},
  month = nov,
  volume = {503},
  pages = {78--84},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature12742},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\T72ENLGF\\Mante et al. - 2013 - Context-dependent computation by recurrent dynamic.pdf},
  journal = {Nature},
  language = {en},
  number = {7474}
}

@book{manuscript_code_2014,
  title = {{{NIH Public Access}}},
  author = {Manuscript, Author and Code, The Theta-gamma Neural},
  year = {2014},
  volume = {77},
  doi = {10.1016/j.neuron.2013.03.007.The},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\956U4AUI\\Manuscript, Code - 2014 - NIH Public Access.pdf},
  isbn = {7-81736-314-5}
}

@article{mao_wu_2019,
  title = {The {{Neuro}}-{{Symbolic Concept Learner}}: {{Interpreting Scenes}}, {{Words}}, and {{Sentences From Natural Supervision}}},
  shorttitle = {The {{Neuro}}-{{Symbolic Concept Learner}}},
  author = {Mao, Jiayuan and Gan, Chuang and Kohli, Pushmeet and Tenenbaum, Joshua B. and Wu, Jiajun},
  year = {2019},
  month = apr,
  abstract = {We propose the Neuro-Symbolic Concept Learner (NS-CL), a model that learns visual concepts, words, and semantic parsing of sentences without explicit supervision on any of them; instead, our model learns by simply looking at images and reading paired questions and answers. Our model builds an object-based scene representation and translates sentences into executable, symbolic programs. To bridge the learning of two modules, we use a neuro-symbolic reasoning module that executes these programs on the latent scene representation. Analogical to human concept learning, the perception module learns visual concepts based on the language description of the object being referred to. Meanwhile, the learned visual concepts facilitate learning new words and parsing new sentences. We use curriculum learning to guide the searching over the large compositional space of images and language. Extensive experiments demonstrate the accuracy and efficiency of our model on learning visual concepts, word representations, and semantic parsing of sentences. Further, our method allows easy generalization to new object attributes, compositions, language concepts, scenes and questions, and even new program domains. It also empowers applications including visual question answering and bidirectional image-text retrieval.},
  archivePrefix = {arXiv},
  eprint = {1904.12584},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5ZX43VZ8\\mao_et_al_2019_the_neuro-symbolic_concept_learner.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\VKGHG4LE\\mao_et_al_2019_the_neuro-symbolic_concept_learner.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\28DGPSC5\\1904.html;C\:\\Users\\wchapman\\Zotero\\storage\\UNPWMRHN\\1904.html},
  journal = {arXiv:1904.12584 [cs]},
  primaryClass = {cs}
}

@article{marblestone_kording_2013,
  title = {Physical Principles for Scalable Neural Recording.},
  author = {Marblestone, Adam H and Zamft, Bradley M and Maguire, Yael G and Shapiro, Mikhail G and Cybulski, Thaddeus R and Glaser, Joshua I and Amodei, Dario and Stranges, P Benjamin and Kalhor, Reza and a Dalrymple, David and Seo, Dongjin and Alon, Elad and Maharbiz, Michel M and Carmena, Jose M and Rabaey, Jan M and Boyden, Edward S and Church, George M and Kording, Konrad P},
  year = {2013},
  month = jan,
  volume = {7},
  pages = {137},
  issn = {1662-5188},
  doi = {10.3389/fncom.2013.00137},
  abstract = {Simultaneously measuring the activities of all neurons in a mammalian brain at millisecond resolution is a challenge beyond the limits of existing techniques in neuroscience. Entirely new approaches may be required, motivating an analysis of the fundamental physical constraints on the problem. We outline the physical principles governing brain activity mapping using optical, electrical, magnetic resonance, and molecular modalities of neural recording. Focusing on the mouse brain, we analyze the scalability of each method, concentrating on the limitations imposed by spatiotemporal resolution, energy dissipation, and volume displacement. Based on this analysis, all existing approaches require orders of magnitude improvement in key parameters. Electrical recording is limited by the low multiplexing capacity of electrodes and their lack of intrinsic spatial resolution, optical methods are constrained by the scattering of visible light in brain tissue, magnetic resonance is hindered by the diffusion and relaxation timescales of water protons, and the implementation of molecular recording is complicated by the stochastic kinetics of enzymes. Understanding the physical limits of brain activity mapping may provide insight into opportunities for novel solutions. For example, unconventional methods for delivering electrodes may enable unprecedented numbers of recording sites, embedded optical devices could allow optical detectors to be placed within a few scattering lengths of the measured neurons, and new classes of molecularly engineered sensors might obviate cumbersome hardware architectures. We also study the physics of powering and communicating with microscale devices embedded in brain tissue and find that, while radio-frequency electromagnetic data transmission suffers from a severe power-bandwidth tradeoff, communication via infrared light or ultrasound may allow high data rates due to the possibility of spatial multiplexing. The use of embedded local recording and wireless data transmission would only be viable, however, given major improvements to the power efficiency of microelectronic devices.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8J4CP6YI\\Marblestone et al. - 2013 - Physical principles for scalable neural recording.pdf},
  journal = {Frontiers in computational neuroscience},
  pmid = {24187539}
}

@article{marblestone_kording_2016,
  title = {Toward an {{Integration}} of {{Deep Learning}} and {{Neuroscience}}},
  author = {Marblestone, Adam H and Wayne, Greg and Kording, Konrad P.},
  year = {2016},
  month = sep,
  volume = {10},
  issn = {1662-5188},
  doi = {10.3389/fncom.2016.00094},
  abstract = {Neuroscience has focused on the detailed implementation of computation, studying neural codes, dynamics and circuits. In machine learning, however, artificial neural networks tend to eschew precisely designed codes, dynamics or circuits in favor of brute force optimization of a cost function, often using simple and relatively uniform initial architectures. Two recent developments have emerged within machine learning that create an opportunity to connect these seemingly divergent perspectives. First, structured architectures are used, including dedicated systems for attention, recursion and various forms of short- and long-term memory storage. Second, cost functions and training procedures have become more complex and are varied across layers and over time. Here we think about the brain in terms of these ideas. We hypothesize that (1) the brain optimizes cost functions, (2) these cost functions are diverse and differ across brain locations and over development, and (3) optimization operates within a pre-structured architecture matched to the computational problems posed by behavior. Such a heterogeneously optimized system, enabled by a series of interacting cost functions, serves to make learning data-efficient and precisely targeted to the needs of the organism. We suggest directions by which neuroscience could seek to refine and test these hypotheses.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GNDYQKXY\\Marblestone, Wayne, Kording - 2016 - Towards an integration of deep learning and neuroscience.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\Q7JASUXL\\Marblestone, Wayne, Kording - Unknown - Towards an integration of deep learning and neuroscience.pdf},
  journal = {Frontiers in Computational Neuroscience},
  keywords = {Cognitive Architecture,Cost Functions,Neural Networks,Neuroscience},
  pmid = {27683554}
}

@article{marchette_epstein_2014,
  title = {Anchoring the Neural Compass: Coding of Local Spatial Reference Frames in Human Medial Parietal Lobe},
  shorttitle = {Anchoring the Neural Compass},
  author = {Marchette, Steven A and Vass, Lindsay K and Ryan, Jack and Epstein, Russell A},
  year = {2014},
  month = nov,
  volume = {17},
  pages = {1598--1606},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn.3834},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JXX98LNZ\\Marchette et al. - 2014 - Anchoring the neural compass coding of local spat.pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {11}
}

@article{marcus_dean_2014,
  title = {The Atoms of Neural Computation},
  author = {Marcus, Gary and Marblestone, Adam H and Dean, Thomas},
  year = {2014},
  volume = {346},
  pages = {551--552},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1261661},
  abstract = {Does the brain depend on a set of elementary, reusable computations?},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\U6KPK9ZS\\Marcus, Marblestone, Dean - 2014 - The atoms of neural computation.pdf},
  journal = {Science},
  keywords = {AI,Deep learning,Neural networks},
  number = {6209},
  pmid = {25359953}
}

@article{marcus_marcus_2018,
  title = {Deep {{Learning}}: {{A Critical Appraisal}}},
  author = {Marcus, Gary},
  year = {2018},
  pages = {1--27},
  abstract = {Although deep learning has historical roots going back decades, neither the term "deep learning" nor the approach was popular just over five years ago, when the field was reignited by papers such as Krizhevsky, Sutskever and Hinton's now classic (2012) deep network model of Imagenet. What has the field discovered in the five subsequent years? Against a background of considerable progress in areas such as speech recognition, image recognition, and game playing, and considerable enthusiasm in the popular press, I present ten concerns for deep learning, and suggest that deep learning must be supplemented by other techniques if we are to reach artificial general intelligence.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LVDVZQQT\\Marcus et al. - Unknown - Deep Learning A Critical Appraisal.pdf},
  journal = {arXiv preprint arXiv:1801.00631}
}

@article{maris_oostenveld_2007,
  title = {Nonparametric Statistical Testing of {{EEG}}- and {{MEG}}-Data},
  author = {Maris, Eric and Oostenveld, Robert},
  year = {2007},
  volume = {164},
  pages = {177--190},
  issn = {01650270},
  doi = {10.1016/j.jneumeth.2007.03.024},
  abstract = {In this paper, we show how ElectroEncephaloGraphic (EEG) and MagnetoEncephaloGraphic (MEG) data can be analyzed statistically using nonparametric techniques. Nonparametric statistical tests offer complete freedom to the user with respect to the test statistic by means of which the experimental conditions are compared. This freedom provides a straightforward way to solve the multiple comparisons problem (MCP) and it allows to incorporate biophysically motivated constraints in the test statistic, which may drastically increase the sensitivity of the statistical test. The paper is written for two audiences: (1) empirical neuroscientists looking for the most appropriate data analysis method, and (2) methodologists interested in the theoretical concepts behind nonparametric statistical tests. For the empirical neuroscientist, a large part of the paper is written in a tutorial-like fashion, enabling neuroscientists to construct their own statistical test, maximizing the sensitivity to the expected effect. And for the methodologist, it is explained why the nonparametric test is formally correct. This means that we formulate a null hypothesis (identical probability distribution in the different experimental conditions) and show that the nonparametric test controls the false alarm rate under this null hypothesis. \textcopyright{} 2007 Elsevier B.V. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3C3ARQZC\\Maris, Oostenveld - 2007 - Nonparametric statistical testing of EEG- and MEG-data.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\IRTUDQAA\\Maris, Oostenveld - 2007 - Nonparametric statistical testing of EEG- and MEG-data.pdf},
  journal = {Journal of Neuroscience Methods},
  keywords = {eeg,Hypothesis testing,MEG,Multiple comparisons problem,Nonparametric statistical testing},
  number = {1},
  pmid = {17517438}
}

@article{markov_kennedy_2014,
  title = {Anatomy of Hierarchy: {{Feedforward}} and Feedback Pathways in Macaque Visual Cortex},
  author = {Markov, Nikola T and Vezoli, Julien and Chameau, Pascal and Falchier, Arnaud and Quilodran, Ren?? and Huissoud, Cyril and Lamy, Camille and Misery, Pierre and Giroud, Pascale and Ullman, Shimon and Barone, Pascal and Dehay, Colette and Knoblauch, Kenneth and Kennedy, Henry},
  year = {2014},
  volume = {522},
  pages = {225--259},
  issn = {00219967},
  doi = {10.1002/cne.23458},
  abstract = {The laminar location of the cell bodies and terminals of interareal connections determines the hierarchical structural organization of the cortex and has been intensively studied. However, we still have only a rudimentary understanding of the connectional principles of feedforward (FF) and feedback (FB) pathways. Quantitative analysis of retrograde tracers was used to extend the notion that the laminar distribution of neurons interconnecting visual areas provides an index of hierarchical distance (percentage of supragranular labeled neurons [SLN]). We show that: 1) SLN values constrain models of cortical hierarchy, revealing previously unsuspected areal relations; 2) SLN reflects the operation of a combinatorial distance rule acting differentially on sets of connections between areas; 3) Supragranular layers contain highly segregated bottom-up and top-down streams, both of which exhibit point-to-point connectivity. This contrasts with the infragranular layers, which contain diffuse bottom-up and top-down streams; 4) Cell filling of the parent neurons of FF and FB pathways provides further evidence of compartmentalization; 5) FF pathways have higher weights, cross fewer hierarchical levels, and are less numerous than FB pathways. Taken together, the present results suggest that cortical hierarchies are built from supra- and infragranular counterstreams. This compartmentalized dual counterstream organization allows point-to-point connectivity in both bottom-up and top-down directions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EM9EJQ6X\\Markov et al. - 2014 - Anatomy of hierarchy Feedforward and feedback pathways in macaque visual cortex.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\NZX4KPII\\Markov et al. - 2014 - Anatomy of hierarchy Feedforward and feedback pathways in macaque visual cortex.pdf},
  journal = {Journal of Comparative Neurology},
  keywords = {Cell morphology,Monkey,Neocortex,Retrograde tracing},
  number = {1},
  pmid = {23983048}
}

@article{markov_utochkin_2019,
  title = {Different Features Are Stored Independently in Visual Working Memory but Mediated by Object-Based Representations},
  author = {Markov, Yuri A. and Tiurina, Natalia A. and Utochkin, Igor S.},
  year = {2019},
  month = jun,
  volume = {197},
  pages = {52--63},
  issn = {00016918},
  doi = {10.1016/j.actpsy.2019.05.003},
  abstract = {The question of whether visual working memory (VWM) stores individual features or bound objects as basic units is actively debated. Evidence exists for both feature-based and object-based storages, as well as hierarchically organized representations maintaining both types of information at different levels. One argument for feature-based storage is that features belonging to different dimensions (e.g., color and orientations) can be stored without interference suggesting independent capacities for every dimension. Here, we studied whether the lack of cross-dimensional interference reflects genuinely independent feature storages or mediated by common objects. In three experiments, participants remembered and recalled the colors and orientations of sets of objects. We independently manipulated set sizes within each feature dimension (making colors and orientations either identical or differing across objects). Critically, we assigned to-be-remembered colors and orientations either to same spatially integrated or to different spatially separated objects. We found that the precision and recall probability within each dimension was not affected by set size manipulations in a different dimension when the features belonged to integrated objects. However, manipulations with color set sizes did affect orientation memory when the features were separated. We conclude therefore that different feature dimensions can be encoded and stored independently but the advantage of the independent storages are mediated at the object-based level. This conclusion is consistent with the idea of hierarchically organized VWM.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XNIJ7QXE\\Markov et al. - 2019 - Different features are stored independently in vis.pdf},
  journal = {Acta Psychologica},
  language = {en}
}

@article{markowitz_datta_2018,
  title = {The {{Striatum Organizes 3D Behavior}} via {{Moment}}-to-{{Moment Action Selection}}},
  author = {Markowitz, Jeffrey E. and Gillis, Winthrop F. and Beron, Celia C. and Neufeld, Shay Q. and Robertson, Keiramarie and Bhagat, Neha D. and Peterson, Ralph E. and Peterson, Emalee and Hyun, Minsuk and Linderman, Scott W. and Sabatini, Bernardo L. and Datta, Sandeep Robert},
  year = {2018},
  month = jun,
  volume = {174},
  pages = {44--58.e17},
  issn = {10974172},
  doi = {10.1016/j.cell.2018.04.019},
  abstract = {Many naturalistic behaviors are built from modular components that are expressed sequentially. Although striatal circuits have been implicated in action selection and implementation, the neural mechanisms that compose behavior in unrestrained animals are not well understood. Here, we record bulk and cellular neural activity in the direct and indirect pathways of dorsolateral striatum (DLS) as mice spontaneously express action sequences. These experiments reveal that DLS neurons systematically encode information about the identity and ordering of sub-second 3D behavioral motifs; this encoding is facilitated by fast-timescale decorrelations between the direct and indirect pathways. Furthermore, lesioning the DLS prevents appropriate sequence assembly during exploratory or odor-evoked behaviors. By characterizing naturalistic behavior at neural timescales, these experiments identify a code for elemental 3D pose dynamics built from complementary pathway dynamics, support a role for DLS in constructing meaningful behavioral sequences, and suggest models for how actions are sculpted over time.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YWSCD82K\\Markowitz et al. - 2018 - The Striatum Organizes 3D Behavior via Moment-to-Moment Action Selection.pdf},
  journal = {Cell},
  keywords = {basal ganglia,behavior,coding,direct pathway,ethology,indirect pathway,machine learning,mouse,photometry,striatum},
  number = {1},
  pmid = {29779950}
}

@article{markowitz_gardner_2015,
  title = {Mesoscopic {{Patterns}} of {{Neural Activity Support Songbird Cortical Sequences}}},
  author = {Markowitz, Jeffrey E and a. Liberti, William and Guitchounts, Grigori and Velho, Tarciso and Lois, Carlos and Gardner, Timothy J},
  year = {2015},
  volume = {13},
  pages = {e1002158},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.1002158},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TS5MDENF\\Markowitz et al. - 2015 - Mesoscopic Patterns of Neural Activity Support Songbird Cortical Sequences.pdf},
  journal = {PLOS Biology},
  number = {6}
}

@article{marshall_schnitzer_2013,
  title = {Optical Strategies for Sensing Neuronal Voltage Using Quantum Dots and Other Semiconductor Nanocrystals.},
  author = {Marshall, Jesse D and Schnitzer, Mark J},
  year = {2013},
  month = may,
  volume = {7},
  pages = {4601--9},
  issn = {1936-086X},
  doi = {10.1021/nn401410k},
  abstract = {Biophysicists have long sought optical methods capable of reporting the electrophysiological dynamics of large-scale neural networks with millisecond-scale temporal resolution. Existing fluorescent sensors of cell membrane voltage can report action potentials in individual cultured neurons, but limitations in brightness and dynamic range of both synthetic organic and genetically encoded voltage sensors have prevented concurrent monitoring of spiking activity across large populations of individual neurons. Here we propose a novel, inorganic class of fluorescent voltage sensors: semiconductor nanoparticles, such as ultrabright quantum dots (qdots). Our calculations revealed that transmembrane electric fields characteristic of neuronal spiking ({$\sim$}10 mV/nm) modulate a qdot's electronic structure and can induce {$\sim$}5\% changes in its fluorescence intensity and {$\sim$}1 nm shifts in its emission wavelength, depending on the qdot's size, composition, and dielectric environment. Moreover, tailored qdot sensors composed of two different materials can exhibit substantial ({$\sim$}30\%) changes in fluorescence intensity during neuronal spiking. Using signal detection theory, we show that conventional qdots should be capable of reporting voltage dynamics with millisecond precision across several tens or more individual neurons over a range of optical and neurophysiological conditions. These results unveil promising avenues for imaging spiking dynamics in neural networks and merit in-depth experimental investigation.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MQP4AY4C\\Marshall, Schnitzer - 2013 - Optical strategies for sensing neuronal voltage using quantum dots and other semiconductor nanocrystals.pdf},
  journal = {ACS nano},
  keywords = {Cell Membrane,Cell Membrane: metabolism,Electric Conductivity,Fluorescence,Microscopy,Neurons,Neurons: cytology,Optical Processes,Quantum Dots,Semiconductors},
  number = {5},
  pmid = {23614672}
}

@article{martenvanes_knapen_2018,
  title = {Spatial Sampling in Human Visual Cortex Is Modulated by Both Spatial and Feature-Based Attention},
  author = {Marten Van Es, Daniel and Theeuwes, Jan and Knapen, Tomas},
  year = {2018},
  doi = {10.7554/eLife.36928.001},
  abstract = {Spatial attention changes the sampling of visual space. Behavioral studies suggest that feature-based attention modulates this resampling to optimize the attended feature's sampling. We investigate this hypothesis by estimating spatial sampling in visual cortex while independently varying both feature-based and spatial attention. Our results show that spatial and feature-based attention interacted: resampling of visual space depended on both the attended location and feature (color vs. temporal frequency). This interaction occurred similarly throughout visual cortex, regardless of an area's overall feature preference. However, the interaction did depend on spatial sampling properties of voxels that prefer the attended feature. These findings are parsimoniously explained by variations in the precision of an attentional gain field. Our results demonstrate that the deployment of spatial attention is tailored to the spatial sampling properties of units that are sensitive to the attended feature.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FRB2E9PQ\\Marten Van Es, Theeuwes, Knapen - 2018 - Spatial sampling in human visual cortex is modulated by both spatial and feature-based attentio.pdf}
}

@techreport{martin_doumas_2018,
  title = {Predicate Learning in Neural Systems: {{Discovering}} Latent Generative Structures},
  author = {Martin, Andrea E and Doumas, Leonidas A A},
  year = {2018},
  abstract = {+31 (0) 243 521 585 RUNNING HEAD: Predicate learning in neural systems 2 ABSTRACT Humans learn complex latent structures from their environments (e.g., natural language, mathematics, music, social hierarchies). In cognitive science and cognitive neuroscience, models that infer higher-order structures from sensory or first-order representations have been proposed to account for the complexity and flexibility of human behavior. But how do the structures that these models invoke arise in neural systems in the first place? To answer this question, we explain how a system can learn latent representational structures (i.e., predicates) from experience with wholly unstructured data. During the process of predicate learning, an artificial neural network exploits the naturally occurring dynamic properties of distributed computing across neuronal assemblies in order to learn predicates, but also to combine them compositionally, two computational aspects which appear to be necessary for human behavior as per formal theories in multiple domains. We describe how predicates can be combined generatively using neural oscillations to achieve human-like extrapolation and compositionality in an artificial neural network. The ability to learn predicates from experience, to represent structures compositionally, and to extrapolate to unseen data offers an inroads to understanding and modeling the most complex human behaviors.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\344GKZ7L\\Martin, Doumas - 2018 - Predicate learning in neural systems Discovering latent generative structures.pdf}
}

@article{marzetti_jensen_2018,
  title = {The Visuospatial Attention Network Recruitment Is Mediate by Alpha and Alpha-Beta Phase Synchronization through the {{Superior Longitudinal Fasciculus}}},
  author = {Marzetti, Laura and D'Andrea, A. and Chella, Federico and Marshall, T.R. and Pizzella, Vittorio and Romani, G.L. and Jensen, Ole},
  year = {2018},
  volume = {131},
  pages = {S74--S75},
  issn = {0167-8760},
  doi = {10.1016/J.IJPSYCHO.2018.07.215},
  abstract = {Please cite this article as: D'Andrea, A., Chella, F., Marshall, T.R., Pizzella, V., Romani, G.L., Jensen, O., Marzetti, L., Alpha and alpha-beta phase synchronization mediate the recruitment of the visuospatial attention network through the Superior Longitudinal Fasciculus, NeuroImage (2019), doi: https://},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4XMI69CD\\Andrea et al. - 2018 - Accepted Manuscript Alpha and alpha-beta phase synchronization mediate the recruitment of the visuospatial attent.pdf},
  journal = {International Journal of Psychophysiology}
}

@article{masquelier_kheradpisheh_2018,
  title = {Optimal {{Localist}} and {{Distributed Coding}} of {{Spatiotemporal Spike Patterns Through STDP}} and {{Coincidence Detection}}},
  author = {Masquelier, Timoth{\'e}e and Kheradpisheh, Saeed R.},
  year = {2018},
  month = sep,
  volume = {12},
  pages = {74},
  issn = {1662-5188},
  doi = {10.3389/fncom.2018.00074},
  abstract = {Repeating spatiotemporal spike patterns exist and carry information. Here we investigated how a single spiking neuron can optimally respond to one given pattern (localist coding), or to either one of several patterns (distributed coding, i.e., the neuron's response is ambiguous but the identity of the pattern could be inferred from the response of multiple neurons), but not to random inputs. To do so, we extended a theory developed in a previous paper (Masquelier, 2017), which was limited to localist coding. More specifically, we computed analytically the signal-to-noise ratio (SNR) of a multi-pattern-detector neuron, using a threshold-free leaky integrate-and-fire (LIF) neuron model with non-plastic unitary synapses and homogeneous Poisson inputs. Surprisingly, when increasing the number of patterns, the SNR decreases slowly, and remains acceptable for several tens of independent patterns. In addition, we investigated whether spike-timing-dependent plasticity (STDP) could enable a neuron to reach the theoretical optimal SNR. To this aim, we simulated a LIF equipped with STDP, and repeatedly exposed it to multiple input spike patterns, embedded in equally dense Poisson spike trains. The LIF progressively became selective to every repeating pattern with no supervision, and stopped discharging during the Poisson spike trains. Furthermore, tuning certain STDP parameters, the resulting pattern detectors were optimal. Tens of independent patterns could be learned by a single neuron using a low adaptive threshold, in contrast with previous studies, in which higher thresholds led to localist coding only. Taken together these results suggest that coincidence detection and STDP are powerful mechanisms, fully compatible with distributed coding. Yet we acknowledge that our theory is limited to single neurons, and thus also applies to feed-forward networks, but not to recurrent ones.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\W96U8ZRC\\Masquelier and Kheradpisheh - 2018 - Optimal Localist and Distributed Coding of Spatiot.pdf},
  journal = {Frontiers in Computational Neuroscience},
  language = {en}
}

@article{masse_freedman_2019,
  title = {Circuit Mechanisms for the Maintenance and Manipulation of Information in Working Memory},
  author = {Masse, Nicolas Y. and Yang, Guangyu R. and Song, H. Francis and Wang, Xiao-Jing and Freedman, David J.},
  year = {2019},
  month = jul,
  volume = {22},
  pages = {1159--1167},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-019-0414-3},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\87D5MZJB\\Masse et al. - 2019 - Circuit mechanisms for the maintenance and manipul.pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {7}
}

@article{masse_freedman_2019a,
  title = {Circuit Mechanisms for the Maintenance and Manipulation of Information in Working Memory},
  author = {Masse, Nicolas Y. and Yang, Guangyu R. and Song, H. Francis and Wang, Xiao-Jing and Freedman, David J.},
  year = {2019},
  month = jul,
  volume = {22},
  pages = {1159--1167},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-019-0414-3},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZMWFDE6V\\Masse et al. - 2019 - Circuit mechanisms for the maintenance and manipul.pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {7}
}

@article{mateo_kleinfeld_2017,
  title = {Entrainment of {{Arteriole Vasomotor Fluctuations}} by {{Neural Activity Is}} a {{Basis}} of {{Blood}}-{{Oxygenation}}-{{Level}}-{{Dependent}} ``{{Resting}}-{{State}}'' {{Connectivity}}},
  author = {Mateo, Celine and Knutsen, Per M. and Tsai, Philbert S. and Shih, Andy Y. and Kleinfeld, David},
  year = {2017},
  month = nov,
  volume = {96},
  pages = {936-948.e3},
  issn = {08966273},
  doi = {10.1016/j.neuron.2017.10.012},
  abstract = {Resting-state signals in blood-oxygenation-leveldependent (BOLD) imaging are used to parcellate brain regions and define ``functional connections'' between regions. Yet a physiological link between fluctuations in blood oxygenation with those in neuronal signaling pathways is missing. We present evidence from studies on mouse cortex that modulation of vasomotion, i.e., intrinsic ultra-slow (0.1 Hz) fluctuations in arteriole diameter, provides this link. First, ultra-slow fluctuations in neuronal signaling, which occur as an envelope over g-band activity, entrains vasomotion. Second, optogenetic manipulations confirm that entrainment is unidirectional. Third, co-fluctuations in the diameter of pairs of arterioles within the same hemisphere diminish to chance for separations {$>$}1.4 mm. Yet the diameters of arterioles in distant ({$>$}5 mm), mirrored transhemispheric sites strongly co-fluctuate; these correlations are diminished in acallosal mice. Fourth, fluctuations in arteriole diameter coherently drive fluctuations in blood oxygenation. Thus, entrainment of vasomotion links neuronal pathways to functional connections.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2U4VW48W\\Mateo et al. - 2017 - Entrainment of Arteriole Vasomotor Fluctuations by.pdf},
  journal = {Neuron},
  language = {en},
  number = {4}
}

@phdthesis{matheusgauy_matheusgauy_2019,
  title = {Biological and {{Artificial Neural Network Mechanisms}} for {{Memory}} and {{Online Learning}}},
  author = {Matheus Gauy, Marcelo},
  year = {2019},
  doi = {10.3929/ethz-b-000353633},
  collaborator = {Steger, Angelika and Lengler, Johannes and Yanik, Mehmet Fatih},
  copyright = {http://rightsstatements.org/page/InC-NC/1.0/, info:eu-repo/semantics/openAccess},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QJL5IS4H\\Matheus Gauy - 2019 - Biological and Artificial Neural Network Mechanism.pdf},
  language = {en},
  school = {ETH Zurich}
}

@article{mathewson_gratton_2014,
  title = {Dynamics of {{Alpha Control}}: {{Preparatory Suppression}} of {{Posterior Alpha Oscillations}} by {{Frontal Modulators Revealed}} with {{Combined EEG}} and {{Event}}-Related {{Optical Signal}}},
  author = {Mathewson, Kyle E. and Beck, Diane M. and Ro, Tony and Maclin, Edward L. and Low, Kathy A. and Fabiani, Monica and Gratton, Gabriele},
  year = {2014},
  month = oct,
  volume = {26},
  pages = {2400--2415},
  issn = {0898-929X},
  doi = {10.1162/jocn_a_00637},
  abstract = {We investigated the dynamics of brain processes facilitating conscious experience of external stimuli. Previously, we proposed that alpha (8\textendash 12 Hz) oscillations, which fluctuate with both sustained and directed attention, represent a pulsed inhibition of ongoing sensory brain activity. Here we tested the prediction that inhibitory alpha oscillations in visual cortex are modulated by top\textendash down signals from frontoparietal attention networks. We measured modulations in phase-coherent alpha oscillations from superficial frontal, parietal, and occipital cortices using the event-related optical signal (EROS), a measure of neuronal activity affording high spatiotemporal resolution, along with concurrently recorded EEG, while participants performed a visual target detection task. The pretarget alpha oscillations measured with EEG and EROS from posterior areas were larger for subsequently undetected targets, supporting alpha's inhibitory role. Using EROS, we localized brain correlates of these awareness-related alpha oscillations measured at the scalp to the cuneus and precuneus. Crucially, EROS alpha suppression correlated with posterior EEG alpha power across participants. Sorting the EROS data based on EEG alpha power quartiles to investigate alpha modulators revealed that suppression of posterior alpha was preceded by increased activity in regions of the dorsal attention network and decreased activity in regions of the cingulo-opercular network. Cross-correlations revealed the temporal dynamics of activity within these preparatory networks before posterior alpha modulation. The novel combination of EEG and EROS afforded localization of the sources and correlates of alpha oscillations and their temporal relationships, supporting our proposal that top\textendash down control from attention networks modulates both posterior alpha and awareness of visual stimuli.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\R3P7ZBEY\\Mathewson et al. - 2014 - Dynamics of Alpha Control Preparatory Suppression of Posterior Alpha Oscillations by Frontal Modulators Reveal.pdf},
  journal = {Journal of Cognitive Neuroscience},
  number = {10}
}

@article{mattar_aguirre_2018,
  title = {Adaptation Decorrelates Shape Representations},
  author = {Mattar, Marcelo G. and Olkkonen, Maria and Epstein, Russell A. and Aguirre, Geoffrey K.},
  year = {2018},
  month = sep,
  volume = {9},
  pages = {3812},
  issn = {2041-1723},
  doi = {10.1038/s41467-018-06278-y},
  abstract = {Adaptation is thought to improve discrimination by pulling neural representations of similar stimuli farther apart. Here, the authors separately show that adaptation to a 3D shape class leads to better discrimination performance on similar shapes, and activity patterns diverge in object selective cortical areas.},
  copyright = {2018 The Author(s)},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BUXR97IZ\\Mattar et al. - 2018 - Adaptation decorrelates shape representations.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\Q773SYSU\\s41467-018-06278-y.html},
  journal = {Nature Communications},
  language = {En},
  number = {1}
}

@article{mattar_bassett_2015,
  title = {A {{Functional Cartography}} of {{Cognitive Systems}}},
  author = {Mattar, Marcelo G. and Cole, Michael W. and {Thompson-Schill}, Sharon L. and Bassett, Danielle S.},
  year = {2015},
  month = dec,
  volume = {11},
  pages = {e1004533},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1004533},
  abstract = {One of the most remarkable features of the human brain is its ability to adapt rapidly and efficiently to external task demands. Novel and non-routine tasks, for example, are implemented faster than structural connections can be formed. The neural underpinnings of these dynamics are far from understood. Here we develop and apply novel methods in network science to quantify how patterns of functional connectivity between brain regions reconfigure as human subjects perform 64 different tasks. By applying dynamic community detection algorithms, we identify groups of brain regions that form putative functional communities, and we uncover changes in these groups across the 64-task battery. We summarize these reconfiguration patterns by quantifying the probability that two brain regions engage in the same network community (or putative functional module) across tasks. These tools enable us to demonstrate that classically defined cognitive systems\textemdash including visual, sensorimotor, auditory, default mode, fronto-parietal, cingulo-opercular and salience systems\textemdash engage dynamically in cohesive network communities across tasks. We define the network role that a cognitive system plays in these dynamics along the following two dimensions: (i) stability vs. flexibility and (ii) connected vs. isolated. The role of each system is therefore summarized by how stably that system is recruited over the 64 tasks, and how consistently that system interacts with other systems. Using this cartography, classically defined cognitive systems can be categorized as ephemeral integrators, stable loners, and anything in between. Our results provide a new conceptual framework for understanding the dynamic integration and recruitment of cognitive systems in enabling behavioral adaptability across both task and rest conditions. This work has important implications for understanding cognitive network reconfiguration during different task sets and its relationship to cognitive effort, individual variation in cognitive performance, and fatigue.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L39W2WLK\\Mattar et al. - 2015 - A Functional Cartography of Cognitive Systems.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\IHKUMF3X\\article.html},
  journal = {PLOS Computational Biology},
  language = {en},
  number = {12}
}

@article{mattar_daw_2018,
  title = {Prioritized Memory Access Explains Planning and Hippocampal Replay},
  author = {Mattar, Marcelo G. and Daw, Nathaniel D.},
  year = {2018},
  month = nov,
  volume = {21},
  pages = {1609},
  issn = {1546-1726},
  doi = {10.1038/s41593-018-0232-z},
  abstract = {To make decisions, animals must evaluate candidate choices by accessing memories of relevant experiences. Yet little is known about which experiences are considered or ignored during deliberation, which ultimately governs choice. We propose a normative theory predicting which memories should be accessed at each moment to optimize future decisions. Using nonlocal `replay' of spatial locations in hippocampus as a window into memory access, we simulate a spatial navigation task in which an agent accesses memories of locations sequentially, ordered by utility: how much extra reward would be earned due to better choices. This prioritization balances two desiderata: the need to evaluate imminent choices versus the gain from propagating newly encountered information to preceding locations. Our theory offers a simple explanation for numerous findings about place cells; unifies seemingly disparate proposed functions of replay including planning, learning, and consolidation; and posits a mechanism whose dysfunction may underlie pathologies like rumination and craving.},
  copyright = {2018 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\A3KJSPN8\\Mattar and Daw - 2018 - Prioritized memory access explains planning and hi.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\4VQ97D7M\\s41593-018-0232-z.html},
  journal = {Nature Neuroscience},
  language = {en},
  number = {11}
}

@article{matthews_clements_2014,
  title = {Spike Sorting by Joint Probabilistic Modeling of Neural Spike Trains and Waveforms.},
  author = {a Matthews, Brett and a Clements, Mark},
  year = {2014},
  month = jan,
  volume = {2014},
  pages = {643059},
  issn = {1687-5273},
  doi = {10.1155/2014/643059},
  abstract = {This paper details a novel probabilistic method for automatic neural spike sorting which uses stochastic point process models of neural spike trains and parameterized action potential waveforms. A novel likelihood model for observed firing times as the aggregation of hidden neural spike trains is derived, as well as an iterative procedure for clustering the data and finding the parameters that maximize the likelihood. The method is executed and evaluated on both a fully labeled semiartificial dataset and a partially labeled real dataset of extracellular electric traces from rat hippocampus. In conditions of relatively high difficulty (i.e., with additive noise and with similar action potential waveform shapes for distinct neurons) the method achieves significant improvements in clustering performance over a baseline waveform-only Gaussian mixture model (GMM) clustering on the semiartificial set (1.98\{\%\} reduction in error rate) and outperforms both the GMM and a state-of-the-art method on the real dataset (5.04\{\%\} reduction in false positive + false negative errors). Finally, an empirical study of two free parameters for our method is performed on the semiartificial dataset.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZLFPM3UA\\Matthews, Clements - 2014 - Spike sorting by joint probabilistic modeling of neural spike trains and waveforms.pdf},
  journal = {Computational intelligence and neuroscience},
  pmid = {24829568}
}

@article{matulewicz_omara_2019,
  title = {Proximal Perimeter Encoding in the Rat Rostral Thalamus},
  author = {Matulewicz, Pawel and Ulrich, Katharina and Islam, Md. Nurul and Mathiasen, Mathias L. and Aggleton, John P. and O'Mara, Shane M.},
  year = {2019},
  month = dec,
  volume = {9},
  pages = {2865},
  issn = {2045-2322},
  doi = {10.1038/s41598-019-39396-8},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VETA7RAQ\\Matulewicz et al. - 2019 - Proximal perimeter encoding in the rat rostral tha.pdf},
  journal = {Scientific Reports},
  language = {en},
  number = {1}
}

@article{mau_eichenbaum_2018,
  title = {The {{Same Hippocampal CA1 Population Simultaneously Codes Temporal Information}} over {{Multiple Timescales}}},
  author = {Mau, William and Sullivan, David W and Kinsky, Nathaniel R and Hasselmo, Michael E and Howard, Marc W and Correspondence, Howard Eichenbaum and Eichenbaum, Howard},
  year = {2018},
  doi = {10.1016/j.cub.2018.03.051},
  abstract = {Highlights d Time cell sequences recorded with Ca 2+ imaging change over minutes and days d Second-resolution temporal information is retained despite population drift d Time cell ensembles carry information about time over seconds, minutes, and days d This population could organize temporal encoding over these timescales In Brief Episodic memories span timescales of seconds, minutes, and days. Mau et al. use calcium imaging to longitudinally monitor cell sequences in hippocampal CA1. Bayesian decoder analyses show that the same population of neurons carries information about time across all three scales. Mau et al., 2018, Current Biology 28, 1\textendash 10 May 21, 2018 \textordfeminine{} 2018 Elsevier Ltd.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\F4CT9942\\Mau et al. - 2018 - The Same Hippocampal CA1 Population Simultaneously Codes Temporal Information over Multiple Timescales.pdf},
  keywords = {CA1,calcium imaging,hippocampus,longitudinal recording,temporal encoding}
}

@article{mazzoni_brunel_2008,
  title = {Encoding of {{Naturalistic Stimuli}} by {{Local Field Potential Spectra}} in {{Networks}} of {{Excitatory}} and {{Inhibitory Neurons}}},
  author = {Mazzoni, Alberto and Panzeri, Stefano and Logothetis, Nikos K. and Brunel, Nicolas},
  editor = {Friston, Karl J.},
  year = {2008},
  month = dec,
  volume = {4},
  pages = {e1000239},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1000239},
  abstract = {Recordings of local field potentials (LFPs) reveal that the sensory cortex displays rhythmic activity and fluctuations over a wide range of frequencies and amplitudes. Yet, the role of this kind of activity in encoding sensory information remains largely unknown. To understand the rules of translation between the structure of sensory stimuli and the fluctuations of cortical responses, we simulated a sparsely connected network of excitatory and inhibitory neurons modeling a local cortical population, and we determined how the LFPs generated by the network encode information about input stimuli. We first considered simple static and periodic stimuli and then naturalistic input stimuli based on electrophysiological recordings from the thalamus of anesthetized monkeys watching natural movie scenes. We found that the simulated network produced stimulus-related LFP changes that were in striking agreement with the LFPs obtained from the primary visual cortex. Moreover, our results demonstrate that the network encoded static input spike rates into gamma-range oscillations generated by inhibitory\textendash excitatory neural interactions and encoded slow dynamic features of the input into slow LFP fluctuations mediated by stimulus\textendash neural interactions. The model cortical network processed dynamic stimuli with naturalistic temporal structure by using low and high response frequencies as independent communication channels, again in agreement with recent reports from visual cortex responses to naturalistic movies. One potential function of this frequency decomposition into independent information channels operated by the cortical network may be that of enhancing the capacity of the cortical column to encode our complex sensory environment.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PAQZKCQD\\Mazzoni et al. - 2008 - Encoding of Naturalistic Stimuli by Local Field Po.PDF},
  journal = {PLoS Computational Biology},
  language = {en},
  number = {12}
}

@article{mazzoni_einevoll_2015,
  title = {Computing the {{Local Field Potential}} ({{LFP}}) from {{Integrate}}-and-{{Fire Network Models}}},
  author = {Mazzoni, Alberto and Lind{\'e}n, Henrik and Cuntz, Hermann and Lansner, Anders and Panzeri, Stefano and Einevoll, Gaute T.},
  editor = {Roth, Arnd},
  year = {2015},
  month = dec,
  volume = {11},
  pages = {e1004584},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1004584},
  abstract = {Leaky integrate-and-fire (LIF) network models are commonly used to study how the spiking dynamics of neural networks changes with stimuli, tasks or dynamic network states. However, neurophysiological studies in vivo often rather measure the mass activity of neuronal microcircuits with the local field potential (LFP). Given that LFPs are generated by spatially separated currents across the neuronal membrane, they cannot be computed directly from quantities defined in models of point-like LIF neurons. Here, we explore the best approximation for predicting the LFP based on standard output from point-neuron LIF networks. To search for this best ``LFP proxy'', we compared LFP predictions from candidate proxies based on LIF network output (e.g, firing rates, membrane potentials, synaptic currents) with ``ground-truth'' LFP obtained when the LIF network synaptic input currents were injected into an analogous three-dimensional (3D) network model of multi-compartmental neurons with realistic morphology, spatial distributions of somata and synapses. We found that a specific fixed linear combination of the LIF synaptic currents provided an accurate LFP proxy, accounting for most of the variance of the LFP time course observed in the 3D network for all recording locations. This proxy performed well over a broad set of conditions, including substantial variations of the neuronal morphologies. Our results provide a simple formula for estimating the time course of the LFP from LIF network simulations in cases where a single pyramidal population dominates the LFP generation, and thereby facilitate quantitative comparison between computational models and experimental LFP recordings in vivo.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KYHM77PB\\Mazzoni et al. - 2015 - Computing the Local Field Potential (LFP) from Int.PDF},
  journal = {PLOS Computational Biology},
  language = {en},
  number = {12}
}

@article{mazzoni_panzeri_2010,
  title = {Understanding the Relationships between Spike Rate and Delta/Gamma Frequency Bands of {{LFPs}} and {{EEGs}} Using a Local Cortical Network Model},
  author = {Mazzoni, Alberto and Whittingstall, Kevin and Brunel, Nicolas and Logothetis, Nikos K and Panzeri, Stefano},
  year = {2010},
  month = sep,
  volume = {52},
  pages = {956--972},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2009.12.040},
  abstract = {Despite the widespread use of EEGs to measure the large-scale dynamics of the human brain, little is known on how the dynamics of EEGs relates to that of the underlying spike rates of cortical neurons. However, progress was made by recent neurophysiological experiments reporting that EEG delta-band phase and gamma-band amplitude reliably predict some complementary aspects of the time course of spikes of visual cortical neurons. To elucidate the mechanisms behind these findings, here we hypothesize that the EEG delta phase reflects shifts of local cortical excitability arising from slow fluctuations in the network input due to entrainment to sensory stimuli or to fluctuations in ongoing activity, and that the resulting local excitability fluctuations modulate both the spike rate and the engagement of excitatory\textendash inhibitory loops producing gamma-band oscillations. We quantitatively tested these hypotheses by simulating a recurrent network of excitatory and inhibitory neurons stimulated with dynamic inputs presenting temporal regularities similar to that of thalamic responses during naturalistic visual stimulation and during spontaneous activity. The network model reproduced in detail the experimental relationships between spike rate and EEGs, and suggested that the complementariness of the prediction of spike rates obtained from EEG delta phase or gamma amplitude arises from nonlinearities in the engagement of excitatory\textendash inhibitory loops and from temporal modulations in the amplitude of the network input, which respectively limit the predictability of spike rates from gamma amplitude or delta phase alone. The model suggested also ways to improve and extend current algorithms for online prediction of spike rates from EEGs.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HFLZ8WJW\\Mazzoni et al. - 2010 - Understanding the relationships between spike rate.pdf},
  journal = {NeuroImage},
  language = {en},
  number = {3}
}

@article{mazzucato_fontanini_2019,
  title = {Expectation-Induced Modulation of Metastable Activity Underlies Faster Coding of Sensory Stimuli},
  author = {Mazzucato, L. and La Camera, G. and Fontanini, A.},
  year = {2019},
  month = may,
  volume = {22},
  pages = {787--796},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-019-0364-9},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WIIJKKNV\\Mazzucato et al. - 2019 - Expectation-induced modulation of metastable activ.pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {5}
}

@techreport{mcclain_buzsaki_2019,
  title = {Position-Theta-Phase Model of Hippocampal Place Cell Activity Applied to Quantification of Running Speed Modulation of Firing Rate},
  author = {McClain, Kathryn and Tingley, David and Heeger, David J. and Buzsaki, Gyorgy},
  year = {2019},
  month = jul,
  institution = {{Neuroscience}},
  doi = {10.1101/714105},
  abstract = {Spiking activity of place cells in the hippocampus encodes the animal's position as it moves through an environment. Within a cell's place field, both the firing rate and the phase of spiking in the local theta oscillation contain spatial information. We propose a position-theta-phase (PTP) model that captures the simultaneous expression of the firing-rate code and theta-phase code in place cell spiking. This model parametrically characterizes place fields to compare across cells, time and condition, generates realistic place cell simulation data, and conceptualizes a framework for principled hypothesis testing to identify additional features of place cell activity. We use the PTP model to assess the effect of running speed in place cell data recorded from rats running on linear tracks. For the majority of place fields we do not find evidence for speed modulation of the firing rate. For a small subset of place fields, we find firing rates significantly increase or decrease with speed. We use the PTP model to compare candidate mechanisms of speed modulation in significantly modulated fields, and determine that speed acts as a gain control on the magnitude of firing rate. Our model provides a tool that connects rigorous analysis with a computational framework for understanding place cell activity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VTN24ITU\\McClain et al. - 2019 - Position-theta-phase model of hippocampal place ce.pdf},
  language = {en},
  type = {Preprint}
}

@book{mcclelland_oreilly_1995,
  title = {Why There Are Complementary Learning Systems in the Hippocampus and Neocortex: Insights Form the Successes and Failures of Connectionist Models of Learning and Memory},
  author = {McClelland, James L and McNaughton, Bruce and O׳Reilly, Randall C},
  year = {1995},
  volume = {102},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\72L62X5H\\McClelland, McNaughton, O׳Reilly - 1995 - Why there are complementary learning systems in the hippocampus and neocortex insights form t.pdf}
}

@article{mcclelland_rogers_2003,
  title = {The Parallel Distributed Processing Approach to Semantic Cognition},
  author = {McClelland, James L. and Rogers, Timothy T.},
  year = {2003},
  month = apr,
  volume = {4},
  pages = {310--322},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn1076},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NPIJYHB2\\McClelland and Rogers - 2003 - The parallel distributed processing approach to se.pdf},
  journal = {Nature Reviews Neuroscience},
  language = {en},
  number = {4}
}

@article{mcdaniel_braver_2013,
  title = {Dissociable Neural Routes to Successful Prospective Memory.},
  author = {a McDaniel, Mark and Lamontagne, Pamela and Beck, Stefanie M and Scullin, Michael K and Braver, Todd S},
  year = {2013},
  volume = {24},
  pages = {1791--1800},
  issn = {1467-9280},
  doi = {10.1177/0956797613481233},
  abstract = {Identifying the processes by which people remember to execute an intention at an appropriate moment (prospective memory) remains a fundamental theoretical challenge. According to one account, top-down attentional control is required to maintain activation of the intention, initiate intention retrieval, or support monitoring. A diverging account suggests that bottom-up, spontaneous retrieval can be triggered by cues that have been associated with the intention and that sustained attentional processes are not required. We used a specialized experimental design and functional MRI methods to selectively marshal and identify each process. Results revealed a clear dissociation. One prospective-memory task recruited sustained activity in attentional-control areas, such as the anterior prefrontal cortex; the other engaged purely transient activity in parietal and ventral brain regions associated with attentional capture, target detection, and episodic retrieval. These patterns provide critical evidence that there are two neural routes to prospective memory, with each route emerging under different circumstances.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GYEB5KQ6\\McDaniel et al. - 2013 - Dissociable neural routes to successful prospective memory.pdf},
  journal = {Psychological science},
  keywords = {beck,braver,chological science,com,dissociable neural routes to,http,mark a,mcdaniel,michael k,pamela lamontagne,pss,sagepub,scullin and todd s,stefanie m,successful prospective memory},
  number = {9},
  pmid = {23907544}
}

@article{mcdaniel_waldum_2015,
  title = {Dual Pathways to Prospective Remembering},
  author = {McDaniel, Mark A and Umanath, Sharda and Einstein, Gilles O and Waldum, Emily R},
  year = {2015},
  volume = {9},
  pages = {1--12},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2015.00392},
  abstract = {According to the multiprocess framework (McDaniel \{\&\} Einstein, 2000), the cognitive system can support prospective memory (PM) retrieval through two general pathways. One pathway depends on top-down attentional control processes that maintain activation of the intention and/or monitor the environment for the triggering or target cues that indicate that the intention should be executed. A second pathway depends on (bottom-up) spontaneous retrieval processes, processes that are often triggered by a PM target cue; critically spontaneous retrieval is assumed to not require monitoring or active maintenance of the intention. Given demand characteristics associated with experimental settings, however, participants are often inclined to monitor, thereby potentially masking discovery of bottom-up spontaneous retrieval processes. In this article, we discuss parameters of laboratory PM paradigms to discourage monitoring and review recent behavioral evidence from such paradigms that implicate spontaneous retrieval in PM. We then re-examine the neuro-imaging evidence from the lens of the multiprocess framework and suggest some critical modifications to existing neuro-cognitive interpretations of the neuro-imaging results. These modifications illuminate possible directions and refinements for further neuro-imaging investigations of PM.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\39BJQGT3\\McDaniel et al. - 2015 - Dual pathways to prospective remembering.pdf},
  journal = {Frontiers in Human Neuroscience},
  keywords = {monitoring in prospective memory,neuroimaging of prospective memory,prospective memory,prospective memory paradigms,spontaneous retrieval},
  number = {July},
  pmid = {26236213}
}

@article{mcguire_mcguire_1997,
  title = {Creating {{Hypothesis Generating}} in {{Psychology}}: {{Some Useful Heuristics}}},
  author = {McGuire, William J},
  year = {1997},
  volume = {48},
  pages = {1--30},
  issn = {0066-4308},
  doi = {10.1146/annurev.psych.48.1.1},
  abstract = {? Abstract To correct a common imbalance in methodology courses, focusing almost entirely on hypothesis-testing issues to the neglect of hypothesis-generating issues which are at least as important, 49 creative heuristics are described, divided into 5 categories and 14 subcategories. Each of these heuristics has often been used to generate hypotheses in psychological research, and each is teachable to students. The 49 heuristics range from common sense perceptiveness of the oddity of natural occurrences to use of sophisticated quantitative data analyses in ways that provoke new insights.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KCAPQF6N\\McGuire - 1997 - Creating Hypothesis Generating in Psychology Some Useful Heuristics.pdf},
  journal = {Annu. Rev. Psychol.},
  keywords = {creativity,heuristics,methodology,theory construction},
  number = {1},
  pmid = {15012475}
}

@article{mckenzie_eichenbaum_2014,
  title = {Hippocampal {{Representation}} of {{Related}} and {{Opposing Memories Develop}} within {{Distinct}}, {{Hierarchically Organized Neural Schemas}}.},
  author = {McKenzie, Sam and Frank, Andrea J and Kinsky, Nathaniel R and Porter, Blake and Rivi{\`e}re, Pamela D and Eichenbaum, Howard B},
  year = {2014},
  month = jul,
  volume = {83},
  pages = {202--215},
  issn = {1097-4199},
  doi = {10.1016/j.neuron.2014.05.019},
  abstract = {UNLABELLED: Recent evidence suggests that the hippocampus may integrate overlapping memories into relational representations, or schemas, that link indirectly related events and support flexible memory expression. Here we explored the nature of hippocampal neural population representations for multiple features of events and the locations and contexts in which they occurred. Hippocampal networks developed hierarchical organizations of associated elements of related but separately acquired memories within a context, and distinct organizations for memories where the contexts differentiated object-reward associations. These findings reveal neural mechanisms for the development and organization of relational representations. VIDEO ABSTRACT:},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UMN6TP9I\\McKenzie et al. - 2014 - Hippocampal Representation of Related and Opposing Memories Develop within Distinct, Hierarchically Organized N.pdf},
  journal = {Neuron},
  number = {1},
  pmid = {24910078}
}

@article{mclaughlin_kim_2004,
  title = {Neural Correlates of Second-Language Word Learning: Minimal Instruction Produces Rapid Change},
  author = {McLaughlin, Judith and Osterhout, Lee and Kim, Albert},
  year = {2004},
  volume = {7},
  pages = {703--704},
  issn = {1097-6256},
  doi = {10.1038/nn1264},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8XI2ZKGE\\McLaughlin, Osterhout, Kim - 2004 - Neural correlates of second-language word learning minimal instruction produces rapid change.pdf},
  journal = {Nature Neuroscience},
  number = {7}
}

@article{mclelland_vanrullen_2016,
  title = {Theta-{{Gamma Coding Meets Communication}}-through-{{Coherence}}: {{Neuronal Oscillatory Multiplexing Theories Reconciled}}},
  author = {McLelland, Douglas and VanRullen, Rufin},
  year = {2016},
  volume = {12},
  pages = {4--10},
  issn = {15537358},
  doi = {10.1371/journal.pcbi.1005162},
  abstract = {Author Summary There is a growing consensus that neuronal oscillations constitute a fundamental computational mechanism in the brain. Beyond this, recent experimental evidence has highlighted interactions between oscillations at high and low frequencies (e.g. gamma oscillations, 40\textendash 80 Hz, are modulated by theta oscillations, 4\textendash 10 Hz), and two major theories have developed regarding the functional role of this kind of cross-frequency coupling. Here, we present a computational modelling study of these theories with strong implications for biological studies. Firstly, we demonstrate for the first time that each of these theories is physiologically plausible, in that they can be implemented in a spiking network model with parameters guided by experimental data. Secondly, we show that they are each computationally useful, able to overcome a feature-binding ambiguity in a presented stimulus. Finally, we implement both theories within a single network model, and find that only a single parameter change is required to switch between the two processing states. This leads to the exciting new proposal that both theories may be correct, both implemented in the brain, with dynamic switching between modes according to processing and attentional requirements.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XR3U7UKE\\McLelland, VanRullen - 2016 - Theta-Gamma Coding Meets Communication-through-Coherence Neuronal Oscillatory Multiplexing Theories Reconc.pdf},
  journal = {PLoS Computational Biology},
  number = {10},
  pmid = {27741229}
}

@article{mcnaughton_okeefe_1984,
  title = {The Contributions of Position, Direction, and Velocity to Single Unit Activity in the Hippocampus of Freely-Moving Rats},
  author = {McNaughton, B L and a. Barnes, C and O'Keefe, J},
  year = {1984},
  volume = {54},
  pages = {195},
  issn = {00144819},
  doi = {10.1007/BF00235832},
  abstract = {Isolated single units in rat dorsal hippocampus and fascia dentata were classified as 'Theta' or 'Complex-Spike' cells, and their firing characteristics were examined with respect to position, direction and velocity of movement during forced choice, food rewarded search behavior on a radial eight arm maze. Most spikes from CS cells occurred when the animal was located within a particular place on the maze and moving in a particular direction. Theta cells had very low spatial selectivity. Both cell categories had discharge probabilities which increased somewhat as a function of running velocity but tended to asymptote well before half-maximal velocity. The place/direction specificity of CS cells was significantly higher in CA1 than in CA3 and CA3 CS cells exhibited a striking preference for the inward radial direction. The pronounced directional selectivity of CS cells, at least in the present environment, suggests that they fire in response to complex, but specific, stimulus features in the extramaze world rather than to absolute place in a non-egocentric space. An alternative possibility is that the geometrical constraints of the maze surface have a profound influence on the shapes of the response fields of CS cells.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8AAMQIGQ\\McNaughton, Barnes, O'Keefe - 1984 - The contributions of position, direction, and velocity to single unit activity in the hippocampus o.pdf},
  journal = {Experimental Brain Research},
  keywords = {behavior - cognitive maps,hip-,neurophysiology - single units,pocampus - radial maze},
  number = {1},
  pmid = {6628596}
}

@article{medawar_medawar_1964,
  title = {Is the Scientific Paper Fraudulent?},
  author = {Medawar, P.B.},
  year = {1964},
  pages = {42--43},
  issn = {0008-4271},
  doi = {10.4141/cjss96-055},
  abstract = {Medawar, P. B. "`Is the Scientific Paper a Fraud?." (1990): 228-33.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MBIXZYCI\\Unknown - Unknown - Is the Scientific Paper Fraudulent.pdf},
  journal = {The Saturday Review},
  number = {Aug. 1},
  pmid = {20328182}
}

@article{medvedeva_sysoev_2018,
  title = {Modeling Spike-Wave Discharges by a Complex Network of Neuronal Oscillators},
  author = {Medvedeva, Tatiana M. and Sysoeva, Marina V. and {van Luijtelaar}, Gilles and Sysoev, Ilya V.},
  year = {2018},
  volume = {98},
  pages = {271--282},
  issn = {18792782},
  doi = {10.1016/j.neunet.2017.12.002},
  abstract = {Purpose: The organization of neural networks and the mechanisms, which generate the highly stereotypical for absence epilepsy spike-wave discharges (SWDs) is heavily debated. Here we describe such a model which can both reproduce the characteristics of SWDs and dynamics of coupling between brain regions, relying mainly on properties of hierarchically organized networks of a large number of neuronal oscillators. Model: We used a two level mesoscale model. The first level consists of three structures: the nervus trigeminus serving as an input, the thalamus and the somatosensory cortex; the second level of a group of nearby situated neurons belonging to one of three modeled structures. Results: The model reproduces the main features of the transition from normal to epileptiformic activity and its spontaneous abortion: an increase in the oscillation amplitude, the emergence of the main frequency and its higher harmonics, and the ability to generate trains of seizures. The model was stable with respect to variations in the structure of couplings and to scaling. The analyzes of the interactions between model structures from their time series using Granger causality method showed that the model reproduced the preictal coupling increase detected previously from experimental data. Conclusion: SWDs can be generated by changes in network organization. It is proposed that a specific pathological architecture of couplings in the brain is necessary to allow the transition from normal to epileptiformic activity, next to by others modeled and reported factors referring to complex, intrinsic, and synaptic mechanisms.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\J96MXM88\\Medvedeva et al. - 2018 - Modeling spike-wave discharges by a complex network of neuronal oscillators.pdf},
  journal = {Neural Networks},
  keywords = {Complex networks,Genetic absence models,Granger causality,Mathematical modeling,Spike-wave discharges}
}

@article{mehta_mcnaughton_1997,
  title = {Experience-Dependent, Asymmetric Expansion of Hippocampal Place Fields.},
  author = {Mehta, M R and Barnes, C A and McNaughton, B L},
  year = {1997},
  volume = {94},
  pages = {8918--8921},
  issn = {00278424},
  doi = {10.1073/pnas.94.16.8918},
  abstract = {Theories of sequence learning based on temporally asymmetric, Hebbian long-term potentiation predict that during route learning the spatial firing distributions of hippocampal neurons should enlarge in a direction opposite to the animal's movement. On a route AB, increased synaptic drive from cells representing A would cause cells representing B to fire earlier and more robustly. These effects appeared within a few laps in rats running on closed tracks. This provides indirect evidence for Hebbian synaptic plasticity and a functional explanation for why place cells become directionally selective during route following, namely, to preserve the synaptic asymmetry necessary to encode the sequence direction.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JND5T4I3\\Mehta, Barnes, McNaughton - 1997 - Experience-dependent, asymmetric expansion of hippocampal place fields.pdf},
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  number = {August},
  pmid = {9238078}
}

@article{mehta_wilson_2000,
  title = {Experience-Dependent Asymmetric Shape of Hippocampal Receptive Fields.},
  author = {Mehta, M R and Quirk, M C and a Wilson, M},
  year = {2000},
  month = mar,
  volume = {25},
  pages = {707--715},
  issn = {0896-6273},
  abstract = {We propose a novel parameter, namely, the skewness, or asymmetry, of the shape of a receptive field to characterize two properties of hippocampal place fields. First, a majority of hippocampal receptive fields on linear tracks are negatively skewed, such that during a single pass the firing rate is low as the rat enters the field but high as it exits. Second, while the place fields are symmetric at the beginning of a session, they become highly asymmetric with experience. Further experiments suggest that these results are likely to arise due to synaptic plasticity during behavior. Using a purely feed forward neural network model, we show that following repeated directional activation, NMDA-dependent long-term potentiation/long-term depotentiation (LTP/LTD) could result in an experience-dependent asymmetrization of receptive fields.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PKZ7IYE3\\Mehta, Quirk, Wilson - 2000 - Experience-dependent asymmetric shape of hippocampal receptive fields.pdf},
  journal = {Neuron},
  keywords = {Animal,Animal: physiology,Animals,Behavior,Conditioning (Psychology),Conditioning (Psychology): physiology,Electrophysiology,Hippocampus,Hippocampus: cytology,Hippocampus: physiology,Long-Evans,Male,Neuronal Plasticity,Neuronal Plasticity: physiology,Orientation,Orientation: physiology,Pyramidal Cells,Pyramidal Cells: physiology,Rats,Space Perception,Space Perception: physiology},
  number = {3},
  pmid = {10774737}
}

@article{mehta_wilson_2002,
  title = {Role of Experience and Oscillations in Transforming a Rate Code into a Temporal Code.},
  author = {Mehta, M R and Lee, A K and Wilson, M A},
  year = {2002},
  volume = {417},
  pages = {741--746},
  issn = {0028-0836},
  doi = {10.1038/nature00807},
  abstract = {In the vast majority of brain areas, the firing rates of neurons, averaged over several hundred milliseconds to several seconds, can be strongly modulated by, and provide accurate information about, properties of their inputs. This is referred to as the rate code. However, the biophysical laws of synaptic plasticity require precise timing of spikes over short timescales (\{\textbackslash textless\}10 ms). Hence it is critical to understand the physiological mechanisms that can generate precise spike timing in vivo, and the relationship between such a temporal code and a rate code. Here we propose a mechanism by which a temporal code can be generated through an interaction between an asymmetric rate code and oscillatory inhibition. Consistent with the predictions of our model, the rate and temporal codes of hippocampal pyramidal neurons are highly correlated. Furthermore, the temporal code becomes more robust with experience. The resulting spike timing satisfies the temporal order constraints of hebbian learning. Thus, oscillations and receptive field asymmetry may have a critical role in temporal sequence learning.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5ZLF9PEG\\Mehta, Lee, Wilson - 2002 - Role of experience and oscillations in transforming a rate code into a temporal code.pdf},
  journal = {Nature},
  pmid = {12066185}
}

@article{mejias_wang_2016,
  title = {Feedforward and Feedback Frequency-Dependent Interactions in a Large-Scale Laminar Network of the Primate Cortex},
  author = {Mejias, Jorge F and Murray, John D and Kennedy, Henry and Wang, Xiao Jing},
  year = {2016},
  volume = {2},
  issn = {23752548},
  doi = {10.1126/sciadv.1601335},
  abstract = {Interactions between top-down and bottom-up processes in the cerebral cortex hold the key to understanding predictive coding, executive control and a gamut of other brain functions. The underlying circuit mechanism, however, remains poorly understood and represents a major challenge in neuroscience. In the present work we tackled this problem using a large-scale computational model of the primate cortex constrained by new directed and weighted connectivity data. In our model, the interplay between feedforward and feedback signaling depends on the cortical laminar structure and involves complex dynamics across multiple (intra-laminar, inter-laminar, inter-areal and whole cortex) scales. The model was tested by reproducing, and shedding insights into, a wide range of neurophysiological findings about frequency-dependent interactions between visual cortical areas: feedforward pathways are associated with enhanced gamma (30-70 Hz) oscillations, whereas feedback projections selectively modulate alpha/low beta (8-15 Hz) oscillations. We found that in order for the model to account for the experimental observations, the feedback projection needs to predominantly target infragranular layers in a target area, which leads to a proposed circuit substrate for predictive coding. The model reproduces a functional hierarchy based on frequency-dependent Granger causality analysis of inter-areal signaling, as reported in recent monkey and human experiments. Taken together, this work highlights the importance of multi-scale approaches and provides a modeling platform for studies of large-scale brain circuit dynamics and functions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WUA2RVBG\\Mejias et al. - Unknown - Feedforward and feedback frequency-dependent interactions in a large-scale laminar network of the primate cort.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\ZZWWRANA\\Mejias et al. - 2016 - Feedforward and feedback frequency-dependent interactions in a large-scale laminar network of the primate cortex.pdf},
  journal = {Science Advances},
  number = {11},
  pmid = {28138530}
}

@article{melchior_wiskott_2019,
  title = {A {{Hippocampus Model}} for {{Online One}}-{{Shot Storage}} of {{Pattern Sequences}}},
  author = {Melchior, Jan and Bayati, Mehdi and Azizi, Amir and Cheng, Sen and Wiskott, Laurenz},
  year = {2019},
  month = may,
  abstract = {We present a computational model based on the CRISP theory (Content Representation, Intrinsic Sequences, and Pattern completion) of the hippocampus that allows to continuously store pattern sequences online in a one-shot fashion. Rather than storing a sequence in CA3, CA3 provides a pre-trained sequence that is hetero-associated with the input sequence, which allows the system to perform one-shot learning. Plasticity on a short time scale therefore only happens in the incoming and outgoing connections of CA3. Stored sequences can later be recalled from a single cue pattern. We identify the pattern separation performed by subregion DG to be necessary for storing sequences that contain correlated patterns. A design principle of the model is that we use a single learning rule named Hebbiand-escent to train all parts of the system. Hebbian-descent has an inherent forgetting mechanism that allows the system to continuously memorize new patterns while forgetting early stored ones. The model shows a plausible behavior when noisy and new patterns are presented and has a rather high capacity of about 40\% in terms of the number of neurons in CA3. One notable property of our model is that it is capable of `boot-strapping' (improving) itself without external input in a process we refer to as `dreaming'. Besides artificially generated input sequences we also show that the model works with sequences of encoded handwritten digits or natural images. To our knowledge this is the first model of the hippocampus that allows to store correlated pattern sequences online in a one-shot fashion without a consolidation process, which can instantaneously be recalled later.},
  archivePrefix = {arXiv},
  eprint = {1905.12937},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BI6LRJLW\\melchior_et_al_2019_a_hippocampus_model_for_online_one-shot_storage_of_pattern_sequences.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\LG2WG7AL\\1905.html},
  journal = {arXiv:1905.12937 [cs, q-bio]},
  primaryClass = {cs, q-bio}
}

@article{melrose_stern_2007,
  title = {An {{fMRI}} Investigation of the Role of the Basal Ganglia in Reasoning},
  author = {Melrose, Rebecca J and Poulin, Renee M and Stern, Chantal E},
  year = {2007},
  volume = {1142},
  pages = {146--158},
  issn = {00068993},
  doi = {10.1016/j.brainres.2007.01.060},
  abstract = {Neuropsychological studies highlight the importance of the prefrontal cortex in abstract reasoning ability. The prefrontal cortex is anatomically connected to the basal ganglia through a series of parallel loops. The dorsolateral prefrontal cortex shares relatively greater connectivity with the caudate head, and it has been proposed that the caudate head may be more sensitive to executive processing. To investigate the frontostriatal circuitry underlying abstract reasoning, we designed a reasoning task in which stimuli varied sequentially across one dimension. Critically, the task required that subjects deduce and apply a sequencing rule. We also developed a match-to-sample working memory task in order to identify and contrast brain regions involved in working memory. We observed reasoning-related activation in both cortical and subcortical regions. Subcortically, the caudate was found to be bilaterally active during both the reasoning and matching tasks, and the left caudate head was more active for reasoning compared to matching. An anatomically defined region of interest analysis demonstrated activity for both reasoning and matching tasks within the body of the caudate. In contrast, the left caudate head was found to more specifically support reasoning. Cortically, we observed activity of bilateral rostrolateral prefrontal cortex, right ventrolateral prefrontal cortex, and bilateral parietal cortex during reasoning. Our results suggest that reasoning requires an interaction between cortical areas and the caudate nucleus, in which the caudate body supports both reasoning and working memory and the head of the caudate is specifically involved in the executive demands of reasoning, namely deducing and applying a sequence rule. \{\textcopyright\} 2007 Elsevier B.V. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SR4R8LYH\\Melrose, Poulin, Stern - 2007 - An fMRI investigation of the role of the basal ganglia in reasoning.pdf},
  journal = {Brain Research},
  keywords = {Caudate,Executive function,Planning,Prefrontal cortex,Sequencing,working-memory},
  number = {1},
  pmid = {17320049}
}

@article{meng_eden_2014,
  title = {A Unified Approach to Linking Experimental, Statistical and Computational Analysis of Spike Train Data.},
  author = {Meng, Liang and a Kramer, Mark and Middleton, Steven J and a Whittington, Miles and Eden, Uri T},
  year = {2014},
  month = jan,
  volume = {9},
  pages = {e85269},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0085269},
  abstract = {A fundamental issue in neuroscience is how to identify the multiple biophysical mechanisms through which neurons generate observed patterns of spiking activity. In previous work, we proposed a method for linking observed patterns of spiking activity to specific biophysical mechanisms based on a state space modeling framework and a sequential Monte Carlo, or particle filter, estimation algorithm. We have shown, in simulation, that this approach is able to identify a space of simple biophysical models that were consistent with observed spiking data (and included the model that generated the data), but have yet to demonstrate the application of the method to identify realistic currents from real spike train data. Here, we apply the particle filter to spiking data recorded from rat layer V cortical neurons, and correctly identify the dynamics of an slow, intrinsic current. The underlying intrinsic current is successfully identified in four distinct neurons, even though the cells exhibit two distinct classes of spiking activity: regular spiking and bursting. This approach\textendash linking statistical, computational, and experimental neuroscience\textendash provides an effective technique to constrain detailed biophysical models to specific mechanisms consistent with observed spike train data.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\R4UNWWGM\\Meng et al. - 2014 - A unified approach to linking experimental, statistical and computational analysis of spike train data.pdf},
  journal = {PloS one},
  number = {1},
  pmid = {24465520}
}

@techreport{meng_kennedy_2018,
  title = {Relational {{Autoencoder}} for {{Feature Extraction}}},
  author = {Meng, Qinxue and Catchpoole, Daniel and Skillicorn, David and Kennedy, Paul J},
  year = {2018},
  abstract = {Feature extraction becomes increasingly important as data grows high dimensional. Autoencoder as a neural network based feature extraction method achieves great success in generating abstract features of high dimensional data. However, it fails to consider the relationships of data samples which may affect experimental results of using original and new features. In this paper, we propose a Relation Autoencoder model considering both data features and their relationships. We also extend it to work with other major autoencoder models including Sparse Au-toencoder, Denoising Autoencoder and Variational Autoencoder. The proposed relational autoencoder models are evaluated on a set of benchmark datasets and the experimental results show that considering data relationships can generate more robust features which achieve lower construction loss and then lower error rate in further classification compared to the other variants of autoencoders.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2KFWXCR2\\Meng et al. - Unknown - Relational Autoencoder for Feature Extraction.pdf}
}

@article{mensh_kording_2017,
  title = {Ten Simple Rules for Structuring Papers},
  author = {Mensh, Brett and Kording, Konrad},
  year = {2017},
  volume = {13},
  issn = {15537358},
  doi = {10.1371/journal.pcbi.1005619},
  abstract = {Good scientific writing is essential to career development and to the progress of science. A well-structured manuscript allows readers and reviewers to get excited about the subject matter, to understand and verify the paper's contributions, and to integrate them into a broader context. However, many scientists struggle with producing high-quality manuscripts and are typically given little training in paper writing. Focusing on how readers consume information, we present a set of 10 simple rules to help you get across the main idea of your paper. These rules are designed to make your paper more influential and the process of writing more efficient and pleasurable.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KCTHN2YD\\Mensh, Kording - 2017 - Ten simple rules for structuring papers.pdf},
  journal = {PLoS Computational Biology},
  number = {9},
  pmid = {22352717}
}

@article{merel_wayne_2019,
  title = {Hierarchical Motor Control in Mammals and Machines},
  author = {Merel, Josh and Botvinick, Matthew and Wayne, Greg},
  year = {2019},
  month = dec,
  volume = {10},
  pages = {5489},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-13239-6},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GT43JDRH\\Merel et al. - 2019 - Hierarchical motor control in mammals and machines.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\WIYPKG4R\\Merel et al. - 2019 - Hierarchical motor control in mammals and machines.pdf},
  journal = {Nature Communications},
  language = {en},
  number = {1}
}

@article{merrikhi_noudoost_2018,
  title = {Concurrent Influence of Top-down and Bottom-up Inputs on Correlated Activity of {{Macaque}} Extrastriate Neurons},
  author = {Merrikhi, Yaser and Clark, Kelsey L and Noudoost, Behrad},
  year = {2018},
  month = dec,
  volume = {9},
  pages = {5393},
  issn = {2041-1723},
  doi = {10.1038/s41467-018-07816-4},
  abstract = {Correlations between neurons can profoundly impact the information encoding capacity of a neural population. We studied how maintenance of visuospatial information affects correlated activity in visual areas by recording the activity of neurons in visual area MT of rhesus macaques during a spatial working memory task. Correlations between MT neurons depended upon the spatial overlap between neurons' receptive fields. These correlations were influenced by the content of working memory, but the effect of a top-down memory signal differed in the presence or absence of bottom-up visual input. Neurons representing the same area of space showed increased correlations when remembering a location in their receptive fields in the absence of visual input, but decreased correlations in the presence of a visual stimulus. This set of results reveals the correlating nature of top-down signals influencing visual areas and uncovers how such a correlating signal, in interaction with bottom-up information, could enhance sensory representations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JU9FQJWY\\Merrikhi, Clark, Noudoost - Unknown - Concurrent influence of top-down and bottom-up inputs on correlated activity of Macaque extrastria.pdf},
  journal = {Nature Communications},
  number = {1}
}

@article{mesnard_brea_2016,
  title = {Towards Deep Learning with Spiking Neurons in Energy Based Models with Contrastive {{Hebbian}} Plasticity},
  author = {Mesnard, Thomas and Gerstner, Wulfram and Brea, Johanni},
  year = {2016},
  month = dec,
  abstract = {In machine learning, error back-propagation in multi-layer neural networks (deep learning) has been impressively successful in supervised and reinforcement learning tasks. As a model for learning in the brain, however, deep learning has long been regarded as implausible, since it relies in its basic form on a non-local plasticity rule. To overcome this problem, energy-based models with local contrastive Hebbian learning were proposed and tested on a classification task with networks of rate neurons. We extended this work by implementing and testing such a model with networks of leaky integrate-and-fire neurons. Preliminary results indicate that it is possible to learn a non-linear regression task with hidden layers, spiking neurons and a local synaptic plasticity rule.},
  archivePrefix = {arXiv},
  eprint = {1612.03214},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\285BA398\\Mesnard et al. - 2016 - Towards deep learning with spiking neurons in ener.pdf},
  journal = {arXiv:1612.03214 [cs, q-bio]},
  language = {en},
  primaryClass = {cs, q-bio}
}

@phdthesis{metcalf_metcalf_2019,
  title = {Representing {{Textual}} and {{Temporal Concepts Through Learned Continuous}}-{{Space Vector Embeddings}}},
  author = {Metcalf, Katherine},
  year = {2019},
  address = {{United States -- Indiana}},
  abstract = {Good representations are crucial for the development of high-quality artificially intelligent systems. This dissertation addresses the problem of how to apply machine learning to build representations. It presents two methods: one method for learning from and representing text-based data and one for learning from and representing time-based data. The first develops joint representations of textual and relation knowledge collected and detailed by humans. The second learns concepts from streams of temporal data and develops a hierarchy of temporally extended concept representations that can be aligned with specific observations of the world. The two algorithms presented are, respectively, JointEmbed and ENHAnCE. JointEmbed and ENHAnCE address two primary challenges:(1) succinctly encoding predictively useful information from text and (2) identifying what about a temporal data stream should be chunked and summarized together as a single meaningful, component. The algorithms are presented in the context of learning representations that address issues faced by indexing for case retrieval in case-based reasoning. JointEmbed is evaluated on its ability to learn word representations that can be used to index electronic health records on the text contained in physicians' notes and retrieval relevant electronic health records from an existing case base. JointEmbed is shown to outperform other related methods. ENHAnCE is evaluated on its ability to detect meaningful concept boundaries in language-based data streams and to develop representations of those concepts that are predictively meaningful. ENHAnCE is shown to be able to learn such representations and to outperform other relevant approaches.},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6B6ZZDIT\\metcalf_2019_representing_textual_and_temporal_concepts_through_learned_continuous-space.pdf},
  language = {English},
  school = {Indiana University},
  type = {Ph.{{D}}.}
}

@article{metz_sohl-dickstein_2017,
  title = {Supervised {{Learning}} of {{Unsupervised Learning Rules}}},
  author = {Metz, Luke and Cheung, Brian and {Sohl-dickstein}, Jascha},
  year = {2017},
  pages = {1--5},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MTHEICMC\\Metz, Cheung, Sohl-dickstein - 2017 - Supervised Learning of Unsupervised Learning Rules.pdf},
  number = {1}
}

@article{meye_mameli_2016,
  title = {Shifted Pallidal Co-Release of {{GABA}} and Glutamate in Habenula Drives Cocaine Withdrawal and Relapse},
  author = {Meye, Frank J and {Soiza-Reilly}, Mariano and Smit, Tamar and Diana, Marco A and Schwarz, Martin K and Mameli, Manuel},
  year = {2016},
  volume = {19},
  pages = {1019--1024},
  issn = {1097-6256},
  doi = {10.1038/nn.4334},
  abstract = {Cocaine withdrawal produces aversive states and vulnerability to relapse, hallmarks of addiction. The lateral habenula (LHb) encodes negative stimuli and contributes to aversive withdrawal symptoms. However, it remains unclear which inputs to LHb promote this and what the consequences are for relapse susceptibility. We report, using rabies-based retrolabeling and optogenetic mapping, that the entopeduncular nucleus (EPN, the mouse equivalent of the globus pallidus interna) projects to an LHb neuronal subset innervating aversion-encoding midbrain GABA neurons. EPN-to-LHb excitatory signaling is limited by GABAergic cotransmission. This inhibitory component decreases during cocaine withdrawal as a result of reduced presynaptic vesicular GABA transporter (VGAT). This shifts the EPN-to-LHb GABA/glutamate balance, disinhibiting EPN-driven LHb activity. Selective virally mediated VGAT overexpression at EPN-to-LHb terminals during withdrawal normalizes GABAergic neurotransmission. This intervention rescues cocaine-evoked aversive states and prevents stress-induced reinstatement, used to model relapse. This identifies diminished inhibitory transmission at EPN-to-LHb GABA/glutamate synapses as a mechanism contributing to the relapsing feature of addictive behavior.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\F7D8D6TH\\Meye et al. - 2016 - Shifted pallidal co-release of GABA and glutamate in habenula drives cocaine withdrawal and relapse.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\RZSCGAJW\\Meye et al. - 2016 - Shifted pallidal co-release of GABA and glutamate in habenula drives cocaine withdrawal and relapse.pdf},
  journal = {Nature Neuroscience},
  number = {8},
  pmid = {27348214}
}

@article{meyers_meyers_2013,
  title = {The Neural Decoding Toolbox.},
  author = {Meyers, Ethan M},
  year = {2013},
  month = jan,
  volume = {7},
  pages = {8},
  issn = {1662-5196},
  doi = {10.3389/fninf.2013.00008},
  abstract = {Population decoding is a powerful way to analyze neural data, however, currently only a small percentage of systems neuroscience researchers use this method. In order to increase the use of population decoding, we have created the Neural Decoding Toolbox (NDT) which is a Matlab package that makes it easy to apply population decoding analyses to neural activity. The design of the toolbox revolves around four abstract object classes which enables users to interchange particular modules in order to try different analyses while keeping the rest of the processing stream intact. The toolbox is capable of analyzing data from many different types of recording modalities, and we give examples of how it can be used to decode basic visual information from neural spiking activity and how it can be used to examine how invariant the activity of a neural population is to stimulus transformations. Overall this toolbox will make it much easier for neuroscientists to apply population decoding analyses to their data, which should help increase the pace of discovery in neuroscience.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7RZBIFRL\\Meyers - 2013 - The neural decoding toolbox.pdf},
  journal = {Frontiers in neuroinformatics},
  keywords = {data analysis,machine learning,matlab,mvpa,neural decoding,readout},
  number = {May},
  pmid = {23734125}
}

@article{mhatre_grossberg_2012,
  title = {Grid Cell Hexagonal Patterns Formed by Fast Self-Organized Learning within Entorhinal Cortex},
  author = {Mhatre, Himanshu and Gorchetchnikov, Anatoli and Grossberg, Stephen},
  year = {2012},
  volume = {22},
  pages = {320--334},
  issn = {10509631},
  doi = {10.1002/hipo.20901},
  abstract = {Grid cells in the dorsal segment of the medial entorhinal cortex (dMEC) show remarkable hexagonal activity patterns, at multiple spatial scales, during spatial navigation. It has previously been shown how a self-organizing map can convert firing patterns across entorhinal grid cells into hippocampal place cells that are capable of representing much larger spatial scales. Can grid cell firing fields also arise during navigation through learning within a self-organizing map? This article describes a simple and general mathematical property of the trigonometry of spatial navigation which favors hexagonal patterns. The article also develops a neural model that can learn to exploit this trigonometric relationship. This GRIDSmap self-organizing map model converts path integration signals into hexagonal grid cell patterns of multiple scales. GRIDSmap creates only grid cell firing patterns with the observed hexagonal structure, predicts how these hexagonal patterns can be learned from experience, and can process biologically plausible neural input and output signals during navigation. These results support an emerging unified computational framework based on a hierarchy of self-organizing maps for explaining how entorhinal-hippocampal interactions support spatial navigation.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HNEY4226\\Mhatre, Gorchetchnikov, Grossberg - 2012 - Grid cell hexagonal patterns formed by fast self-organized learning within entorhinal cortex.pdf},
  journal = {Hippocampus},
  keywords = {Entorhinal cortex,Grid cells,Path integration,Self-organized learning,Spatial navigation},
  number = {2},
  pmid = {21136517}
}

@article{michalareas_fries_2016,
  title = {Alpha-{{Beta}} and {{Gamma Rhythms Subserve Feedback}} and {{Feedforward Influences}} among {{Human Visual Cortical Areas}}},
  author = {Michalareas, Georgios and Vezoli, Julien and {van Pelt}, Stan and Schoffelen, Jan Mathijs and Kennedy, Henry and Fries, Pascal},
  year = {2016},
  volume = {89},
  pages = {384--397},
  issn = {10974199},
  doi = {10.1016/j.neuron.2015.12.018},
  abstract = {Primate visual cortex is hierarchically organized. Bottom-up and top-down influences are exerted through distinct frequency channels, as was recently revealed in macaques by correlating inter-areal influences with laminar anatomical projection patterns. Because this anatomical data cannot be obtained in human subjects, we selected seven homologous macaque and human visual areas, and we correlated the macaque laminar projection patterns to human inter-areal directed influences as measured with magnetoencephalography. We show that influences along feedforward projections predominate in the gamma band, whereas influences along feedback projections predominate in the alpha-beta band. Rhythmic inter-areal influences constrain a functional hierarchy of the seven homologous human visual areas that is in close agreement with the respective macaque anatomical hierarchy. Rhythmic influences allow an extension of the hierarchy to 26 human visual areas including uniquely human brain areas. Hierarchical levels of ventral- and dorsal-stream visual areas are differentially affected by inter-areal influences in the alpha-beta band. Michalareas et al. show that in human visual cortex influences along feedforward projections predominate in the gamma band, whereas influences along feedback projections predominate in the alpha-beta band. These influences constrain a functional hierarchy in agreement with macaque anatomical hierarchy.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KCPXLRY9\\Michalareas et al. - 2016 - Alpha-Beta and Gamma Rhythms Subserve Feedback and Feedforward Influences among Human Visual Cortical Areas.pdf},
  journal = {Neuron},
  number = {2},
  pmid = {26777277}
}

@article{michalareas_gross_2013,
  title = {Investigating Causality between Interacting Brain Areas with Multivariate Autoregressive Models of {{MEG}} Sensor Data},
  author = {Michalareas, George and Schoffelen, Jan Mathijs and Paterson, Gavin and Gross, Joachim},
  year = {2013},
  month = apr,
  volume = {34},
  pages = {890--913},
  issn = {10659471},
  doi = {10.1002/hbm.21482},
  abstract = {In this work, we investigate the feasibility to estimating causal interactions between brain regions based on multivariate autoregressive models (MAR models) fitted to magnetoencephalographic (MEG) sensor measurements. We first demonstrate the theoretical feasibility of estimating source level causal interactions after projection of the sensor-level model coefficients onto the locations of the neural sources. Next, we show with simulated MEG data that causality, as measured by partial directed coherence (PDC), can be correctly reconstructed if the locations of the interacting brain areas are known. We further demonstrate, if a very large number of brain voxels is considered as potential activation sources, that PDC as a measure to reconstruct causal interactions is less accurate. In such case the MAR model coefficients alone contain meaningful causality information. The proposed method overcomes the problems of model nonrobustness and large computation times encountered during causality analysis by existing methods. These methods first project MEG sensor time-series onto a large number of brain locations after which the MAR model is built on this large number of source-level time-series. Instead, through this work, we demonstrate that by building the MAR model on the sensor-level and then projecting only the MAR coefficients in source space, the true casual pathways are recovered even when a very large number of locations are considered as sources. The main contribution of this work is that by this methodology entire brain causality maps can be efficiently derived without any a priori selection of regions of interest. Hum Brain Mapp, 2012. \textcopyright{} 2012 Wiley Periodicals, Inc.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\35FUMKJH\\Michalareas et al. - 2013 - Investigating causality between interacting brain areas with multivariate autoregressive models of MEG senso.pdf},
  journal = {Human Brain Mapping},
  keywords = {Functional connectivity,Granger causality,MEG,Multivariate autoregressive models,Partial directed coherence},
  number = {4},
  pmid = {22328419}
}

@article{middleton_mchugh_2020,
  title = {{{CA2}}: {{A Highly Connected Intrahippocampal Relay}}},
  shorttitle = {{{CA2}}},
  author = {Middleton, Steven J. and McHugh, Thomas J.},
  year = {2020},
  month = jul,
  volume = {43},
  pages = {annurev-neuro-080719-100343},
  issn = {0147-006X, 1545-4126},
  doi = {10.1146/annurev-neuro-080719-100343},
  abstract = {Although Lorente de No' recognized the anatomical distinction of the hippocampal Cornu Ammonis (CA) 2 region, it had, until recently, been assigned no unique function. Its location between the key players of the circuit, CA3 and CA1, which along with the entorhinal cortex and dentate gyrus compose the classic trisynaptic circuit, further distracted research interest. However, the connectivity of CA2 pyramidal cells, together with unique patterns of gene expression, hints at a much larger contribution to hippocampal information processing than has been ascribed. Here we review recent advances that have identified new roles for CA2 in hippocampal centric processing, together with specialized functions in social memory and, potentially, as a broadcaster of novelty. These new data, together with CA2's role in disease, justify a closer look at how this small region exerts its influence and how it might best be exploited to understand and treat disease-related circuit dysfunctions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9GIIK23P\\Middleton and McHugh - 2020 - CA2 A Highly Connected Intrahippocampal Relay.pdf},
  journal = {Annual Review of Neuroscience},
  language = {en},
  number = {1}
}

@article{middleton_strick_1996,
  title = {The Temporal Lobe Is a Target of Output from the Basal Ganglia.},
  author = {Middleton, F. A. and Strick, P. L.},
  year = {1996},
  volume = {93},
  pages = {8683--8687},
  issn = {0027-8424},
  doi = {10.1073/pnas.93.16.8683},
  abstract = {The basal ganglia are known to receive inputs from widespread regions of the cerebral cortex, such as the frontal, parietal, and temporal lobes. Of these cortical areas, only the frontal lobe is thought to be the target of basal ganglia output. One of the cortical regions that is a source of input to the basal ganglia is area TE, in inferotemporal cortex. This cortical area is thought to be critically involved in the recognition and discrimination of visual objects. Using retrograde transneuronal transport of herpes simplex virus type 1, we have found that one of the output nuclei of the basal ganglia, the substantia nigra pars reticulata, projects via the thalamus to TE. Thus, TE is not only a source of input to the basal ganglia, but also is a target of basal ganglia output. This result implies that the output of the basal ganglia influences higher order aspects of visual processing. In addition, we propose that dysfunction of the basal ganglia loop with TE leads to alterations in visual perception, including visual hallucinations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DDIC887M\\Middleton, Strick - 1996 - The temporal lobe is a target of output from the basal ganglia.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  number = {16},
  pmid = {8710931}
}

@article{middleton_strick_2000,
  title = {Basal Ganglia and Cerebellar Loops: Motor and Cognitive Circuits},
  author = {Middleton, Frank A and Strick, Peter L},
  year = {2000},
  volume = {31},
  pages = {236--250},
  abstract = {The traditional view that the basal ganglia and cerebellum are simply involved in the control of movement has been challenged in recent years. One of the pivotal reasons for this reappraisal has been new information about basal ganglia and cerebellar connections with the cerebral cortex. In essence, recent anatomical studies have revealed that these connections are organized into discrete circuits or 'loops'. Rather than serving as a means for widespread cortical areas to gain access to the motor system, these loops reciprocally interconnect a large and diverse set of cerebral cortical areas with the basal ganglia and cerebellum. The properties of neurons within the basal ganglia or cerebellar components of these circuits resembles the properties of neurons within the cortical areas subserved by these loops. For example, neuronal activity within basal ganglia and cerebellar loops with motor areas of the cerebral cortex is highly correlated with parameters of movement, while neuronal activity within basal ganglia and cerebellar loops with areas of the prefrontal cortex is more related to aspects of cognitive function. Thus, individual loops appear to be involved in distinct behavioral functions. Studies of basal ganglia and cerebellar pathology support this conclusion. Damage to the basal ganglia or cerebellar components of circuits with motor areas of cortex leads to motor symptoms, whereas damage of the subcortical components of circuits with non-motor areas of cortex causes higher-order deficits. In this report, we review some of the new anatomical, physiological and behavioral findings that have contributed to a reappraisal of function concerning the basal ganglia and cerebellar loops with the cerebral cortex. q},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FV7EJYP9\\Middleton, Strick - 2000 - Basal ganglia and cerebellar loops motor and cognitive circuits.pdf},
  journal = {Brain Research Reviews},
  keywords = {Dentate nucleus,Globus pallidus,Prefrontal cortex,Primate,Substantia nigra,Virus tracing}
}

@article{mikolov_zweig_2013,
  title = {Linguistic Regularities in Continuous Space Word Representations},
  author = {Mikolov, Tomas and Yih, Wen-Tau and Zweig, Geoffrey},
  year = {2013},
  pages = {746--751},
  issn = {9781937284473},
  doi = {10.3109/10826089109058901},
  abstract = {Continuous space language models have re- cently demonstrated outstanding results across a variety of tasks. In this paper, we ex- amine the vector-space word representations that are implicitly learned by the input-layer weights. We find that these representations are surprisingly good at capturing syntactic and semantic regularities in language, and that each relationship is characterized by a relation-specific vector offset. This allows vector-oriented reasoning based on the offsets between words. For example, the male/female relationship is automatically learned, and with the induced vector representations, ``King - Man + Woman'' results in a vector very close to ``Queen.'' We demonstrate that the word vectors capture syntactic regularities by means of syntactic analogy questions (provided with this paper), and are able to correctly answer almost 40\% of the questions. We demonstrate that the word vectors capture semantic regu- larities by using the vector offset method to answer SemEval-2012 Task 2 questions. Re- markably, this method outperforms the best previous systems. 1},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LIUTCM28\\Mikolov, Yih, Zweig - 2013 - Linguistic Regularities in Continuous Space Word Representations.pdf},
  journal = {Proceedings of NAACL-HLT},
  number = {June},
  pmid = {1938007}
}

@book{milford_milford_2001,
  title = {Robot {{Navigation}} from {{Nature}}: {{Simultaneous Localisation}}, {{Mapping}}, and {{Path Planning Based}} on {{Hippocampal Models}}},
  author = {Milford, Michael J},
  year = {2001},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\85NJSCRN\\Milford - 2001 - Robot Navigation from Nature Simultaneous Localisation, Mapping, and Path Planning Based on Hippocampal Models.pdf},
  isbn = {978-3-540-77519-5}
}

@article{milford_schulz_2014,
  title = {Principles of Goal-Directed Spatial Robot Navigation in Biomimetic Models {{Principles}} of Goal-Directed Spatial Robot Navigation in Biomimetic Models},
  author = {Milford, Michael J and Schulz, Ruth},
  year = {2014},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NZ44NP2S\\Milford, Schulz - 2014 - Principles of goal-directed spatial robot navigation in biomimetic models Principles of goal-directed spatial r.pdf},
  journal = {Philosophical Transactions of the Royal Society B},
  number = {September}
}

@article{milford_wyeth_2010,
  title = {Solving Navigational Uncertainty Using Grid Cells on Robots},
  author = {Milford, Michael J and Wiles, Janet and Wyeth, Gordon F},
  year = {2010},
  volume = {6},
  issn = {1553734X},
  doi = {10.1371/journal.pcbi.1000995},
  abstract = {To successfully navigate their habitats, many mammals use a combination of two mechanisms, path integration and calibration using landmarks, which together enable them to estimate their location and orientation, or pose. In large natural environments, both these mechanisms are characterized by uncertainty: the path integration process is subject to the accumulation of error, while landmark calibration is limited by perceptual ambiguity. It remains unclear how animals form coherent spatial representations in the presence of such uncertainty. Navigation research using robots has determined that uncertainty can be effectively addressed by maintaining multiple probabilistic estimates of a robot's pose. Here we show how conjunctive grid cells in dorsocaudal medial entorhinal cortex (dMEC) may maintain multiple estimates of pose using a brain-based robot navigation system known as RatSLAM. Based both on rodent spatially-responsive cells and functional engineering principles, the cells at the core of the RatSLAM computational model have similar characteristics to rodent grid cells, which we demonstrate by replicating the seminal Moser experiments. We apply the RatSLAM model to a new experimental paradigm designed to examine the responses of a robot or animal in the presence of perceptual ambiguity. Our computational approach enables us to observe short-term population coding of multiple location hypotheses, a phenomenon which would not be easily observable in rodent recordings. We present behavioral and neural evidence demonstrating that the conjunctive grid cells maintain and propagate multiple estimates of pose, enabling the correct pose estimate to be resolved over time even without uniquely identifying cues. While recent research has focused on the grid-like firing characteristics, accuracy and representational capacity of grid cells, our results identify a possible critical and unique role for conjunctive grid cells in filtering sensory uncertainty. We anticipate our study to be a starting point for animal experiments that test navigation in perceptually ambiguous environments.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\R42HN2BW\\Milford, Wiles, Wyeth - 2010 - Solving navigational uncertainty using grid cells on robots.pdf},
  journal = {PLoS Computational Biology},
  number = {11},
  pmid = {21085643}
}

@article{milford_wyeth_2010a,
  title = {Persistent {{Navigation}} and {{Mapping}} Using a {{Biologically Inspired SLAM System}}},
  author = {Milford, Michael J and Wyeth, G},
  year = {2010},
  volume = {29},
  pages = {1131--1153},
  issn = {0278-3649},
  doi = {10.1177/0278364909340592},
  abstract = {The challenge of persistent navigation and mapping is to develop an autonomous robot system that can simultaneously localize, map and navigate over the lifetime of the robot with little or no human intervention. Most solutions to the simultaneous localization and mapping (SLAM) problem aim to produce highly accurate maps of areas that are assumed to be static. In contrast, solutions for persistent navigation and mapping must produce reliable goal-directed navigation outcomes in an environment that is assumed to be in constant flux. We investigate the persistent navigation and mapping problem in the context of an autonomous robot that performs mock deliveries in a working office environment over a two-week period. The solution was based on the biologically inspired visual SLAM system, RatSLAM. RatSLAM performed SLAM continuously while interacting with global and local navigation systems, and a task selection module that selected between exploration, delivery, and recharging modes. The robot performed 1,143 delivery tasks to 11 different locations with only one delivery failure (from which it recovered), traveled a total distance of more than 40 km over 37 hours of active operation, and recharged autonomously a total of 23 times.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RDII4KDG\\Milford, Wyeth - 2010 - Persistent Navigation and Mapping using a Biologically Inspired SLAM System.pdf},
  journal = {The International Journal of Robotics Research},
  keywords = {biologically inspired,persistent navigation and mapping,ratslam,slam}
}

@book{miller_bastos_2018,
  title = {Working {{Memory}} 2.0},
  author = {Miller, Earl K. and Lundqvist, Mikael and Bastos, Andr{\'e} M.},
  year = {2018},
  month = oct,
  volume = {100},
  doi = {10.1016/j.neuron.2018.09.023},
  abstract = {Working memory is the fundamental function by which we break free from reflexive input-output reactions to gain control over our own thoughts. It has two types of mechanisms: online maintenance of information and its volitional or executive control. Classic models proposed persistent spiking for maintenance but have not explicitly addressed executive control. We review recent theoretical and empirical studies that suggest updates and additions to the classic model. Synaptic weight changes between sparse bursts of spiking strengthen working memory maintenance. Executive control acts via interplay between network oscillations in gamma (30\textendash 100 Hz) in superficial cortical layers (layers 2 and 3) and alpha and beta (10\textendash 30 Hz) in deep cortical layers (layers 5 and 6). Deep-layer alpha and beta are associated with top-down information and inhibition. It regulates the flow of bottom-up sensory information associated with superficial layer gamma. We propose that interactions between different rhythms in distinct cortical layers underlie working memory maintenance and its volitional control. Miller et al. present a new model of working memory. Synaptic weight changes between sparse spiking help strengthen working memory maintenance. Interplay between alpha, beta, and gamma rhythms in different cortical layers provide an infrastructure for its volitional control.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JTPM3JPJ\\Miller, Lundqvist, Bastos - 2018 - Working Memory 2.0(2).pdf},
  keywords = {bottom-up,cognition,cortex,oscillations,prefrontal cortex,synchrony,to-read,top-down,working-memory}
}

@article{miller_brody_2017,
  title = {Dorsal Hippocampus Contributes to Model-Based Planning},
  author = {Miller, Kevin J and Botvinick, Matthew M and Brody, Carlos D},
  year = {2017},
  volume = {20},
  pages = {1269--1276},
  issn = {15461726},
  doi = {10.1038/nn.4613},
  abstract = {Planning can be defined as a process of action selection that leverages an internal model of the environment. Such models provide information about the likely outcomes that will follow each selected action, and their use is a key function underlying complex adaptive behavior. However, the neural mechanisms supporting this ability remain poorly understood. In the present work, we adapt for rodents recent advances from work on human planning, presenting for the first time a task for animals which produces many trials of planned behavior per session, allowing the experimental toolkit available for use in trial-by-trial tasks for rodents to be applied to the study of planning. We take advantage of one part of this toolkit to address a perennially controversial issue in planning research: the role of the dorsal hippocampus. Although prospective representations in the hippocampus have been proposed to support model-based planning, intact planning in hippocampally damaged animals has been observed in a number of assays. Combining formal algorithmic behavioral analysis with muscimol inactivation, we provide the first causal evidence directly linking dorsal hippocampus with planning behavior. The results reported, and the methods introduced, open the door to new and more detailed investigations of the neural mechanisms of planning, in the hippocampus and throughout the brain.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IFUYIEE9\\Miller, Botvinick, Brody - 2017 - Dorsal hippocampus contributes to model-based planning.pdf},
  journal = {Nature Neuroscience},
  number = {9},
  pmid = {28758995}
}

@article{miller_buschman_2013,
  title = {Cortical Circuits for the Control of Attention},
  author = {Miller, Earl K and Buschman, Timothy J},
  year = {2013},
  volume = {23},
  pages = {216--222},
  issn = {09594388},
  doi = {10.1016/j.conb.2012.11.011},
  abstract = {How are some thoughts favored over others? A wealth of data at the level of single neurons has yielded candidate brain areas and mechanisms for our best-understood model: visual attention. Recent work has naturally evolved toward efforts at a more integrative, network, understanding. It suggests that focusing attention arises from interactions between widespread cortical and subcortical networks that may be regulated via their rhythmic synchronization. ?? 2012 Elsevier Ltd.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VQS52MVW\\Miller, Buschman - 2013 - Cortical circuits for the control of attention.pdf},
  journal = {Current Opinion in Neurobiology},
  number = {2},
  pmid = {23265963}
}

@article{miller_cohen_2001,
  title = {An {{Integrative Theory}} of {{Prefrontal Cortex Function}}},
  author = {Miller, Earl K and Cohen, Jonathan D},
  year = {2001},
  pages = {167--202},
  issn = {0066-4286},
  doi = {10.1146/annurev.phyto.41.052002.095656},
  abstract = {Abstract The prefrontal cortex has long been suspected to play an important role in cognitive control, in the ability to orchestrate thought and action in accordance with internal goals. Its neural basis, however, has remained a mystery. Here, we propose that cognitive control stems from the active maintenance of patterns of activity in the prefrontal cortex that represent goals and the means to achieve them. They provide bias signals to other brain structures whose net effect is to guide the flow of activity along neural pathways that establish the proper mappings between inputs, internal states, and outputs needed to perform a given task. We review neurophysiological, neurobiological, neuroimaging, and computational studies that support this theory and discuss its implications as well as further issues to be addressed.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FUXV9HY9\\Miller, Cohen - 2001 - An Integrative Theory of Prefrontal Cortex Function.pdf},
  journal = {Annu Rev Neurosci.},
  keywords = {attention,cognition,executive control,frontal lobes,working-memory},
  pmid = {11283309}
}

@article{miller_farne_2019,
  title = {Somatosensory {{Cortex Efficiently Processes Touch Located Beyond}} the {{Body}}},
  author = {Miller, Luke E. and Fabio, C{\'e}cile and Ravenda, Valeria and Bahmad, Salam and Koun, Eric and Salemme, Romeo and Luaut{\'e}, Jacques and Bolognini, Nadia and Hayward, Vincent and Farn{\`e}, Alessandro},
  year = {2019},
  month = dec,
  pages = {S0960982219313831},
  issn = {09609822},
  doi = {10.1016/j.cub.2019.10.043},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CTERCLUA\\Miller et al. - 2019 - Somatosensory Cortex Efficiently Processes Touch L.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\YA98WWL7\\Miller et al. - 2019 - Somatosensory Cortex Efficiently Processes Touch L.pdf},
  journal = {Current Biology},
  language = {en}
}

@article{miller_miller_2007,
  title = {Theory of the Normal Waking {{EEG}}: {{From}} Single Neurones to Waveforms in the Alpha, Beta and Gamma Frequency Ranges},
  author = {Miller, Robert},
  year = {2007},
  volume = {64},
  pages = {18--23},
  issn = {01678760},
  doi = {10.1016/j.ijpsycho.2006.07.009},
  abstract = {The classic alpha rhythm, recorded intracortically, consists of alternating surface-negative troughs and briefer surface-positive peaks. The troughs are associated with neuronal hyperpolarization, the peaks with brief depolarization and burst firing. Each hyperpolarization is mainly a potassium potential, lasting {$\sim$} 100 ms. Depolarization and burst firing arise when this inactivates. In the desynchronized state, membrane potential is poised just below threshold. Firing in vivo is somewhat irregular and non-bursting. It is suggested that EEG bistability (classic alpha vs desynchronization) corresponds to bistability of single pyramidal cells. In vitro, paired pulses lead to depression of synaptic transmission in synapses linking two pyramidal cells, but to facilitation in synapses linking pyramidal cells to inhibitory neurones. These effects should be recruited by burst firing in vivo. Thus, enhancement of inhibitory and excitatory transmission occur respectively during the classic alpha rhythm, and the desynchronized state. As a result both states tend to be self-sustaining. In the desynchronized state high frequency (gamma or beta) activity predominates. In simulations, gamma activity has been modeled as the behaviour of cortical networks where populations of excitatory and inhibitory neurones interact. These simulations assume conduction times between neurones to be negligible. However, this is not true for long-distance interactions. Introduction into the models of plausible conduction delays should slow the oscillation frequency. The activated cortex can then produce not only gamma activity but also beta, and sometimes alpha activity. Thus, alpha frequencies can arise both in the "idling" cortex (classic alpha), and in the activated cortex, although the respective mechanisms are quite different. \{\textcopyright\} 2006 Elsevier B.V. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\92L7ZMR3\\Miller - 2007 - Theory of the normal waking EEG From single neurones to waveforms in the alpha, beta and gamma frequency ranges.pdf},
  journal = {International Journal of Psychophysiology},
  keywords = {alpha,Beta,Down-state,eeg,Gamma,Paired pulse,Up-state},
  number = {1},
  pmid = {16997407}
}

@article{miller_miller_2013,
  title = {The "Working" of Working Memory},
  author = {Miller, Earl K},
  year = {2013},
  volume = {15},
  pages = {411--418},
  issn = {12948322},
  abstract = {This review examines the evidence for a neurobiological explanation of executive functions of working memory. We suggest that executive control stems from information about task rules acquired by mixed selective, adaptive coding, multifunctional neurons in the prefrontal cortex. The output of these neurons dynamically links the cortex-wide networks needed to complete the task. The linking may occur via synchronizing of neural rhythms, which may explain why we have a limited capacity for simultaneous thought.\$\textbackslash backslash\$n\$\textbackslash backslash\$nAbstract available from the publisher.\$\textbackslash backslash\$n\$\textbackslash backslash\$nAbstract available from the publisher.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4I7ZRLMC\\Miller - 2013 - The working of working memory.pdf},
  journal = {Dialogues in Clinical Neuroscience},
  keywords = {Basal ganglia,Cognition,Executive function,Oscillation,Prefrontal cortex,Synchrony,working-memory},
  number = {4},
  pmid = {24459408}
}

@techreport{milstein_romani_2020,
  title = {Bidirectional Synaptic Plasticity Rapidly Modifies Hippocampal Representations Independent of Correlated Activity},
  author = {Milstein, Aaron D. and Li, Yiding and Bittner, Katie C. and Grienberger, Christine and Soltesz, Ivan and Magee, Jeffrey C. and Romani, Sandro},
  year = {2020},
  month = feb,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.02.04.934182},
  abstract = {Abstract                        According to standard models of synaptic plasticity, correlated activity between connected neurons drives changes in synaptic strengths to store associative memories. Here we tested this hypothesis             in vivo             by manipulating the activity of hippocampal place cells and measuring the resulting changes in spatial selectivity. We found that the spatial tuning of place cells was rapidly reshaped via bidirectional synaptic plasticity. To account for the magnitude and direction of plasticity, we evaluated two models \textendash{} a standard model that depended on synchronous pre- and post-synaptic activity, and an alternative model that depended instead on whether active synaptic inputs had previously been potentiated. While both models accounted equally well for the data, they predicted opposite outcomes of a perturbation experiment, which ruled out the standard correlation-dependent model. Finally, network modeling suggested that this form of bidirectional synaptic plasticity enables population activity, rather than pairwise neuronal correlations, to drive plasticity in response to changes in the environment.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PMCVDWY2\\Milstein et al. - 2020 - Bidirectional synaptic plasticity rapidly modifies.pdf},
  language = {en},
  type = {Preprint}
}

@article{miltner_taub_1999,
  title = {Coherence of Gamma-Band {{EEG}} Activity as a Basis for Associative Learning.},
  author = {Miltner, W H and Braun, C and Arnold, M and Witte, H and Taub, E},
  year = {1999},
  volume = {397},
  pages = {434--436},
  issn = {0028-0836},
  doi = {10.1038/17126},
  abstract = {Different regions of the brain must communicate with each other to provide the basis for the integration of sensory information, sensory-motor coordination and many other functions that are critical for learning, memory, information processing, perception and the behaviour of organisms. Hebb suggested that this is accomplished by the formation of assemblies of cells whose synaptic linkages are strengthened whenever the cells are activated or 'ignited' synchronously. Hebb's seminal concept has intrigued investigators since its formulation, but the technology to demonstrate its existence had been lacking until the past decade. Previous studies have shown that very fast electroencephalographic activity in the gamma band (20-70 Hz) increases during, and may be involved in, the formation of percepts and memory, linguistic processing, and other behavioural and perceptual functions. We show here that increased gamma-band activity is also involved in associative learning. In addition, we find that another measure, gamma-band coherence, increases between regions of the brain that receive the two classes of stimuli involved in an associative-learning procedure in humans. An increase in coherence could fulfil the criteria required for the formation of hebbian cell assemblies, binding together parts of the brain that must communicate with one another in order for associative learning to take place. In this way, coherence may be a signature for this and other types of learning.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PI4SVPNI\\Miltner et al. - 1999 - Coherence of gamma-band EEG activity as a basis for associative learning.pdf},
  journal = {Nature},
  number = {6718},
  pmid = {9989409}
}

@article{mingus_mingus_2015,
  title = {An {{Investigation}} of {{Motor Chunking}}},
  author = {Mingus, Brian J},
  year = {2015},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YUW496W4\\Mingus - 2015 - An Investigation of Motor Chunking.pdf}
}

@article{miranda-dominguez_fair_2017,
  title = {Heritability of the Human Connectome: A Connectotyping Study},
  author = {{Miranda-Dom{\'i}nguez}, {\'O}scar and Feczko, Eric and Grayson, David S and Walum, Hasse and Nigg, Joel T and Fair, Damien A},
  year = {2017},
  pages = {1--48},
  issn = {2472-1751},
  doi = {10.1162/NETN_a_00029},
  abstract = {Abstract Scale-free neuronal dynamics and inter-areal correlations are emergent characteristics of spontaneous brain activity. How such dynamics and the anatomical patterns of neuronal connectivity are mutually related in brain networks has, however, remained unclear. We addressed this relationship by quantifying the network co-localization of scale-free neuronal activity\textemdash neuronal avalanches and long-range temporal correlations (LRTCs)\textemdash and functional connectivity (FC) with intra-cranial and non-invasive human resting-state electrophysiological recordings. We first found frequency specific co-localization of scale-free dynamics and FC so that inter-areal coupling of LRTCs and propagation of neuronal avalanches were most pronounced in the predominant pathways of FC. Several lines of control analyses as well as the frequency specificity of network co-localization showed that the results were not trivial side product of brain dynamics or our analysis approach. Crucially, scale-free neuronal dynamics and conne...},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TGJIYPVP\\Miranda-Dominguez et al. - 2017 - Heritability of the human connectome A connectotyping study under a Creative Commons Attribution 4.0 I.pdf},
  journal = {Network Neuroscience},
  keywords = {Development,Effective connectivity,Functional connectivity,Heritability,MRI,Resting-state MRI},
  pmid = {18056803}
}

@article{mirza_parr_2019,
  title = {Introducing a {{Bayesian}} Model of Selective Attention Based on Active Inference},
  author = {Mirza, M. Berk and Adams, Rick A. and Friston, Karl and Parr, Thomas},
  year = {2019},
  month = dec,
  volume = {9},
  pages = {13915},
  issn = {2045-2322},
  doi = {10.1038/s41598-019-50138-8},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KND6L4ER\\Mirza et al. - 2019 - Introducing a Bayesian model of selective attentio.pdf},
  journal = {Scientific Reports},
  language = {en},
  number = {1}
}

@article{mitchell_petzold_2018,
  title = {Control of Neural Systems at Multiple Scales Using Model-Free, Deep Reinforcement Learning},
  author = {Mitchell, B A and Petzold, L R},
  year = {2018},
  volume = {8},
  pages = {10721},
  issn = {20452322},
  doi = {10.1038/s41598-018-29134-x},
  abstract = {Recent improvements in hardware and data collection have lowered the barrier to practical neural control. Most of the current contributions to the field have focus on model-based control, however, models of neural systems are quite complex and difficult to design. To circumvent these issues, we adapt a model-free method from the reinforcement learning literature, Deep Deterministic Policy Gradients (DDPG). Model-free reinforcement learning presents an attractive framework because of the flexibility it offers, allowing the user to avoid modeling system dynamics. We make use of this feature by applying DDPG to models of low-level and high-level neural dynamics. We show that while model-free, DDPG is able to solve more difficult problems than can be solved by current methods. These problems include the induction of global synchrony by entrainment of weakly coupled oscillators and the control of trajectories through a latent phase space of an underactuated network of neurons. While this work has been performed on simulated systems, it suggests that advances in modern reinforcement learning may enable the solution of fundamental problems in neural control and movement towards more complex objectives in real systems. With the advent of deep learning and deep neural networks, reinforcement learning has rapidly advanced beyond methods in classical neuro-dynamic programming by the publication of the Deep Q-Network (DQN) 1. This approach to Q-learning relies on convolutional neural network approximations of both the policy as well as the value (Q) function and was used to allow a computer to better learn to play Atari games. Since its publication, deep Q-learning has been applied to a number of different physical problems. Particularly relevant to neural control is the extension of DQN to problems with continuous state and action spaces by the Deep Deterministic Policy Gradient (DDPG) method 2. At the same time, application of deep reinforcement learning to neural control has not yet been reported and in general, the application of deep reinforcement learning for control of biological systems has not been reported either. There are many reasons for this, but perhaps the most important and serious hurdle involves the difficulty in constructing accurate models of complex biological systems amenable to control. This is not to say that good models don't exist: in fact, a number of approaches have been tried including dynamical systems 3-10 and statistical approaches using a point-process model of past inputs and spikes 11-15. It is certainly possible to incorporate a deep neural network into these existing approaches (e.g. using a deep neural network to fit the rate of the point process, as in 16). From either a dynamical systems or a statistical perspective though, networks of neurons are difficult to model in that the modeling process requires significant interdisciplinary insight. In addition to the non-linearity and stochasticity of these systems, there is the added difficulty of selecting the scale at which to model these systems. Behavior can be strongly influenced by single protein dynamics as well as small and large neural population dynamics and the selection of the scale at which to model these systems can be non-trivial. Moreover, the construction of a model for a single scale is typically useless when trying to model events at other scales. Due to the current complexities and limitations of models of actual neural systems, we have chosen to pursue a control strategy that is model-free (i.e. DDPG). This framework frees us from the need to model the state transition dynamics at all. Such an approach may be useful for fields including translational research whose goal is to generate medical therapies: in these areas, understanding the dynamics of the pathological system is often thought of as a prerequisite for developing a therapy. We argue that our results indicate that this may not always be necessary. These results would also allow researchers to easily adapt our control system to changes in system dynamics. While these advantages are significant, there are additional challenges posed by a model-free strategy 1},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8R8TMUI9\\Mitchell, Petzold - 2018 - Control of neural systems at multiple scales using model-free, deep reinforcement learning.pdf},
  journal = {Scientific Reports},
  number = {1}
}

@article{miyamoto_wise_2017,
  title = {Causal Neural Network of Metamemory for Retrospection in Primates},
  author = {Miyamoto, Kentaro and Osada, Takahiro and Setsuie, Rieko and Takeda, Masaki and Tamura, Keita and Adachi, Yusuke and Miyashita, Yasushi and Squire, L R and Knowlton, B and Musen, G and Petrides, M and Gold, J I and Shadlen, M N and Rushworth, M F and Kolling, N and Sallet, J and Mars, R B and Miyashita, Y and Nelson, T O and Shimamura, A P and Passingham, R and Tomita, H and Ohbayashi, M and Nakahara, K and Hasegawa, I and Vanduffel, W and Zhu, Q and Orban, G A and Hampton, R R and Smith, J D and Shields, W E and Allendoerfer, K R and Washburn, D A and Kepecs, A and Uchida, N and Zariwala, H A and Mainen, Z F and Kiani, R and Fetsch, C R and Newsome, W T and Middlebrooks, P G and Sommer, M A and Miyamoto, K and Osada, T and Adachi, Y and Matsui, T and Kimura, H M and Watanabe, T and Setsuie, R and Zivin, A and Murray, E A and Maniscalco, B and Lau, H and Caspari, N and Janssens, T and Mantini, D and Vandenberghe, R and Kaping, D and Vinck, M and Hutchison, R M and Everling, S and Womelsdorf, T and Noonan, M P and Neubert, F.-X. and Jbabdi, S and O'Reilly, J X and Filippini, N and Thomas, A G and Fleming, S M and Weil, R S and Nagy, Z and Dolan, R J and Rees, G and Ryu, J and Golfinos, J G and Blackmon, K E and Neubert, F X and Hayashi, T and Konishi, S and Koyama, M and Jimura, K and Hirabayashi, T and Takeuchi, D and Tamura, K and Takeda, M and Koyano, K W and Wright, A A and Santiago, H C and Sands, S F and Kendrick, D F and Cook, R G and Kornell, N and Son, L K and Terrace, H S and Guttmannova, K and Wagner, A D and Desmond, J E and Glover, G H and Gabrieli, J D and Baird, B and Smallwood, J and Gorgolewski, K J and Margulies, D S and Burgund, E D and Lugar, H M and Miezin, F M and Petersen, S E and Nichols, T and Brett, M and Andersson, J and Wager, T and Poline, J.-B. and Friston, Karl J. and Buechel, C and Fink, G R and Morris, J and Rolls, E and Chumbley, J R and Worsley, K J and Evans, A C and Marrett, S and Neelin, P and Chau, B K and Papageorgiou, G K and Bell, A H and Walton, M E and Dromme, I C Van and Premereur, E and Verhoef, B.-E. and Janssen, P and Moeller, S and Freiwald, W A and Tsao, D Y and Logothetis, N K and Schlag, J and {Schlag-Rey}, M and Chen, L L and Wise, S P},
  year = {2017},
  volume = {355},
  pages = {453--495},
  issn = {0036-8075},
  doi = {10.1126/science.aal0162},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\984G85NI\\Miyamoto et al. - 2017 - Causal neural network of metamemory for retrospection in primates.pdf},
  journal = {Science},
  number = {6321},
  pmid = {8434894}
}

@article{mizuseki_buzsaki_2011,
  title = {Hippocampal {{CA1}} Pyramidal Cells Form Functionally Distinct Sublayers},
  author = {Mizuseki, Kenji and Diba, Kamran and Pastalkova, Eva and Buzs{\'a}ki, Gy{\"o}rgy},
  year = {2011},
  volume = {14},
  pages = {1174--1181},
  issn = {1097-6256},
  doi = {10.1038/nn.2894},
  abstract = {Hippocampal CA1 pyramidal neurons have frequently been regarded as a homogeneous cell population in biophysical, pharmacological and modeling studies. We found robust differences between pyramidal neurons residing in the deep and superficial CA1 sublayers in rats. Compared with their superficial peers, deep pyramidal cells fired at higher rates, burst more frequently, were more likely to have place fields and were more strongly modulated by slow oscillations of sleep. Both deep and superficial pyramidal cells fired preferentially at the trough of theta oscillations during maze exploration, whereas deep pyramidal cells shifted their preferred phase of firing to the peak of theta during rapid eye movement (REM) sleep. Furthermore, although the majority of REM theta phase-shifting cells fired at the ascending phase of gamma oscillations during waking, nonshifting cells preferred the trough. Thus, CA1 pyramidal cells in adjacent sublayers can address their targets jointly or differentially, depending on brain states.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\J8ATUYB9\\Mizuseki et al. - 2011 - Hippocampal CA1 pyramidal cells form functionally distinct sublayers.pdf},
  journal = {Nature Neuroscience},
  number = {9},
  pmid = {21822270}
}

@article{mnih_hassabis_2015,
  title = {Human-Level Control through Deep Reinforcement Learning},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and a Rusu, Andrei and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  year = {2015},
  volume = {518},
  pages = {529--533},
  issn = {0028-0836},
  doi = {10.1038/nature14236},
  abstract = {The theory of reinforcement learning provides a normative account 1 , deeply rooted in psychological 2 and neuroscientific 3 perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory pro-cessing systems 4,5 , the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopa-minergic neurons and temporal difference reinforcement learning algorithms 3 . While reinforcement learning agents have achieved some successes in a variety of domains 6\textendash 8 , their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks 9\textendash 11 to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games 12},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ASBBWTTY\\Mnih et al. - 2015 - Human-level control through deep reinforcement learning.pdf},
  journal = {Nature},
  number = {7540}
}

@article{mobarhan_einevoll_2018,
  title = {Firing-Rate Based Network Modeling of the {{dLGN}} Circuit: {{Effects}} of Cortical Feedback on Spatiotemporal Response Properties of Relay Cells},
  author = {Mobarhan, Milad Hobbi and Halnes, Geir and {Mart{\'i}nez-Ca{\~n}ada}, Pablo and Hafting, Torkel and Fyhn, Marianne and Einevoll, Gaute T},
  year = {2018},
  volume = {14},
  issn = {15537358},
  doi = {10.1371/journal.pcbi.1006156},
  abstract = {Despite half-a-century of research since the seminal work of Hubel and Wiesel, the role of the dorsal lateral geniculate nucleus (dLGN) in shaping the visual signals is not properly understood. Placed on route from retina to primary visual cortex in the early visual pathway, a striking feature of the dLGN circuit is that both the relay cells (RCs) and interneurons (INs) not only receive feedforward input from retinal ganglion cells, but also a prominent feedback from cells in layer 6 of visual cortex. This feedback has been proposed to affect synchronicity and other temporal properties of the RC firing. It has also been seen to affect spatial properties such as the center-surround antagonism of thalamic receptive fields, i.e., the suppression of the response to very large stimuli compared to smaller, more optimal stimuli. Here we explore the spatial effects of cortical feedback on the RC response by means of a a comprehensive network model with biophysically detailed, single-compartment and multicompartment neuron models of RCs, INs and a population of orientation-selective layer 6 simple cells, consisting of pyramidal cells (PY). We have considered two different arrangements of synaptic feedback from the ON and OFF zones in the visual cortex to the dLGN: phase-reversed (`push-pull') and phase-matched (`push-push'), as well as different spatial extents of the corticothalamic projection pattern. Our simulation results support that a phase-reversed arrangement provides a more effective way for cortical feedback to provide the increased center-surround antagonism seen in experiments both for flashing spots and, even more prominently, for patch gratings. This implies that ON-center RCs receive direct excitation from OFF-dominated cortical cells and indirect inhibitory feedback from ON-dominated cortical cells. The increased center-surround antagonism in the model is accompanied by spatial focusing, i.e., the maximum RC response occurs for smaller stimuli when feedback is present.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6UYI45SF\\Mobarhan et al. - 2018 - Firing-rate based network modeling of the dLGN circuit Effects of cortical feedback on spatiotemporal response.pdf},
  journal = {PLoS Computational Biology},
  number = {5}
}

@article{mohanta_assisi_2019,
  title = {Parallel Scalable Simulations of Biological Neural Networks Using {{TensorFlow}}: {{A}} Beginner's Guide},
  shorttitle = {Parallel Scalable Simulations of Biological Neural Networks Using {{TensorFlow}}},
  author = {Mohanta, Saptarshi Soham and Assisi, Collins},
  year = {2019},
  month = jun,
  abstract = {Neuronal networks are often modeled as systems of coupled, nonlinear, ordinary or partial differential equations. The number of differential equations used to model a network increases with the size of the network and the level of detail used to model individual neurons and synapses. As one scales up the size of the simulation it becomes important to use powerful computing platforms. Many tools exist that solve these equations numerically. However, these tools are often platform specific. There is a high barrier of entry to developing flexible general purpose code that is platform independent and supports hardware acceleration on modern computing architectures such as GPUs/TPUs and Distributed Platforms. TensorFlow is a Python-based open-source package initially designed for machine learning algorithms, but it presents a scalable environment for a variety of computations including solving differential equations using iterative algorithms such as Runge Kutta methods. In this article, organized as a series of tutorials, we present a simple exposition of numerical methods to solve ordinary differential equations using Python and TensorFlow. It consists of a series of Python notebooks that, over the course of five sessions, will lead novice programmers from writing programs to integrate simple 1-dimensional differential equations using Python, to solving a large system (1000's of differential equations) of conductance-based neurons using a highly parallel and scalable framework. Embedded within the tutorial is a physiologically realistic implementation of a network in the insect olfactory system. This system, consisting of multiple neuron and synapse types, can serve as a template to simulate other networks.},
  archivePrefix = {arXiv},
  eprint = {1906.03958},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2EWDU9XC\\mohanta_assisi_2019_parallel_scalable_simulations_of_biological_neural_networks_using_tensorflow.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\INC9M8UW\\1906.html},
  journal = {arXiv:1906.03958 [q-bio]},
  primaryClass = {q-bio}
}

@article{molinaro_job_2008,
  title = {Anaphoric Agreement Violation: {{An ERP}} Analysis of Its Interpretation},
  author = {Molinaro, Nicola and Kim, Albert and Vespignani, Francesco and Job, Remo},
  year = {2008},
  volume = {106},
  pages = {963--974},
  issn = {00100277},
  doi = {10.1016/j.cognition.2007.03.006},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8XYIF55L\\Molinaro et al. - 2008 - Anaphoric agreement violation An ERP analysis of its interpretation.pdf},
  journal = {Cognition},
  number = {2}
}

@article{mollick_mollick_2013,
  title = {Exploring the {{Brain Mechanisms Involved}} in {{Reward Prediction Errors Using Conditioned Inhibition}}},
  author = {Mollick, Jessica},
  year = {2013},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PJNSJ2K6\\Mollick - 2013 - Exploring the Brain Mechanisms Involved in Reward Prediction Errors Using Conditioned Inhibition.pdf}
}

@article{momennejad_gershman_2017,
  title = {The Successor Representation in Human Reinforcement Learning},
  author = {Momennejad, I. and Russek, E. M. and Cheong, J. H. and Botvinick, M. M. and Daw, N. D. and Gershman, S. J.},
  year = {2017},
  volume = {1},
  pages = {680--692},
  issn = {23973374},
  doi = {10.1038/s41562-017-0180-8},
  abstract = {Theories of reinforcement learning in neuroscience have focused on two families of algorithms. Model-free algorithms cache action values, making them cheap but inflexible: a candidate mechanism for adaptive and maladaptive habits. Model-based algorithms achieve flexibility at computational expense, by rebuilding values from a model of the environment. We examine an intermediate class of algorithms, the successor representation (SR), which caches long-run state expectancies, blending model-free efficiency with model-based flexibility. Although previous reward revaluation studies distinguish model-free from model-based learning algorithms, such designs cannot discriminate between model-based and SR-based algorithms, both of which predict sensitivity to reward revaluation. However, changing the transition structure (" transition revaluation ") should selectively impair revaluation for the SR. In two studies we provide evidence that humans are differentially sensitive to reward vs. transition revaluation, consistent with SR predictions. These results support a new neuro-computational mechanism for flexible choice, while introducing a subtler, more cognitive notion of habit.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QSCEGFLP\\Momennejad I et al. - Unknown - The successor representation in human reinforcement learning(2).pdf},
  journal = {Nature Human Behaviour},
  keywords = {Decision making,Human behavior,Model-based,Planning,Predictive representation,Reinforcement learning,Retrospective revaluation,Successor representation},
  number = {9}
}

@article{monaco_zhang_2019,
  title = {Spatial Synchronization Codes from Coupled Rate-Phase Neurons},
  author = {Monaco, Joseph D. and De Guzman, Rose M. and Blair, Hugh T. and Zhang, Kechen},
  editor = {Bush, Daniel},
  year = {2019},
  month = jan,
  volume = {15},
  pages = {e1006741},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1006741},
  abstract = {During spatial navigation, the frequency and timing of spikes from spatial neurons including place cells in hippocampus and grid cells in medial entorhinal cortex are temporally organized by continuous theta oscillations (6\textendash 11 Hz). The theta rhythm is regulated by subcortical structures including the medial septum, but it is unclear how spatial information from place cells may reciprocally organize subcortical theta-rhythmic activity. Here we recorded single-unit spiking from a constellation of subcortical and hippocampal sites to study spatial modulation of rhythmic spike timing in rats freely exploring an open environment. Our analysis revealed a novel class of neurons that we termed `phaser cells,' characterized by a symmetric coupling between firing rate and spike theta-phase. Phaser cells encoded space by assigning distinct phases to allocentric isocontour levels of each cell's spatial firing pattern. In our dataset, phaser cells were predominantly located in the lateral septum, but also the hippocampus, anteroventral thalamus, lateral hypothalamus, and nucleus accumbens. Unlike the unidirectional late-to-early phase precession of place cells, bidirectional phase modulation acted to return phaser cells to the same theta-phase along a given spatial isocontour, including cells that characteristically shifted to later phases at higher firing rates. Our dynamical models of intrinsic theta-bursting neurons demonstrated that experienceindependent temporal coding mechanisms can qualitatively explain (1) the spatial ratephase relationships of phaser cells and (2) the observed temporal segregation of phaser cells according to phase-shift direction. In open-field phaser cell simulations, competitive learning embedded phase-code entrainment maps into the weights of downstream targets, including path integration networks. Bayesian phase decoding revealed error correction capable of resetting path integration at subsecond timescales. Our findings suggest that phaser cells may instantiate a subcortical theta-rhythmic loop of spatial feedback. We outline a framework in which location-dependent synchrony reconciles internal idiothetic processes with the allothetic reference points of sensory experience.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3RK5XDSU\\Monaco et al. - 2019 - Spatial synchronization codes from coupled rate-ph.pdf},
  journal = {PLOS Computational Biology},
  language = {en},
  number = {1}
}

@article{monaghan_hasselmo_2017,
  title = {Systemic Administration of Two Different Anxiolytic Drugs Decreases Local Field Potential Theta Frequency in the Medial Entorhinal Cortex without Affecting Grid Cell Firing Fields},
  author = {Monaghan, Caitlin K. and Chapman, G William and Hasselmo, Michael E},
  year = {2017},
  volume = {364},
  pages = {60--70},
  issn = {18737544},
  doi = {10.1016/j.neuroscience.2017.08.056},
  abstract = {Neurons coding spatial location (grid cells) are found in medial entorhinal cortex (MEC) and demonstrate increasing size of firing fields and spacing between fields (grid scale) along the dorsoventral axis. This change in grid scale correlates with differences in theta frequency, a 6\textendash 10 Hz rhythm in the local field potential (LFP) and rhythmic firing of cells. A relationship between theta frequency and grid scale can be found when examining grid cells recorded in different locations along the dorsoventral axis of MEC. When describing the relationship between theta frequency and grid scale, it is important to account for the strong positive correlation between theta frequency and running speed. Plotting LFP theta frequency across running speeds dissociates two components of this relationship: slope and intercept of the linear fit. Change in theta frequency through a change in the slope component has been modeled and shown experimentally to affect grid scale, but the prediction that change in the intercept component would not affect grid scale has not been tested experimentally. This prediction about the relationship of intercept to grid scale is the primary hypothesis tested in the experiments presented here. All known anxiolytic drugs decrease hippocampal theta frequency despite their differing mechanisms of action. Specifically, anxiolytics decrease the intercept of the theta frequency-running speed relationship in the hippocampus. Here we demonstrate that anxiolytics decrease the intercept of the theta frequency-running speed relationship in the MEC, similar to hippocampus, and the decrease in frequency through this change in intercept does not affect grid scale.},
  copyright = {All rights reserved},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5TKI6BKL\\Monaghan, Chapman, Hasselmo - 2017 - Systemic administration of two different anxiolytic drugs decreases local field potential theta fre.pdf},
  journal = {Neuroscience},
  keywords = {diazepam,grid cells,navigation,theta}
}

@phdthesis{monaghan_monaghan_2015,
  title = {Effects of {{Pharmacological Manipulations}} on {{Activity}} in the {{Medial Entorhinal Cortex}}},
  author = {Monaghan, Caitlin K},
  year = {2015},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\J342A9IZ\\Monaghan - 2015 - Effects of Pharmacological Manipulations on Activity in the Medial Entorhinal Cortex.pdf},
  school = {Boston University},
  type = {Doctor of {{Philosophy}}}
}

@article{monosov_hikosaka_2013,
  title = {Selective and Graded Coding of Reward Uncertainty by Neurons in the Primate Anterodorsal Septal Region.},
  author = {Monosov, Ilya E and Hikosaka, Okihide},
  year = {2013},
  month = jun,
  volume = {16},
  pages = {756--762},
  issn = {1546-1726},
  doi = {10.1038/nn.3398},
  abstract = {Natural environments are uncertain. Uncertainty of emotional outcomes can induce anxiety and raise vigilance, promote and signal the opportunity for learning, modulate economic choice and regulate risk-seeking. Here we demonstrate that a subset of neurons in the anterodorsal region of the primate septum (ADS) are primarily devoted to processing uncertainty in a highly specific manner. Those neurons were selectively activated by visual cues indicating probabilistic delivery of reward (for example, 25\{\%\}, 50\{\%\} and 75\{\%\} reward) and did not respond to cues indicating certain outcomes (0\{\%\} and 100\{\%\} reward). The average ADS uncertainty response was graded with the magnitude of reward uncertainty and selectively signaled uncertainty about rewards rather than punishments. The selective and graded information about reward uncertainty encoded by many neurons in the ADS may underlie modulation of uncertainty of value- and sensorimotor-related areas to regulate goal-directed behavior.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CMKQUS94\\Monosov, Hikosaka - 2013 - Selective and graded coding of reward uncertainty by neurons in the primate anterodorsal septal region.pdf},
  journal = {Nature neuroscience},
  keywords = {Animal,Animal: physiology,Animals,Behavior,Classical,Classical: physiology,Conditioning,Cues,Macaca mulatta,Male,Neurons,Neurons: physiology,Neuropsychological Tests,Punishment,Punishment: psychology,Reward,Septum of Brain,Septum of Brain: cytology,Septum of Brain: physiology,Uncertainty},
  number = {6},
  pmid = {23666181}
}

@article{monsalve-mercado_leibold_2017,
  title = {Hippocampal {{Spike}}-{{Timing Correlations Lead}} to {{Hexagonal Grid Fields}}},
  author = {{Monsalve-mercado}, Mauro M and Leibold, Christian},
  year = {2017},
  pages = {1--4},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4HW765MA\\Monsalve-Mercado and Leibold - 2017 - Hippocampal Spike-Timing Correlations Lead to Hexa.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\STFCIAMS\\Monsalve-mercado, Leibold - 2017 - Hippocampal Spike-Timing Correlations Lead to Hexagonal Grid Fields.pdf},
  number = {1}
}

@article{monsalve-mercado_roudi_2019,
  title = {Hippocampal Spike-time Correlations and Place Field Overlaps during Open Field Foraging},
  author = {Monsalve-Mercado, Mauro M. and Roudi, Yasser},
  year = {2019},
  month = nov,
  pages = {hipo.23173},
  issn = {1050-9631, 1098-1063},
  doi = {10.1002/hipo.23173},
  abstract = {Phase precessing place cells encode spatial information on fine timescales via the timing of their spikes. This phase code has been extensively studied on linear tracks and for short runs in the open field. However, less is known about the phase code on unconstrained trajectories lasting tens of minutes, typical of open field foraging. In previous work (Monsalve-Mercado and Leibold, Physical Review Letters, 119, 38101 (2017)), an analytic expression was derived for the spike-time cross-correlation between phase precessing place cells during natural foraging in the open field. This expression makes two predictions on how this phase code differs from the linear track case: cross-correlations are symmetric with respect to time, and they represent the distance between pairs of place fields in that the theta-filtered cross-correlations around zero time lag are positive for cells with nearby fields while they are negative for those with fields further apart. Here we analyze several available open field recordings and show that these predictions hold for pairs of CA1 place cells. We also show that the relationship remains during remapping in CA1, and it is also present in place cells in area CA3. For CA1 place cells of Fmr1-null mice, which exhibit normal place fields but somewhat weaker temporal coordination with respect to theta compared to wild type, the cross-correlations still remain symmetric but the relationship to place field overlap is largely lost. The relationship discussed here describes how spatial information is communicated by place cells to downstream areas in a finer theta-timescale, relevant for learning and memory formation in behavioral tasks lasting tens of minutes in the open field.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SWT8EYLJ\\Monsalve‐Mercado and Roudi - 2019 - Hippocampal spike‐time correlations and place fiel.pdf},
  journal = {Hippocampus},
  language = {en}
}

@article{montefusco-siegmund_devia_2013,
  title = {Effects of Ocular Artifact Removal through {{ICA}} Decomposition on {{EEG}} Phase},
  author = {{Montefusco-Siegmund}, Rodrigo and Maldonado, Pedro E and Devia, Christ},
  year = {2013},
  pages = {1374--1377},
  issn = {19483546},
  doi = {10.1109/NER.2013.6696198},
  abstract = {Neurophysiological data are widely affected by different forms of signal artifacts. In electroencephalographic recordings from the scalp, eye blinks are a main contribution as a source of signal alteration. Different approaches have been used to improve on this problem, from the rejection of part of the signal, to corrections through linear decomposition methods. A widely used technique is independent component analysis (ICA). Different studies have shown the suitability of ICA to correct a variety of artifact sources, but to our knowledge, there is no evidence of the effect of ICA in the phase of a signal, over time. This is of importance because the phase is a critical component of the physiological signals that has been implicated in several neural mechanisms. The aim of this work is to assess the level of phase distortion that ICA can potentially introduce to real and simulated data.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XERTLS6J\\Montefusco-Siegmund, Maldonado, Devia - 2013 - Effects of ocular artifact removal through ICA decomposition on EEG phase.pdf},
  journal = {International IEEE/EMBS Conference on Neural Engineering, NER},
  keywords = {Cognitive Engineering and Science}
}

@article{moran_friston_2013,
  title = {Neural Masses and Fields in Dynamic Causal Modeling.},
  author = {Moran, Rosalyn and a Pinotsis, Dimitris and Friston, Karl J.},
  year = {2013},
  month = jan,
  volume = {7},
  pages = {57},
  issn = {1662-5188},
  doi = {10.3389/fncom.2013.00057},
  abstract = {Dynamic causal modeling (DCM) provides a framework for the analysis of effective connectivity among neuronal subpopulations that subtend invasive (electrocorticograms and local field potentials) and non-invasive (electroencephalography and magnetoencephalography) electrophysiological responses. This paper reviews the suite of neuronal population models including neural masses, fields and conductance-based models that are used in DCM. These models are expressed in terms of sets of differential equations that allow one to model the synaptic underpinnings of connectivity. We describe early developments using neural mass models, where convolution-based dynamics are used to generate responses in laminar-specific populations of excitatory and inhibitory cells. We show that these models, though resting on only two simple transforms, can recapitulate the characteristics of both evoked and spectral responses observed empirically. Using an identical neuronal architecture, we show that a set of conductance based models-that consider the dynamics of specific ion-channels-present a richer space of responses; owing to non-linear interactions between conductances and membrane potentials. We propose that conductance-based models may be more appropriate when spectra present with multiple resonances. Finally, we outline a third class of models, where each neuronal subpopulation is treated as a field; in other words, as a manifold on the cortical surface. By explicitly accounting for the spatial propagation of cortical activity through partial differential equations (PDEs), we show that the topology of connectivity-through local lateral interactions among cortical layers-may be inferred, even in the absence of spatially resolved data. We also show that these models allow for a detailed analysis of structure-function relationships in the cortex. Our review highlights the relationship among these models and how the hypothesis asked of empirical data suggests an appropriate model class.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\I3I995A8\\Moran, Pinotsis, Friston - 2013 - Neural masses and fields in dynamic causal modeling.pdf},
  journal = {Frontiers in computational neuroscience},
  keywords = {dynamic causal modeling,eeg,experimental:fMRI,lfp,local field,m,magnetoencephalography,meg,neural mass models,potential,som},
  number = {May},
  pmid = {23755005}
}

@article{morrison_gerstner_2008,
  title = {Phenomenological Models of Synaptic Plasticity Based on Spike Timing},
  author = {Morrison, Abigail and Diesmann, Markus and Gerstner, Wulfram},
  year = {2008},
  volume = {98},
  pages = {459--478},
  issn = {03401200},
  doi = {10.1007/s00422-008-0233-1},
  abstract = {Synaptic plasticity is considered to be the bio-logical substrate of learning and memory. In this document we review phenomenological models of short-term and long-term synaptic plasticity, in particular spike-timing dependent plasticity (STDP). The aim of the document is to provide a framework for classifying and evaluating different models of plasticity. We focus on phenomenological synaptic models that are compatible with integrate-and-fire type neuron models where each neuron is described by a small number of variables. This implies that synaptic update rules for short-term or long-term plasticity can only depend on spike timing and, potentially, on membrane potential, as well as on the value of the synaptic weight, or on low-pass filtered (tempo-rally averaged) versions of the above variables. We examine the ability of the models to account for experimental data and to fulfill expectations derived from theoretical considera-tions. We further discuss their relations to teacher-based rules (supervised learning) and reward-based rules (reinforcement learning). All models discussed in this paper are suitable for large-scale network simulations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5I83LYB4\\Morrison, Diesmann, Gerstner - 2008 - Phenomenological models of synaptic plasticity based on spike timing.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\MGI4HJHT\\Morrison, Diesmann, Gerstner - 2008 - Phenomenological models of synaptic plasticity based on spike timing.pdf},
  journal = {Biological Cybernetics},
  keywords = {Animals,Learning,Modeling,Models,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Short term plasticity,Simulation,Spike-timing dependent plasticity,Synapses,Synapses: physiology,Time Factors},
  number = {6},
  pmid = {18491160}
}

@article{moscovitch_nadel_2016,
  title = {Episodic Memory and beyond: {{The}} Hippocampus and Neocortex in Transformation},
  author = {Moscovitch, M and Cabeza, R and Winocur, G and Nadel, L},
  year = {2016},
  volume = {67},
  pages = {105--134},
  issn = {0066-4308},
  doi = {10.1146/annurev-psych-113011-143733},
  abstract = {The last decade has seen dramatic technological and conceptual changes in research on episodic memory and the brain. New technologies, and in- creased use of more naturalistic observations, have enabled investigators to delve deeply into the structures that mediate episodic memory, particularly the hippocampus, and to track functional and structural interactions among brain regions that support it. Conceptually, episodic memory is increasingly being viewed as subject to lifelong transformations that are reflected in the neural substrates that mediate it. In keeping with this dynamic perspective, research on episodicmemory(and the hippocampus) has infiltrated domains, from perception to language and from empathy to problem solving, that were once considered outside its boundaries. Using the component process model as a framework, and focusing on the hippocampus, its subfields, and special- ization along its longitudinal axis, along with its interaction with other brain regions, we consider these new developments and their implications for the organization of episodic memory and its contribution to functions in other domains.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4LIFWUIY\\Moscovitch et al. - 2016 - Episodic memory and beyond The hippocampus and neocortex in transformation(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\5VPTMYS9\\Moscovitch et al. - 2016 - Episodic memory and beyond The hippocampus and neocortex in transformation.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\8L6669PV\\Moscovitch et al. - 2016 - Episodic memory and beyond The hippocampus and neocortex in transformation.pdf},
  journal = {Annual Review of Psychology},
  keywords = {episodic memory,frontal cortex,hippocampus,parietal cortex,schema},
  number = {1},
  pmid = {26726963}
}

@article{moser_moser_2014,
  title = {Grid Cells and Cortical Representation.},
  author = {Moser, Edvard I and Roudi, Yasser and Witter, Menno P and Kentros, Clifford and Bonhoeffer, Tobias and Moser, May-Britt},
  year = {2014},
  volume = {15},
  pages = {466--481},
  issn = {1471-0048},
  doi = {10.1038/nrn3766},
  abstract = {One of the grand challenges in neuroscience is to comprehend neural computation in the association cortices, the parts of the cortex that have shown the largest expansion and differentiation during mammalian evolution and that are thought to contribute profoundly to the emergence of advanced cognition in humans. In this Review, we use grid cells in the medial entorhinal cortex as a gateway to understand network computation at a stage of cortical processing in which firing patterns are shaped not primarily by incoming sensory signals but to a large extent by the intrinsic properties of the local circuit.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DE47M35T\\Moser et al. - 2014 - Grid cells and cortical representation.pdf},
  journal = {Nature reviews. Neuroscience},
  keywords = {Animals,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: physiology,Computational Biology,Computational Biology: methods,Computational Biology: trends,Entorhinal Cortex,Entorhinal Cortex: cytology,Entorhinal Cortex: physiology,Humans,Nerve Net,Nerve Net: cytology,Nerve Net: physiology},
  number = {7},
  pmid = {24917300}
}

@article{moser_roudi_2013,
  title = {Network Mechanisms of Grid Cells},
  author = {Moser, E I and Moser, M.-B. and Roudi, Yasser},
  year = {2013},
  volume = {369},
  pages = {20120511},
  issn = {0962-8436},
  doi = {10.1098/rstb.2012.0511},
  abstract = {One of the major breakthroughs in neuroscience is the emerging understanding of how signals from the external environment are extracted and represented in the primary sensory cortices of the mammalian brain. The operational principles of the rest of the cortex, however, have essentially remained in the dark. The discovery of grid cells, and their functional organization, opens the door to some of the first insights into the workings of the association cortices, at a stage of neural processing where firing properties are shaped not primarily by the nature of incoming sensory signals but rather by internal self-organizing principles. Grid cells are place-modulated neurons whose firing locations define a periodic triangular array overlaid on the entire space available to a moving animal. The unclouded firing pattern of these cells is rare within the association cortices. In this paper, we shall review recent advances in our understanding of the mechanisms of grid-cell formation which suggest that the pattern originates by competitive network interactions, and we shall relate these ideas to new insights regarding the organization of grid cells into functionally segregated modules.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TKIHIFU2\\Moser, Moser, Roudi - 2013 - Network mechanisms of grid cells.pdf},
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  number = {1635},
  pmid = {24366126}
}

@article{most_astur_2007,
  title = {Feature-Based Attentional Set as a Cause of Traffic Accidents},
  author = {Most, Steven B and Astur, Robert S},
  year = {2007},
  volume = {15},
  pages = {125--132},
  issn = {1350-6285},
  doi = {10.1080/13506280600959316},
  abstract = {Voluntary and relatively involuntary subsystems of attention often compete. On one hand, people can intentionally ``tune'' attention for features that then receive visual priority; on the other hand, more reflexive attentional shifts can ``short-circuit'' top-down control in the face of urgent, behaviourally relevant stimuli. Thus, it is questionable whether voluntary attentional tuning (i.e., attentional set) can affect one's ability to respond to unexpected, urgent information in the real world. We show that the consequences of such tuning extend to a realistic, safety-relevant scenario. Participants drove in a first-person driving simulation where they searched at every intersection for either a yellow or blue arrow indicating which way to turn. At a critical intersection, a yellow or blue motorcycle*either matching or not matching drivers' attentional set*suddenly veered into drivers' paths and stopped in their way. Collision rates with the motorcycle were substantially greater when the motorcycle did not match drivers' attentional sets.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JJM3LIHG\\Most, Astur - 2007 - Feature-based attentional set as a cause of traffic accidents.pdf},
  journal = {Visual Cognition},
  number = {2}
}

@article{most_simons_2005,
  title = {What You See Is What You Set: Sustained Inattentional Blindness and the Capture of Awareness.},
  author = {Most, Steven B and Scholl, Brian J and Clifford, Erin R and Simons, Daniel J},
  year = {2005},
  volume = {112},
  pages = {217--42},
  issn = {0033-295X},
  doi = {10.1037/0033-295X.112.1.217},
  abstract = {This article reports a theoretical and experimental attempt to relate and contrast 2 traditionally separate research programs: inattentional blindness and attention capture. Inattentional blindness refers to failures to notice unexpected objects and events when attention is otherwise engaged. Attention capture research has traditionally used implicit indices (e.g., response times) to investigate automatic shifts of attention. Because attention capture usually measures performance whereas inattentional blindness measures awareness, the 2 fields have existed side by side with no shared theoretical framework. Here, the authors propose a theoretical unification, adapting several important effects from the attention capture literature to the context of sustained inattentional blindness. Although some stimulus properties can influence noticing of unexpected objects, the most influential factor affecting noticing is a person's own attentional goals. The authors conclude that many\textendash but not all\textendash aspects of attention capture apply to inattentional blindness but that these 2 classes of phenomena remain importantly distinct.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LQWCQBDW\\Most et al. - 2005 - What you see is what you set sustained inattentional blindness and the capture of awareness.pdf},
  journal = {Psychological review},
  keywords = {Attention,Awareness,Cues,Female,Humans,Male,Psychological Theory},
  number = {1},
  pmid = {15631594}
}

@article{muddapu_ramaswamy_2018,
  title = {A Computational Model of Loss of Dopaminergic Cells in {{Parkinson}}'s Disease Due to Glutamate-Induced Excitotoxicity},
  author = {Muddapu, Vignayanandam Ravindernath and Mandali, Alekhya and Chakravarthy, Srinivasa Vaddadi and Ramaswamy, Srikanth},
  year = {2018},
  month = aug,
  doi = {10.1101/385138},
  abstract = {Parkinson's disease (PD) is a neurodegenerative disease associated with progressive and inexorable loss of dopaminergic cells in Substantia Nigra pars compacta (SNc). A full understanding of the underlying pathogenesis of this cell loss is unavailable, though a number of mechanisms have been indicated in the literature. A couple of these mechanisms, however, show potential for the development of radical and promising PD therapeutics. One of these mechanisms is the peculiar metabolic vulnerability of SNc cells by virtue of their excessive energy demands; the other is the excitotoxicity caused by excessive glutamate release onto SNc by an overactive Subthalamic Nucleus (STN). To investigate the latter hypothesis computationally, we developed a spiking neuron network model of the SNc-STN-GPe system. In the model, prolonged stimulation of SNc cells by an overactive STN leads to an increase in a `stress' variable; when the stress in a SNc neuron exceeds a stress threshold the neuron dies. The model shows that the interaction between SNc and STN involves a positive feedback due to which, an initial loss of SNc cells that crosses a threshold causes a runaway effect that leads to an inexorable loss of SNc cells, strongly resembling the process of neurodegeneration. The model further suggests a link between the two aforementioned PD mechanisms: metabolic vulnerability and glutamate excitotoxicity. Our simulation results show that the excitotoxic cause of SNc cell loss in PD might be initiated by weak excitotoxicity mediated by energy deficit, followed by strong excitotoxicity, mediated by a disinhibited STN. A variety of conventional therapies are simulated in the model to test their efficacy in slowing down or arresting SNc cell loss. Among the current therapeutics, glutamate inhibition, dopamine restoration, subthalamotomy and deep brain stimulation showed superior neuroprotective effects in the proposed model.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8KYKC72U\\Muddapu et al. - 2018 - A computational model of loss of dopaminergic cell.pdf},
  journal = {bioRxiv},
  language = {en}
}

@article{mueller_oppenheimer_2014,
  title = {The {{Pen Is Mightier Than}} the {{Keyboard}}: {{Advantages}} of {{Longhand Over Laptop Note Taking}}},
  author = {Mueller, Pam A and Oppenheimer, Daniel M},
  year = {2014},
  month = jun,
  volume = {25},
  pages = {1159--1168},
  issn = {0956-7976},
  doi = {10.1177/0956797614524581},
  abstract = {Taking notes on laptops rather than in longhand is increasingly common. Many researchers have suggested that laptop note taking is less effective than longhand note taking for learning. Prior studies have primarily focused on students' capacity for multitasking and distraction when using laptops. The present research suggests that even when laptops are used solely to take notes, they may still be impairing learning because their use results in shallower processing. In three studies, we found that students who took notes on laptops performed worse on conceptual questions than students who took notes longhand. We show that whereas taking more notes can be beneficial, laptop note takers' tendency to transcribe lectures verbatim rather than processing information and reframing it in their own words is detrimental to learning},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RCTBPGV4\\Mueller, Oppenheimer - 2014 - The Pen Is Mightier Than the Keyboard Advantages of Longhand Over Laptop Note Taking.pdf},
  journal = {Psychological Science},
  number = {6}
}

@article{munakata_oreilly_2011,
  title = {A Unified Framework for Inhibitory Control},
  author = {Munakata, Yuko and a. Herd, Seth and Chatham, Christopher H. and Depue, Brendan E. and Banich, Marie T. and O'Reilly, Randall C},
  year = {2011},
  volume = {15},
  pages = {453--459},
  issn = {13646613},
  doi = {10.1016/j.tics.2011.07.011},
  abstract = {Inhibiting unwanted thoughts, actions and emotions figures centrally in daily life, and the prefrontal cortex (PFC) is widely viewed as a source of this inhibitory control. We argue that the function of the PFC is best understood in terms of representing and actively maintaining abstract information, such as goals, which produces two types of inhibitory effects on other brain regions. Inhibition of some subcortical regions takes a directed global form, with prefrontal regions providing contextual information relevant to when to inhibit all processing in a region. Inhibition within neocortical (and some subcortical) regions takes an indirect competitive form, with prefrontal regions providing excitation of goal-relevant options. These distinctions are crucial for understanding the mechanisms of inhibition and how they can be impaired or improved. \textcopyright{} 2011 Elsevier Ltd.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\A3BB27AE\\Munakata et al. - 2011 - A unified framework for inhibitory control.pdf},
  journal = {Trends in Cognitive Sciences},
  number = {10},
  pmid = {21889391}
}

@article{murphy_medin_1985,
  title = {The Role of Theories in Conceptual Coherence.},
  author = {Murphy, Gregory L. and Medin, Douglas L.},
  year = {1985},
  volume = {92},
  pages = {289--316},
  issn = {1939-1471},
  doi = {10.1037/0033-295X.92.3.289},
  abstract = {In order to answer the question of what makes a concept coherent (what makes its members form a comprehensible class), accounts based on similarity, features correlations, and various theories of categorization are reviewed. In general, the similarity-based approach is seen to require a minimum of conceptual organization and relations, whereas the theory-based approach emphasizes both. It is concluded that each theory provides an inadequate account of conceptual coherence (or no account at all), because none provides enough constraints on possible concepts. The authors propose that concepts are coherent to the extent that they fit people's background knowledge or naive theories about the world. These theories help to relate the concepts in a domain and to structure the attributes that are internal to a concept. Evidence of the influence of theories on various conceptual tasks is presented, and the possible importance of theories in cognitive development is discussed. (109 ref) (PsycINFO Database Record (c) 2008 APA, all rights reserved)},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\76LTQG6C\\Murphy, Medin - 1985 - The role of theories in conceptual coherence.pdf},
  journal = {Psychological Review},
  number = {3},
  pmid = {4023146}
}

@article{murray_murray_2019,
  title = {Local Online Learning in Recurrent Networks with Random Feedback},
  author = {Murray, James M},
  year = {2019},
  pages = {25},
  abstract = {Recurrent neural networks (RNNs) enable the production and processing of timedependent signals such as those involved in movement or working memory. Classic gradient-based algorithms for training RNNs have been available for decades, but are inconsistent with biological features of the brain, such as causality and locality. We derive an approximation to gradient-based learning that comports with these constraints by requiring synaptic weight updates to depend only on local information about pre- and postsynaptic activities, in addition to a random feedback projection of the RNN output error. In addition to providing mathematical arguments for the effectiveness of the new learning rule, we show through simulations that it can be used to train an RNN to perform a variety of tasks. Finally, to overcome the difficulty of training over very large numbers of timesteps, we propose an augmented circuit architecture that allows the RNN to concatenate short-duration patterns into longer sequences},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YSNAUSBV\\Murray - Local online learning in recurrent networks with r.pdf},
  journal = {ELife},
  language = {en}
}

@article{murray_wang_2014,
  title = {A Hierarchy of Intrinsic Timescales across Primate Cortex},
  author = {Murray, John D and Bernacchia, Alberto and Freedman, David J and Romo, Ranulfo and Wallis, Jonathan D and Cai, Xinying and {Padoa-Schioppa}, Camillo and Pasternak, Tatiana and Seo, Hyojung and Lee, Daeyeol and Wang, Xiao-Jing},
  year = {2014},
  volume = {17},
  doi = {10.1038/nn.3862},
  abstract = {1 6 6 1 B r i e f c o m m u n i c at i o n s Hierarchy provides a parsimonious description of various functional differences across cortical areas. For instance, the sizes of spatial receptive fields increase along the visual hierarchy 1 , and a posterior-anterior hierarchy exists for cognitive abstraction within prefrontal cortex 2 . In the temporal domain, higher cortical areas can activate selectively for stimuli that are coherent over longer periods of time 3,4 . It remains an open question whether temporal specialization arises from a cortical area's intrinsic dynamical properties, that is, related to dynamics that exist even in the absence of direct stimulus processing. We hypothesized that differential dynamics would be manifested in the timescales of fluctuations in single-neuron spiking activity. Variable neuronal activity is ubiquitous across the cortex 5,6 , yet it has been unclear what the timescales underlying this variability are or whether they differ across areas. Neuronal activity fluctuates over a wide range of timescales, with potential contributions from distinct underlying mechanisms. For example, the timescales of correlated fluctuations of activity within a local microcircuit are likely longer than those of single-neuron burstiness and refractoriness 7 but shorter than those of drifts in arousal. In typical electrophysiological record-ings from behaving animals, spike trains from a single neuron are recorded over many trials of a task. Using single-neuron spike trains, we sought to characterize underlying fluctuations in activity that are not locked to trial onset. To measure the timescales of these fluctua-tions, we used the spike-count autocorrelation for pairs of time bins separated by a time lag. The spike-count autocorrelation is calculated as the correlation coefficient between the number of spikes in each time bin across all trials (Online Methods). As the time lag increases, the autocorrelation decays according to the fluctuation timescales 8 (Supplementary Note). We measured intrinsic timescales using single-neuron spike trains in data sets from 6 research groups, recorded in a total of 26 monkeys, that include 7 cortical areas (Fig. 1a). Five cortical areas are constit-uents of the visual-prefrontal hierarchy, including sensory, parietal association and prefrontal cortex: medial-temporal (MT) area in visual cortex, lateral intraparietal (LIP) area in parietal association cortex, lateral prefrontal cortex (LPFC), orbitofrontal cortex (OFC) and ante-rior cingulate cortex (ACC). To test for generality of results outside the visual system, we also examined two somatosensory areas: primary somatosensory cortex (S1) and secondary somatosensory cortex (S2). These areas span multiple levels of the anatomical hierarchy defined by the laminar patterns of long-range projections among cortical areas 9,10 (Fig. 1b). For each data set, monkeys were engaged in cognitive tasks. We restricted our analysis to one epoch of the task, the foreperiod that begins each trial. During the foreperiod, the monkey was in a control-led, attentive state awaiting stimulus onset (fixation of eye position for visual tasks, lever hold for the somatosensory task). This restriction minimizes stimulus-related confounds and allows application of the same analyses across areas and data sets. This definition of intrinsic timescale does not refer to single-neuron physiology or imply that the timescale does not change with stimulus conditions. The decay of autocorrelation with increasing time lag could be well fit by an exponential decay with an offset (Fig. 1c). This fit was obtained at the population level rather than the single-neuron level (Online Methods and Supplementary Figs. 1 and 2), enabling us to extract an intrinsic timescale as a population-level statistic for each area in a data set. Within each data set, the intrinsic timescales dif-fered across areas, in the range of 50\textendash 350 ms. Over all data sets, we found a consistent ordering of the intrinsic timescales across cortical areas (P \textbackslash textless 10 -5 , r s = 0.89, Spearman's rank correlation) (Fig. 1d). Sensory cortex showed shorter timescales, parietal association cortex showed intermediate timescales and prefrontal cortex showed longer timescales, with medial prefrontal area ACC consistently showing the longest timescale in our data sets. Both visual and somatosen-sory systems had hierarchical ordering. Differences in intrinsic timescales could not be explained by differences in mean firing rates across areas (Supplementary Fig. 3). Notably, this hierarchy of intrinsic timescales aligns with the anatomical hierarchy defined by long-range projections among cortical areas 9,10 (P = 0.002, r s = 0.97, Spearman's rank correlation), although our physiologically defined A hierarchy of intrinsic timescales across primate cortex},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DVTNS6W2\\Murray et al. - 2014 - A hierarchy of intrinsic timescales across primate cortex.pdf},
  journal = {nature neuroscience},
  number = {12}
}

@article{murray_wang_2018,
  title = {Working {{Memory}} and {{Decision}}-{{Making}} in a {{Frontoparietal Circuit Model}}},
  author = {Murray, John D and Jaramillo, Jorge and Wang, Xiao-Jing},
  year = {2018},
  doi = {10.1523/JNEUROSCI.0343-17.2017},
  abstract = {Working memory (WM) and decision-making (DM) are fundamental cognitive functions involving a distributed interacting network of brain areas, with the posterior parietal cortex (PPC) and prefrontal cortex (PFC) at the core. However, the shared and distinct roles of these areas and the nature of their coordination in cognitive function remain poorly understood. Biophysically based computational models of cortical circuits have provided insights into the mechanisms supporting these functions, yet they have primarily focused on the local microcircuit level, raising questions about the principles for distributed cognitive computation in multiregional networks. To examine these issues, we developed a distributed circuit model of two reciprocally interacting modules representing PPC and PFC circuits. The circuit architecture includes hierarchical differences in local recurrent structure and implements reciprocal long-range projections. This parsimonious model captures a range of behavioral and neuronal features of frontoparietal circuits across multiple WM and DM paradigms. In the context of WM, both areas exhibit persistent activity, but, in response to intervening distractors, PPC tran-siently encodes distractors while PFC filters distractors and supports WM robustness. With regard to DM, the PPC module generates graded representations of accumulated evidence supporting target selection, while the PFC module generates more categorical responses related to action or choice. These findings suggest computational principles for distributed, hierarchical processing in cortex during cognitive function and provide a framework for extension to multiregional models.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Z43QS3Z5\\Murray, Jaramillo, Wang - Unknown - Working Memory and Decision-Making in a Frontoparietal Circuit Model.pdf},
  keywords = {Attractor,decision-making,NMDA receptor,parietal cortex,prefrontal cortex,working-memory}
}

@article{mursalin_chawla_2017,
  title = {Automated Epileptic Seizure Detection Using Improved Correlation-Based Feature Selection with Random Forest Classifier},
  author = {Mursalin, Md and Zhang, Yuan and Chen, Yuehui and Chawla, Nitesh V},
  year = {2017},
  month = jun,
  volume = {241},
  pages = {204--214},
  issn = {18728286},
  doi = {10.1016/j.neucom.2017.02.053},
  abstract = {Analysis of electroencephalogram (EEG) signal is crucial due to its non-stationary characteristics, which could lead the way to proper detection method for the treatment of patients with neurological abnormalities, especially for epilepsy. The performance of EEG-based epileptic seizure detection relies largely on the quality of selected features from an EEG data that characterize seizure activity. This paper presents a novel analysis method for detecting epileptic seizure from EEG signal using Improved Correlation-based Feature Selection method (ICFS) with Random Forest classifier (RF). The analysis involves, first applying ICFS to select the most prominent features from the time domain, frequency domain, and entropy based features. An ensemble of Random Forest (RF) classifiers is then learned on the selected set of features. The experimental results demonstrate that the proposed method shows better performance compared to the conventional Correlation-based method and also outperforms some other state-of-the-art methods of epileptic seizure detection using the same benchmark EEG dataset.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\54Y8FJPM\\Mursalin et al. - 2017 - Automated epileptic seizure detection using improved correlation-based feature selection with random forest cla.pdf},
  journal = {Neurocomputing},
  keywords = {Correlation-based Feature Selection (CFS),Discrete Wavelet transformation (DWT),Electroencephalogram (EEG),Improved Correlation-based Feature Selection (ICFS,Random Forest (RF)}
}

@article{murta_lemieux_2017,
  title = {Phase???Amplitude Coupling and the {{BOLD}} Signal: {{A}} Simultaneous Intracranial {{EEG}} ({{icEEG}}) - {{fMRI}} Study in Humans Performing a Finger-Tapping Task},
  author = {Murta, T and Chaudhary, U J and Tierney, Tim M and Dias, A and Leite, M and Carmichael, D W and Figueiredo, P and Lemieux, L},
  year = {2017},
  volume = {146},
  pages = {438--451},
  issn = {10959572},
  doi = {10.1016/j.neuroimage.2016.08.036},
  abstract = {Although it has been consistently found that local blood-oxygen-level-dependent (BOLD) changes are better modelled by a combination of the power of multiple EEG frequency bands rather than by the power of a unique band alone, the local electro-haemodynamic coupling function is not yet fully characterised. Electrophysiological studies have revealed that the strength of the coupling between the phase of low- and the amplitude of high- frequency EEG activities (phase???amplitude coupling - PAC) has an important role in brain function in general, and in preparation and execution of movement in particular. Using electrocorticographic (ECoG) and functional magnetic resonance imaging (fMRI) data recorded simultaneously in humans performing a finger-tapping task, we investigated the single-trial relationship between the amplitude of the BOLD signal and the strength of PAC and the power of ??, ??, and ?? bands, at a local level. In line with previous studies, we found a positive correlation for the ?? band, and negative correlations for the PAC???? strength, and the ?? and ?? bands. More importantly, we found that the PAC???? strength explained variance of the amplitude of the BOLD signal that was not explained by a combination of the ??, ??, and ?? band powers. Our main finding sheds further light on the distinct nature of PAC as a functionally relevant mechanism and suggests that the sensitivity of EEG-informed fMRI studies may increase by including the PAC strength in the BOLD signal model, in addition to the power of the low- and high- frequency EEG bands.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FTVDVQN9\\Murta et al. - 2017 - Phase-amplitude coupling and the BOLD signal A simultaneous intracranial EEG (icEEG) - fMRI study in humans perfor.pdf},
  journal = {NeuroImage},
  keywords = {Electro-haemodynamic coupling,fmri,Intracranial EEG,Phase???amplitude coupling},
  pmid = {27554531}
}

@article{muscinelli_muscinelli_2018,
  title = {Slow Dynamics in Structured Neural Network Models},
  author = {Muscinelli, Samuel Pavio},
  year = {2018},
  pages = {141},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\34WHM99E\\Muscinelli - Slow dynamics in structured neural network models.pdf},
  language = {en}
}

@article{muscinelli_schwalger_2019,
  title = {How Single Neuron Properties Shape Chaotic Dynamics and Signal Transmission in Random Neural Networks},
  author = {Muscinelli, Samuel P. and Gerstner, Wulfram and Schwalger, Tilo},
  editor = {Latham, Peter E.},
  year = {2019},
  month = jun,
  volume = {15},
  pages = {e1007122},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1007122},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IVXFUAKG\\Muscinelli et al. - 2019 - How single neuron properties shape chaotic dynamic.pdf},
  journal = {PLOS Computational Biology},
  language = {en},
  number = {6}
}

@techreport{mushtaq_ivry_2019,
  title = {Distinct {{Processing}} of {{Selection}} and {{Execution Errors}} in {{Neural Signatures}} of {{Outcome Monitoring}}},
  author = {Mushtaq, Faisal and McDougle, Samuel D. and Craddock, Matt P. and Parvin, Darius E. and Brookes, Jack and Schaefer, Alexandre and {Mon-Williams}, Mark and Taylor, Jordan A. and Ivry, Richard B.},
  year = {2019},
  month = nov,
  institution = {{Neuroscience}},
  doi = {10.1101/853317},
  abstract = {Abstract           Losing a point playing tennis may result from poor shot selection or poor stroke execution. To explore how the brain responds to these different types of errors, we examined EEG signatures of feedback-related processing while participants performed a simple decision-making task. In Experiment 1, we used a task in which unrewarded outcomes were framed as selection errors, similar to how feedback information is treated in most studies. Consistent with previous work, EEG differences between rewarded and unrewarded trials in the medial frontal negativity (MFN) correlated with behavioral adjustment. In Experiment 2, the task was modified such that unrewarded outcomes could arise from either poor execution or selection. For selection errors, the results replicated that observed in Experiment 1. However, unrewarded outcomes attributed to poor execution produced larger amplitude MFN, alongside an attenuation in activity preceding this component and a subsequent enhanced error positivity (Pe) response in posterior sites. In terms of behavioral correlates, only the degree of the early attenuation and amplitude of the Pe correlated with behavioral adjustment following execution errors relative to reward; the amplitude of the MFN did not correlate with behavioral changes related to execution errors. These results indicate the existence of distinct neural correlates of selection and execution error processing and are consistent with the hypothesis that execution errors can modulate action selection evaluation. More generally, they provide insight into how the brain responds to different classes of error that determine future action.                        Significance Statement             To learn from mistakes, we must resolve whether decisions that fail to produce rewards are due to poorly selected action plans or badly executed movements. EEG data were obtained to identify and compare the physiological correlates of selection and execution errors, and how these are related to behavioral changes. A neural signature associated with reinforcement learning, a medial frontal negative (MFN) ERP deflection, correlated with behavioral adjustment after selection errors relative to reward outcomes, but not motor execution errors. In contrast, activity preceding and following the MFN response correlated with behavioral adjustment after execution errors relative to reward. These results provide novel insight into how the brain responds to different classes of error that determine future action.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\B9HGEB5E\\Mushtaq et al. - 2019 - Distinct Processing of Selection and Execution Err.pdf},
  language = {en},
  type = {Preprint}
}

@article{mysore_kothari_2020,
  title = {Mechanisms of Competitive Selection: {{A}} Canonical Neural Circuit Framework},
  shorttitle = {Mechanisms of Competitive Selection},
  author = {Mysore, Shreesh P and Kothari, Ninad B},
  year = {2020},
  month = may,
  volume = {9},
  pages = {e51473},
  issn = {2050-084X},
  doi = {10.7554/eLife.51473},
  abstract = {Competitive selection, the transformation of multiple competing sensory inputs and internal states into a unitary choice, is a fundamental component of animal behavior. Selection behaviors have been studied under several intersecting umbrellas including decision-making, action selection, perceptual categorization, and attentional selection. Neural correlates of these behaviors and computational models have been investigated extensively. However, specific, identifiable neural circuit mechanisms underlying the implementation of selection remain elusive. Here, we employ a first principles approach to map competitive selection explicitly onto neural circuit elements. We decompose selection into six computational primitives, identify demands that their execution places on neural circuit design, and propose a canonical neural circuit framework. The resulting framework has several links to neural literature, indicating its biological feasibility, and has several common elements with prominent computational models, suggesting its generality. We propose that this framework can help catalyze experimental discovery of the neural circuit underpinnings of competitive selection.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ANNB585A\\Mysore and Kothari - 2020 - Mechanisms of competitive selection A canonical n.pdf},
  journal = {eLife},
  language = {en}
}

@article{nadalin_kramer_2019,
  title = {A Statistical Modeling Framework to Assess Cross-Frequency Coupling While Accounting for Confounding Effects},
  author = {Nadalin, Jessica K and Martinet, Louis-Emmanuel and Blackwood, Ethan and Lo, Meng-Chen and Widge, Alik S and Cash, Sydney S and Eden, Uri and Kramer, Mark A},
  year = {2019},
  month = feb,
  doi = {10.1101/519470},
  abstract = {Cross frequency coupling (CFC) is emerging as a fundamental feature of brain activity, correlated with brain function and dysfunction. Many different types of CFC have been identified through application of numerous data analysis methods, each developed to characterize a specific CFC type. Choosing an inappropriate method weakens statistical power and introduces opportunities for confounding effects. To address this, we propose a statistical modeling framework to estimate high frequency amplitude as a function of both the low frequency amplitude and low frequency phase; the result is a measure of phase-amplitude coupling that accounts for changes in the low frequency amplitude. We show in simulations that the proposed method successfully detects CFC between the low frequency phase or amplitude and the high frequency amplitude, and outperforms an existing method in biologically-motivated examples. Applying the method to                          data, we illustrate how CFC evolves during seizures and is affected by electrical stimuli.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IM2SVXCQ\\Nadalin et al. - 2019 - A statistical modeling framework to assess cross-f.pdf},
  journal = {bioRxiv},
  language = {en}
}

@article{najafi_churchland_2018,
  title = {Excitatory and Inhibitory Subnetworks Are Equally Selective during Decision-Making and Emerge Simultaneously during Learning},
  author = {Najafi, Farzaneh and Elsayed, Gamaleldin F and Cao, Robin and Pnevmatikakis, Eftychios and Latham, Peter E and Cunningham, John P and Churchland, Anne K},
  year = {2018},
  doi = {10.1101/354340},
  abstract = {Inhibitory neurons play a critical role in decision-making models and are often simplified as a single pool of non-selective neurons lacking connection specificity. This assumption is in keeping with observations in primary visual cortex: inhibitory neurons are broadly tuned in vivo, and show non-specific connectivity in slice. Selectivity of excitatory and inhibitory neurons within decision circuits is not known. We simultaneously measured their activity in the posterior parietal cortex of mice making multisensory decisions. Surprisingly, excitatory and inhibitory neurons were equally selective for the animal's choice, both at the single cell and population level. Further, excitatory and inhibitory populations exhibited similar changes in selectivity and temporal dynamics during the transition from novice to expert decision-making, paralleling behavioral improvements. These observations, combined with simulations, argue against models assuming non-selective inhibitory neurons. Instead, they argue for selective subnetworks of inhibitory and excitatory neurons that are shaped by experience to support expert decision-making.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FZSK7WQ9\\Najafi et al. - Unknown - Excitatory and inhibitory subnetworks are equally selective during decision-making and emerge simultaneously d.pdf}
}

@article{nakamura_komatsu_2019,
  title = {Information Seeking Mechanism of Neural Populations in the Lateral Prefrontal Cortex},
  author = {Nakamura, Kiyohiko and Komatsu, Misako},
  year = {2019},
  month = mar,
  volume = {1707},
  pages = {79--89},
  issn = {00068993},
  doi = {10.1016/j.brainres.2018.11.029},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KEETM6WW\\Nakamura, Komatsu - 2019 - Information seeking mechanism of neural populations in the lateral prefrontal cortex.pdf},
  journal = {Brain Research}
}

@article{nakano_doya_2015,
  title = {A Spiking Neural Network Model of Model- {{Free}} Reinforcement Learning with High- Dimensional Sensory Input and Perceptual Ambiguity},
  author = {Nakano, Takashi and Otsuka, Makoto and Yoshimoto, Junichiro and Doya, Kenji},
  year = {2015},
  volume = {10},
  pages = {1--18},
  issn = {19326203},
  doi = {10.1371/journal.pone.0115620},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ADVZ7P4X\\Nakano et al. - 2015 - A spiking neural network model of model- Free reinforcement learning with high- dimensional sensory input and per.pdf},
  journal = {PLoS ONE},
  number = {3}
}

@article{nalatore_rangarajan_2009,
  title = {Short-Window Spectral Analysis Using {{AMVAR}} and Multitaper Methods: {{A}} Comparison},
  author = {Nalatore, Hariharan and Rangarajan, Govindan},
  year = {2009},
  volume = {101},
  pages = {71--80},
  issn = {03401200},
  doi = {10.1007/s00422-009-0318-5},
  abstract = {We compare two popular methods for estimating the power spectrum from short data windows, namely the adaptive multivariate autoregressive (AMVAR) method and the multitaper method. By analyzing a simulated signal (embedded in a background Ornstein\textendash Uhlenbeck noise process) we demonstrate that the AMVAR method performs better at detecting short bursts of oscillations compared to the multitaper method. However, both methods are immune to jitter in the temporal location of the signal. We also show that coherence can still be detected in noisy bivariate time series data by the AMVAR method even if the individual power spectra fail to show any peaks. Finally, using data from two monkeys performing a visuomotor pattern discrimination task, we demonstrate that the AMVAR method is better able to determine the termination of the beta oscillations when compared to the multitaper method.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QZUDWL4T\\Nalatore, Rangarajan - 2009 - Short-window spectral analysis using AMVAR and multitaper methods A comparison.pdf},
  journal = {Biological Cybernetics},
  keywords = {Multitaper method,mvar,Spectral analysis},
  number = {1},
  pmid = {19471956}
}

@article{narayanan_oberlaender_2017,
  title = {Cell {{Type}}-{{Specific Structural Organization}} of the {{Six Layers}} in {{Rat Barrel Cortex}}},
  author = {Narayanan, Rajeevan T. and Udvary, Daniel and Oberlaender, Marcel},
  year = {2017},
  volume = {11},
  issn = {1662-5129},
  doi = {10.3389/fnana.2017.00091},
  abstract = {The cytoarchitectonic subdivision of the neocortex into six layers is often used to describe the organization of the cortical circuitry, sensory-evoked signal flow or cortical functions. However, each layer comprises neuronal cell types that have different genetic, functional and/or structural properties. Here, we reanalyze structural data from some of our recent work in the posterior-medial barrel-subfield of the vibrissal part of rat primary somatosensory cortex (vS1). We quantify the degree to which somata, dendrites and axons of the ten major excitatory cell types of the cortex are distributed with respect to the cytoarchitectonic organization of vS1. We show that within each layer, somata of multiple cell types intermingle, but that each cell type displays dendrite and axon distributions that are aligned to specific cytoarchitectonic landmarks. The resultant quantification of the structural composition of each layer in terms of the cell type-specific number of somata, dendritic and axonal path lengths will aid future studies to bridge between layer- and cell type-specific analyses.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WBBPSA3J\\Narayanan, Udvary, Oberlaender - 2017 - Cell Type-Specific Structural Organization of the Six Layers in Rat Barrel Cortex.pdf},
  journal = {Frontiers in Neuroanatomy},
  pmid = {29081739}
}

@article{nassar_bugallo_2019,
  title = {Tree-{{Structured Recurrent Switching Linear Dynamical Systems}} for {{Multi}}-Scale {{Modeling}}},
  author = {Nassar, Josue and Linderman, Scott W and Bugallo, M{\'o}nica F},
  year = {2019},
  pages = {17},
  abstract = {Many real-world systems studied are governed by complex, nonlinear dynamics. By modeling these dynamics, we can gain insight into how these systems work, make predictions about how they will behave, and develop strategies for controlling them. While there are many methods for modeling nonlinear dynamical systems, existing techniques face a trade off between offering interpretable descriptions and making accurate predictions. Here, we develop a class of models that aims to achieve both simultaneously, smoothly interpolating between simple descriptions and more complex, yet also more accurate models1. Our probabilistic model achieves this multi-scale property through a hierarchy of locally linear dynamics that jointly approximate global nonlinear dynamics. We call it the tree-structured recurrent switching linear dynamical system. To fit this model, we present a fully-Bayesian sampling procedure using P\'olya-Gamma data augmentation to allow for fast and conjugate Gibbs sampling. Through a variety of synthetic and real examples, we show how these models outperform existing methods in both interpretability and predictive capability.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ABVXW3DE\\Nassar et al. - 2019 - TREE-STRUCTURED RECURRENT SWITCHING LINEAR DYNAMIC.pdf},
  language = {en}
}

@article{naud_gerstner_2008,
  title = {Firing Patterns in the Adaptive Exponential Integrate-and-Fire Model},
  author = {Naud, Richard and Marcille, Nicolas and Clopath, Claudia and Gerstner, Wulfram},
  year = {2008},
  month = nov,
  volume = {99},
  pages = {335--347},
  issn = {0340-1200, 1432-0770},
  doi = {10.1007/s00422-008-0264-7},
  abstract = {For simulations of large spiking neuron networks, an accurate, simple and versatile single-neuron modeling framework is required. Here we explore the versatility of a simple two-equation model: the adaptive exponential integrate-and-fire neuron. We show that this model generates multiple firing patterns depending on the choice of parameter values, and present a phase diagram describing the transition from one firing type to another. We give an analytical criterion to distinguish between continuous adaption, initial bursting, regular bursting and two types of tonic spiking. Also, we report that the deterministic model is capable of producing irregular spiking when stimulated with constant current, indicating low-dimensional chaos. Lastly, the simple model is fitted to real experiments of cortical neurons under step current stimulation. The results provide support for the suitability of simple models such as the adaptive exponential integrate-and-fire neuron for large network simulations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GW78PUHP\\Naud et al. - 2008 - Firing patterns in the adaptive exponential integr.pdf},
  journal = {Biological Cybernetics},
  language = {en},
  number = {4-5}
}

@article{naud_sprekeler_2018,
  ids = {naud\_sprekeler\_2018a},
  title = {Sparse Bursts Optimize Information Transmission in a Multiplexed Neural Code},
  author = {Naud, Richard and Sprekeler, Henning},
  year = {2018},
  month = jul,
  volume = {115},
  pages = {E6329-E6338},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1720995115},
  abstract = {Many cortical neurons combine the information ascending and descending the cortical hierarchy. In the classical view, this information is combined nonlinearly to give rise to a single firing-rate output, which collapses all input streams into one. We analyze the extent to which neurons can simultaneously represent multiple input streams by using a code that distinguishes spike timing patterns at the level of a neural ensemble. Using computational simulations constrained by experimental data, we show that cortical neurons are well suited to generate such multiplexing. Interestingly, this neural code maximizes information for short and sparse bursts, a regime consistent with in vivo recordings. Neurons can also demultiplex this information, using specific connectivity patterns. The anatomy of the adult mammalian cortex suggests that these connectivity patterns are used by the nervous system to maintain sparse bursting and optimal multiplexing. Contrary to firing-rate coding, our findings indicate that the physiology and anatomy of the cortex may be interpreted as optimizing the transmission of multiple independent signals to different targets.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FLL88MYN\\Naud and Sprekeler - 2018 - Sparse bursts optimize information transmission in.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\NZKTJJCT\\Naud and Sprekeler - 2018 - Sparse bursts optimize information transmission in.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {27}
}

@techreport{naumann_sprekeler_2020,
  title = {Presynaptic Inhibition Rapidly Stabilises Recurrent Excitation in the Face of Plasticity},
  author = {Naumann, Laura Bella and Sprekeler, Henning},
  year = {2020},
  month = feb,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.02.11.944082},
  abstract = {Hebbian plasticity, a mechanism believed to be the substrate of learning and memory, detects and further enhances correlated neural activity. Because this constitutes an unstable positive feedback loop, it requires additional homeostatic control. Computational work suggests that in recurrent networks, the homeostatic mechanisms observed in experiments are too slow to compensate instabilities arising from Hebbian plasticity and need to be complemented by rapid compensatory processes. We suggest presynaptic inhibition as a candidate that rapidly provides stability by compensating recurrent excitation induced by Hebbian changes. Presynaptic inhibition is mediated by presynaptic GABA receptors that effectively and reversibly attenuate transmitter release. Activation of these receptors can be triggered by excess network activity, hence providing a stabilising negative feedback loop that weakens recurrent interactions on sub-second timescales. We study the stabilising effect of presynaptic inhibition in a recurrent networks, in which presynaptic inhibition is implemented as a multiplicative reduction of recurrent synaptic weights in response to increasing inhibitory activity. We show that networks with presynaptic inhibition display a gradual increase of firing rates with growing excitatory weights, in contrast to traditional excitatory-inhibitory networks. This alleviates the positive feedback loop between Hebbian plasticity and network activity and thereby allows homeostasis to act on timescales similar to those observed in experiments. Our results generalise to spiking networks with a biophysically more detailed implementation of the presynaptic inhibition mechanism. In conclusion, presynaptic inhibition provides a powerful compensatory mechanism that rapidly reduces effective recurrent interactions and thereby stabilises Hebbian learning.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4YYCAZZZ\\Naumann and Sprekeler - 2020 - Presynaptic inhibition rapidly stabilises recurren.pdf},
  language = {en},
  type = {Preprint}
}

@article{nautrup_renner_2020,
  title = {Operationally Meaningful Representations of Physical Systems in Neural Networks},
  author = {Nautrup, Hendrik Poulsen and Metger, Tony and Iten, Raban and Jerbi, Sofiene and Trenkwalder, Lea M. and Wilming, Henrik and Briegel, Hans J. and Renner, Renato},
  year = {2020},
  month = jan,
  abstract = {To make progress in science, we often build abstract representations of physical systems that meaningfully encode information about the systems. The representations learnt by most current machine learning techniques reflect statistical structure present in the training data; however, these methods do not allow us to specify explicit and operationally meaningful requirements on the representation. Here, we present a neural network architecture based on the notion that agents dealing with different aspects of a physical system should be able to communicate relevant information as efficiently as possible to one another. This produces representations that separate different parameters which are useful for making statements about the physical system in different experimental settings. We present examples involving both classical and quantum physics. For instance, our architecture finds a compact representation of an arbitrary two-qubit system that separates local parameters from parameters describing quantum correlations. We further show that this method can be combined with reinforcement learning to enable representation learning within interactive scenarios where agents need to explore experimental settings to identify relevant variables.},
  archivePrefix = {arXiv},
  eprint = {2001.00593},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6DQP8Q36\\Nautrup et al. - 2020 - Operationally meaningful representations of physic.pdf},
  journal = {arXiv:2001.00593 [quant-ph]},
  language = {en},
  primaryClass = {quant-ph}
}

@article{navarro_stringer_2018,
  title = {Self-Organising Coordinate Transformation with Peaked and Monotonic Gain Modulation in the Primate Dorsal Visual Pathway},
  author = {Navarro, Daniel M. and Mender, Bedeho M. W. and Smithson, Hannah E. and Stringer, Simon M.},
  editor = {Morrison, Abigail},
  year = {2018},
  month = nov,
  volume = {13},
  pages = {e0207961},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0207961},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\X5344TWE\\Navarro et al. - 2018 - Self-organising coordinate transformation with pea.pdf},
  journal = {PLOS ONE},
  language = {en},
  number = {11}
}

@incollection{nessler_maass_2009,
  title = {Hebbian {{Learning}} of {{Bayes Optimal Decisions}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 21},
  author = {Nessler, Bernhard and Pfeiffer, Michael and Maass, Wolfgang},
  editor = {Koller, D. and Schuurmans, D. and Bengio, Y. and Bottou, L.},
  year = {2009},
  pages = {1169--1176},
  publisher = {{Curran Associates, Inc.}},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SDZJB7G4\\Nessler et al_2009_Hebbian Learning of Bayes Optimal Decisions.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\RV6UMBKE\\3391-hebbian-learning-of-bayes-optimal-decisions.html}
}

@article{newman_hasselmo_2012,
  title = {Cholinergic Modulation of Cognitive Processing: Insights Drawn from Computational Models.},
  author = {Newman, Ehren L and Gupta, Kishan and Climer, Jason R and Monaghan, Caitlin K and Hasselmo, Michael E},
  year = {2012},
  month = jan,
  volume = {6},
  pages = {24},
  issn = {1662-5153},
  doi = {10.3389/fnbeh.2012.00024},
  abstract = {Acetylcholine plays an important role in cognitive function, as shown by pharmacological manipulations that impact working memory, attention, episodic memory, and spatial memory function. Acetylcholine also shows striking modulatory influences on the cellular physiology of hippocampal and cortical neurons. Modeling of neural circuits provides a framework for understanding how the cognitive functions may arise from the influence of acetylcholine on neural and network dynamics. We review the influences of cholinergic manipulations on behavioral performance in working memory, attention, episodic memory, and spatial memory tasks, the physiological effects of acetylcholine on neural and circuit dynamics, and the computational models that provide insight into the functional relationships between the physiology and behavior. Specifically, we discuss the important role of acetylcholine in governing mechanisms of active maintenance in working memory tasks and in regulating network dynamics important for effective processing of stimuli in attention and episodic memory tasks. We also propose that theta rhythm plays a crucial role as an intermediary between the physiological influences of acetylcholine and behavior in episodic and spatial memory tasks. We conclude with a synthesis of the existing modeling work and highlight future directions that are likely to be rewarding given the existing state of the literature for both empiricists and modelers.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\M3NFMSWZ\\Newman et al. - 2012 - Cholinergic modulation of cognitive processing insights drawn from computational models.pdf},
  journal = {Frontiers in behavioral neuroscience},
  keywords = {attention,entorhinal cortex,memory,oscillatory,oscillatory interference,spatial navigation,theta},
  number = {June},
  pmid = {22707936}
}

@article{newman_hasselmo_2013,
  title = {Cholinergic {{Blockade Reduces Theta}}-{{Gamma Phase Amplitude Coupling}} and {{Speed Modulation}} of {{Theta Frequency Consistent}} with {{Behavioral Effects}} on {{Encoding}}},
  author = {Newman, Ehren L and Gillet, S N and Climer, Jason R and Hasselmo, Michael E},
  year = {2013},
  volume = {33},
  pages = {19635--19646},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.2586-13.2013},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VUZLSMQN\\Newman et al. - 2013 - Cholinergic Blockade Reduces Theta-Gamma Phase Amplitude Coupling and Speed Modulation of Theta Frequency Consist.pdf},
  journal = {Journal of Neuroscience},
  keywords = {encoding,entorhinal cortex,gamma,path integration,theta},
  number = {50}
}

@article{newman_hasselmo_2014,
  title = {Grid Cell Firing Properties Vary as a Function of Theta Phase Locking Preferences in the Rat Medial Entorhinal Cortex},
  author = {Newman, Ehren L and Hasselmo, Michael E},
  year = {2014},
  month = oct,
  volume = {8},
  pages = {1--15},
  issn = {1662-5137},
  doi = {10.3389/fnsys.2014.00193},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\A34XJ2UH\\Newman, Hasselmo - 2014 - Grid cell firing properties vary as a function of theta phase locking preferences in the rat medial entorhinal.pdf},
  journal = {Frontiers in Systems Neuroscience},
  keywords = {grid cells,medial entorhinal cortex,navigation,spatial tuning,theta},
  number = {October}
}

@article{newman_hasselmo_2014a,
  title = {Grid Cell Spatial Tuning Reduced Following Systemic Muscarinic Receptor Blockade},
  author = {Newman, Ehren L and Climer, Jason R and Hasselmo, Michael E},
  year = {2014},
  volume = {24},
  pages = {643--655},
  issn = {10981063},
  doi = {10.1002/hipo.22253},
  abstract = {Grid cells of the medial entorhinal cortex exhibit a periodic and stable pattern of spatial tuning that may reflect the output of a path integration system. This grid pattern has been hypothesized to serve as a spatial coordinate system for navigation and memory function. The mechanisms underlying the generation of this characteristic tuning pattern remain poorly understood. Systemic administration of the muscarinic antagonist scopolamine flattens the typically positive correlation between running speed and entorhinal theta frequency in rats. The loss of this neural correlate of velocity, an important signal for the calculation of path integration, raises the question of what influence scopolamine has on the grid cell tuning as a read out of the path integration system. To test this, the spatial tuning properties of grid cells were compared before and after systemic administration of scopolamine as rats completed laps on a circle track for food rewards. The results show that the spatial tuning of the grid cells was reduced following scopolamine administration. The tuning of head direction cells, in contrast, was not reduced by scopolamine. This is the first report to demonstrate a link between cholinergic function and grid cell tuning. This work suggests that the loss of tuning in the grid cell network may underlie the navigational disorientation observed in Alzheimer's patients and elderly individuals with reduced cholinergic tone.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KAXDBYJT\\Newman, Climer, Hasselmo - 2014 - Grid cell spatial tuning reduced following systemic muscarinic receptor blockade.pdf},
  journal = {Hippocampus},
  keywords = {Medial entorhinal cortex,Navigation,Spatial tuning,Theta},
  number = {6},
  pmid = {24493379}
}

@article{newman_levy_2017,
  title = {Precise Spike Timing Dynamics of Hippocampal Place Cell Activity Sensitive to Cholinergic Disruption},
  author = {Newman, Ehren L and Venditto, Sarah Jo C. and Climer, Jason R and Petter, Elijah A and Gillet, Shea N and Levy, Sam},
  year = {2017},
  volume = {27},
  pages = {1069--1082},
  issn = {10981063},
  doi = {10.1002/hipo.22753},
  abstract = {New memory formation depends upon both the hippocampus and modulatory effects of acetylcholine. The mechanism by which acetylcholine levels in the hippocampus enable new encoding remains poorly understood. Here, we tested the hypothesis that cholinergic modulation supports memory formation by leading to structured spike timing in the hippocampus. Specifically, we tested if phase precession in dorsal CA1 was reduced under the influence of a systemic cholinergic antagonist. Unit and field potential was recorded from the dorsal CA1 of rats as they completed laps on a circular track for food rewards before and during the influence of the systemically administered acetylcholine muscarinic receptor antagonist scopolamine. We found that scopolamine significantly reduced phase precession of spiking relative to the field theta, and that this was due to a decrease in the frequency of the spiking rhythmicity. We also found that the correlation between position - theta phase was significantly reduced. This effect was not to be due to changes in spatial tuning as tuning remained stable for those cells analyzed. Likewise, it was not due to changes in lap-to-lap reliability of spiking onset or offset relative to either position or phase as the reliability did not decrease following scopolamine administration. These findings support the hypothesis that memory impairments that follow muscarinic blockade are the result of degraded spike timing in the hippocampus. This article is protected by copyright. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2ETPJYC8\\Newman et al. - Unknown - Precise spike timing dynamics of hippocampal place cell activity sensitive to cholinergic disruption.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\APHPZSG7\\Newman et al. - Unknown - Precise spike timing dynamics of hippocampal place cell activity sensitive to cholinergic disruption Running t.pdf},
  journal = {Hippocampus},
  keywords = {aging,Alzheimer's,but has not been,memory,navigation,pagination and proofreading process,phase precession,place cells,rhythmicity,s disease,spike,spike timing,theta,this article has been,through the copyediting,timing,typesetting,undergone full peer review},
  number = {10},
  pmid = {28628945}
}

@article{neymotin_lytton_2013,
  title = {Ih {{Tunes Theta}}/{{Gamma Oscillations}} and {{Cross}}-{{Frequency Coupling In}} an {{In Silico CA3 Model}}},
  author = {Neymotin, Samuel A and Hilscher, Markus M and Moulin, Thiago C and Skolnick, Yosef and Lazarewicz, Maciej T and Lytton, William W},
  year = {2013},
  volume = {8},
  issn = {19326203},
  doi = {10.1371/journal.pone.0076285},
  abstract = {Ih channels are uniquely positioned to act as neuromodulatory control points for tuning hippocampal theta (4-12 Hz) and gamma (25 Hz) oscillations, oscillations which are thought to have importance for organization of information flow. contributes to neuronal membrane resonance and resting membrane potential, and is modulated by second messengers. We investigated oscillatory control using a multiscale computer model of hippocampal CA3, where each cell class (pyramidal, basket, and oriens-lacunosum moleculare cells), contained type-appropriate isoforms of . Our model demonstrated that modulation of pyramidal and basket allows tuning theta and gamma oscillation frequency and amplitude. Pyramidal also controlled cross-frequency coupling (CFC) and allowed shifting gamma generation towards particular phases of the theta cycle, effected via 's ability to set pyramidal excitability. Our model predicts that in vivo neuromodulatory control of allows flexibly controlling CFC and the timing of gamma discharges at particular theta phases.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VEKPATD9\\Neymotin et al. - 2013 - Ih Tunes ThetaGamma Oscillations and Cross-Frequency Coupling In an In Silico CA3 Model.pdf},
  journal = {PLoS ONE},
  number = {10},
  pmid = {24204609}
}

@phdthesis{nezis_rossum_2008,
  title = {Multiplication {{With Neurons}}},
  author = {Nezis, Pe and Rossum, M Van},
  year = {2008},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8EZMS8QU\\Nezis - 2008 - Multiplication With Neurons.pdf},
  pmid = {1000111978},
  type = {{{PhD Thesis}}}
}

@article{nezis_vanrossum_2011,
  title = {Accurate Multiplication with Noisy Spiking Neurons},
  author = {Nezis, Panagiotis and Van Rossum, Mark C W},
  year = {2011},
  month = jun,
  volume = {8},
  pages = {034005},
  issn = {17412560},
  doi = {10.1088/1741-2560/8/3/034005},
  abstract = {Multiplication is an operation which is fundamental in mathematics, but it is also relevant for many sensory computations in the nervous system. Nevertheless, despite a number of suggestions in the literature, it is not known how multiplication is implemented in neural circuitry. We propose a simple feedforward circuit that combines a rate model of neural activity and a realistic neural input-output relation to accurately and efficiently implement multiplication of two rate-coded quantities. By simulating a network of integrate and fire neurons, we demonstrate the functional efficiency of the circuit. Finally we discuss how the model can be tested experimentally.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AX5B6XRY\\Nezis, van Rossum - 2011 - Accurate multiplication with noisy spiking neurons.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\Q8BWJGPY\\Nezis, van Rossum - 2011 - Accurate multiplication with noisy spiking neurons.pdf},
  journal = {Journal of Neural Engineering},
  number = {3},
  pmid = {21572218}
}

@article{nicola_clopath_2017,
  title = {Supervised Learning in Spiking Neural Networks with {{FORCE}} Training},
  author = {Nicola, Wilten and Clopath, Claudia},
  year = {2017},
  volume = {8},
  issn = {20411723},
  doi = {10.1038/s41467-017-01827-3},
  abstract = {Populations of neurons display an extraordinary diversity in the behaviors they affect and display. Machine learning techniques have recently emerged that allow us to create networks of model neurons that display behaviours of similar complexity. Here, we demonstrate the direct applicability of one such technique, the FORCE method, to spiking neural networks. We train these networks to mimic dynamical systems, classify inputs, and store discrete sequences that correspond to the notes of a song. Finally, we use FORCE training to create two biologically motivated model circuits. One is inspired by the zebra-finch and successfully reproduces songbird singing. The second network is motivated by the hippocampus and is trained to store and replay a movie scene. FORCE trained networks reproduce behaviors comparable in complexity to their inspired circuits and yield information not easily obtainable with other techniques such as behavioral responses to pharmacological manipulations and spike timing statistics.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MQKD5EGH\\Nicola and Clopath - 2017 - Supervised learning in spiking neural networks wit.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\QJGL82BK\\Nicola, Clopath - Unknown - Supervised learning in spiking neural networks with FORCE training.pdf},
  journal = {Nature Communications},
  number = {1},
  pmid = {19842989}
}

@article{nicola_nicola_2019,
  title = {A Diversity of Interneurons and {{Hebbian}} Plasticity Facilitate Rapid Compressible Learning in the Hippocampus},
  author = {Nicola, Wilten},
  year = {2019},
  volume = {22},
  pages = {20},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZQXR5XIC\\Nicola - 2019 - A diversity of interneurons and Hebbian plasticity.pdf},
  journal = {Nature Neuroscience},
  language = {en}
}

@techreport{nir-cohen_egner_2019,
  title = {Distinct Neural Substrates for Opening and Closing the Gate from Perception to Working Memory},
  author = {{Nir-Cohen}, Gal and Kessler, Yoav and Egner, Tobias},
  year = {2019},
  month = nov,
  institution = {{Neuroscience}},
  doi = {10.1101/853630},
  abstract = {Abstract           Working memory (WM) needs to protect current content from interference and simultaneously be amenable to rapid updating with newly relevant information. An influential model suggests these opposing requirements are met via a basal ganglia (BG) - thalamus gating mechanism that allows for selective updating of prefrontal cortex (PFC) WM representations. A large neuroimaging literature supports the general involvement of the PFC, BG, and thalamus, as well as posterior parietal cortex (PPC), in WM. However, the specific functional contributions of these regions to key sub-process of WM updating, namely gate-opening, content substitution, and gate closing, are still unknown, as common WM tasks conflate these processes. We therefore combined functional MRI (19 male and 29 female participants) with the reference-back task, specifically designed to tease apart these sub-processes. Participants compared externally presented face stimuli to a reference face held in WM, while alternating between updating and maintaining this reference, resulting in opening vs. closing the gate to WM. Gate opening and substitution processes were associated with strong BG, thalamic and fronto-parietal activation, but \textendash{} intriguingly - the same activity profile was observed for sensory cortex supporting task stimulus processing (i.e., the fusiform face area). In contrast, gate closing was associated near-exclusively with PPC activation. These novel findings provide support for the gate opening process proposed by the BG gating model, but qualify the model's assumptions by demonstrating that gate closing does not depend on the BG but the PPC, and that gate opening also involves task-relevant sensory cortex.                        Significance statement             The ability to selectively ``gate'' task-relevant information into working memory (WM) is crucial for the efficient use of its limited capacity. Whereas previous studies documented the involvement of multiple brain regions in WM updating, how these regions mediate specific sub-processes of WM updating has remained unknown. In this neuroimaging study we utilized a task specifically designed to dissociate gate-opening, content substitution, and gate-closing processes. Our results demonstrate the involvement of the basal ganglia, frontoparietal, and task-relevant sensory cortex in opening the gate from perception to WM. Importantly, we also document that gate-opening and gate-closing are mediated by different brain regions, with gate-closing being supported by the parietal cortex. These results inform and extend current models of WM.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6AQ9WTI2\\Nir-Cohen et al. - 2019 - Distinct neural substrates for opening and closing.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\L76M6ZHM\\Nir-Cohen et al. - 2019 - Distinct neural substrates for opening and closing.pdf},
  language = {en},
  type = {Preprint}
}

@article{nisbett_norenzayan_2001,
  title = {Culture and Systems of Thought: {{Holistic}} versus Analytic Cognition.},
  author = {Nisbett, Richard E and Peng, Kaiping and Choi, Incheol and Norenzayan, Ara},
  year = {2001},
  volume = {108},
  pages = {291--310},
  issn = {1939-1471},
  doi = {10.1037/0033-295X.108.2.291},
  abstract = {The authors find East Asians to be holistic, attending to the entire field and assigning causality to it, making relatively little use of categories and formal logic, and relying on "dialectical" reasoning, whereas Westerners are more analytic, paying attention primarily to the object and the categories to which it belongs and using rules, including formal logic, to understand its behavior. The 2 types of cognitive processes are embedded in different naive metaphysical systems and tacit epistemologies. The authors speculate that the origin of these differences is traceable to markedly different social systems. The theory and the evidence presented call into question long-held assumptions about basic cognitive processes and even about the appropriateness of the process-content distinction.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FVE5ADDW\\Nisbett et al. - 2001 - Culture and systems of thought Holistic versus analytic cognition.pdf},
  journal = {Psychological Review},
  number = {2},
  pmid = {11381831}
}

@article{nishida_yoshimura_2018,
  title = {Comparing {{EEG}}/{{MEG}} Neuroimaging Methods Based on Localization Error, False Positive Activity, and False Positive Connectivity},
  author = {Nishida, Keiichiro and Yoshimura, Masafumi},
  year = {2018},
  pages = {1--18},
  doi = {10.1101/269753},
  abstract = {Corresponding author: RD Pascual-Marqui pascualmarqui@key.uzh.ch ; www.uzh.ch/keyinst/loreta.htm scholar.google.com/citations?user=pascualmarqui 1. Abstract EEG/MEG neuroimaging consists of estimating the cortical distribution of time varying signals of electric neuronal activity, for the study of functional localization and connectivity. Currently, many different imaging methods are being used, with very different capabilities of correct localization of activity and of correct localization of connectivity. The aim here is to provide a guideline for choosing the best (i.e. least bad) imaging method. This first study is limited to the comparison of the following methods for EEG signals: sLORETA and eLORETA (standardized and exact low resolution electromagnetic tomography), MNE (minimum norm estimate), dSPM (dynamic statistical parametric mapping), and LCMVBs (linearly constrained minimum variance beamformers). These methods are linear, except for the LCMVBs that make use of the quadratic EEG covariances. To achieve a fair comparison, it is assumed here that the generators are independent and widely distributed (i.e. not few in number), giving a well-defined theoretical population EEG covariance matrix for use with the LCMVBs. Measures of localization error, false positive activity, and false positive connectivity are defined and computed under ideal no-noise conditions. It is empirically shown with extensive simulations that: (1) MNE, dSPM, and all LCMVBs are in general incapable of correct localization, while sLORETA and eLORETA have exact (zero-error) localization; (2) the brain volume with false positive activity is significantly larger for MN, dSPM, and all LCMVBs, as compared to sLORETA and eLORETA; and (3) the number of false positive connections is significantly larger for MN, dSPM, all LCMVBs, and sLORETA, as compared to eLORETA. Non-vague and fully detailed equations are given. PASCAL program codes and data files are available. It is noted that the results reported here do not apply to the LCMVBs based on EEG covariance matrices generated from extremely few generators, such as only one or two independent point sources. 2. Introduction This paper deals with the EEG neuroimaging problem: given non-invasive measurements of scalp electric potential differences, find the generators, in the form of time varying cortical distribution of electric neuronal activity. Focused reviews can be found in (Valdes-Sosa et al 2009; Pascual-Marqui 2009; Pascual-Marqui et al 2009). There are available many different solutions, and the aim here is to provide a guideline for choosing the best (i.e. least bad) imaging method.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QEZT3DFT\\Nishida, Yoshimura - 2018 - Comparing EEGMEG neuroimaging methods based on localization error, false positive activity, and false positi.pdf},
  keywords = {eloreta,loreta,pascual-marqui,sloreta}
}

@article{nobre_vanede_2017,
  title = {Anticipated Moments: Temporal Structure in Attention},
  author = {Nobre, Anna C and {van Ede}, Freek},
  year = {2017},
  volume = {19},
  doi = {10.1038/nrn.2017.141},
  abstract = {Our environment unfolds dynamically, affording us boundless stimulation and possibilities. Although the incoming stream of information is ever new, not all of it is unpredictable. Embedded relationships among the attributes of events over different timescales carry predictions that guide proactive sensory and motor preparation in the brain. The same holds for the tempo-ral structuring of events. Recurring temporal structures enable proactive and temporally selective preparation for anticipated relevant events. The field of selective attention has uncovered many mechanisms by which the brain anticipates and selects relevant events to guide adaptive perception and action \textemdash{} for example, the filtering of competing sensory inputs, the upregulation of firing rates and inter-areal synchro-nization. At the core of most of these mechanisms is the modulation of neuronal activity and of neuronal com-munication on the basis of receptive field (RF) properties, leading to the prioritization of items that occur at the relevant location or contain a relevant feature 1\textendash 3 . Thus, we have come to a relatively advanced understanding of still frames, or snapshots, of attention. However, how the brain can use predictable temporal structure to anticipate and select relevant events immersed in the continuous flow of stimulation remains less clear. As attention is, by definition, a dynamic process, we need to add 'time' to understand attention fully. The study of temporal expectation in attention is finally gaining momentum and joining the mainstream. The aims of this Review are to introduce the reader to temporal attention and to highlight the emerging principles and interesting findings in this burgeoning field. A first major advance has been to recognize that many types of predictable temporal structure support attention. We illustrate their strong effects on perfor-mance and consider how they are utilized by the brain. Temporal expectations can act through various mecha-nisms at different stages of neural processing to enhance performance. One interesting observation is that, rather than acting in isolation, temporal expectations often accompany expectations about other identifying attributes of anticipated events, markedly boosting the effects of the latter. We stress that the effects of temporal expectation are not confined to typical attention labo-ratory experiments but also influence our perception of complex streams of information as well as many other fundamental aspects of cognition, such as learning and memory.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NNPZ8SAQ\\Nobre, van Ede - 2017 - Anticipated moments temporal structure in attention.pdf},
  journal = {Nature Publishing Group}
}

@article{noda_takahashi_2017,
  title = {Stimulus {{Phase Locking}} of {{Cortical Oscillations}} for {{Rhythmic Tone Sequences}} in {{Rats}}},
  author = {Noda, Takahiro and Amemiya, Tomoki and Shiramatsu, Tomoyo I and Takahashi, Hirokazu},
  year = {2017},
  volume = {11},
  pages = {1--13},
  issn = {1662-5110},
  doi = {10.3389/fncir.2017.00002},
  abstract = {\{\textcopyright\} 2017 Noda, Amemiya, Shiramatsu and Takahashi.Humans can rapidly detect regular patterns (i.e., within few cycles) without any special attention to the acoustic environment. This suggests that human sensory systems are equipped with a powerful mechanism for automatically predicting forthcoming stimuli to detect regularity. It has recently been hypothesized that the neural basis of sensory predictions exists for not only what happens (predictive coding) but also when a particular stimulus occurs (predictive timing). Here, we hypothesize that the phases of neural oscillations are critical in predictive timing, and these oscillations are modulated in a band-specific manner when acoustic patterns become predictable, i.e., regular. A high-density microelectrode array (10 \texttimes{} 10 within 4 \texttimes{} 4 mm2) was used to characterize spatial patterns of band-specific oscillations when a random-tone sequence was switched to a regular-tone sequence. Increasing the regularity of the tone sequence enhanced phase locking in a band-specific manner, notwithstanding the type of the regular sound pattern. Gamma-band phase locking increased immediately after the transition from random to regular sequences, while beta-band phase locking gradually evolved with time after the transition. The amplitude of the tone-evoked response, in contrast, increased with frequency separation with respect to the prior tone, suggesting that the evoked-response amplitude encodes sequence information on a local scale, i.e., the local order of tones. The phase locking modulation spread widely over the auditory cortex, while the amplitude modulation was confined around the activation foci. Thus, our data suggest that oscillatory phase plays a more important role than amplitude in the neuronal detection of tone sequence regularity, which is closely related to predictive timing. Furthermore, band-specific contributions may support recent theories that gamma oscillations encode bottom-up prediction errors, whereas beta oscillations are involved in top-down prediction.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\S5LAAYUI\\Noda et al. - 2017 - Stimulus Phase Locking of Cortical Oscillations for Rhythmic Tone Sequences in Rats.pdf},
  journal = {Frontiers in Neural Circuits},
  keywords = {auditory cortex,high-density microelectrod,high-density microelectrode array,oscillatory phase locking,regular tone sequences},
  number = {January}
}

@article{nokland_eidnes_2019,
  title = {Training {{Neural Networks}} with {{Local Error Signals}}},
  author = {N{\o}kland, Arild and Eidnes, Lars Hiller},
  year = {2019},
  month = may,
  abstract = {Supervised training of neural networks for classification is typically performed with a global loss function. The loss function provides a gradient for the output layer, and this gradient is back-propagated to hidden layers to dictate an update direction for the weights. An alternative approach is to train the network with layer-wise loss functions. In this paper we demonstrate, for the first time, that layer-wise training can approach the state-of-the-art on a variety of image datasets. We use single-layer sub-networks and two different supervised loss functions to generate local error signals for the hidden layers, and we show that the combination of these losses help with optimization in the context of local learning. Using local errors could be a step towards more biologically plausible deep learning because the global error does not have to be transported back to hidden layers. A completely backprop free variant outperforms previously reported results among methods aiming for higher biological plausibility. Code is available https://github.com/anokland/local-loss},
  archivePrefix = {arXiv},
  eprint = {1901.06656},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3RJSIQ9S\\Nøkland and Eidnes - 2019 - Training Neural Networks with Local Error Signals.pdf},
  journal = {arXiv:1901.06656 [cs, stat]},
  language = {en},
  primaryClass = {cs, stat}
}

@article{nolte_muller_2008,
  title = {Comparison of {{Granger Causality}} and {{Phase Slope Index}}},
  author = {Nolte, Guido and Ziehe, Andreas and Kramer, Nicole and Popescu, Florin and Muller, Klaus-Robert},
  year = {2008},
  volume = {6},
  pages = {267--276},
  abstract = {We recently proposed a new measure, termed Phase Slope Index (PSI), It estimates the\$\textbackslash backslash\$r\$\textbackslash backslash\$ncausal direction of interactions robustly with respect to instantaneous mixtures of independent\$\textbackslash backslash\$r\$\textbackslash backslash\$nsources with arbitrary spectral content. We compared this method to Granger Causality for\$\textbackslash backslash\$r\$\textbackslash backslash\$nlinear systems containing spatially and temporarily mixed noise and found that, in contrast to\$\textbackslash backslash\$r\$\textbackslash backslash\$nPSI, the latter was not able to properly distinguish truly interacting systems from mixed noise.\$\textbackslash backslash\$r\$\textbackslash backslash\$nHere, we extent this analysis with respect to two aspects: a) we analyze Granger causality and\$\textbackslash backslash\$r\$\textbackslash backslash\$nPSI also for non-mixed noise, and b) we analyze PSI for nonlinear interactions. We found a)\$\textbackslash backslash\$r\$\textbackslash backslash\$nthat Granger causality, in contrast to PSI, fails also for non-mixed noise if the memory-time of\$\textbackslash backslash\$r\$\textbackslash backslash\$nthe sender of information is long compared to the transmission time of the information, and b)\$\textbackslash backslash\$r\$\textbackslash backslash\$nthat PSI, being a linear method, eventually misses nonlinear interactions but is unlikely to give\$\textbackslash backslash\$r\$\textbackslash backslash\$nfalse positive results.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\P9LYY237\\Nolte et al. - 2008 - Comparison of Granger Causality and Phase Slope Index.pdf},
  journal = {JMLR Workshop and Conference Proceedings},
  keywords = {c 2010 g,f,granger causality,krämer,müller,n,noise,nolte,nonlinearity,phase slope index,popescu}
}

@article{nord_voon_2019,
  title = {The Effect of Frontoparietal Paired Associative Stimulation on Decision-Making and Working Memory},
  author = {Nord, Camilla L. and Popa, Traian and Smith, Emma and Hannah, Ricci and Do{\~n}amayor, Nuria and Weidacker, Kathrin and Bays, Paul M. and Rothwell, John and Voon, Valerie},
  year = {2019},
  month = aug,
  volume = {117},
  pages = {266--276},
  issn = {00109452},
  doi = {10.1016/j.cortex.2019.03.015},
  abstract = {Previous single-site neurostimulation experiments have unsuccessfully attempted to shift decision-making away from habitual control, a fast, inflexible cognitive strategy, towards goal-directed control, a flexible, though computationally expensive strategy. We employed a dual-target neurostimulation approach in 30 healthy participants, using cortico-cortical paired associative stimulation (ccPAS) to target two key nodes: lateral prefrontal cortex (LPFC) and intraparietal sulcus (IPS), to test whether decision-making can be artificially shifted from habitual toward goal-directed control. Participants received three active stimulations, delivered at least six days apart (each involving 100 paired pulses over the IPS and LPFC, varying the interstimulus interval): two interventional, time-relevant ccPAS (10ms interval) and one control, non-time-relevant ccPAS (100ms interval). Following stimulation, participants completed a sequential learning task, measuring goal-directed/habitual control, and a working memory task. IPS LPFC ccPAS (stimulating IPS, then LPFC with a 10ms interval) shifted decision-making from habitual toward goal-directed control, compared to control ccPAS, but this effect was only visible in a post-hoc contrast. There was no effect of LPFC IPS ccPAS, nor an effect of any PAS condition on working memory. Previous studies have shown ccPAS effects outside the motor domain targeting prefrontal regions on response inhibition, attentional bias, and alpha asymmetry. The present study measures the behavioural effects of parietalprefrontal PAS, focusing on a highly complex decision-making task and working memory. If confirmed in larger studies, this would be the first instance of neurostimulation successfully shifting decision-making from habitual to goal-directed control, putatively via inducing long-term potentiation between the IPS and LPFC. However, we found no effect in the other direction (LPFC IPS ccPAS), and no effect on working memory overall. PAS is a relatively new neuromodulatory technique in the cognitive arsenal, and this study could help guide future approaches in healthy and disordered decision-making.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Z572M34W\\Nord et al. - 2019 - The effect of frontoparietal paired associative st.pdf},
  journal = {Cortex},
  language = {en}
}

@article{nordlie_plesser_2009,
  title = {Towards Reproducible Descriptions of Neuronal Network Models.},
  author = {Nordlie, Eilen and Gewaltig, Marc-Oliver and Plesser, Hans Ekkehard},
  year = {2009},
  month = aug,
  volume = {5},
  pages = {e1000456},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1000456},
  abstract = {Progress in science depends on the effective exchange of ideas among scientists. New ideas can be assessed and criticized in a meaningful manner only if they are formulated precisely. This applies to simulation studies as well as to experiments and theories. But after more than 50 years of neuronal network simulations, we still lack a clear and common understanding of the role of computational models in neuroscience as well as established practices for describing network models in publications. This hinders the critical evaluation of network models as well as their re-use. We analyze here 14 research papers proposing neuronal network models of different complexity and find widely varying approaches to model descriptions, with regard to both the means of description and the ordering and placement of material. We further observe great variation in the graphical representation of networks and the notation used in equations. Based on our observations, we propose a good model description practice, composed of guidelines for the organization of publications, a checklist for model descriptions, templates for tables presenting model structure, and guidelines for diagrams of networks. The main purpose of this good practice is to trigger a debate about the communication of neuronal network models in a manner comprehensible to humans, as opposed to machine-readable model description languages. We believe that the good model description practice proposed here, together with a number of other recent initiatives on data-, model-, and software-sharing, may lead to a deeper and more fruitful exchange of ideas among computational neuroscientists in years to come. We further hope that work on standardized ways of describing\textendash and thinking about\textendash complex neuronal networks will lead the scientific community to a clearer understanding of high-level concepts in network dynamics, and will thus lead to deeper insights into the function of the brain.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\U957BDZE\\Nordlie, Gewaltig, Plesser - 2009 - Towards reproducible descriptions of neuronal network models.pdf},
  journal = {PLoS computational biology},
  keywords = {Animals,Brain,Brain: physiology,Computational Biology,Computational Biology: methods,Humans,Membrane Potentials,Membrane Potentials: physiology,Models,Nerve Net,Nerve Net: physiology,Neurological,Neurons,Neurons: physiology,Neurosciences,Neurosciences: methods,Reproducibility of Results,Synapses,Synapses: physiology},
  number = {8},
  pmid = {19662159}
}

@book{norman_perotte_2005,
  title = {Methods for Reducing Interference in the {{Complementary Learning Systems}} Model: {{Oscillating}} Inhibition and Autonomous Memory Rehearsal},
  author = {Norman, Kenneth A and Newman, Ehren L and Perotte, Adler J},
  year = {2005},
  volume = {18},
  doi = {10.1016/j.neunet.2005.08.010},
  abstract = {The stability-plasticity problem (i.e. how the brain incorporates new information into its model of the world, while at the same time preserving existing knowledge) has been at the forefront of computational memory research for several decades. In this paper, we critically evaluate how well the Complementary Learning Systems theory of hippocampo-cortical interactions addresses the stability-plasticity problem. We identify two major challenges for the model: Finding a learning algorithm for cortex and hippocampus that enacts selective strengthening of weak memories, and selective punishment of competing memories; and preventing catastrophic forgetting in the case of non-stationary environments (i.e. when items are temporarily removed from the training set). We then discuss potential solutions to these problems: First, we describe a recently developed learning algorithm that leverages neural oscillations to find weak parts of memories (so they can be strengthened) and strong competitors (so they can be punished), and we show how this algorithm outperforms other learning algorithms (CPCA Hebbian learning and Leabra at memorizing overlapping patterns. Second, we describe how autonomous re-activation of memories (separately in cortex and hippocampus) during REM sleep, coupled with the oscillating learning algorithm, can reduce the rate of forgetting of input patterns that are no longer present in the environment. We then present a simple demonstration of how this process can prevent catastrophic interference in an AB-AC learning paradigm. ?? 2005 Elsevier Ltd. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CT6BGMQJ\\Norman, Newman, Perotte - 2005 - Methods for reducing interference in the Complementary Learning Systems model Oscillating inhibition an.pdf},
  isbn = {0893-6080 (Print)},
  keywords = {Consolidation,Hippocampus,Interference,Learning algorithm,Neocortex,Neural network,Sleep,Theta Oscillations},
  pmid = {16260116}
}

@article{nowicki_siegelmann_2010,
  title = {Flexible Kernel Memory},
  author = {Nowicki, Dimitri and Siegelmann, Hava},
  year = {2010},
  volume = {5},
  issn = {19326203},
  doi = {10.1371/journal.pone.0010955},
  abstract = {This paper introduces a new model of associative memory, capable of both binary and continuous-valued inputs. Based on kernel theory, the memory model is on one hand a generalization of Radial Basis Function networks and, on the other, is in feature space, analogous to a Hopfield network. Attractors can be added, deleted, and updated on-line simply, without harming existing memories, and the number of attractors is independent of input dimension. Input vectors do not have to adhere to a fixed or bounded dimensionality; they can increase and decrease it without relearning previous memories. A memory consolidation process enables the network to generalize concepts and form clusters of input data, which outperforms many unsupervised clustering techniques; this process is demonstrated on handwritten digits from MNIST. Another process, reminiscent of memory reconsolidation is introduced, in which existing memories are refreshed and tuned with new inputs; this process is demonstrated on series of morphed faces.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CUTTDNPN\\Nowicki, Siegelmann - 2010 - Flexible kernel memory.pdf},
  journal = {PLoS ONE},
  number = {6},
  pmid = {20552013}
}

@article{nunez_srinivasan_2017,
  title = {How Attention Influences Perceptual Decision Making: {{Single}}-Trial {{EEG}} Correlates of Drift-Diffusion Model Parameters},
  author = {Nunez, Michael D and Vandekerckhove, Joachim and Srinivasan, Ramesh},
  year = {2017},
  volume = {76},
  pages = {117--130},
  issn = {10960880},
  doi = {10.1016/j.jmp.2016.03.003},
  abstract = {Perceptual decision making can be accounted for by drift-diffusion models, a class of decision-making models that assume a stochastic accumulation of evidence on each trial. Fitting response time and accuracy to a drift-diffusion model produces evidence accumulation rate and non-decision time parameter estimates that reflect cognitive processes. Our goal is to elucidate the effect of attention on visual decision making. In this study, we show that measures of attention obtained from simultaneous EEG recordings can explain per-trial evidence accumulation rates and perceptual preprocessing times during a visual decision making task. Models assuming linear relationships between diffusion model parameters and EEG measures as external inputs were fit in a single step in a hierarchical Bayesian framework. The EEG measures were features of the evoked potential (EP) to the onset of a masking noise and the onset of a task-relevant signal stimulus. Single-trial evoked EEG responses, P200s to the onsets of visual noise and N200s to the onsets of visual signal, explain single-trial evidence accumulation and preprocessing times. Within-trial evidence accumulation variance was not found to be influenced by attention to the signal or noise. Single-trial measures of attention lead to better out-of-sample predictions of accuracy and correct reaction time distributions for individual subjects.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\R2TAIWN9\\Nunez, Vandekerckhove, Srinivasan - 2017 - How attention influences perceptual decision making Single-trial EEG correlates of drift-diff.pdf},
  journal = {Journal of Mathematical Psychology},
  keywords = {Diffusion models,Electroencephalography (EEG),Hierarchical Bayesian modeling,Neurocognitive modeling,Perceptual decision making,Visual attention},
  pmid = {28435173}
}

@article{nyhus_badre_2013,
  title = {Brain {{Networks Related}} to {{Theta Oscillatory Activity During Episodic Memory Retrieval}}},
  author = {Nyhus, Erika and Badre, David},
  year = {2013},
  pages = {170--170},
  issn = {0898-929X},
  doi = {10.1162/jocn_a_01194},
  abstract = {\ding{110} Evidence from fMRI has consistently located a widespread network of frontal, parietal, and temporal lobe regions during episodic retrieval. However, the temporal limitations of the fMRI methodology have made it difficult to assess the transient network dynamics by which these distributed regions coordi-nate activity. Recent evidence suggests that beta oscillations (17\textendash 20 Hz) are important for top\textendash down control for memory suppression. However, the spatial limitations of the EEG meth-odology make it difficult to assess the relationship between these oscillatory signals and the distributed networks identified with fMRI. This study used simultaneous EEG/fMRI to identify networks related to beta oscillations during episodic retrieval. Participants studied adjectives and either imagined a scene (Place Task) or judged its pleasantness (Pleasant Task). During the recognition test, participants decided which task was performed with each word (" Old Place Task " or " Old Pleasant Task ") or " New. " EEG results revealed that posterior beta power was greater for new than old words. fMRI results revealed activ-ity in a frontal, parietal network that was greater for old than new words, consistent with prior studies. Although overall beta power increases correlated with decreased activity within a pre-dominantly parietal network, within the right dorsolateral and ventrolateral pFC, beta power correlated with BOLD activity more under conditions requiring more cognitive control and EEG/fMRI effects in the right frontal cortex correlated with BOLD activity in a frontoparietal network. Therefore, using simultaneous EEG and fMRI, the present results suggest that beta oscillations are related to postretrieval control operations in the right frontal cortex and act within a broader postretrieval control network. \ding{110}},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BXFMK66Q\\Nyhus, Badre - 2013 - Brain Networks Related to Theta Oscillatory Activity During Episodic Memory Retrieval.pdf},
  journal = {Journal of Cognitive Neuroscience}
}

@article{nyhus_curran_2011,
  title = {{{NIH Public Access}}},
  author = {Nyhus, Erika and Curran, Tim},
  year = {2011},
  volume = {34},
  pages = {1023--1035},
  doi = {10.1016/j.neubiorev.2009.12.014.Functional},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Q2CAG5GD\\Nyhus, Curran - 2011 - NIH Public Access.pdf},
  journal = {Brain Research},
  number = {7}
}

@article{ocko_giocomo_2018,
  title = {Principles Governing the Integration of Landmark and Self-Motion Cues in Entorhinal Cortical Codes for Navigation},
  author = {Ocko, Samuel A and Mallory, Caitlin S and Campbell, Malcolm G and Low, Isabel I C and Ganguli, Surya and Giocomo, Lisa M},
  year = {2018},
  volume = {21},
  pages = {1096},
  doi = {10.1038/s41593-018-0189-y},
  abstract = {T o navigate, the brain combines self-motion information with sensory landmarks to form a position estimate. The neural substrates thought to support such position coding include functionally defined medial entorhinal cortex (MEC) cell types 1 , namely grid cells 2 , head direction cells 3,4 , border cells 5,6 and speed cells 7,8. Together, these neurons generate an internal map of space, with their codes emerging from interactions between self-motion cues, such as locomotion and optic flow, and sensory cues from environmental landmarks. However, the principles by which MEC cells integrate self-motion versus landmark cues remain incompletely understood. While several works indicate that grid cell patterns rely on self-motion cues 2,9-11 , increasing evidence suggests that grid patterns emerge from a complex interaction between self-motion and sensory landmarks. For example, grid cells deform when the geometry of the environment changes, depend on environmental boundaries to maintain an error-free spatial map, and destabilize after visual landmarks are removed 2,12-19. How multisensory self-motion cues combine to drive MEC speed cells remains equally unknown. Speed cells retain speed tuning in darkness, but firing rates decrease 16 , suggesting that visual inputs calibrate their response. In addition, while previous works often ascribe the neural basis of path integration to MEC functionally defined cell types 1,2,9 , the degree to which behaviorally measured path integration position estimates and MEC neural codes follow the same cue combination principles remains unclear 13-17. Here we examine the principles by which both mouse behavior and MEC cell classes integrate self-motion with visual landmark cues (Fig. 1a). To do this, we analyzed the neural activity and behavior of mice while they explored virtual reality (VR) environments 20,21. By combining these experimental approaches with an attractor-based network model, we propose a framework for understanding how optic flow, locomotion and landmark cues interact to generate MEC firing patterns and behavioral position estimates during navigation. Results We recorded MEC neural activity in 21 mice as they navigated unidirectional VR linear tracks for water rewards (Fig. 1b-d and Supplementary Figs. 1 and 2). Spatially responsive cells were classified on the basis of their tuning in an open field (grid n = 151 of 1,136, border n = 160 of 1,136; Methods) and identified in VR by matching waveforms (781 of 1,136 cells; 96 of 151 grid cells, 97 of 160 border cells; Fig. 1b,c and Supplementary Fig. 3). Many cells had spatially stable firing fields in VR, with VR stability values similar to those observed on a real-world linear track 22 (mean stability {$\pm$} s.d.: grid, 0.40 {$\pm$} 0.24; border, 0.54 {$\pm$} 0.23; Fig. 1e,f and Supplementary Fig. 4). In VR, border cells were more stable than grid cells (Wilcoxon rank-sum P = 4.4 \texttimes{} 10-5), and the firing rate of border cells peaked near visual landmarks (repeated-measures ANOVA P = 0.016; Fig. 1e and Methods). In contrast, grid cell firing rates were more uniformly distributed across the track (repeated-measures ANOVA P = 0.18; Fig. 1e). This suggests that grid and border cells are driven by different cues in VR, with border cell firing likely determined by the locations of landmarks. We next investigated this further by manipulating the virtual environment. To ascertain the contribution of locomotion versus visual cues (optic flow and visual landmarks) to the firing patterns of MEC neurons, we put these cues into conflict by altering the gain of the transformation between the rotation of the ball and translation of the VR track (Fig. 2) 21. Manipulations followed an A-B-A{${'}$} design, with gain in B decreasing (0.5\texttimes ) or increasing (1.5\texttimes ) the visual scene translation (Fig. 2a). To avoid plasticity in the representation of the virtual environment, we limited the number of gain manipulation trials for each session (5 for gain decrease; 10 for gain increase). Grid cell (total n = 80, gain decrease n = 65, gain increase n = 56) and border cell (total n = 68, gain decrease n = 44, gain increase n = 48) firing patterns were analyzed with respect to virtual position on the track (Fig. 2b-d and Supplementary Fig. 5). To guide navigation, the nervous system integrates multisensory self-motion and landmark information. We dissected how these inputs generate spatial representations by recording entorhinal grid, border and speed cells in mice navigating virtual environments. Manipulating the gain between the animal's locomotion and the visual scene revealed that border cells responded to landmark cues while grid and speed cells responded to combinations of locomotion, optic flow and landmark cues in a context-dependent manner, with optic flow becoming more influential when it was faster than expected. A network model explained these results by revealing a phase transition between two regimes in which grid cells remain coherent with or break away from the landmark reference frame. Moreover, during path-integration-based navigation, mice estimated their position following principles predicted by our recordings. Together, these results provide a theoretical framework for understanding how landmark and self-motion cues combine during navigation to generate spatial representations and guide behavior.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\95ANKCTD\\Ocko et al. - Unknown - Principles governing the integration of landmark and self-motion cues in entorhinal cortical codes for navigatio.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\ZU8A6WUU\\Ocko et al. - 2018 - Principles governing the integration of landmark and self-motion cues in entorhinal cortical codes for navigation.pdf},
  journal = {Nature Neuroscience}
}

@book{oconnell_kelly_2018,
  title = {Bridging {{Neural}} and {{Computational Viewpoints}} on {{Perceptual Decision}}-{{Making}}},
  author = {O'Connell, Redmond G. and Shadlen, Michael N and {Wong-Lin}, Kong Fatt and Kelly, Simon P},
  year = {2018},
  volume = {41},
  doi = {10.1016/j.tins.2018.06.005},
  abstract = {Sequential sampling models have provided a dominant theoretical framework guiding computational and neurophysiological investigations of perceptual decision-making. While these models share the basic principle that decisions are formed by accumulating sensory evidence to a bound, they come in many forms that can make similar predictions of choice behaviour despite invoking fundamentally different mechanisms. The identification of neural signals that reflect some of the core computations underpinning decision formation offers new avenues for empirically testing and refining key model assumptions. Here, we highlight recent efforts to explore these avenues and, in so doing, consider the conceptual and methodological challenges that arise when seeking to infer decision computations from complex neural data.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JBMTAT6I\\O'connell et al. - 2018 - Bridging Neural and Computational Viewpoints on Perceptual Decision-Making.pdf},
  isbn = {0012-1606},
  keywords = {computational modelling,lateral intraparietal area (LIP),perceptual decision-making,sequential sampling},
  pmid = {30007746}
}

@article{oconnor_welling_2019,
  title = {{{INITIALIZED EQUILIBRIUM PROPAGATION FOR BACKPROP}}-{{FREE TRAINING}}},
  author = {O'Connor, Peter and Gavves, Efstratios and Welling, Max},
  year = {2019},
  pages = {15},
  abstract = {Deep neural networks are almost universally trained with reverse-mode automatic differentiation (a.k.a. backpropagation). Biological networks, on the other hand, appear to lack any mechanism for sending gradients back to their input neurons, and thus cannot be learning in this way. In response to this, Scellier \& Bengio (2017) proposed Equilibrium Propagation - a method for gradient-based training of neural networks which uses only local learning rules and, crucially, does not rely on neurons having a mechanism for back-propagating an error gradient. Equilibrium propagation, however, has a major practical limitation: inference involves doing an iterative optimization of neural activations to find a fixed-point, and the number of steps required to closely approximate this fixed point scales poorly with the depth of the network. In response to this problem, we propose Initialized Equilibrium Propagation, which trains a feedforward network to initialize the iterative inference procedure for Equilibrium propagation. This feed-forward network learns to approximate the state of the fixed-point using a local learning rule. After training, we can simply use this initializing network for inference, resulting in a learned feedforward network. Our experiments show that this network appears to work as well or better than the original version of Equilibrium propagation while requiring fewer steps to converge. This shows how we might go about training deep networks without using backpropagation.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GCJK27LT\\O’Connor et al. - 2019 - INITIALIZED EQUILIBRIUM PROPAGATION FOR BACKPROP-F.pdf},
  language = {en}
}

@article{oconnor_welling_2019a,
  title = {Training a {{Spiking Neural Network}} with {{Equilibrium Propagation}}},
  author = {O'Connor, Peter and Gavves, Efstratios and Welling, Max},
  year = {2019},
  pages = {8},
  abstract = {Backpropagation is almost universally used to train artificial neural networks. However, there are several reasons that backpropagation could not be plausibly implemented by biological neurons. Among these are the facts that (1) biological neurons appear to lack any mechanism for sending gradients backwards across synapses, and (2) biological ``spiking'' neurons emit binary signals, whereas back-propagation requires that neurons communicate continuous values between one another. Recently Scellier and Bengio [2017], demonstrated an alternative to backpropagation, called Equilibrium Propagation, wherein gradients are implicitly computed by the dynamics of the neural network, so that neurons do not need an internal mechanism for backpropagation of gradients. This provides an interesting solution to problem (1). In this paper, we address problem (2) by proposing a way in which Equilibrium Propagation can be implemented with neurons which are constrained to just communicate binary values at each time step. We show that with appropriate step-size annealing, we can converge to the same fixed-point as a real-valued neural network, and that with predictive coding, we can make this convergence much faster. We demonstrate that the resulting model can be used to train a spiking neural network using the update scheme from Equilibrium propagation.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XDV858P9\\O’Connor et al. - Training a Spiking Neural Network with Equilibrium.pdf},
  language = {en}
}

@book{okeefe_burgess_1996,
  title = {Geometric Determinants of the Place Fields of Hippocampal Neurons.},
  author = {O'Keefe, J and Burgess, N},
  year = {1996},
  volume = {381},
  doi = {10.1038/381425a0},
  abstract = {The human hippocampus has been implicated in memory, in particular episodic or declarative memory. In rats, hippocampal lesions cause selective spatial deficits, and hippocampal complex spike cells (place cells) exhibit spatially localized firing, suggesting a role in spatial memory, although broader functions have also been suggested. Here we report the identification of the environmental features controlling the location and shape of the receptive fields (place fields) of the place cells. This was done by recording from the same cell in four rectangular boxes that differed solely in the length of one or both sides. Most of our results are explained by a model in which the place field is formed by the summation of gaussian tuning curves, each oriented perpendicular to a box wall and peaked at a fixed distance from it.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5RMEV97M\\O'Keefe, Burgess - 1996 - Geometric determinants of the place fields of hippocampal neurons.pdf},
  isbn = {0028-0836 (Print)\$\textbackslash backslash\$r0028-0836 (Linking)},
  pmid = {8632799}
}

@article{oleary_sloutsky_2017,
  title = {Carving {{Metacognition}} at {{Its Joints}}: {{Protracted Development}} of {{Component Processes}}},
  author = {O'Leary, Allison P and Sloutsky, Vladimir M},
  year = {2017},
  volume = {88},
  pages = {1015--1032},
  issn = {14678624},
  doi = {10.1111/cdev.12644},
  abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein-protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-\$\textbackslash alpha\$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD {$\leq$} 2.0 \{\textbackslash AA\} for the interface backbone atoms) increased from 21\{\%\} with default Glide SP settings to 58\{\%\} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63\{\%\} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40\{\%\} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MTEE4JR6\\O'Leary, Sloutsky - 2017 - Carving Metacognition at Its Joints Protracted Development of Component Processes.pdf},
  journal = {Child Development},
  number = {3},
  pmid = {25246403}
}

@article{olejarczyk_zappasodi_2017,
  title = {Comparison of Connectivity Analyses for Resting State {{EEG}} Data},
  author = {Olejarczyk, Elzbieta and Marzetti, Laura and Pizzella, Vittorio and Zappasodi, Filippo},
  year = {2017},
  volume = {14},
  pages = {036017},
  issn = {1741-2560},
  doi = {10.1088/1741-2552/aa6401},
  abstract = {Objective. In the present work, a nonlinear measure (transfer entropy, TE) was used in a multivariate approach for the analysis of effective connectivity in high density resting state EEG data in eyes open and eyes closed. Advantages of the multivariate approach in comparison to the bivariate one were tested. Moreover, the multivariate TE was compared to an effective linear measure, i.e. directed transfer function (DTF). Finally, the existence of a relationship between the information transfer and the level of brain synchronization as measured by phase synchronization value (PLV) was investigated. Approach. The comparison between the connectivity measures, i.e. bivariate versus multivariate TE, TE versus DTF, TE versus PLV, was performed by means of statistical analysis of indexes based on graph theory. Main results. The multivariate approach is less sensitive to false indirect connections with respect to the bivariate estimates. The multivariate TE differentiated better between eyes closed and eyes open conditions compared to DTF. Moreover, the multivariate TE evidenced non-linear phenomena in information transfer, which are not evidenced by the use of DTF. We also showed that the target of information flow, in particular the frontal region, is an area of greater brain synchronization. Significance. Comparison of different connectivity analysis methods pointed to the advantages of nonlinear methods, and indicated a relationship existing between the flow of information and the level of synchronization of the brain. Keywords:},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FBZ97AUF\\Olejarczyk et al. - 2017 - Comparison of connectivity analyses for resting state EEG data.pdf},
  journal = {Journal of Neural Engineering},
  keywords = {directed transfer function,eeg,entropy,functional and effective connectivity,graph theory,multivariate transfer,phase-locking value,resting state},
  number = {3},
  pmid = {28378705}
}

@article{olsen_ryan_2015,
  title = {The {{Role}} of {{Relational Binding}} in {{Item Memory}}: {{Evidence}} from {{Face Recognition}} in a {{Case}} of {{Developmental Amnesia}}},
  author = {Olsen, Rosanna K and Lee, Yunjo and Kube, Jana and Rosenbaum, R Shayna and Grady, Cheryl L and Moscovitch, Morris and Ryan, Jennifer D},
  year = {2015},
  doi = {10.1523/JNEUROSCI.3987-14.2015},
  abstract = {Current theories state that the hippocampus is responsible for the formation of memory representations regarding relations, whereas extrahip-pocampal cortical regions support representations for single items. However, findings of impaired item memory in hippocampal amnesics suggest a more nuanced role for the hippocampus in item memory. The hippocampus may be necessary when the item elements need to be bound within and across episodes to form a lasting representation that can be used flexibly. The current investigation was designed to test this hypothesis in face recognition. H.C., an individual who developed with a compromised hippocampal system, and control participants incidentally studied individual faces that either varied in presentation viewpoint across study repetitions or remained in a fixed viewpoint across the study repetitions. Eye movements were recorded during encoding and participants then completed a surprise recognition memory test. H.C. demonstrated altered face viewing during encoding. Although the overall number of fixations made by H.C. was not significantly different from that of controls, the distribution of her viewing was primarily directed to the eye region. Critically, H.C. was significantly impaired in her ability to subsequently recognize faces studied from variable viewpoints, but demonstrated spared performance in recognizing faces she encoded from a fixed viewpoint, implicating a relationship between eye movement behavior in the service of a hippocampal binding function. These findings suggest that a compromised hippocampal system disrupts the ability to bind item features within and across study repetitions, ultimately disrupting recognition when it requires access to flexible relational representations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9U9LEZJM\\Olsen et al. - 2015 - The Role of Relational Binding in Item Memory Evidence from Face Recognition in a Case of Developmental Amnesia.pdf},
  keywords = {amnesia,eye movements,faces,hippocampus,memory,viewpoint}
}

@article{omidvarnia_boashash_2011,
  title = {Analysis of the Time-Varying Cortical Neural Connectivity in the Newborn {{EEG}}: {{A}} Time-Frequency Approach},
  author = {Omidvarnia, Amir and Mesbah, Mostefa and O'Toole, John M. and Colditz, Paul and Boashash, Boualem},
  year = {2011},
  pages = {179--182},
  doi = {10.1109/WOSSPA.2011.5931445},
  abstract = {Relationships between cortical neural recordings as a representation of functional connectivity between cortical brain regions were quantified using different time-frequency criteria. Among these, Partial Directed Coherence (PDC) and Directed Transfer Function (DTF) and their extensions have found wide acceptance. This paper aims to assess and compare the performance of these two connectivity measures that are based on time-varying multivariate AR modeling. The time-varying parameters of the AR model are estimated using an Adaptive AR modeling (AAR) approach and a short-time based stationary approach. The performance of these two approaches is compared using both simulated signal and a multichannel newborn EEG recording. The results show that the time-varying PDC outperforms the time-varying DTF measure. The results also point to the limitation of the AAR algorithm in tracking rapid parameter changes and the drawback of the short-time approach in providing high resolution time-frequency coherence functions. However, it can be demonstrated that time-varying MVAR representations of the cortical connectivity will potentially lead to better understanding of non-symmetric relations between EEG channels.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\P7YRHMPR\\Omidvarnia et al. - 2011 - Analysis of the time-varying cortical neural connectivity in the newborn EEG A time-frequency approach.pdf},
  journal = {7th International Workshop on Systems, Signal Processing and their Applications, WoSSPA 2011}
}

@article{onslow_newman_2014,
  title = {{{DC}}-Shifts in Amplitude in-Field Generated by an Oscillatory Interference Model of Grid Cell Firing.},
  author = {Onslow, Angela C E and Hasselmo, Michael E and Newman, Ehren L},
  year = {2014},
  month = jan,
  volume = {8},
  pages = {1},
  issn = {1662-5137},
  doi = {10.3389/fnsys.2014.00001},
  abstract = {Oscillatory interference models propose a mechanism by which the spatial firing pattern of grid cells can arise from the interaction of multiple oscillators that shift in relative phase. These models produce aspects of the physiological data such as the phase precession dynamics observed in grid cells. However, existing oscillatory interference models did not predict the in-field DC shifts in the membrane potential of grid cells that have been observed during intracellular recordings in navigating animals. Here, we demonstrate that DC shifts can be generated in an oscillatory interference model when half-wave rectified oscillatory inputs are summed by a leaky integrate-and-fire neuron with a long membrane decay constant (100 ms). The non-linear mean of the half-wave rectified input signal is reproduced in the grid cell's membrane potential trace producing the DC shift within field. For shorter values of the decay constant integration is more effective if the input signal, comprising input from 6 head direction selective populations, is temporally spread during in-field epochs; this requires that the head direction selective populations act as velocity controlled oscillators with baseline oscillations that are phase offset from one another. The resulting simulated membrane potential matches several properties of the empirical intracellular recordings, including: in-field DC-shifts, theta-band oscillations, phase precession of both membrane potential oscillations and grid cell spiking activity relative to network theta and a stronger correlation between DC-shift amplitude and firing-rate than between theta-band oscillation amplitude and firing-rate. This work serves to demonstrate that oscillatory interference models can account for the DC shifts in the membrane potential observed during intracellular recordings of grid cells without the need to appeal to attractor dynamics.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CBYF9J3S\\Onslow, Hasselmo, Newman - 2014 - DC-shifts in amplitude in-field generated by an oscillatory interference model of grid cell firing.pdf},
  journal = {Frontiers in systems neuroscience},
  pmid = {24478639}
}

@article{oostenveld_schoffelen_2011,
  title = {{{FieldTrip}}: {{Open}} Source Software for Advanced Analysis of {{MEG}}, {{EEG}}, and Invasive Electrophysiological Data},
  author = {Oostenveld, Robert and Fries, Pascal and Maris, Eric and Schoffelen, Jan Mathijs},
  year = {2011},
  volume = {2011},
  issn = {16875265},
  doi = {10.1155/2011/156869},
  abstract = {This paper describes FieldTrip, an open source software package that we developed for the analysis of MEG, EEG, and other electrophysiological data. The software is implemented as a MATLAB toolbox and includes a complete set of consistent and user-friendly high-level functions that allow experimental neuroscientists to analyze experimental data. It includes algorithms for simple and advanced analysis, such as time-frequency analysis using multitapers, source reconstruction using dipoles, distributed sources and beamformers, connectivity analysis, and nonparametric statistical permutation tests at the channel and source level. The implementation as toolbox allows the user to perform elaborate and structured analyses of large data sets using the MATLAB command line and batch scripting. Furthermore, users and developers can easily extend the functionality and implement new algorithms. The modular design facilitates the reuse in other software packages.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4B3N97WI\\Oostenveld et al. - 2011 - FieldTrip Open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data.pdf},
  journal = {Computational Intelligence and Neuroscience},
  pmid = {21253357}
}

@article{oota_s_2018,
  title = {{{fMRI Semantic Category Decoding}} Using {{Linguistic Encoding}} of {{Word Embeddings}}},
  author = {Oota, Subba Reddy and Manwani, Naresh and S, Bapi Raju},
  year = {2018},
  abstract = {The dispute of how the human brain represents conceptual knowledge has been argued in many scientific fields. Brain imaging studies have shown that the spatial patterns of neural activation in the brain are correlated with thinking about different semantic categories of words (for example, tools, animals, and buildings) or when viewing the related pictures. In this paper, we present a computational model that learns to predict the neural activation captured in functional magnetic resonance imaging (fMRI) data of test words. Unlike the models with hand-crafted features that have been used in the literature, in this paper we propose a novel approach wherein decoding models are built with features extracted from popular linguistic encodings of Word2Vec, GloVe, Meta-Embeddings in conjunction with the empirical fMRI data associated with viewing several dozen concrete nouns. We compared these models with several other models that use word features extracted from FastText, Randomly-generated features, Mitchell's 25 features [1]. The experimental results show that the predicted fMRI images using Meta-Embeddings meet the state-of-the-art performance. Although models with features from GloVe and Word2Vec predict fMRI images similar to the state-of-the-art model, model with features from Meta-Embeddings predicts significantly better. The proposed scheme that uses popular linguistic encoding offers a simple and easy approach for semantic decoding from fMRI experiments.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ITJDVTAR\\Reddy Oota, Manwani, Bapi - Unknown - fMRI Semantic Category Decoding using Linguistic Encoding of Word Embeddings.pdf}
}

@article{openaccesscitation;brea_senn_2016,
  title = {Prospective {{Coding}} by {{Spiking Neurons}}},
  author = {Open Access Citation ; Brea, J and Ga{\'a}l, A T and Urbanczik, R and Senn, W},
  year = {2016},
  volume = {12},
  pages = {1005003},
  doi = {10.1371/journal.pcbi.1005003},
  abstract = {Animals learn to make predictions, such as associating the sound of a bell with upcoming feeding or predicting a movement that a motor command is eliciting. How predictions are realized on the neuronal level and what plasticity rule underlies their learning is not well understood. Here we propose a biologically plausible synaptic plasticity rule to learn predictions on a single neuron level on a timescale of seconds. The learning rule allows a spiking two-compartment neuron to match its current firing rate to its own expected future discounted firing rate. For instance, if an originally neutral event is repeatedly followed by an event that elevates the firing rate of a neuron, the originally neutral event will eventually also elevate the neuron's firing rate. The plasticity rule is a form of spike timing dependent plasticity in which a presynaptic spike followed by a postsynaptic spike leads to potentiation. Even if the plasticity window has a width of 20 milliseconds, associations on the time scale of seconds can be learned. We illustrate prospective coding with three examples: learning to predict a time varying input, learning to predict the next stimulus in a delayed paired-associate task and learning with a recurrent network to reproduce a temporally compressed version of a sequence. We discuss the potential role of the learning mechanism in classical trace conditioning. In the special case that the signal to be predicted encodes reward, the neuron learns to predict the discounted future reward and learning is closely related to the temporal difference learning algorithm TD({$\lambda$}). Author Summary Sensory inputs are often predictable. Lightning is followed by thunder, a falling object causes noise when hitting the ground, our skin gets wet when we jump into the water. Humans learn regularities like these without effort. Learned predictions allow to cover the ears in anticipation of thunder or close the eyes just before an object hits the ground and breaks into pieces. What changes in the brain when new predictions are learned? In this article, we present a mathematical model and computer simulations of the idea that the activity of a single neuron represents expected future events. Such a prospective coding can be learned in a neuron that receives input from the memory trace of a first event (e.g.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\R8STEGCS\\Open Access Citation Brea et al. - 2016 - Prospective Coding by Spiking Neurons.pdf},
  journal = {PLoS Comput Biol},
  number = {6}
}

@article{opris_deadwyler_2015,
  title = {Prefrontal Cortical Recordings with Biomorphic {{MEAs}} Reveal Complex Columnar-Laminar Microcircuits for {{BCI}}/{{BMI}} Implementation},
  author = {Opris, Ioan and Fuqua, Joshua L and Gerhardt, Greg A and Hampson, Robert E and Deadwyler, Samuel A},
  year = {2015},
  volume = {244},
  pages = {104--113},
  issn = {1872678X},
  doi = {10.1016/j.jneumeth.2014.05.029},
  abstract = {The mammalian prefrontal cortex known as the seat of high brain functions uses a six layer distribution of minicolumnar neurons to coordinate the integration of sensory information and the selection of relevant signals for goal driven behavior. To reveal the complex functionality of these columnar microcircuits we employed simultaneous recordings with several configurations of biomorphic microelectrode arrays (MEAs) within cortical layers in adjacent minicolumns, in four nohuman primates (NHPs) performing a delayed match-to-sample (DMS) visual discrimination task. We examined: (1) the functionality of inter-laminar, and inter-columnar interactions between pairs of cells in the same or different minicolumns by use of normalized cross-correlation histograms (CCH), (2) the modulation of glutamate concentration in layer 2/3, and (3) the potential interactions within these microcircuits. The results demonstrate that neurons in both infra-granular and supra-granular layers interact through inter-laminar loops, as well as through intra-laminar to produce behavioral response signals. These results provide new insights into the manner in which prefrontal cortical microcircuitry integrates sensory stimuli used to provide behaviorally relevant signals that may be implemented in brain computer/machine interfaces (BCI/BMIs) during performance of the task.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EPXFCGHB\\Opris et al. - 2015 - Prefrontal cortical recordings with biomorphic MEAs reveal complex columnar-laminar microcircuits for BCIBMI imple.pdf},
  journal = {Journal of Neuroscience Methods},
  keywords = {Columnar processing,Executive control,Glutamate modulation,Microcircuits,Nonhuman primates,Prefrontal cortex},
  pmid = {24954713}
}

@article{orchard_ji_2013,
  title = {Does the Entorhinal Cortex Use the {{Fourier}} Transform?},
  author = {Orchard, Jeff and Yang, Hao and Ji, Xiang},
  year = {2013},
  volume = {7},
  pages = {179},
  issn = {1662-5188},
  doi = {10.3389/fncom.2013.00179},
  abstract = {Some neurons in the entorhinal cortex (EC) fire bursts when the animal occupies locations organized in a hexagonal grid pattern in their spatial environment. Place cells have also been observed, firing bursts only when the animal occupies a particular region of the environment. Both of these types of cells exhibit theta-cycle modulation, firing bursts in the 4-12 Hz range. Grid cells fire bursts of action potentials that precess with respect to the theta cycle, a phenomenon dubbed "theta precession." Various models have been proposed to explain these phenomena, and how they relate to navigation. Among the most promising are the oscillator interference models. The bank-of-oscillators model proposed by Welday et al. (2011) exhibits all these features. However, their simulations are based on theoretical oscillators, and not implemented entirely with spiking neurons. We extend their work in a number of ways. First, we place the oscillators in a frequency domain and reformulate the model in terms of Fourier theory. Second, this perspective suggests a division of labor for implementing spatial maps: position vs. map layout. The animal's position is encoded in the phases of the oscillators, while the spatial map shape is encoded implicitly in the weights of the connections between the oscillators and the read-out nodes. Third, it reveals that the oscillator phases all need to conform to a linear relationship across the frequency domain. Fourth, we implement a partial model of the EC using spiking leaky integrate-and-fire (LIF) neurons. Fifth, we devise new coupling mechanisms, enlightened by the global phase constraint, and show they are capable of keeping spiking neural oscillators in consistent formation. Our model demonstrates place cells, grid cells, and phase precession. The Fourier model also gives direction for future investigations, such as integrating sensory feedback to combat drift, or explaining why grid cells exist at all.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GUHYTNU9\\Orchard, Yang, Ji - 2013 - Does the entorhinal cortex use the Fourier transform.pdf},
  journal = {Frontiers in computational neuroscience},
  keywords = {computational neuroscience,doi,entorhinal cortex,fncom,fourier transform,ginal research article,path integra,published},
  number = {December},
  pmid = {24376415}
}

@article{oreilly_busby_2002,
  title = {Generalizable Relational Binding from Coarse-Coded Distributed Representations},
  author = {O'Reilly, Randall C and Busby, R.S.},
  year = {2002},
  volume = {1},
  pages = {75--82},
  issn = {1049-5258},
  abstract = {We present a model of binding of relationship information in a spatial\$\textbackslash backslash\$n\$\textbackslash backslash\$ndomain (e.g., square above triangle) that uses low-order coarse-coded\$\textbackslash backslash\$n\$\textbackslash backslash\$nconjunctive representations instead of more popular temporal synchrony\$\textbackslash backslash\$n\$\textbackslash backslash\$nmechanisms. Supporters of temporal synchrony argue that conjunctive\$\textbackslash backslash\$n\$\textbackslash backslash\$nrepresentations lack both efficiency (i.e., combinatorial numbers\$\textbackslash backslash\$nof units\$\textbackslash backslash\$n\$\textbackslash backslash\$nare required) and systematicity (i.e., the resulting representations\$\textbackslash backslash\$nare\$\textbackslash backslash\$n\$\textbackslash backslash\$noverly specific and thus do not support generalization to novel exemplars).\$\textbackslash backslash\$n\$\textbackslash backslash\$nTo counter these claims, we show that our model: a) uses far\$\textbackslash backslash\$n\$\textbackslash backslash\$nfewer hidden units than the number of conjunctions represented, by\$\textbackslash backslash\$nusing\$\textbackslash backslash\$n\$\textbackslash backslash\$ncoarse-coded, distributed representations where each unit has a broad\$\textbackslash backslash\$n\$\textbackslash backslash\$ntuning curve through high-dimensional conjunction space, and b) is\$\textbackslash backslash\$ncapable\$\textbackslash backslash\$n\$\textbackslash backslash\$nof considerable generalization to novel inputs.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HV98GC7G\\O'Reilly, Busby - 2002 - Generalizable relational binding from coarse-coded distributed representations.pdf},
  journal = {Advances in neural information processing systems}
}

@article{oreilly_cohen_2002,
  title = {Prefrontal Cortex and Dynamic Categorization Tasks: Representational Organization and Neuromodulatory Control.},
  author = {O'Reilly, Randall C and Noelle, David C and Braver, Todd S and Cohen, Jonathan D},
  year = {2002},
  volume = {12},
  pages = {246--257},
  issn = {1047-3211},
  doi = {10.1093/cercor/12.3.246},
  abstract = {We present a computational model of the intradimensional/ extradimensional (ID/ED) task (a variant of the Wisconsin card sorting task) that simulates the performance of intact and frontally lesioned monkeys on three different kinds of rule changes (Dias et al., 1997, J Neurosci 17:9285-9297). Although Dias et al. interpret the lesion data as supporting a model in which prefrontal cortex is organized into different processing functions, our model suggests an alternative account based on representational content. A key aspect of the model is that prefrontal cortex representations are organized according to different levels of abstraction, with orbital areas encoding more specific featural information and dorsolateral areas encoding more abstract dimensional information. This representational scheme of the model is integrated with two additional key elements: (i) activation-based working memory representations controlled by a dynamic gating mechanism that simulates the hypothesized phasic actions of dopaminergic neuromodulation in prefrontal cortex, which acts to stabilize or destabilize frontal representations based on success in the task; and (ii) a weight-based associative learning system simulating posterior cortex and other subcortical areas, where the stimulus-response mappings are encoded. Frontal cortex contributes to the task via top-down activation-based biasing of task-appropriate features and dimensions in this posterior cortex system - this top-down biasing is specifically important for overcoming prepotent associations after a sorting rule reverses. The ability of the model to capture the double-dissociation observed by Dias et al. with orbital versus dorsolateral lesions supports the validity of these principles, many of which have also been useful in accounting for other frontal phenomena.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GL8PLHS7\\O'Reilly et al. - 2002 - Prefrontal cortex and dynamic categorization tasks representational organization and neuromodulatory control.pdf},
  journal = {Cerebral cortex (New York, N.Y. : 1991)},
  number = {3},
  pmid = {11839599}
}

@article{oreilly_frank_2003,
  title = {Making {{Working Memory Work}}: {{A Computational Model}} of {{Learning}} in the {{Prefrontal Cortex}} and {{Basal Ganglia}}},
  author = {O'Reilly, Randall C and Frank, Michael J.},
  year = {2003},
  volume = {328},
  pages = {283--328},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QHKCLJUC\\O'Reilly, Frank - 2003 - Making Working Memory Work A Computational Model of Learning in the Prefrontal Cortex and Basal Ganglia.pdf},
  keywords = {juergen},
  number = {ICS-03-03}
}

@incollection{oreilly_herd_2019,
  title = {Computational Models of Motivated Frontal Function},
  booktitle = {Handbook of {{Clinical Neurology}}},
  author = {O'Reilly, Randall C. and Russin, Jacob and Herd, Seth A.},
  year = {2019},
  volume = {163},
  pages = {317--332},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-0-12-804281-6.00017-3},
  abstract = {Computational models of frontal function have made important contributions to understanding how the frontal lobes support a wide range of important functions, in their interactions with other brain areas including, critically, the basal ganglia (BG). We focus here on the specific case of how different frontal areas support goal-directed, motivated decision-making, by representing three essential types of information: possible plans of action (in more dorsal and lateral frontal areas), affectively significant outcomes of those action plans (in ventral, medial frontal areas including the orbital frontal cortex), and the overall utility of a given plan compared to other possible courses of action (in anterior cingulate cortex).},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5B86B3IW\\O’Reilly et al. - 2019 - Computational models of motivated frontal function.pdf},
  isbn = {978-0-12-804281-6},
  language = {en}
}

@article{oreilly_jilk_2013,
  title = {Recurrent Processing during Object Recognition},
  author = {O'Reilly, Randall C and Wyatte, Dean and Herd, Seth and Mingus, Brian and Jilk, David J.},
  year = {2013},
  volume = {4},
  pages = {1--14},
  issn = {16641078},
  doi = {10.3389/fpsyg.2013.00124},
  abstract = {How does the brain learn to recognize objects visually, and perform this difficult feat robustly in the face of many sources of ambiguity and variability? We present a computational model based on the biology of the relevant visual pathways that learns to reliably recognize 100 different object categories in the face of naturally occurring variability in location, rotation, size, and lighting. The model exhibits robustness to highly ambiguous, partially occluded inputs. Both the unified, biologically plausible learning mechanism and the robustness to occlusion derive from the role that recurrent connectivity and recurrent processing mechanisms play in the model. Furthermore, this interaction of recurrent connectivity and learning predicts that high-level visual representations should be shaped by error signals from nearby, associated brain areas over the course of visual learning. Consistent with this prediction, we show how semantic knowledge about object categories changes the nature of their learned visual representations, as well as how this representational shift supports the mapping between perceptual and conceptual knowledge. Altogether, these findings support the potential importance of ongoing recurrent processing throughout the brain's visual system and suggest ways in which object recognition can be understood in terms of interactions within and between processes over time.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WSQCQWUS\\O'Reilly et al. - 2013 - Recurrent processing during object recognition.pdf},
  journal = {Frontiers in Psychology},
  keywords = {Computational model,Feedback,Object recognition,Recurrent processing,Winners-take-all mechanism},
  number = {APR},
  pmid = {23554596}
}

@article{oreilly_ketz_2014,
  title = {Complementary Learning Systems},
  author = {O'Reilly, Randall C and Bhattacharyya, Rajan and Howard, Michael D. and a Ketz, Nicholas},
  year = {2014},
  volume = {38},
  pages = {1229--1248},
  issn = {03640213},
  doi = {10.1111/j.1551-6709.2011.01214.x},
  abstract = {This paper reviews the fate of the central ideas behind the complementary learning systems (CLS) framework as originally articulated in McClelland, McNaughton, and O'Reilly (1995). This framework explains why the brain requires two differentially specialized learning and memory systems, and it nicely specifies their central properties (i.e., the hippocampus as a sparse, pattern-separated system for rapidly learning episodic memories, and the neocortex as a distributed, overlapping system for gradually integrating across episodes to extract latent semantic structure). We review the application of the CLS framework to a range of important topics, including the following: the basic neural processes of hippocampal memory encoding and recall, conjunctive encoding, human recognition memory, consolidation of initial hippocampal learning in cortex, dynamic modulation of encoding versus recall, and the synergistic interactions between hippocampus and neocortex. Overall, the CLS framework remains a vital theoretical force in the field, with the empirical data over the past 15 years generally confirming its key principles.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IJFVT9WX\\O'Reilly et al. - 2014 - Complementary learning systems.pdf},
  journal = {Cognitive Science},
  keywords = {Consolidation,Hippocampus,Learning,Memory,Neocortex,Neural network models},
  number = {6},
  pmid = {22141588}
}

@incollection{oreilly_kriete_2014,
  title = {How {{Limited Systematicity Emerges}} : {{A Computational Cognitive Neuroscience Approach}}},
  booktitle = {The {{Architecture}} of {{Cognition}}},
  author = {O'Reilly, Randall C and Calvo, In Paco and Eds, John Symons and Fodor, Rethinking and Petrov, Alex A and Cohen, Jonathan D and Lebiere, Christian J and Herd, Seth A and Kriete, Trenton},
  year = {2014},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5SCXKLNW\\O'Reilly et al. - 2014 - How Limited Systematicity Emerges A Computational Cognitive Neuroscience Approach.pdf}
}

@book{oreilly_munakata_2000,
  title = {Computational {{Explorations}} in {{Cognitive Neuroscience}}: {{Understanding}} the {{Mind}} by {{Simulating}} the {{Brain}}},
  author = {O'Reilly, Randall C and Munakata, Yuko},
  year = {2000},
  edition = {Second},
  publisher = {{MIT Press}},
  address = {{Cambridge, MA}},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AHFBTC43\\O'Reilly, Munakata - 2000 - Computational Explorations in Cognitive Neuroscience Understanding the Mind by Simulating the Brain.pdf}
}

@incollection{oreilly_munakata_2003,
  title = {Psychological {{Function}} in {{Computational Models}} of {{Neural Networks}}},
  booktitle = {Handbook of {{Psychology}}},
  author = {O'Reilly, Randall C. and Munakata, Yuko},
  editor = {Weiner, Irving B.},
  year = {2003},
  month = apr,
  pages = {wei0322},
  publisher = {{John Wiley \& Sons, Inc.}},
  address = {{Hoboken, NJ, USA}},
  doi = {10.1002/0471264385.wei0322},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LIJFZ7HM\\O'Reilly and Munakata - 2003 - Psychological Function in Computational Models of .pdf},
  isbn = {978-0-471-26438-5},
  language = {en}
}

@book{oreilly_munakata_2012,
  title = {Computational {{Cognitive Neuroscience}}},
  author = {O'Reilly, Randall C and Munakata, Y},
  year = {2012},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2JKR4Y7Z\\O'Reilly, Munakata - 2012 - Computational Cognitive Neuroscience.pdf}
}

@article{oreilly_oreilly_1997,
  title = {The {{LEABRA}} Model of Neural Interactions and Learning in the Neocortex},
  author = {O'Reilly, Randall C},
  year = {1997},
  volume = {57},
  pages = {6792},
  abstract = {There is evidence that the specialized neural processing systems in the neocortex, which are responsible for much of human cognition, arise from the action of a relatively general-purpose learning mechanism. I propose that such a neocortical learning mechanical can be best understood as the combination of error-driven and self-organizing (Hebbian associative) learning. This model of neoconical learning, called LEABRA (local, error-driven and associative, biologically realistic algorithm), is computationally powerful, has important implications for psychological models, and is biologically feasible. The thesis begins with an evaluation of the strengths and limitations of current neural network learning algorithms as models of a neoconical learning mechanism according to psychological, biological, and computational criteria. I argue the error-driven (e.g., backpropagation) learning is a reasonable computational and psychological model, but it is biologically implausible. I show that backpropagation can be implemented in a biologically plausible fashion by using interactive (bi-directional, recurrent) activation flow, which is known to exist in the neocortex, and has been important for accounting for psychological data. However, the interactivity required for biological and psychological plausibility significantly impairs the ability to respond systematically to novel stimuli, making it still a bad psychological model (e.g., for nonword reading). I propose that the neocortex solves this problem by using inhibitory activity regulation and Hebbian associative learning, the computational properties of which have been explored in the context of self-organizing learning models. I show that by introducing these properties into an interactive (biologically plausible) error-driven network, one obtains a model of neocortical learning that: (1) provides a clear computational role for a number of biological features of the neocortex; (2) behaves systematically on novel stimuli, and exhibits transfer to novel tasks; (3) learns rapidly in networks with many hidden layers; (4) provides flexible access to learned knowledge; (5) shows promise in accounting for psychological phenomena such as the U-shaped curve in over-regularization of the past-tense inflection; (6) has a number of other nice properties. (PsycINFO Database Record (c) 2007 APA, all rights reserved)},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7CLTYTXS\\O'Reilly - 1997 - The LEABRA model of neural interactions and learning in the neocortex.pdf},
  journal = {Dissertation Abstracts International: Section B: The Sciences and Engineering},
  keywords = {Algorithms,Cerebral Cortex,Cognitive Processes 2340,error-driven \& self-organizing learning algorithm,Errors,Learning,Neural Networks,Physiological Psychology \& Neuroscience 2500},
  pmid = {1000185228}
}

@article{oreilly_oreilly_2000,
  title = {Generalization in {{Interactive Networks}}: {{The Benefits}} of {{Inhibitory Competition}} and {{Hebbian Learning}}},
  author = {O'Reilly, Randall C},
  year = {2000},
  volume = {1241},
  pages = {1199--1241},
  abstract = {Computational models in cognitive neuroscience should ideally use biological properties and pow-erful computational principles to produce behavior consistent with psychological findings. Error-driven backpropagation is computationally powerful, and has proven useful for modeling a range of psycho-logical data, but is not biologically plausible. Several approaches to implementing backpropagation in a biologically plausible fashion converge on the idea of using bidirectional activation propagation in interactive networks to convey error signals. This paper demonstrates two main points about these error-driven interactive networks: (a) they generalize poorly due to attractor dynamics that interfere with the network's ability to systematically produce novel combinatorial representations in response to novel inputs; and (b) this generalization problem can be remedied by adding two widely used mechanistic principles, inhibitory competition and Hebbian learning, that can be independently motivated for a va-riety of biological, psychological and computational reasons. Simulations using the Leabra algorithm, which combines the generalized recirculation (GeneRec) biologically-plausible error-driven learning al-gorithm with inhibitory competition and Hebbian learning, show that these mechanisms can result in good generalization in interactive networks. These results support the general conclusion that cognitive neuroscience models that incorporate the core mechanistic principles of interactivity, inhibitory com-petition, and error-driven and Hebbian learning satisfy a wider range of biological, psychological and computational constraints than models employing a subset of these principles.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KC9XQ2EG\\O'Reilly - 2000 - Generalization in Interactive Networks The Benefits of Inhibitory Competition and Hebbian Learning.pdf}
}

@article{oreilly_oreilly_2006,
  title = {Biologically Based Computational Models of High-Level Cognition},
  author = {O'Reilly, Randall C},
  year = {2006},
  volume = {314},
  pages = {91--94},
  issn = {0036-8075},
  doi = {10.1126/science.1127242},
  abstract = {Computer models based on the detailed biology of the brain can help us understand the myriad complexities of human cognition and intelligence. Here, we review models of the higher level aspects of human intelligence, which depend critically on the prefrontal cortex and associated subcortical areas. The picture emerging from a convergence of detailed mechanistic models and more abstract functional models represents a synthesis between analog and digital forms of computation. Specifically, the need for robust active maintenance and rapid updating of information in the prefrontal cortex appears to be satisfied by bistable activation states and dynamic gating mechanisms. These mechanisms are fundamental to digital computers and may be critical for the distinctive aspects of human intelligence.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BB2RMQYY\\O'Reilly - 2006 - Biologically based computational models of high-level cognition.pdf},
  journal = {Science},
  number = {5796},
  pmid = {17023651}
}

@article{oreilly_oreilly_2010,
  title = {The {{What}} and How of Prefrontal Cortical Organization},
  author = {O'Reilly, Randall C},
  year = {2010},
  volume = {33},
  pages = {355--361},
  issn = {01662236},
  doi = {10.1016/j.tins.2010.05.002},
  abstract = {How is the prefrontal cortex (PFC) organized such that it is capable of making people more flexible and in control of their behavior? Is there any systematic organization across the many diverse areas that comprise the PFC, or is it uniquely adaptive such that no fixed representational structure can develop? Going against the current tide, this paper argues that there is indeed a systematic organization across PFC areas, with an important functional distinction between ventral and dorsal regions characterized as processing What versus How information, respectively. This distinction has implications for the rostro-caudal and medial-lateral axes of organization as well. The resulting large-scale functional map of PFC could prove useful in integrating diverse data, and in generating novel predictions. ?? 2010 Elsevier Ltd.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MKBNTWVH\\O'Reilly - 2010 - The What and how of prefrontal cortical organization(2).pdf},
  journal = {Trends in Neurosciences},
  number = {8},
  pmid = {20573407}
}

@article{oreilly_oreilly_2011,
  title = {Surely {{You Must All}} Be {{Joking}}: {{An Outsider}}'s {{Critique}} of {{Quantum Physics}}},
  author = {O'Reilly, Randall C},
  year = {2011},
  pages = {42},
  abstract = {A critique of the state of current quantum theory in physics is presented, based on a perspective outside the normal physics training. From this perspective, the acceptance of quantum nonlocality seems unwarranted, and the fundamental assumptions that give rise to it in the first place seem questionable, based on the current status of the quantum theory of light. The relevant data can instead be accounted for using physically motivated local models, based on detailed properties of the experimental setups. The semiclassical approach, particularly in the form of the fully coupled Maxwell-Dirac equations with a pure wave ontology, seems to provide a satisfying, local, paradox-free physical model of the quantum world, that appears consistent with known phenomena. It is unclear why this approach is not pursued more vigorously in the field, given its clear potential to resolve all the conundrums that have perplexed generations of physicists.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RQC82ZQF\\O'Reilly - 2011 - Surely You Must All be Joking An Outsider's Critique of Quantum Physics.pdf},
  number = {January}
}

@article{oreilly_oreilly_2013,
  title = {Individual Differences in Cognitive Flexibility.},
  author = {O'Reilly, Randall C},
  year = {2013},
  volume = {74},
  pages = {78--9},
  issn = {1873-2402},
  doi = {10.1016/j.biopsych.2013.05.012},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3GIM7EG6\\O'Reilly - 2013 - Individual differences in cognitive flexibility.pdf},
  journal = {Biological psychiatry},
  keywords = {Dextroamphetamine,Dextroamphetamine: pharmacology,Dopamine,Dopamine: metabolism,Female,Humans,Male,Nerve Net,Psychological,Psychological: drug effects},
  number = {2},
  pmid = {23809259}
}

@article{oreilly_oreilly_2020,
  title = {Unraveling the {{Mysteries}} of {{Motivation}}},
  author = {O'Reilly, Randall C.},
  year = {2020},
  month = apr,
  pages = {S1364661320300681},
  issn = {13646613},
  doi = {10.1016/j.tics.2020.03.001},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FPLX3ZYJ\\O’Reilly - 2020 - Unraveling the Mysteries of Motivation.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en}
}

@article{oreilly_pauli_2010,
  title = {Computational Models of Cognitive Control},
  author = {O'Reilly, Randall C and Herd, S A and Pauli, W M},
  year = {2010},
  volume = {20},
  pages = {257--261},
  issn = {1873-6882},
  doi = {DOI 10.1016/j.conb.2010.01.008},
  abstract = {Cognitive control refers to the ability to perform task-relevant processing in the face of other distractions or other forms of interference, in the absence of strong environmental support. It depends on the integrity of the prefrontal cortex and associated biological structures (e.g., the basal ganglia). Computational models have played an influential role in developing our understanding of this system, and we review current developments in three major areas: dynamic gating of prefrontal representations, hierarchies in the prefrontal cortex, and reward, motivation, and goal-related processing in prefrontal cortex. Models in these and other areas are advancing the field further forward.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ICMG3WSF\\O'Reilly, Herd, Pauli - 2010 - Computational models of cognitive control.pdf},
  journal = {Current Opinion in Neurobiology},
  keywords = {anterior cingulate,basal ganglia,decision-making,dopamine function,organization,parkinsonism,performance,perspectives,prefrontal cortex,working-memory},
  number = {2},
  pmid = {20185294}
}

@article{oreilly_rohrlich_2017,
  title = {Deep {{Predictive Learning}}: {{A Comprehensive Model}} of {{Three Visual Streams}}},
  author = {O'Reilly, Randall C and Wyatte, Dean R and Rohrlich, John},
  year = {2017},
  abstract = {How does the neocortex learn and develop the foundations of all our high-level cognitive abilities? We present a comprehensive framework spanning biological, computational, and cognitive levels, with a clear theoretical continuity between levels, providing a coherent answer directly supported by extensive data at each level. Learning is based on making predictions about what the senses will report at 100 msec (alpha frequency) intervals, and adapting synaptic weights to improve prediction accuracy. The pulvinar nucleus of the thalamus serves as a projection screen upon which predictions are generated, through deep-layer 6 corticothalamic inputs from multiple brain areas and levels of abstraction. The sparse driving inputs from layer 5 intrinsic bursting neurons provide the target signal, and the temporal difference between it and the prediction reverberates throughout the cortex, driving synaptic changes that approximate error backpropagation, using only local activation signals in equations derived directly from a detailed biophysical model. In vision, predictive learning requires a carefully-organized developmental progression and anatomical organization of three pathways (What, Where, and What * Where), according to two central principles: top-down input from compact, high-level, abstract representations is essential for accurate prediction of low-level sensory inputs; and the collective, low-level prediction error must be progressively and opportunistically partitioned to enable extraction of separable factors that drive the learning of further high-level abstractions. Our model self-organized systematic invariant object representations of 100 different objects from simple movies, accounts for a wide range of data, and makes many testable predictions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UU8S8X29\\O'Reilly, Wyatte, Rohrlich - 2017 - Deep Predictive Learning A Comprehensive Model of Three Visual Streams.pdf},
  journal = {arXiv}
}

@article{oreilly_soto_2012,
  title = {Three Forms of Binding and Their Neural Substrates: {{Alternatives}} to Temporal Synchrony},
  author = {O'Reilly, Randall C and Busby, Richard S. and Soto, Rodolfo},
  year = {2012},
  doi = {10.1093/acprof:oso/9780198508571.003.0009},
  abstract = {This paper presents three different ways of addressing the binding problem in different brain areas: generic neocortex, hippocampus, and prefrontal cortex. None of these approaches involve the popular mechanism of temporal synchrony. The first two involve conjunctive representations that bind by ensuring that different neural units are activated for different combinations of input features. Specifically, we think the cortex constructs low-order conjunctions using coarse-coded distributed representations to avoid the combinatorial explosion usually associated with conjunctive solutions to the binding problem. We present a model that learns these representations in a challenging relational binding task, and furthermore is capable of considerable generalization to novel inputs. Next, we review the idea that the hippocampus performs conjunctive binding in long term memory through the use of higher-order conjunctions that are much more specific to particular events than those in the cortex. Finally, we present a model of a very different form of binding that involves the phonological loop \textemdash{} a mechanism for maintaining arbitrary sequences of phonemes in active memory. This phonological system can be used to bind by continuously repeating the to-be-bound information (e.g., ``press left key for green X's,...''). In total, this work suggests that instead of one simple and generic solution to the binding problem, the brain has developed a number of specialized mechanisms that build on the strengths of existing neural hardware in different brain areas.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9WK7622A\\O'Reilly, Busby, Soto - 2012 - Three forms of binding and their neural substrates Alternatives to temporal synchrony.pdf},
  journal = {The Unity of Consciousness: Binding, Integration, and Dissociation},
  keywords = {Conjunctive binding,Conjunctive representations,Hippocampus,Long-term memory,Neural substrates,Temporal synchrony},
  number = {June}
}

@article{ororbia_ororbia_2019,
  title = {Spiking {{Neural Predictive Coding}} for {{Continual Learning}} from {{Data Streams}}},
  author = {Ororbia, Alexander},
  year = {2019},
  month = aug,
  abstract = {For energy-efficient computation in specialized neuromorphic hardware, we present the Spiking Neural Coding Network, an instantiation of a family of artificial neural models strongly motivated by the theory of predictive coding. The model, in essence, works by operating in a never-ending process of ``guess-and-check'', where neurons predict the activity values of one another and then immediately adjust their own activities to make better future predictions. The interactive, iterative nature of our neural system fits well into the continuous time formulation of data sensory stream prediction and, as we show, the model's structure yields a simple, local synaptic update rule, which could be used to complement or replace online spike-timing dependent plasticity rules. In this article, we experiment with an instantiation of our model that consists of leaky integrate-and-fire units. However, the general framework within which our model is situated can naturally incorporate more complex, formal neurons such as the Hodgkin-Huxley model. Our experimental results in pattern recognition demonstrate the potential of the proposed model when binary spike trains are the primary paradigm for inter-neuron communication. Notably, our model is competitive in terms of classification performance, capable of conducting online semi-supervised learning, and more computationally economical and biologically-plausible than popular artificial neural networks.},
  archivePrefix = {arXiv},
  eprint = {1908.08655},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MFMAR8R4\\Ororbia - 2019 - Spiking Neural Predictive Coding for Continual Lea.pdf},
  journal = {arXiv:1908.08655 [cs, q-bio]},
  language = {en},
  primaryClass = {cs, q-bio}
}

@article{osipova_jensen_2008,
  title = {Gamma {{Power Is Phase}}-{{Locked}} to {{Posterior Alpha Activity}}},
  author = {Osipova, Daria and Hermes, Dora and Jensen, Ole},
  editor = {Rustichini, Aldo},
  year = {2008},
  month = dec,
  volume = {3},
  pages = {e3990},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0003990},
  abstract = {Neuronal oscillations in various frequency bands have been reported in numerous studies in both humans and animals. While it is obvious that these oscillations play an important role in cognitive processing, it remains unclear how oscillations in various frequency bands interact. In this study we have investigated phase to power locking in MEG activity of healthy human subjects at rest with their eyes closed. To examine cross-frequency coupling, we have computed coherence between the time course of the power in a given frequency band and the signal itself within every channel. The time-course of the power was calculated using a sliding tapered time window followed by a Fourier transform. Our findings show that high-frequency gamma power (30\textendash 70 Hz) is phase-locked to alpha oscillations (8\textendash 13 Hz) in the ongoing MEG signals. The topography of the coupling was similar to the topography of the alpha power and was strongest over occipital areas. Interestingly, gamma activity per se was not evident in the power spectra and only became detectable when studied in relation to the alpha phase. Intracranial data from an epileptic subject confirmed these findings albeit there was slowing in both the alpha and gamma band. A tentative explanation for this phenomenon is that the visual system is inhibited during most of the alpha cycle whereas a burst of gamma activity at a specific alpha phase (e.g. at troughs) reflects a window of excitability.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\33KMV3ZX\\Osipova et al. - 2008 - Gamma Power Is Phase-Locked to Posterior Alpha Act.PDF},
  journal = {PLoS ONE},
  language = {en},
  number = {12}
}

@book{osterhout_inoue_2004,
  title = {Sentences in the Brain: {{Event}}-Related Potentials as Real-Time Reflections of Sentence Comprehension and Language Learning},
  author = {Osterhout, L and McLaughlin, J and Kim, A and Greenwald, R and Inoue, K},
  year = {2004},
  abstract = {Behavioral studies appear to confirm this notion by showing that the proficiency scores of learners on a variety of language tasks decline with the age of initial exposure to the second language (Johnson, 1992; Johnson \{\&\} Newport, 1989).},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PHPB2USG\\Osterhout et al. - 2004 - Sentences in the brain Event-related potentials as real-time reflections of sentence comprehension and languag.pdf},
  isbn = {0-415-93379-X},
  keywords = {anomalies,bilingual brain,cortical representation,current-density,english,fmri,functional mri,semantic incongruity,syntactic positive shift},
  number = {January}
}

@article{osullivan_mesgarani_2019,
  title = {Hierarchical {{Encoding}} of {{Attended Auditory Objects}} in {{Multi}}-Talker {{Speech Perception}}},
  author = {O'Sullivan, James and Herrero, Jose and Smith, Elliot and Schevon, Catherine and McKhann, Guy M. and Sheth, Sameer A. and Mehta, Ashesh D. and Mesgarani, Nima},
  year = {2019},
  month = dec,
  volume = {104},
  pages = {1195-1209.e3},
  issn = {08966273},
  doi = {10.1016/j.neuron.2019.09.007},
  abstract = {Humans can easily focus on one speaker in a multitalker acoustic environment, but how different areas of the human auditory cortex (AC) represent the acoustic components of mixed speech is unknown. We obtained invasive recordings from the primary and nonprimary AC in neurosurgical patients as they listened to multi-talker speech. We found that neural sites in the primary AC responded to individual speakers in the mixture and were relatively unchanged by attention. In contrast, neural sites in the nonprimary AC were less discerning of individual speakers but selectively represented the attended speaker. Moreover, the encoding of the attended speaker in the nonprimary AC was invariant to the degree of acoustic overlap with the unattended speaker. Finally, this emergent representation of attended speech in the nonprimary AC was linearly predictable from the primary AC responses. Our results reveal the neural computations underlying the hierarchical formation of auditory objects in human AC during multi-talker speech perception.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\U5IAMRD9\\O’Sullivan et al. - 2019 - Hierarchical Encoding of Attended Auditory Objects.pdf},
  journal = {Neuron},
  language = {en},
  number = {6}
}

@article{oswald_oswald_2004,
  title = {Parallel {{Processing}} of {{Sensory Input}} by {{Bursts}} and {{Isolated Spikes}}},
  author = {Oswald, A.-M. M.},
  year = {2004},
  month = may,
  volume = {24},
  pages = {4351--4362},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0459-04.2004},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3PUYVWR6\\Oswald - 2004 - Parallel Processing of Sensory Input by Bursts and.pdf},
  journal = {Journal of Neuroscience},
  language = {en},
  number = {18}
}

@article{otis_stuber_2017,
  title = {Prefrontal Cortex Output Circuits Guide Reward Seeking through Divergent Cue Encoding},
  author = {Otis, James M and Namboodiri, Vijay M K and Matan, Ana M and Voets, Elisa S and Mohorn, Emily P and Kosyk, Oksana and McHenry, Jenna A and Robinson, J Elliott and Resendez, Shanna L and Rossi, Mark A and Stuber, Garret D},
  year = {2017},
  volume = {543},
  pages = {103--107},
  issn = {0028-0836},
  doi = {10.1038/nature21376},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NDJ3KAM2\\Otis et al. - 2017 - Prefrontal cortex output circuits guide reward seeking through divergent cue encoding.pdf},
  journal = {Nature},
  number = {7643},
  pmid = {28225752}
}

@article{ott_nieder_2019,
  title = {Dopamine and {{Cognitive Control}} in {{Prefrontal Cortex}}},
  author = {Ott, Torben and Nieder, Andreas},
  year = {2019},
  month = mar,
  volume = {23},
  pages = {213--234},
  issn = {1364-6613, 1879-307X},
  doi = {10.1016/j.tics.2018.12.006},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WRQ8EFUA\\Ott and Nieder - 2019 - Dopamine and Cognitive Control in Prefrontal Corte.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\M79KFU69\\Ott and Nieder - 2019 - Dopamine and Cognitive Control in Prefrontal Corte.html},
  journal = {Trends in Cognitive Sciences},
  language = {English},
  number = {3},
  pmid = {30711326}
}

@article{owen_manning_2017,
  title = {Towards {{Human Super EEG}}},
  author = {Owen, Lucy L W and Manning, Jeremy R},
  year = {2017},
  pages = {121020},
  doi = {10.1101/121020},
  abstract = {Human Super EEG entails measuring ongoing activity from every cell in a living human brain at millisecond-scale temporal resolutions. Although direct cell-by-cell Super EEG recordings are impossible using existing methods, here we present a technique for inferring neural activity at arbitrarily high spatial resolutions using human intracranial electrophysiological recordings. Our approach, based on Gaussian process regression, relies on two assumptions. First, we assume that some of the correlational structure of people's brain activity is similar across individuals. Second, we resolve ambiguities in the data by assuming that neural activity from nearby sources will tend to be similar, all else being equal. One can then ask, for an arbitrary individual's brain: given what we know about the correlational structure of other people's brains, and given the recordings we made from electrodes implanted in this person's brain, how would those recordings most likely have looked at other locations throughout this person's brain?},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7R96DP7X\\Owen, Heusser, Manning - Unknown - A Gaussian process model of human electrocorticographic.pdf},
  journal = {bioRxiv}
}

@book{p.murphy_p.murphy_2011,
  title = {Machine {{Learning}}: {{A Probabilistic Perspective}}},
  author = {P. Murphy, Kevin},
  year = {2011},
  doi = {10.1007/SpringerReference_35834},
  abstract = {Some of the most remarkable issues related to interharmonics observed from a probabilistic perspective are presented. Attention is firstly devoted to interharmonic frequency and amplitude variability. Starting from the basic mathematical and computational aspects of probabilistic harmonic models, the difficulties to include interharmonics are discussed with particular attention to the problem of the frequency resolution and of the computational burden. Then, simulation and measurement aspects are discussed, also showing some numerical and experimental results.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JL8GZDPV\\P. Murphy - 2011 - Machine Learning A Probabilistic Perspective.pdf},
  isbn = {978-0-262-01802-9},
  pmid = {20236947}
}

@article{padilla-coreano_gordon_2019,
  title = {Hippocampal-{{Prefrontal Theta Transmission Regulates Avoidance Behavior}}},
  author = {{Padilla-Coreano}, Nancy and Canetta, Sarah and Mikofsky, Rachel M. and Alway, Emily and Passecker, Johannes and Myroshnychenko, Maxym V. and {Garcia-Garcia}, Alvaro L. and Warren, Richard and Teboul, Eric and Blackman, Dakota R. and Morton, Mitchell P. and Hupalo, Sofiya and Tye, Kay M. and Kellendonk, Christoph and Kupferschmidt, David A. and Gordon, Joshua A.},
  year = {2019},
  month = sep,
  pages = {S0896627319306907},
  issn = {08966273},
  doi = {10.1016/j.neuron.2019.08.006},
  abstract = {Long-range synchronization of neural oscillations correlates with distinct behaviors, yet its causal role remains unproven. In mice, tests of avoidance behavior evoke increases in theta-frequency (\$8 Hz) oscillatory synchrony between the ventral hippocampus (vHPC) and medial prefrontal cortex (mPFC). To test the causal role of this synchrony, we dynamically modulated vHPC-mPFC terminal activity using optogenetic stimulation. Oscillatory stimulation at 8 Hz maximally increased avoidance behavior compared to 2, 4, and 20 Hz. Moreover, avoidance behavior was selectively increased when 8-Hz stimulation was delivered in an oscillatory, but not pulsatile, manner. Furthermore, 8-Hz oscillatory stimulation enhanced vHPC-mPFC neurotransmission and entrained neural activity in the vHPCmPFC network, resulting in increased synchrony between vHPC theta activity and mPFC spiking. These data suggest a privileged role for vHPC-mPFC thetafrequency communication in generating avoidance behavior and provide direct evidence that synchronized oscillations play a role in facilitating neural transmission and behavior.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\F3VJ2H2W\\Padilla-Coreano et al. - 2019 - Hippocampal-Prefrontal Theta Transmission Regulate.pdf},
  journal = {Neuron},
  language = {en}
}

@article{padoa-schioppa_conen_2017,
  title = {Orbitofrontal {{Cortex}}: {{A Neural Circuit}} for {{Economic Decisions}}},
  shorttitle = {Orbitofrontal {{Cortex}}},
  author = {{Padoa-Schioppa}, Camillo and Conen, Katherine E.},
  year = {2017},
  month = nov,
  volume = {96},
  pages = {736--754},
  issn = {08966273},
  doi = {10.1016/j.neuron.2017.09.031},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\B7CE3TDQ\\Padoa-Schioppa and Conen - 2017 - Orbitofrontal Cortex A Neural Circuit for Economi.pdf},
  journal = {Neuron},
  language = {en},
  number = {4}
}

@article{page_jeffery_2018,
  title = {Landmark-{{Based Updating}} of the {{Head Direction System}} by {{Retrosplenial Cortex}}: {{A Computational Model}}},
  author = {Page, Hector J. I. and Jeffery, Kate J.},
  year = {2018},
  volume = {12},
  pages = {1--17},
  issn = {1662-5102},
  doi = {10.3389/fncel.2018.00191},
  abstract = {Maintaining a sense of direction is fundamental to navigation, and is achieved in the brain by a network of head direction (HD) cells, which update their signal using stable environmental landmarks. How landmarks are detected and their stability determined is still unknown. Recently we reported a new class of cells (Jacob et al., 2017), the bidirectional cells, in a brain region called retrosplenial cortex (RSC) which relays environmental sensory information to the HD system. A subset of these cells, between-compartment (BC) cells, are directionally tuned (like ordinary HD cells) but follow environmental cues in preference to the global HD signal, resulting in opposing (i.e., bidirectional) tuning curves in opposed environments. Another subset, within-compartment (WC) cells, unexpectedly expressed bidirectional tuning curves in each one of the opposed compartments. Both BC and WC cells lost directional tuning in an open field, unlike HD cells. Two questions arise from this discovery: (i) how do these cells acquire their unusual response properties, and (ii) what are they for? We propose that bidirectional cells reflect a two-way interaction between local direction, as indicated by the visual environment, and global direction as signalled by the HD system. We suggest that BC cells receive strong inputs from visual cues, while WC cells additionally receive modifiable inputs from HD cells which, due to Hebbian coactivation of visual inputs plus two opposing sets of HD inputs, acquire the ability to fire in both directions. A neural network model instantiating this hypothesis is presented, which indeed forms both BC and WC bidirectional cells with properties similar to those seen experimentally. We then demonstrate how tuning specificity degrades when WC/BC cells are exposed to multiple directionalities, replicating the observed loss of WC and BC directional tuning in the open field. We suggest that the function of these neurons is to assess the stability of environmental landmarks, thereby determining their utility as reference points by which to set the HD sense of direction. This role could extend to the ability of the HD system to prefer distal over proximal landmarks, and to correct for parallax errors.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NDMCWCL4\\Page, Jeffery - 2018 - Landmark-Based Updating of the Head Direction System by Retrosplenial Cortex A Computational Model.pdf},
  journal = {Frontiers in Cellular Neuroscience},
  keywords = {attractor dynamics,head direction cells,landmark process,landmark processing,navigation,retrosplenial cortex,vision},
  number = {July}
}

@article{pagnotta_plomp_2018,
  title = {Time-Varying Mvar Algorithms for Directed Connectivity Analysis: {{Critical}} Comparison in Simulations and Benchmark {{EEG}} Data},
  author = {Pagnotta, Mattia F. and Plomp, Gijs},
  editor = {{Sendi{\~n}a-Nadal}, Irene},
  year = {2018},
  month = jun,
  volume = {13},
  pages = {e0198846},
  issn = {19326203},
  doi = {10.1371/journal.pone.0198846},
  abstract = {Human brain function depends on directed interactions between multiple areas that evolve in the subsecond range. Time-varying multivariate autoregressive (tvMVAR) modeling has been proposed as a way to help quantify directed functional connectivity strengths with high temporal resolution. While several tvMVAR approaches are currently available, there is a lack of unbiased systematic comparative analyses of their performance and of their sensitivity to parameter choices. Here, we critically compare four recursive tvMVAR algorithms and assess their performance while systematically varying adaptation coefficients, model order, and signal sampling rate. We also compared two ways of exploiting repeated observations: single-trial modeling followed by averaging, and multi-trial modeling where one tvMVAR model is fitted across all trials. Results from numerical simulations and from benchmark EEG recordings showed that: i) across a broad range of model orders all algorithms correctly reproduced patterns of interactions; ii) signal downsampling degraded connectivity estimation accuracy for most algorithms, although in some cases downsampling was shown to reduce variability in the estimates by lowering the number of parameters in the model; iii) single-trial modeling followed by averaging showed optimal performance with larger adaptation coefficients than previously suggested, and showed slower adaptation speeds than multi-trial modeling. Overall, our findings identify strengths and weaknesses of existing tvMVAR approaches and provide practical recommendations for their application to model-ing dynamic directed interactions from electrophysiological signals.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BYT5X3AQ\\Pagnotta, Plomp - 2018 - Time-varying MVAR algorithms for directed connectivity analysis Critical comparison in simulations and benchmar.pdf},
  journal = {PLoS ONE},
  keywords = {Diabetes,Dopaminergic agonists,Gabapentin,Microvascular,Neuropathy,Opioids,Pregabalin},
  number = {6}
}

@techreport{pagnotta_plomp_2020,
  title = {Nested Oscillations and Brain Connectivity during Sequential Stages of Feature-Based Attention},
  author = {Pagnotta, Mattia F. and Pascucci, David and Plomp, Gijs},
  year = {2020},
  month = feb,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.02.28.969253},
  abstract = {Abstract           Brain mechanisms of visual selective attention involve both local and network-level activity changes at specific oscillatory rhythms, but their interplay remains poorly explored. Here, we investigate anticipatory and reactive effects of feature-based attention using separate fMRI and EEG recordings, while participants attended to one of two spatially overlapping visual features (motion and orientation). We focused on EEG source analysis of local nested oscillations and on graph analysis of connectivity changes in a network of fMRI-defined regions of interest, and characterized a cascade of attentional effects and their interplay at multiple spatial scales. We discuss how the results may reconcile several theories of selective attention, by showing how {$\beta$} rhythms support anticipatory information routing through increased network efficiency and {$\beta$}-{$\gamma$} coupling in functionally specialized regions (V1 for orientation, V5 for motion), while reactive {$\alpha$}-band desynchronization patterns and increased {$\alpha$}-{$\gamma$} coupling in V1 and V5 mediate stimulus-evoked processing of task-relevant signals.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\T862PTER\\Pagnotta et al. - 2020 - Nested oscillations and brain connectivity during .pdf},
  language = {en},
  type = {Preprint}
}

@article{palmeri_turner_2017,
  title = {Model-Based Cognitive Neuroscience},
  author = {Palmeri, Thomas J. and Love, Bradley C. and Turner, Brandon M.},
  year = {2017},
  volume = {76},
  pages = {59--64},
  issn = {10960880},
  doi = {10.1016/j.jmp.2016.10.010},
  abstract = {This special issue explores the growing intersection between mathematical psychology and cognitive neuroscience. Mathematical psychology, and cognitive modeling more generally, has a rich history of formalizing and testing hypotheses about cognitive mechanisms within a mathematical and computational language, making exquisite predictions of how people perceive, learn, remember, and decide. Cognitive neuroscience aims to identify neural mechanisms associated with key aspects of cognition using techniques like neurophysiology, electrophysiology, and structural and functional brain imaging. These two come together in a powerful new approach called model-based cognitive neuroscience, which can both inform cognitive modeling and help to interpret neural measures. Cognitive models decompose complex behavior into representations and processes and these latent model states can be used to explain the modulation of brain states under different experimental conditions. Reciprocally, neural measures provide data that help constrain cognitive models and adjudicate between competing cognitive models that make similar predictions about behavior. As examples, brain measures are related to cognitive model parameters fitted to individual participant data, measures of brain dynamics are related to measures of model dynamics, model parameters are constrained by neural measures, model parameters or model states are used in statistical analyses of neural data, or neural and behavioral data are analyzed jointly within a hierarchical modeling framework. We provide an introduction to the field of model-based cognitive neuroscience and to the articles contained within this special issue.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HEZH2HTM\\Palmeri, Love, Turner - 2017 - Model-based cognitive neuroscience.pdf},
  journal = {Journal of Mathematical Psychology},
  keywords = {Cognitive modeling,Cognitive neuroscience,Model-based cognitive neuroscience}
}

@article{palmigiano_battaglia_2017,
  title = {Flexible Information Routing by Transient Synchrony},
  author = {Palmigiano, Agostina and Geisel, Theo and Wolf, Fred and Battaglia, Demian},
  year = {2017},
  volume = {20},
  pages = {1014--1022},
  issn = {1097-6256},
  doi = {10.1038/nn.4569},
  abstract = {Perception, cognition and behavior rely on flexible communication between microcircuits in distinct cortical regions. The mechanisms underlying rapid information rerouting between such microcircuits are still unknown. It has been proposed that changing patterns of coherence between local gamma rhythms support flexible information rerouting. The stochastic and transient nature of gamma oscillations in vivo, however, is hard to reconcile with such a function. Here we show that models of cortical circuits near the onset of oscillatory synchrony selectively route input signals despite the short duration of gamma bursts and the irregularity of neuronal firing. In canonical multiarea circuits, we find that gamma bursts spontaneously arise with matched timing and frequency and that they organize information flow by large-scale routing states. Specific self-organized routing states can be induced by minor modulations of background activity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FH8A8ZD8\\Palmigiano et al. - 2017 - Flexible information routing by transient synchrony.pdf},
  journal = {Nature Neuroscience},
  number = {7},
  pmid = {28530664}
}

@techreport{pals_borst_2019,
  title = {A Functional Spiking-Neuron Model of Activity-Silent Working Memory in Humans Based on Calcium-Mediated Short-Term Synaptic Plasticity},
  author = {Pals, Matthijs and Stewart, Terrence C. and Aky{\"u}rek, Elkan G. and Borst, Jelmer P.},
  year = {2019},
  month = oct,
  institution = {{Neuroscience}},
  doi = {10.1101/823559},
  abstract = {Abstract           In this paper, we present a functional spiking-neuron model of human working memory (WM). This model combines neural firing for encoding of information with activity-silent maintenance. While it used to be widely assumed that information in WM is maintained through persistent recurrent activity, recent studies have shown that information can be maintained without persistent firing; instead, information can be stored in activity-silent states. A candidate mechanism underlying this type of storage is short-term synaptic plasticity (STSP), by which the strength of connections between neurons rapidly changes to encode new information. To demonstrate that STSP can lead to functional behavior, we integrated STSP by means of calcium-mediated synaptic facilitation in a large-scale spiking-neuron model and added a decision mechanism. The model was used to simulate a recent study that measured behavior and EEG activity of participants in three delayed-response tasks. In these tasks, one or two visual gratings had to be maintained in WM, and compared to subsequent probes. The original study demonstrated that WM contents and its priority status could be decoded from neural activity elicited by a task-irrelevant stimulus displayed during the activity-silent maintenance period. In support of our model, we show that it can perform these tasks, and that both its behavior as well as its neural representations are in agreement with the human data. We conclude that information in WM can be effectively maintained in activity-silent states by means of calcium-mediated STSP.                        Author Summary             Mentally maintaining information for short periods of time in working memory is crucial for human adaptive behavior. It was recently shown that the human brain does not only store information through neural firing \textendash{} as was widely believed \textendash{} but also maintains information in activity-silent states. Here, we present a detailed neural model of how this could happen in our brain through short-term synaptic plasticity: rapidly adapting the connection strengths between neurons in response to incoming information. By reactivating the adapted network, the stored information can be read out later. We show that our model can perform three working memory tasks as accurately as human participants can, while using similar mental representations. We conclude that our model is a plausible and effective neural implementation of human working memory.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HPMZ3KXC\\Pals et al. - 2019 - A functional spiking-neuron model of activity-sile.pdf},
  language = {en},
  type = {Preprint}
}

@article{palva_palva_2012,
  title = {Discovering Oscillatory Interaction Networks with {{M}}/{{EEG}}: Challenges and Breakthroughs},
  author = {Palva, Satu and Palva, J Matias},
  year = {2012},
  doi = {10.1016/j.tics.2012.02.004},
  abstract = {The systems-level neuronal mechanisms that coordinate temporally, anatomically and functionally distributed neuronal activity into coherent cognitive operations in the human brain have remained poorly understood. Syn-chronization of neuronal oscillations may regulate net-work communication and could thus serve as such a mechanism. Evidence for this hypothesis, however, was until recently sparse, as methodological challenges limit the investigation of interareal interactions with non-invasive magneto-and electroencephalography (M/EEG) recordings. Nevertheless, recent advances in M/EEG source reconstruction and clustering methods support complete phase-interaction mappings that are essential for uncovering the large-scale neuronal assemblies and their functional roles. These data show that synchroniza-tion is a robust and behaviorally significant phenomenon in task-relevant cortical networks and could hence bind distributed neuronal processing to coherent cognitive states.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\24FIZZIF\\Unknown - Unknown - Discovering oscillatory interaction networks with MEEG challenges and breakthroughs.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\QL6WUPSQ\\Palva, Palva - 2012 - Discovering oscillatory interaction networks with MEEG challenges and breakthroughs.pdf}
}

@article{palva_palva_2018,
  title = {Roles of {{Brain Criticality}} and {{Multiscale Oscillations}} in {{Temporal Predictions}} for {{Sensorimotor Processing}}},
  author = {Palva, Satu and Palva, J. Matias},
  year = {2018},
  volume = {41},
  pages = {729--743},
  issn = {1878108X},
  doi = {10.1016/j.tins.2018.08.008},
  abstract = {Sensorimotor predictions are essential for adaptive behavior. In natural environments, events that demand sensorimotor predictions unfold across many timescales, and corresponding temporal predictions (either explicit or implicit) should therefore emerge in brain dynamics. Neuronal oscillations are scale-specific processes found in several frequency bands. They underlie periodicity in sensorimotor processing and can represent temporal predictions via their phase dynamics. These processes build upon endogenous neural rhythmicity and adapt in response to exogenous timing demands. While much of the research on periodicity in neural processing has focused on subsecond oscillations, these fast-scale rhythms are in fact paralleled by critical-like, scale-free dynamics and fluctuations of brain activity at various timescales, ranging from seconds to hundreds of seconds. In this review, we put forth a framework positing that critical brain dynamics are essential for the role of neuronal oscillations in timing and that cross-frequency coupling flexibly organizes neuronal processing across multiple frequencies.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KBXMVIY2\\Palva, Palva - 2018 - Roles of Brain Criticality and Multiscale Oscillations in Temporal Predictions for Sensorimotor Processing(2).pdf},
  journal = {Trends in Neurosciences},
  keywords = {criticality,oscillation,scale-free temporal predictions},
  number = {10},
  pmid = {30274607}
}

@article{palva_palva_2018a,
  title = {Functional Integration across Oscillation Frequencies by Cross-Frequency Phase Synchronization},
  author = {Palva, J. Matias and Palva, Satu},
  year = {2018},
  month = oct,
  volume = {48},
  pages = {2399--2406},
  issn = {0953816X},
  doi = {10.1111/ejn.13767},
  abstract = {Neuronal oscillations and their inter-areal synchronization may be instrumental in regulating neuronal communication in distributed networks. Several lines of research have, however, shown that cognitive tasks engage neuronal oscillations simultaneously in multiple frequency bands that have distinct functional roles in cognitive processing. Gamma oscillations (30\textendash 120 Hz) are associated with bottom-up processing, while slower oscillations in delta (1\textendash 4 Hz), theta (4\textendash 7 Hz), alpha (8\textendash 14 Hz) and beta (14\textendash 30 Hz) frequency bands may have roles in executive or top-down controlling functions, although also other distinctions have been made. Identification of the mechanisms that integrate such spectrally distributed processing and govern neuronal communication among these networks is crucial for understanding how cognitive functions are achieved in neuronal circuits. Cross-frequency interactions among oscillations have been recognized as a likely candidate mechanism for such integration. We advance here the hypothesis that phase\textendash phase synchronization of neuronal oscillations in two different frequency bands, cross-frequency phase synchrony (CFS), could serve to integrate, coordinate and regulate neuronal processing distributed into neuronal assemblies concurrently in multiple frequency bands. A trail of studies over the past decade has revealed the presence of CFS among cortical oscillations and linked CFS with roles in cognitive integration. We propose that CFS could connect fast and slow oscillatory networks and thereby integrate distributed cognitive functions such as representation of sensory information with attentional and executive functions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RQ6RCVYV\\Palva and Palva - 2018 - Functional integration across oscillation frequenc.pdf},
  journal = {European Journal of Neuroscience},
  language = {en},
  number = {7}
}

@techreport{pang_vanrullen_2020,
  title = {Turning the Stimulus on and off Dynamically Changes the Direction of Alpha Travelling Waves},
  author = {Pang, Zhaoyang and Alamia, Andrea and VanRullen, Rufin},
  year = {2020},
  month = apr,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.04.15.041756},
  abstract = {Travelling waves have been studied to characterize the complex spatiotemporal dynamics of the brain. Several studies have suggested that the propagation direction of travelling waves can be task-dependent. For example, a recent EEG study from our group found that forward waves (i.e. occipital to frontal, FW waves) were observed during visual processing, whereas backward waves (i.e. frontal to occipital, BW waves) mostly occurred in the absence of sensory input. These EEG recordings, however, were obtained from different experimental sessions and different groups of subjects. To further examine how the waves' direction changes between task conditions, 13 participants were tested on a target detection task while EEG signals were recorded simultaneously. We alternated visual stimulation (5 s display of visual luminance sequences) and resting state (5 s of black screen) within each single trial, allowing us to monitor the moment-to-moment progression of travelling waves. As expected, the waves' direction was closely linked with task conditions (visual processing vs. rest state). First, FW waves from occipital to frontal regions, absent during rest, emerged as a result of visual processing, while BW waves in the opposite direction dominated in the absence of visual inputs, and were reduced (but not eliminated) by external visual inputs. Second, during visual stimulation (but not rest), both waves coexisted on average, but were negatively correlated. That is, when the FW waves were stronger than expected based on alpha amplitude alone, the BW waves tended to be weaker, and vice-versa. In summary, we conclude that the functional role of travelling waves is closely related with their propagating direction, with stimulus-evoked FW waves supporting visual processing and spontaneous BW waves involved more in top-down control.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3RGRFPX9\\Pang et al. - 2020 - Turning the stimulus on and off dynamically change.pdf},
  language = {en},
  type = {Preprint}
}

@article{panichello_buschman_2018,
  title = {Error-Correcting Dynamics in Visual Working Memory},
  author = {Panichello, Matthew F and DePasquale, Brian and Pillow, Jonathan W and Buschman, Timothy},
  year = {2018},
  doi = {10.1101/319103},
  abstract = {Working memory is critical to cognition, decoupling behavior from the immediate world. Yet, it is imperfect; internal noise introduces errors into memory representations (1, 2). Such errors accumulate over time (3\textendash 5) and increase with the number of items simultaneously held in working memory (6\textendash 10). Here, we show that error-correcting attractor dynamics mitigate the impact of noise on working memory. These dynamics pull memories towards a few stable representations in mnemonic space, inducing a bias in memory representations but reducing the effect of noise. Model-based and model-free analyses show attractor dynamics account for the frequency, bias, and precision of working memory reports in both humans and monkeys. Furthermore, attractor dynamics were optimized to the context; they adapted to the statistics of the environment, such that memories drifted towards contextually-predicted values. Our results suggest attractor dynamics mediate errors in working memory by counteracting noise and integrating contextual information into memories.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BI8FUG3M\\Panichello et al. - 2018 - Error-correcting dynamics in visual working memory.pdf},
  journal = {bioRxiv}
}

@article{paninski_cunningham_2018,
  title = {Neural Data Science: Accelerating the Experiment-Analysis-Theory Cycle in Large-Scale Neuroscience},
  author = {Paninski, L and Cunningham, J P},
  year = {2018},
  volume = {50},
  pages = {232--241},
  doi = {10.1016/j.conb.2018.04.007},
  abstract = {Modern large-scale multineuronal recording methodologies, including multielectrode arrays, calcium imaging, and optogenetic techniques, produce single-neuron resolution data of a magnitude and precision that were the realm of science fiction twenty years ago. The major bottlenecks in systems and circuit neuroscience no longer lie in simply collecting data from large neural populations, but also in understanding this data: developing novel scientific questions, with corresponding analysis techniques and experimental designs to fully harness these new capabilities and meaningfully interrogate these questions. Advances in methods for signal processing, network analysis, dimensionality reduction, and optimal control-developed in lockstep with advances in experimental neurotechnology-promise major breakthroughs in multiple fundamental neuroscience problems. These trends are clear in a broad array of subfields of modern neuroscience; this review focuses on recent advances in methods for analyzing neural time-series data with single-neuronal precision.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4RCRE2TL\\Paninski, Cunningham - 2018 - Neural data science accelerating the experiment-analysis-theory cycle in large-scale neuroscience.pdf},
  journal = {Current Opinion in Neurobiology}
}

@article{paninski_paninski_2004,
  title = {Maximum Likelihood Estimation of Cascade Point-Process Neural Encoding Models},
  author = {Paninski, Liam},
  year = {2004},
  volume = {15},
  pages = {243--262},
  issn = {0954-898X},
  doi = {10.1088/0954-898X/15/4/002},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RZZ3TCRX\\Paninski - 2004 - Maximum likelihood estimation of cascade point-process neural encoding models.pdf},
  journal = {Network: Computation in Neural Systems},
  number = {4}
}

@techreport{paninski_paninski_2007,
  title = {Statistical Analysis of Neural Data: {{Generalized}} Linear Models for Spike Trains *},
  author = {Paninski, Liam},
  year = {2007},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9CP6YM72\\Paninski - 2007 - Statistical analysis of neural data Generalized linear models for spike trains.pdf}
}

@article{paoletti_vanzoest_2018,
  title = {Spontaneous Pre-Stimulus Oscillatory Activity Shapes the Way We Look:{{A}} Concurrent Imaging and Eye-Movement Study},
  author = {Paoletti, Davide and Braun, Christoph and Vargo, Elisabeth Julie and {van Zoest}, Wieske},
  year = {2018},
  issn = {0953816X},
  doi = {10.1111/ejn.14285},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IEJFS9EA\\Paoletti et al. - 2018 - Spontaneous pre-stimulus oscillatory activity shapes the way we lookA concurrent imaging and eye-movement study.pdf},
  journal = {European Journal of Neuroscience}
}

@article{papadopoulou_marinazzo_2015,
  title = {Estimating {{Directed Connectivity}} from {{Cortical Recordings}} and {{Reconstructed Sources}}},
  author = {Papadopoulou, Margarita and Friston, Karl and Marinazzo, Daniele},
  year = {2015},
  month = sep,
  issn = {0896-0267, 1573-6792},
  doi = {10.1007/s10548-015-0450-6},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\R4RRKBW3\\Papadopoulou et al. - 2015 - Estimating Directed Connectivity from Cortical Rec.pdf},
  journal = {Brain Topography},
  language = {en}
}

@book{pare_duvarci_2012,
  title = {Amygdala Microcircuits Mediating Fear Expression and Extinction},
  author = {Pare, Denis and Duvarci, Sevil},
  year = {2012},
  volume = {22},
  doi = {10.1016/j.conb.2012.02.014},
  abstract = {This review summarizes the latest developments in our understanding of amygdala networks that support classical fear conditioning, the experimental paradigm most commonly used to study learned fear in the laboratory. These recent advances have considerable translational significance as congruent findings from studies of fear learning in animals and humans indicate that anxiety disorders result from abnormalities in the mechanisms that normally regulate conditioned fear. Because of the introduction of new techniques and the continued use of traditional approaches, it is becoming clear that conditioned fear involves much more complex networks than initially believed, including coordinated interactions between multiple excitatory and inhibitory circuits within the amygdala. ?? 2012 Elsevier Ltd.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DJVDHBQ8\\Pare, Duvarci - 2012 - Amygdala microcircuits mediating fear expression and extinction.pdf},
  isbn = {1873-6882 (Electronic)\$\textbackslash backslash\$r0959-4388 (Linking)},
  pmid = {22424846}
}

@techreport{parish_bowman_2020,
  title = {Modelling the {{Replay}} of {{Dynamic Memories}} from {{Cortical Alpha Oscillations}} with the {{Sync}}-{{Fire}} / {{deSync Model}}},
  author = {Parish, George and Michelmann, Sebastian and Hanslmayr, Simon and Bowman, Howard},
  year = {2020},
  month = jan,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.01.28.921205},
  abstract = {We here propose a neural network model to explore how neural oscillations might regulate the replay of memory traces. We simulate the encoding and retrieval of a series of events, where temporal sequences are uniquely identifiable by analysing population activity, as several recent EEG/MEG studies have shown. Our model comprises three parts, each considering distinct hypotheses. A cortical region actively represents sequences through the disruption of an intrinsically generated alpha rhythm, where a desynchronisation marks information-rich operations as the literature predicts. A binding region converts each event into a discrete index, enabling repetitions through a sparse encoding of events. We also instantiate a temporal region, where an oscillatory ``ticking-clock'' made up of hierarchical synfire chains discretely indexes a moment in time. By encoding the absolute timing between events, we show how one can use cortical desynchronisations to dynamically detect unique temporal signatures as they are replayed in the brain.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\C5HJ3BUI\\Parish et al. - 2020 - Modelling the Replay of Dynamic Memories from Cort.pdf},
  language = {en},
  type = {Preprint}
}

@article{park_pillow_2014,
  title = {Encoding and Decoding in Parietal Cortex during Sensorimotor Decision-Making},
  author = {Park, Il Memming and Meister, Miriam L R and Huk, Alexander C and Pillow, Jonathan W},
  year = {2014},
  volume = {17},
  pages = {1395--1403},
  issn = {1097-6256},
  doi = {10.1038/nn.3800},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QS2UNMWB\\Park et al. - 2014 - Encoding and decoding in parietal cortex during sensorimotor decision-making.pdf},
  journal = {Nature Neuroscience},
  number = {10}
}

@article{parr_friston_2017,
  title = {Working Memory, Attention, and Salience in Active Inference},
  author = {Parr, Thomas and Friston, Karl J.},
  year = {2017},
  month = nov,
  volume = {7},
  pages = {14678},
  issn = {2045-2322},
  doi = {10.1038/s41598-017-15249-0},
  abstract = {The psychological concepts of working memory and attention are widely used in the cognitive and neuroscientific literatures. Perhaps because of the interdisciplinary appeal of these concepts, the same terms are often used to mean very different things. Drawing on recent advances in theoretical neurobiology, this paper tries to highlight the correspondence between these established psychological constructs and the formal processes implicit in mathematical descriptions of brain function. Here, we consider attention and salience from the perspective offered by active inference. Using variational principles and simulations, we use active inference to demonstrate how attention and salience can be disambiguated in terms of message passing between populations of neurons in cortical and subcortical structures. In brief, we suggest that salience is something that is afforded to actions that realise epistemic affordance, while attention per se is afforded to precise sensory evidence \textendash{} or beliefs about the causes of sensations.},
  copyright = {2017 The Author(s)},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6CTBMNPW\\Parr and Friston - 2017 - Working memory, attention, and salience in active .pdf;C\:\\Users\\wchapman\\Zotero\\storage\\IXXRA7S4\\Parr and Friston - 2017 - Working memory, attention, and salience in active .html},
  journal = {Scientific Reports},
  language = {En},
  number = {1}
}

@article{parr_friston_2019,
  title = {Prefrontal {{Computation}} as {{Active Inference}}},
  author = {Parr, Thomas and Rikhye, Rajeev Vijay and Halassa, Michael M. and Friston, Karl J.},
  year = {2019},
  doi = {10.1093/cercor/bhz118},
  abstract = {Abstract.  The prefrontal cortex is vital for a range of cognitive processes, including working memory, attention, and decision-making. Notably, its absence imp},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MM3NAX6A\\Parr et al. - Prefrontal Computation as Active Inference.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\GHUEHMV4\\Parr et al. - Prefrontal Computation as Active Inference.html},
  journal = {Cerebral Cortex},
  language = {en}
}

@article{patihis_loftus_2013,
  title = {False Memories in Highly Superior Autobiographical Memory Individuals.},
  author = {Patihis, Lawrence and Frenda, Steven J and LePort, Aurora K R and Petersen, Nicole and Nichols, Rebecca M and Stark, Craig E L and McGaugh, James L and Loftus, Elizabeth F},
  year = {2013},
  volume = {110},
  pages = {20947--20952},
  issn = {1091-6490},
  doi = {10.1073/pnas.1314373110},
  abstract = {The recent identification of highly superior autobiographical memory (HSAM) raised the possibility that there may be individuals who are immune to memory distortions. We measured HSAM participants' and age- and sex-matched controls' susceptibility to false memories using several research paradigms. HSAM participants and controls were both susceptible to false recognition of nonpresented critical lure words in an associative word-list task. In a misinformation task, HSAM participants showed higher overall false memory compared with that of controls for details in a photographic slideshow. HSAM participants were equally as likely as controls to mistakenly report they had seen nonexistent footage of a plane crash. Finding false memories in a superior-memory group suggests that malleable reconstructive mechanisms may be fundamental to episodic remembering. Paradoxically, HSAM individuals may retrieve abundant and accurate autobiographical memories using fallible reconstructive processes.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GMQNNUU8\\Patihis et al. - 2013 - False memories in highly superior autobiographical memory individuals.pdf},
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  keywords = {Association,Communication,Episodic,Female,Humans,Male,Memory,Neuropsychological Tests,Psychology,Repression},
  number = {52},
  pmid = {24248358}
}

@article{patino-saucedo_linares-barranco_2020,
  title = {Event-Driven Implementation of Deep Spiking Convolutional Neural Networks for Supervised Classification Using the {{SpiNNaker}} Neuromorphic Platform},
  author = {{Pati{\~n}o-Saucedo}, Alberto and {Rostro-Gonzalez}, Horacio and {Serrano-Gotarredona}, Teresa and {Linares-Barranco}, Bernab{\'e}},
  year = {2020},
  month = jan,
  volume = {121},
  pages = {319--328},
  issn = {08936080},
  doi = {10.1016/j.neunet.2019.09.008},
  abstract = {Neural networks have enabled great advances in recent times due mainly to improved parallel computing capabilities in accordance to Moore's Law, which allowed reducing the time needed for the parameter learning of complex, multi-layered neural architectures. However, with silicon technology reaching its physical limits, new types of computing paradigms are needed to increase the power efficiency of learning algorithms, especially for dealing with deep spatio-temporal knowledge on embedded applications. With the goal of mimicking the brain's power efficiency, new hardware architectures such as the SpiNNaker board have been built. Furthermore, recent works have shown that networks using spiking neurons as learning units can match classical neural networks in supervised tasks. In this paper, we show that the implementation of state-of-the-art models on both the MNIST and the event-based NMNIST digit recognition datasets is possible on neuromorphic hardware. We use two approaches, by directly converting a classical neural network to its spiking version and by training a spiking network from scratch. For both cases, software simulations and implementations into a SpiNNaker 103 machine were performed. Numerical results approaching the state of the art on digit recognition are presented, and a new method to decrease the spike rate needed for the task is proposed, which allows a significant reduction of the spikes (up to 34 times for a fully connected architecture) while preserving the accuracy of the system. With this method, we provide new insights on the capabilities offered by networks of spiking neurons to efficiently encode spatio-temporal information.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7DF68QYY\\Patiño-Saucedo et al. - 2020 - Event-driven implementation of deep spiking convol.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\Y24NKTLC\\Patiño-Saucedo et al. - 2020 - Event-driven implementation of deep spiking convol.pdf},
  journal = {Neural Networks},
  language = {en}
}

@article{pauli_oreilly_2008,
  title = {Attentional Control of Associative Learning-{{A}} Possible Role of the Central Cholinergic System},
  author = {Pauli, Wolfgang M and O'Reilly, Randall C},
  year = {2008},
  volume = {1202},
  pages = {43--53},
  issn = {00068993},
  doi = {10.1016/j.brainres.2007.06.097},
  abstract = {How does attention interact with learning? Kruschke [Kruschke, J.K. (2001). Toward a unified Model of Attention in Associative Learning. J. Math. Psychol. 45, 812-863.] proposed a model (EXIT) that captures Mackintosh's [Mackintosh, N.J. (1975). A theory of attention: Variations in the associability of stimuli with reinforcement. Psychological Review, 82(4), 276-298.] framework for attentional modulation of associative learning. We developed a computational model that showed analogous interactions between selective attention and associative learning, but is significantly simplified and, in contrast to EXIT, is motivated by neurophysiological findings. Competition among input representations in the internal representation layer, which increases the contrast between stimuli, is critical for simulating these interactions in human behavior. Furthermore, this competition is modulated in a way that might be consistent with the phasic activation of the central cholinergic system, which modulates activity in sensory cortices. Specifically, phasic increases in acetylcholine can cause increased excitability of both pyramidal excitatory neurons in cortical layers II/III and cortical GABAergic inhibitory interneurons targeting the same pyramidal neurons. These effects result in increased attentional contrast in our model. This model thus represents an initial attempt to link human attentional learning data with underlying neural substrates. \textcopyright{} 2007 Elsevier B.V. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AL6MB4GC\\Pauli, O'Reilly - 2008 - Attentional control of associative learning-A possible role of the central cholinergic system.pdf},
  journal = {Brain Research},
  keywords = {associative learning,Layer gain,Neural network,Selective attention},
  pmid = {17870060}
}

@article{pauli_pauli_2011,
  title = {Long-Term Memories in Dorsomedial and Dorsolateral Striatal Areas Differentially Affect Behavioral Flexibility},
  author = {Pauli, Wolfgang M},
  year = {2011},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SRBLYHNM\\Pauli - 2011 - Long-term memories in dorsomedial and dorsolateral striatal areas differentially affect behavioral flexibility.pdf}
}

@book{paxinos_franklin_2004,
  title = {Mouse {{Brain}} in {{Stereotaxic Coordinates}}},
  author = {Paxinos, George and Franklin, Keith B J and {Paxinos, G {and} Franklin}, K B J and Paxinos, George and Franklin, Keith B J},
  year = {2004},
  volume = {2nd},
  doi = {10.1016/S0306-4530(03)00088-X},
  abstract = {The Mouse Brain in Stereotaxic Coordinates, Second Edition has been the acknowledged reference in this field since the publication of the first edition, and is now available in a Compact Edition. This will provide a more affordable option for students, as well as researchers needing an additional lab atlas. This version includes the coronal diagrams delineating the entire brain as well as the introductory text from the Deluxe edition. It is an essential reference for anyone studying the mouse brain or related species. Includes 100 detailed diagrams of the coronal set delineating the entire mouse brain Compact edition of the most comprehensive and accurate mouse brain atlas available Contains minor updates and revisions from the full edition},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RRAVY5ND\\Paxinos et al. - 2004 - Mouse Brain in Stereotaxic Coordinates.pdf},
  isbn = {0-12-547636-1},
  pmid = {661}
}

@techreport{payeur_naud_2020,
  title = {Burst-Dependent Synaptic Plasticity Can Coordinate Learning in Hierarchical Circuits},
  author = {Payeur, Alexandre and Guerguiev, Jordan and Zenke, Friedemann and Richards, Blake A. and Naud, Richard},
  year = {2020},
  month = mar,
  institution = {{arXiv}},
  doi = {10.1101/2020.03.30.015511},
  abstract = {Synaptic plasticity is believed to be a key physiological mechanism for learning. It is well-established that it depends on pre and postsynaptic activity. However, models that rely solely on pre and postsynaptic activity for synaptic changes have, to date, not been able to account for learning complex tasks that demand hierarchical networks. Here, we show that if synaptic plasticity is regulated by high-frequency bursts of spikes, then neurons higher in the hierarchy can coordinate the plasticity of lower-level connections. Using simulations and mathematical analyses, we demonstrate that, when paired with short-term synaptic dynamics, regenerative activity in the apical dendrites, and synaptic plasticity in feedback pathways, a burst-dependent learning rule can solve challenging tasks that require deep network architectures. Our results demonstrate that well-known properties of dendrites, synapses, and synaptic plasticity are sufficient to enable sophisticated learning in hierarchical circuits.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\V8TETZC3\\Payeur et al. - 2020 - Burst-dependent synaptic plasticity can coordinate.pdf},
  language = {en},
  type = {Preprint}
}

@article{pearce_hall_1980,
  title = {A Model for {{Pavlovian}} Learning: {{Variations}} in the Effectiveness of Conditioned but Not of Unconditioned Stimuli.},
  author = {Pearce, John M and Hall, Geoffrey},
  year = {1980},
  volume = {87},
  pages = {532--552},
  issn = {0033-295X},
  doi = {10.1037/0033-295X.87.6.532},
  abstract = {Several formal models of excitatory classical conditioning are reviewed. It is suggested that a central problem for all of them is the explanation of cases in which learning does not occur in spite of the fact that the conditioned stimulus is a signal for the reinforcer. We propose a new model that deals with this problem by specifying that certain procedures cause a conditioned stimulus (CS) to lose effectiveness; in particular, we argue that a CS will lose associ-ability when its consequences are accurately predicted. In contrast to other current models, the effectiveness of the reinforcer remains constant throughout conditioning. The second part of the article presents a reformulation of the nature of the learning produced by inhibitory-conditioning procedures and a discussion of the way in which such learning can be accommodated within the model outlined for excitatory learning.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HL9RDWHG\\Pearce, Hall - 1980 - A model for Pavlovian learning Variations in the effectiveness of conditioned but not of unconditioned stimuli.pdf},
  journal = {Psychological Review},
  number = {6},
  pmid = {7443916}
}

@article{pedrosa_clopath_2017,
  title = {The Role of Neuromodulators in Cortical Plasticity. {{A}} Computational Perspective},
  author = {Pedrosa, Victor and Clopath, Claudia},
  year = {2017},
  volume = {8},
  pages = {38},
  issn = {16633563},
  doi = {10.3389/fnsyn.2016.00038},
  abstract = {Neuromodulators play a ubiquitous role across the brain in regulating plasticity. With recent advances in experimental techniques, it is possible to study the effects of diverse neuromodulatory states in specific brain regions. Neuromodulators are thought to impact plasticity through predominantly two mechanisms: the gating of plasticity, or the upregulation of neuronal activity. However, the consequences of these mechanisms are poorly understood and there is a need for both experimental and theoretical exploration. Here we illustrate how neuromodulatory state affects cortical plasticity through these two mechanisms. First, we explore the ability of neuromodulators to gate plasticity by reshaping the learning window for spike-timing-dependent plasticity. Using a simple computational model, we implement four different learning rules and demonstrate their effects on receptive field plasticity. We then compare the neuromodulatory effects of upregulating learning rate versus the effects of upregulating neuronal activity. We find that these seemingly similar mechanisms do not yield the same outcome: upregulating neuronal activity can lead to either a broadening or a sharpening of receptive field tuning, whereas upregulating learning rate only intensifies the sharpening of receptive field tuning. This simple model demonstrates the need for further exploration of the rich landscape of neuromodulator-mediated plasticity. Future experiments, coupled with biologically detailed computational models, will elucidate the diversity of mechanisms by which neuromodulatory state regulates cortical plasticity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\C65YBXLK\\Pedrosa, Clopath - 2017 - The role of neuromodulators in cortical plasticity. A computational perspective.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\P4RBBUHK\\Pedrosa, Clopath - 2017 - The role of neuromodulators in cortical plasticity. A computational perspective(2).pdf},
  journal = {Frontiers in Synaptic Neuroscience},
  keywords = {Computational modeling,Dopamine,Neuromodulation,Noradrenaline,Synaptic plasticity},
  number = {JAN},
  pmid = {28119596}
}

@article{penn_povinelli_2008,
  title = {Darwin's Mistake: {{Explaining}} the Discontinuity between Human and Nonhuman Minds},
  author = {Penn, Derek C and Holyoak, Keith J. and Povinelli, Daniel J},
  year = {2008},
  volume = {31},
  issn = {0140-525X},
  doi = {10.1017/S0140525X08003543},
  abstract = {Over the last quarter century, the dominant tendency in comparative cognitive psychology has been to emphasize the similarities between human and nonhuman minds and to downplay the differences as "one of degree and not of kind" (Darwin 1871). In the present target article, we argue that Darwin was mistaken: the profound biological continuity between human and nonhuman animals masks an equally profound discontinuity between human and nonhuman minds. To wit, there is a significant discontinuity in the degree to which human and nonhuman animals are able to approximate the higher-order, systematic, relational capabilities of a physical symbol system (PSS) (Newell 1980). We show that this symbolic-relational discontinuity pervades nearly every domain of cognition and runs much deeper than even the spectacular scaffolding provided by language or culture alone can explain. We propose a representational-level specification as to where human and nonhuman animals' abilities to approximate a PSS are similar and where they differ. We conclude by suggesting that recent symbolic-connectionist models of cognition shed new light on the mechanisms that underlie the gap between human and nonhuman minds.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Y8BF4YAU\\Penn, Holyoak, Povinelli - 2008 - Darwin's mistake Explaining the discontinuity between human and nonhuman minds.pdf},
  journal = {Behavioral and Brain Sciences},
  keywords = {analogy,animal cognition,causal learning,connectionism,Darwin,discontinuity,evolution,human mind,language,language of thought,physical symbol system,reasoning,same-different,theory of mind},
  number = {02},
  pmid = {18479531}
}

@article{penny_burgess_2013,
  title = {Forward and {{Backward Inference}} in {{Spatial Cognition}}},
  author = {Penny, Will D and Zeidman, Peter and Burgess, Neil},
  year = {2013},
  volume = {9},
  issn = {1553734X},
  doi = {10.1371/journal.pcbi.1003383},
  abstract = {This paper shows that the various computations underlying spatial cognition can be implemented using statistical inference in a single probabilistic model. Inference is implemented using a common set of 'lower-level' computations involving forward and backward inference over time. For example, to estimate where you are in a known environment, forward inference is used to optimally combine location estimates from path integration with those from sensory input. To decide which way to turn to reach a goal, forward inference is used to compute the likelihood of reaching that goal under each option. To work out which environment you are in, forward inference is used to compute the likelihood of sensory observations under the different hypotheses. For reaching sensory goals that require a chaining together of decisions, forward inference can be used to compute a state trajectory that will lead to that goal, and backward inference to refine the route and estimate control signals that produce the required trajectory. We propose that these computations are reflected in recent findings of pattern replay in the mammalian brain. Specifically, that theta sequences reflect decision making, theta flickering reflects model selection, and remote replay reflects route and motor planning. We also propose a mapping of the above computational processes onto lateral and medial entorhinal cortex and hippocampus.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KIL9YBLW\\Penny, Zeidman, Burgess - 2013 - Forward and Backward Inference in Spatial Cognition.pdf},
  journal = {PLoS Computational Biology},
  number = {12},
  pmid = {24348230}
}

@article{perrone-bertolotti_lachaux_2020,
  title = {A Real-Time Marker of Object-Based Attention in the Human Brain. {{A}} Possible Component of a ``Gate-Keeping Mechanism'' Performing Late Attentional Selection in the {{Ventro}}-{{Lateral Prefrontal Cortex}}},
  author = {{Perrone-Bertolotti}, M. and El Bouza{\"i}di Tiali, S. and Vidal, J.R. and Petton, M. and Croize, A.C. and Deman, P. and Rheims, S. and Minotti, L. and Bhattacharjee, M. and Baciu, M. and Kahane, P. and Lachaux, J.P.},
  year = {2020},
  month = jan,
  pages = {116574},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2020.116574},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\B4WXFR8G\\Perrone-Bertolotti et al. - 2020 - A real-time marker of object-based attention in th.pdf},
  journal = {NeuroImage},
  language = {en}
}

@article{petersen_cahill_2015,
  title = {Oral Contraceptive Pill Use Is Associated with Localized Decreases in Cortical Thickness},
  author = {Petersen, Nicole and Touroutoglou, Alexandra and Andreano, Joseph M and Cahill, Larry},
  year = {2015},
  volume = {00},
  pages = {n/a----n/a},
  issn = {10659471},
  doi = {10.1002/hbm.22797},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Z9NINR6Z\\Petersen et al. - 2015 - Oral contraceptive pill use is associated with localized decreases in cortical thickness.pdf},
  journal = {Human Brain Mapping},
  keywords = {cortical thickness,hormonal contraception,morphometric analysis,neuroendocrinology},
  number = {November 2014}
}

@article{peterson_griffiths_2020,
  title = {Parallelograms Revisited: {{Exploring}} the Limitations of Vector Space Models for Simple Analogies},
  shorttitle = {Parallelograms Revisited},
  author = {Peterson, Joshua C. and Chen, Dawn and Griffiths, Thomas L.},
  year = {2020},
  month = dec,
  volume = {205},
  pages = {104440},
  issn = {00100277},
  doi = {10.1016/j.cognition.2020.104440},
  abstract = {Classic psychological theories have demonstrated the power and limitations of spatial representations, providing geometric tools for reasoning about the similarity of objects and showing that human intuitions sometimes violate the constraints of geometric spaces. Recent machine learning methods for deriving vector-space em\- beddings of words have begun to garner attention for their surprising capacity to capture simple analogies consistently across large corpora, giving new life to a classic model of analogies as parallelograms that was first proposed and briefly explored by psychologists. We evaluate the parallelogram model of analogy as applied to modern data-driven word embeddings, providing a detailed analysis of the extent to which this approach cap\- tures human behavior in the domain of word pairs. Using a large novel benchmark dataset of human analogy completions, we show that word similarity alone surprisingly captures some aspects of human responses better than the parallelogram model. To gain a fine-grained picture of how well these models predict relational si\- milarity, we also collect a large dataset of human relational similarity judgments and find that the parallelogram model captures some semantic relationships better than others. Finally, we provide evidence for deeper lim\- itations of the parallelogram model of analogy based on the intrinsic geometric constraints of vector spaces, paralleling classic results for item similarity. Taken together, these results show that while modern word em\- beddings do an impressive job of capturing semantic similarity at scale, the parallelogram model alone is in\- sufficient to account for how people form even the simplest analogies.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LFPZDET9\\Peterson et al. - 2020 - Parallelograms revisited Exploring the limitation.pdf},
  journal = {Cognition},
  language = {en}
}

@article{peterson_peterson_2015,
  title = {The {{Baby Factory}}: {{Difficult}} Research Objects, Disciplinary Standards, and the Production of Statistical Significance},
  author = {Peterson, David},
  year = {2015},
  volume = {2},
  pages = {1--10},
  issn = {2378-0231},
  doi = {10.1177/2378023115625071},
  abstract = {Science studies scholars have shown that the management of natural complexity in lab settings is accomplished through a mixture of technological standardization and tacit knowledge by lab workers. Yet these strategies are not available to researchers who study difficult research objects. Using 16 months of ethnographic data from three laboratories that conduct experiments on infants and toddlers, the author shows how psychologists produce statistically significant results under challenging circumstances by using strategies that enable them to bridge the distance between an uncontrollable research object and a professional culture that prizes methodological rigor. This research raises important questions regarding the value of restrictive evidential cultures in challenging research environments.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\42UEYCIQ\\Peterson - 2015 - The Baby Factory Difficult research objects, disciplinary standards, and the production of statistical significance.pdf},
  journal = {Socius},
  keywords = {laboratory ethnography,science and knowledge,sociology of psychology,standardization}
}

@article{petrides_pandya_2002,
  title = {Comparative Cytoarchitectonic Analysis of the Human and the Macaque Ventrolateral Prefrontal Cortex and Corticocortical Connection Patterns in the Monkey: {{Ventrolateral}} Prefrontal Cortex in Human and Monkey},
  shorttitle = {Comparative Cytoarchitectonic Analysis of the Human and the Macaque Ventrolateral Prefrontal Cortex and Corticocortical Connection Patterns in the Monkey},
  author = {Petrides, M. and Pandya, D. N.},
  year = {2002},
  month = jul,
  volume = {16},
  pages = {291--310},
  issn = {0953816X},
  doi = {10.1046/j.1460-9568.2001.02090.x},
  abstract = {A comparison of the cytoarchitecture of the human and the macaque monkey ventrolateral prefrontal cortex demonstrated a region in the monkey that exhibits the architectonic characteristic of area 45 in the human brain. This region occupies the dorsal part of the ventrolateral prefrontal convexity just below area 9/46v. Rostroventral to area 45 in the human brain lies a large cortical region labelled as area 47 by Brodmann. The ventrolateral component of this region extending as far as the lateral orbital sulcus has architectonic characteristics similar to those of the ventrolateral prefrontal region labelled by Walker as area 12 in the macaque monkey. We designated this region in both the human and the monkey ventrolateral prefrontal cortex as area 47/12. Thus, area 47/12 designates the speci\textregistered c part of the zone previously labelled as area 47 in the human brain that has the same overall architectonic pattern as that of Walker's area 12 in the macaque monkey brain. The cortical connections of these two areas were examined in the monkey by injecting \textasciimacron uorescent retrograde tracers. Although both area 45 and area 47/12 as de\textregistered ned here had complex multimodal input, they could be differentiated in terms of some of their inputs. Retrograde tracers restricted to area 47/12 resulted in heavy labelling of neurons in the rostral inferotemporal visual association cortex and in temporal limbic areas (i.e. perirhinal and parahippocampal cortex). In contrast, injections of tracers into dorsally adjacent area 45 demonstrated strong labelling in the superior temporal gyrus (i.e. the auditory association cortex) and the multimodal cortex in the upper bank of the superior temporal sulcus.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9VZSZRLY\\Petrides and Pandya - 2002 - Comparative cytoarchitectonic analysis of the huma.pdf},
  journal = {European Journal of Neuroscience},
  language = {en},
  number = {2}
}

@book{petrides_pandya_2012,
  title = {The Prefrontal Cortex: {{Comparative}} Architectonic Organization in the Human and the Macaque Monkey Brains},
  author = {Petrides, Michael and Tomaiuolo, Francesco and Yeterian, Edward H and Pandya, Deepak N},
  year = {2012},
  volume = {48},
  doi = {10.1016/j.cortex.2011.07.002},
  abstract = {Detailed cytoarchitectonic studies of the human cerebral cortex appeared during the first quarter of the 20th century. The incorporation of the cytoarchitectonic map by Brodmann (1909) in the Talairach proportional stereotaxic space (Talairach and Tournoux, 1988) has established the Brodmann numerical nomenclature as the basis for describing the cortical location of structural and functional findings obtained with modern neuroimaging. In experimental anatomical and physiological investigations of the macaque monkey performed during the last 50years, the numerical architectonic nomenclature used to describe findings in the prefrontal cortex has been largely based on the map by Walker (1940). Unfortunately, the map by Walker was not based on a comparative investigation of the cytoarchitecture of the human and macaque monkey prefrontal cortex and, as a result, the nomenclature and the criteria for demarcating areas in the two primate species are not always consistent. These discrepancies are a major obstacle in the ability to compare experimental findings from nonhuman primates with results obtained in functional and structural neuroimaging of the human brain. The present article outlines these discrepancies in the classical maps and describes comparative investigations of the cytoarchitecture of the prefrontal cortex of the macaque monkey and human (Petrides and Pandya, 1994, 1999, 2002a) in order to resolve these discrepancies and enable easy translation of experimental research in the monkey to findings in the human brain obtained with modern neuroimaging. \textcopyright{} 2011 Elsevier Srl.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KCCKQQF4\\Petrides et al. - 2012 - The prefrontal cortex Comparative architectonic organization in the human and the macaque monkey brains.pdf},
  isbn = {1973-8102 (Electronic)\$\textbackslash backslash\$r0010-9452 (Linking)},
  keywords = {Cytoarchitecture,Fiber pathways,Prefrontal cortex},
  pmid = {21872854}
}

@article{pettersen_einevoll_2010,
  title = {Extracellular Spikes and Current-Source Density},
  author = {Pettersen, Klas H and Lind{\'e}n, Henrik and Dale, Anders M and Einevoll, Gaute T},
  year = {2010},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JLPJXND3\\Pettersen et al. - 2010 - Extracellular spikes and current-source density.pdf},
  journal = {Handbook of Neural Activity Measurement},
  number = {August}
}

@article{peyrache_buzsaki_2016,
  title = {Transformation of Head-Direction Signal into Spatial Code},
  author = {Peyrache, Adrien and Roux, Lisa and Schieferstein, Natalie and Buzsaki, Gyorgy},
  year = {2016},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6GPHE8RX\\Peyrache et al. - 2016 - Transformation of head-direction signal into spatial code.pdf}
}

@article{peyrache_buzsaki_2017,
  title = {Transformation of the Head-Direction Signal into a Spatial Code},
  author = {Peyrache, Adrien and Schieferstein, Natalie and Buzs{\'a}ki, Gyorgy},
  year = {2017},
  month = dec,
  volume = {8},
  pages = {1752},
  issn = {2041-1723},
  doi = {10.1038/s41467-017-01908-3},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\S7RQWC3S\\Peyrache et al. - 2017 - Transformation of the head-direction signal into a.pdf},
  journal = {Nature Communications},
  language = {en},
  number = {1}
}

@article{pezeshki_bengio_2015,
  title = {Deconstructing the {{Ladder Network Architecture}}},
  author = {Pezeshki, Mohammad and Fan, Linxi and Brakel, Philemon and Courville, Aaron and Bengio, Yoshua},
  year = {2015},
  issn = {9290795158},
  abstract = {The Manual labeling of data is and will remain a costly endeavor. For this reason, semi-supervised learning remains a topic of practical importance. The recently proposed Ladder Network is one such approach that has proven to be very successful. In addition to the supervised objective, the Ladder Network also adds an unsupervised objective corresponding to the reconstruction costs of a stack of denoising autoencoders. Although the empirical results are impressive, the Ladder Network has many components intertwined, whose contributions are not obvious in such a complex architecture. In order to help elucidate and disentangle the different ingredients in the Ladder Network recipe, this paper presents an extensive experimental investigation of variants of the Ladder Network in which we replace or remove individual components to gain more insight into their relative importance. We find that all of the components are necessary for achieving optimal performance, but they do not contribute equally. For semi-supervised tasks, we conclude that the most important contribution is made by the lateral connection, followed by the application of noise, and finally the choice of what we refer to as the `combinator function' in the decoder path. We also find that as the number of labeled training examples increases, the lateral connections and reconstruction criterion become less important, with most of the improvement in generalization being due to the injection of noise in each layer. Furthermore, we present a new type of combinator function that outperforms the original design in both fully- and semi-supervised tasks, reducing record test error rates on Permutation-Invariant MNIST to 0.57\% for the supervised setting, and to 0.97\% and 1.0\% for semi-supervised settings with 1000 and 100 labeled examples respectively.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\G39FNPMN\\Pezeshki et al. - 2015 - Deconstructing the Ladder Network Architecture.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\WNCZY2DF\\Pezeshki et al. - 2015 - Deconstructing the Ladder Network Architecture.pdf}
}

@article{pezzulo_friston_2018,
  title = {Hierarchical {{Active Inference}}: {{A Theory}} of {{Motivated Control}}},
  shorttitle = {Hierarchical {{Active Inference}}},
  author = {Pezzulo, Giovanni and Rigoli, Francesco and Friston, Karl J.},
  year = {2018},
  month = apr,
  volume = {22},
  pages = {294--306},
  issn = {13646613},
  doi = {10.1016/j.tics.2018.01.009},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NDCWAGSK\\Pezzulo et al. - 2018 - Hierarchical Active Inference A Theory of Motivat.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {4}
}

@article{pfeiffer_foster_2013,
  title = {Hippocampal Place-Cell Sequences Depict Future Paths to Remembered Goals},
  author = {Pfeiffer, Brad E. and Foster, David J.},
  year = {2013},
  month = may,
  volume = {497},
  pages = {74--79},
  issn = {1476-4687},
  doi = {10.1038/nature12112},
  abstract = {Effective navigation requires planning extended routes to remembered goal locations. Hippocampal place cells have been proposed to have a role in navigational planning, but direct evidence has been lacking. Here we show that before goal-directed navigation in an open arena, the rat hippocampus generates brief sequences encoding spatial trajectories strongly biased to progress from the subject's current location to a known goal location. These sequences predict immediate future behaviour, even in cases in which the specific combination of start and goal locations is novel. These results indicate that hippocampal sequence events characterized previously in linearly constrained environments as `replay' are also capable of supporting a goal-directed, trajectory-finding mechanism, which identifies important places and relevant behavioural paths, at specific times when memory retrieval is required, and in a manner that could be used to control subsequent navigational behaviour.},
  copyright = {2013 Nature Publishing Group},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NDXLAHZT\\Pfeiffer and Foster - 2013 - Hippocampal place-cell sequences depict future pat.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\SDHY3F6U\\nature12112.html},
  journal = {Nature},
  language = {en},
  number = {7447}
}

@article{pfeiffer_maass_2010,
  title = {Reward-{{Modulated Hebbian Learning}} of {{Decision Making}}},
  author = {Pfeiffer, Michael and Nessler, Bernhard and Douglas, Rodney J. and Maass, Wolfgang},
  year = {2010},
  month = jun,
  volume = {22},
  pages = {1399--1444},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/neco.2010.03-09-980},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3DFAP72U\\Pfeiffer et al. - 2010 - Reward-Modulated Hebbian Learning of Decision Maki.pdf},
  journal = {Neural Computation},
  language = {en},
  number = {6}
}

@article{pfister_pfister_2006,
  title = {Triplets of {{Spikes}} in a {{Model}} of {{Spike Timing}}-{{Dependent Plasticity}}},
  author = {Pfister, J.-P.},
  year = {2006},
  month = sep,
  volume = {26},
  pages = {9673--9682},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1425-06.2006},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IFXZ5LMG\\Pfister - 2006 - Triplets of Spikes in a Model of Spike Timing-Depe.pdf},
  journal = {Journal of Neuroscience},
  language = {en},
  number = {38}
}

@article{phillips_phillips_2014,
  title = {Analogy, Cognitive Architecture and Universal Construction: {{A}} Tale of Two Systematicities},
  author = {Phillips, Steven},
  year = {2014},
  volume = {9},
  issn = {19326203},
  doi = {10.1371/journal.pone.0089152},
  abstract = {Cognitive science recognizes two kinds of systematicity: (1) as the property where certain cognitive capacities imply certain other related cognitive capacities (Fodor and Pylyshyn); and (2) as the principle that analogical mappings based on collections of connected relations are preferred over relations in isolation (Gentner). Whether these kinds of systematicity are two aspects of a deeper property of cognition is hitherto unknown. Here, it is shown that both derive from the formal, category-theoretic notion of universal construction. In conceptual/psychological terms, a universal construction is a form of optimization of cognitive resources: optimizing the re-utilization of common component processes for common task components. Systematic cognitive capacity and the capacity for analogy are hallmarks of human cognition, which suggests that universal constructions (in the category-theoretic sense) are a crucial component of human cognitive architecture.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\I3BZ2ZWY\\Phillips - 2014 - Analogy, cognitive architecture and universal construction A tale of two systematicities.pdf},
  journal = {PLoS ONE},
  number = {2},
  pmid = {24586555}
}

@article{pietras_schwalger_2020,
  title = {Low-Dimensional Firing-Rate Dynamics for Populations of Renewal-Type Spiking Neurons},
  author = {Pietras, Bastian and Gallice, No{\'e} and Schwalger, Tilo},
  year = {2020},
  month = mar,
  abstract = {The macroscopic dynamics of large populations of neurons can be mathematically analyzed using low-dimensional firing-rate or neural-mass models. However, these models fail to capture spike synchronization effects of stochastic spiking neurons such as the non-stationary population response to rapidly changing stimuli. Here, we derive low-dimensional firing-rate models for homogeneous populations of general renewal-type neurons, including integrate-and-fire models driven by white noise. Renewal models account for neuronal refractoriness and spike synchronization dynamics. The derivation is based on an eigenmode expansion of the associated refractory density equation, which generalizes previous spectral methods for Fokker-Planck equations to arbitrary renewal models. We find a simple relation between the eigenvalues, which determine the characteristic time scales of the firing rate dynamics, and the Laplace transform of the interspike interval density or the survival function of the renewal process. Analytical expressions for the Laplace transforms are readily available for many renewal models including the leaky integrate-and-fire model. Retaining only the first eigenmode yields already an adequate low-dimensional approximation of the firing-rate dynamics that captures spike synchronization effects and fast transient dynamics at stimulus onset. We explicitly demonstrate the validity of our model for a large homogeneous population of Poisson neurons with absolute refractoriness, and other renewal models that admit an explicit analytical calculation of the eigenvalues. The here presented eigenmode expansion provides a systematic framework for novel firing-rate models in computational neuroscience based on spiking neuron dynamics with refractoriness.},
  archivePrefix = {arXiv},
  eprint = {2003.06038},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\T6Y7DNLN\\Pietras et al. - 2020 - Low-dimensional firing-rate dynamics for populatio.pdf},
  journal = {arXiv:2003.06038 [q-bio]},
  language = {en},
  primaryClass = {q-bio}
}

@article{pignatelli_johansen_2019,
  title = {Valence Coding in Amygdala Circuits {{This}} Review Comes from a Themed Issue on {{Pain}} and Aversive Motivation {{Neural}} Substrate of Valence},
  author = {Pignatelli, Michele and Beyeler, Anna and Seymour, Ben and Johansen, Joushua},
  year = {2019},
  doi = {10.1016/j.cobeha.2018.10.010},
  abstract = {The neural mechanisms underlying emotional valence are at the interface between perception and action, integrating inputs from the external environment with past experiences to guide the behavior of an organism. Depending on the positive or negative valence assigned to an environmental stimulus, the organism will approach or avoid the source of the stimulus. Multiple convergent studies have demonstrated that the amygdala complex is a critical node of the circuits assigning valence. Here we examine the current progress in identifying valence coding properties of neural populations in different nuclei of the amygdala, based on their activity, connectivity, and gene expression profile.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IA2GUYAN\\Pignatelli et al. - 2019 - Valence coding in amygdala circuits This review comes from a themed issue on Pain and aversive motivation Neu.pdf}
}

@article{pignatelli_leinekugel_2012,
  title = {Neural Circuits Underlying the Generation of Theta Oscillations},
  author = {Pignatelli, Michele and Beyeler, Anna and Leinekugel, Xavier},
  year = {2012},
  volume = {106},
  pages = {81--92},
  issn = {09284257},
  doi = {10.1016/j.jphysparis.2011.09.007},
  abstract = {Theta oscillations represent the neural network configuration underlying active awake behavior and paradoxical sleep. This major EEG pattern has been extensively studied, from physiological to anatomical levels, for more than half a century. Nevertheless the cellular and network mechanisms accountable for the theta generation are still not fully understood. This review synthesizes the current knowledge on the circuitry involved in the generation of theta oscillations, from the hippocampus to extra hippocampal structures such as septal complex, entorhinal cortex and pedunculopontine tegmentum, a main trigger of theta state through direct and indirect projections to the septal complex. We conclude with a short overview of the perspectives offered by technical advances for deciphering more precisely the different neural components underlying the emergence of theta oscillations. ?? 2011 Elsevier Ltd.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FAMTE72F\\Pignatelli, Beyeler, Leinekugel - 2012 - Neural circuits underlying the generation of theta oscillations.pdf},
  journal = {Journal of Physiology Paris},
  keywords = {Brainstem,Cholinergic system,Hippocampus,Limbic system,Neuronal networks,Oscillations,Theta},
  number = {3-4},
  pmid = {21964249}
}

@article{pillow_paninski_2011,
  title = {Model-{{Based Decoding}}, {{Information Estimation}}, and {{Change}}-{{Point Detection Techniques}} for {{Multineuron Spike Trains}}},
  author = {Pillow, Jonathan W. and Ahmadian, Yashar and Paninski, Liam},
  year = {2011},
  month = jan,
  volume = {23},
  pages = {1--45},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/NECO_a_00058},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QJHWVI3Z\\Pillow et al. - 2011 - Model-Based Decoding, Information Estimation, and .pdf},
  journal = {Neural Computation},
  language = {en},
  number = {1}
}

@article{pillow_pillow_2005,
  title = {Prediction and {{Decoding}} of {{Retinal Ganglion Cell Responses}} with a {{Probabilistic Spiking Model}}},
  author = {Pillow, Jonathan W},
  year = {2005},
  volume = {25},
  pages = {11003--11013},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.3305-05.2005},
  abstract = {Sensory encoding in spiking neurons depends on both the integration of sensory inputs and the intrinsic dynamics and variability of spike generation. We show that the stimulus selectivity, reliability, and timing precision of primate retinal ganglion cell (RGC) light responses can be reproduced accurately with a simple model consisting of a leaky integrate-and-fire spike generator driven by a linearly filtered stimulus, a postspike current, and a Gaussian noise current. We fit model parameters for individual RGCs by maximizing the likelihood of observed spike responses to a stochastic visual stimulus. Although compact, the fitted model predicts the detailed time structure of responses to novel stimuli, accurately capturing the interaction between the spiking history and sensory stimulus selectivity. The model also accounts for the variability in responses to repeated stimuli, even when fit to data from a single (nonrepeating) stimulus sequence. Finally, the model can be used to derive an explicit, maximum-likelihood decoding rule for neural spike trains, thus providing a tool for assessing the limitations that spiking variability imposes on sensory performance.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\697AK768\\Pillow et al. - 2005 - Prediction and Decoding of Retinal Ganglion Cell Responses with a Probabilistic Spiking Model.pdf},
  journal = {Journal of Neuroscience},
  keywords = {computational model,decoding,integrate and fire,neural coding,precision,retinal ganglion cell,spike timing,spike trains,variability},
  number = {47},
  pmid = {16306413}
}

@article{pillow_simoncelli_2008,
  title = {Spatio-Temporal Correlations and Visual Signalling in a Complete Neuronal Population},
  author = {Pillow, Jonathan W and Shlens, Jonathon and Paninski, Liam and Sher, Alexander and Litke, Alan M and Chichilnisky, E J and Simoncelli, Eero P},
  year = {2008},
  volume = {454},
  pages = {995--999},
  issn = {00280836},
  doi = {10.1038/nature07140},
  abstract = {Statistical dependencies in the responses of sensory neurons govern both the amount of stimulus information conveyed and the means by which downstream neurons can extract it. Although a variety of measurements indicate the existence of such dependencies, their origin and importance for neural coding are poorly understood. Here we analyse the functional significance of correlated firing in a complete population of macaque parasol retinal ganglion cells using a model of multi-neuron spike responses. The model, with parameters fit directly to physiological data, simultaneously captures both the stimulus dependence and detailed spatio-temporal correlations in population responses, and provides two insights into the structure of the neural code. First, neural encoding at the population level is less noisy than one would expect from the variability of individual neurons: spike times are more precise, and can be predicted more accurately when the spiking of neighbouring neurons is taken into account. Second, correlations provide additional sensory information: optimal, model-based decoding that exploits the response correlation structure extracts 20\% more information about the visual scene than decoding under the assumption of independence, and preserves 40\% more visual information than optimal linear decoding. This model-based approach reveals the role of correlated activity in the retinal coding of visual stimuli, and provides a general framework for understanding the importance of correlated activity in populations of neurons.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SZ2IHG7K\\Pillow et al. - 2008 - Spatio-temporal correlations and visual signalling in a complete neuronal population(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\VDCVILCJ\\Pillow et al. - 2008 - Spatio-temporal correlations and visual signalling in a complete neuronal population.pdf},
  journal = {Nature},
  number = {7207},
  pmid = {18650810}
}

@article{pinotsis_friston_2016,
  title = {Bayesian {{Modelling}} of {{Induced Responses}} and {{Neuronal Rhythms}}},
  author = {Pinotsis, Dimitris A. and Loonis, Roman and Bastos, Andre M. and Miller, Earl K and Friston, Karl J.},
  year = {2016},
  month = oct,
  pages = {1--14},
  issn = {0896-0267},
  doi = {10.1007/s10548-016-0526-y},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3LZFB5KN\\Pinotsis et al. - 2016 - Bayesian Modelling of Induced Responses and Neuronal Rhythms.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\54XTX5YS\\Pinotsis et al. - 2019 - Bayesian Modelling of Induced Responses and Neuron.pdf},
  journal = {Brain Topography}
}

@article{pinotsis_miller_2017,
  title = {On Memories, Neural Ensembles and Mental Flexibility},
  author = {Pinotsis, Dimitris A. and Brincat, Scott L. and Miller, Earl K.},
  year = {2017},
  month = aug,
  volume = {157},
  pages = {297--313},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2017.05.068},
  abstract = {Memories are assumed to be represented by groups of co-activated neurons, called neural ensembles. Describing ensembles is a challenge: complexity of the underlying micro-circuitry is immense. Current approaches use a piecemeal fashion, focusing on single neurons and employing local measures like pairwise correlations. We introduce an alternative approach that identifies ensembles and describes the effective connectivity between them in a holistic fashion. It also links the oscillatory frequencies observed in ensembles with the spatial scales at which activity is expressed. Using unsupervised learning, biophysical modeling and graph theory, we analyze multi-electrode LFPs from frontal cortex during a spatial delayed response task. We find distinct ensembles for different cues and more parsimonious connectivity for cues on the horizontal axis, which may explain the oblique effect in psychophysics. Our approach paves the way for biophysical models with learned parameters that can guide future Brain Computer Interface development.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\S5HYB5TY\\Pinotsis et al. - 2017 - On memories, neural ensembles and mental flexibili.pdf},
  journal = {NeuroImage},
  language = {en}
}

@article{pinotsis_miller_2018,
  title = {Working {{Memory Load Modulates Neuronal Coupling}}},
  author = {Pinotsis, Dimitris A and Buschman, Timothy J and Miller, Earl K},
  year = {2018},
  volume = {1},
  issn = {1047-3211},
  doi = {10.1101/192336},
  abstract = {There is a severe limitation in the number of items that can be held in working memory. However, the neurophysiological limits remain unknown. We asked whether the capacity limit might be explained by differences in neuronal coupling. We developed a theoretical model based on Predictive Coding and used it to analyze Cross Spectral Density data from the prefrontal cortex (PFC), frontal eye fields (FEF) and lateral intraparietal area (LIP). Monkeys performed a change detection task (Buschman et al., 2011). The number of objects that had to be remembered (memory load) was varied (1-3 objects in the same visual hemifield). Changes in memory load changed the connectivity in the PFC-FEF-LIP network. Feedback (top-down) coupling broke down when the number of objects exceeded cognitive capacity. This provides new insights into the neuronal underpinnings of cognitive capacity and how coupling in a distributed working memory network is affected by memory load.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GUDVGRVI\\Pinotsis, Buschman, Miller - 2018 - Working Memory Load Modulates Neuronal Coupling.pdf},
  journal = {Cerebral Cortex},
  keywords = {biophysical modeling,cognitive capacity,prefrontal cortex,synchrony,working-memory},
  number = {12}
}

@article{pinotsis_miller_2019,
  title = {Sensory Processing and Categorization in Cortical and Deep Neural Networks},
  author = {Pinotsis, Dimitris A. and Siegel, Markus and Miller, Earl K.},
  year = {2019},
  month = nov,
  volume = {202},
  pages = {116118},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2019.116118},
  abstract = {Many recent advances in artificial intelligence (AI) are rooted in visual neuroscience. However, ideas from more complicated paradigms like decision-making are less used. Although automated decision-making systems are ubiquitous (driverless cars, pilot support systems, medical diagnosis algorithms etc.), achieving human-level performance in decision making tasks is still a challenge. At the same time, these tasks that are hard for AI are easy for humans. Thus, understanding human brain dynamics during these decision-making tasks and modeling them using deep neural networks could improve AI performance. Here we modelled some of the complex neural interactions during a sensorimotor decision making task. We investigated how brain dynamics flexibly represented and distinguished between sensory processing and categorization in two sensory domains: motion direction and color. We used two different approaches for understanding neural representations. We compared brain responses to 1) the geometry of a sensory or category domain (domain selectivity) and 2) predictions from deep neural networks (computation selectivity). Both approaches gave us similar results. This confirmed the validity of our analyses. Using the first approach, we found that neural representations changed depending on context. We then trained deep recurrent neural networks to perform the same tasks as the animals. Using the second approach, we found that computations in different brain areas also changed flexibly depending on context. Color computations appeared to rely more on sensory processing, while motion computations more on abstract categories. Overall, our results shed light to the biological basis of categorization and differences in selectivity and computations in different brain areas. They also suggest a way for studying sensory and categorical representations in the brain: compare brain responses to both a behavioral model and a deep neural network and test if they give similar results.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MSEQSHUI\\Pinotsis et al. - 2019 - Sensory processing and categorization in cortical .pdf},
  journal = {NeuroImage},
  language = {en}
}

@article{pinotsis_miller_2019a,
  title = {Working {{Memory Load Modulates Neuronal Coupling}}},
  author = {Pinotsis, Dimitris A and Buschman, Timothy J and Miller, Earl K},
  year = {2019},
  month = apr,
  volume = {29},
  pages = {1670--1681},
  issn = {1047-3211, 1460-2199},
  doi = {10.1093/cercor/bhy065},
  abstract = {There is a severe limitation in the number of items that can be held in working memory. However, the neurophysiological limits remain unknown. We asked whether the capacity limit might be explained by differences in neuronal coupling. We developed a theoretical model based on Predictive Coding and used it to analyze Cross Spectral Density data from the prefrontal cortex (PFC), frontal eye fields (FEF), and lateral intraparietal area (LIP). Monkeys performed a change detection task. The number of objects that had to be remembered (memory load) was varied (1\textendash 3 objects in the same visual hemifield). Changes in memory load changed the connectivity in the PFC\textendash FEF\textendash LIP network. Feedback (top-down) coupling broke down when the number of objects exceeded cognitive capacity. Thus, impaired behavioral performance coincided with a breakdown of Prediction signals. This provides new insights into the neuronal underpinnings of cognitive capacity and how coupling in a distributed working memory network is affected by memory load.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BGHURXD9\\Pinotsis et al. - 2019 - Working Memory Load Modulates Neuronal Coupling.pdf},
  journal = {Cerebral Cortex},
  language = {en},
  number = {4}
}

@article{pinto_kopell_2003,
  title = {Analysis of State-Dependent Transitions in Frequency and Long-Distance Coordination in a Model Oscillatory Cortical Circuit.},
  author = {Pinto, David J and Jones, Stephanie R and Kaper, Tasso J and Kopell, Nancy},
  year = {2003},
  volume = {15},
  pages = {283--298},
  issn = {0929-5313},
  abstract = {Changes in behavioral state are typically accompanied by changes in the frequency and spatial coordination of rhythmic activity in the neocortex. In this article, we analyze the effects of neuromodulation on ionic conductances in an oscillating cortical circuit model. The model consists of synaptically-coupled excitatory and inhibitory neurons and supports rhythmic activity in the alpha, beta, and gamma ranges. We find that the effects of neuromodulation on ionic conductances are, by themselves, sufficient to induce transitions between synchronous gamma and beta rhythms and asynchronous alpha rhythms. Moreover, these changes are consistent with changes in behavioral state, with the rhythm transitioning from the slower alpha to the faster gamma and beta as arousal increases. We also observe that it is the same set of underlying intrinsic and network mechanisms that appear to be simultaneously responsible for both the observed transitions between the rhythm types and between their synchronization properties. Spike time response curves (STRCs) are used to study the relationship between the transitions in rhythm and the underlying biophysics.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3W3IKHKD\\Pinto et al. - 2003 - Analysis of state-dependent transitions in frequency and long-distance coordination in a model oscillatory cortica.pdf},
  journal = {Journal of computational neuroscience},
  keywords = {Biophysical Phenomena,Biophysics,Cortical Synchronization,Electroencephalography,Models,Neocortex,Neocortex: physiology,Nerve Net,Neural Inhibition,Neural Networks (Computer),Neurological,Neurons,Neurons: physiology,Synapses,Synapses: physiology,Synaptic Transmission,Time Factors},
  number = {2},
  pmid = {14512752}
}

@techreport{piray_daw_2019,
  title = {A Transparent Model for Learning in Volatile Environments},
  author = {Piray, Payam and Daw, Nathaniel D.},
  year = {2019},
  month = jul,
  institution = {{Neuroscience}},
  doi = {10.1101/701466},
  abstract = {Sound principles of statistical inference dictate that uncertainty shapes learning. In this work, we revisit the question of learning in volatile environments, in which both the first and second-order statistics of environments dynamically evolve over time. We propose a new model, the volatile Kalman filter (VKF), which is based on a tractable state-space model of uncertainty and extends the Kalman filter algorithm to volatile environments. Algorithmically, the proposed model is simpler and more transparent than existing models, and encompasses the Kalman filter as a special case. Specifically, in addition to the errorcorrecting rule of Kalman filter for learning observations, the VKF learns volatility according to a second error-correcting rule. These dual updates echo and contextualize classical psychological models of learning, in particular hybrid accounts of Pearce-Hall and Rescorla-Wagner. At the computational level, compared with existing models, the VKF is more accurate, particularly in estimating volatility, as it is based on more faithful approximations to the exact inference. Accordingly, when fit to empirical data, the VKF is better behaved than alternatives and better captures human choice data in a probabilistic learning task. The proposed model provides a transparent and coherent account of learning in stable or volatile environments and has implications for decision neuroscience research.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BKIRVMMW\\Piray and Daw - 2019 - A transparent model for learning in volatile envir.pdf},
  language = {en},
  type = {Preprint}
}

@article{pisauro_philiastides_2017,
  title = {Neural Correlates of Evidence Accumulation during Value-Based Decisions Revealed via Simultaneous {{EEG}}-{{fMRI}}},
  author = {Pisauro, M Andrea and Fouragnan, Elsa and Retzler, Chris and Philiastides, Marios G},
  year = {2017},
  volume = {8},
  pages = {15808},
  issn = {2041-1723},
  doi = {10.1038/ncomms15808},
  abstract = {Current computational accounts posit that, in simple binary choices, humans accumulate evidence in favour of the different alternatives before committing to a decision. Neural correlates of this accumulating activity have been found during perceptual decisions in parietal and prefrontal cortex; however the source of such activity in value-based choices remains unknown. Here we use simultaneous EEG-fMRI and computational modelling to identify EEG signals reflecting an accumulation process and demonstrate that the within- and across-trial variability in these signals explains fMRI responses in posterior-medial frontal cortex. Consistent with its role in integrating the evidence prior to reaching a decision, this region also exhibits task-dependent coupling with the ventromedial prefrontal cortex and the striatum, brain areas known to encode the subjective value of the decision alternatives. These results further endorse the proposition of an evidence accumulation process during value-based decisions in humans and implicate the posterior-medial frontal cortex in this process.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\A4Y2T9JV\\Pisauro et al. - 2017 - Neural correlates of evidence accumulation during value-based decisions revealed via simultaneous EEG-fMRI.pdf},
  journal = {Nature Communications},
  pmid = {28598432}
}

@article{pisoni_cattaneo_2012,
  title = {Neural Correlates of the Semantic Interference Effect: New Evidence from Transcranial Direct Current Stimulation.},
  author = {Pisoni, a and Papagno, C and Cattaneo, Z},
  year = {2012},
  month = oct,
  volume = {223},
  pages = {56--67},
  issn = {1873-7544},
  doi = {10.1016/j.neuroscience.2012.07.046},
  abstract = {In two experiments, we combined a semantic blocked naming paradigm with anodal transcranial direct current stimulation (tDCS) to shed light on the neural correlates of the semantic interference (SI) effect. In particular, prior to the naming task, anodal tDCS was applied over the left superior temporal gyrus (STG, Experiment 1) or the left inferior frontal gyrus (IFG, Experiment 2) to enhance cortical excitability in these regions. In both experiments, participants were tested in two sessions in which either real or sham tDCS was delivered. We found that anodal tDCS over the left STG significantly increased the SI effect, whereas anodal tDCS over the left IFG led to a reduction of the SI effect. Overall, our data confirm the existence of a distributed cortical network involved in lexical retrieval and show that both the left IFG and the left STG play a causal role in this process. In particular, the left IFG is likely to be critical in resolving the conflict between competitor lexical representations, while the left STG seems to be the neural locus of the lexical representational system, where competition among different lexical representations occurs.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XIZQ3PTK\\Pisoni, Papagno, Cattaneo - 2012 - Neural correlates of the semantic interference effect new evidence from transcranial direct current s.pdf},
  journal = {Neuroscience},
  keywords = {Attention,Attention: physiology,Brain Mapping,Female,Functional Laterality,Functional Laterality: physiology,Humans,Male,Names,Neuropsychological Tests,Photic Stimulation,Reaction Time,Reaction Time: physiology,Semantics,Temporal Lobe,Temporal Lobe: physiology,Transcranial Magnetic Stimulation},
  pmid = {22863670}
}

@article{pitkow_angelaki_2017,
  title = {Perspective {{Inference}} in the {{Brain}}: {{Statistics Flowing}} in {{Redundant Population Codes}}},
  author = {Pitkow, Xaq and Angelaki, Dora E},
  year = {2017},
  volume = {94},
  pages = {943--953},
  doi = {10.1016/j.neuron.2017.05.028},
  abstract = {It is widely believed that the brain performs approximate probabilistic inference to estimate causal variables in the world from ambiguous sensory data. To understand these computations, we need to analyze how information is represented and transformed by the actions of nonlinear recurrent neural networks. We propose that these probabilistic computations function by a message-passing algorithm operating at the level of redundant neural populations. To explain this framework, we review its underlying concepts, including graphical models, sufficient statistics, and message-passing, and then describe how these concepts could be implemented by recurrently connected probabilistic population codes. The relevant information flow in these networks will be most interpretable at the population level, particularly for redundant neural codes. We therefore outline a general approach to identify the essential features of a neural message-passing algorithm. Finally, we argue that to reveal the most important aspects of these neural computations, we must study large-scale activity patterns during moderately complex, naturalistic behaviors.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4BFZ8H3J\\Pitkow, Angelaki - 2017 - Perspective Inference in the Brain Statistics Flowing in Redundant Population Codes.pdf},
  journal = {Neuron},
  keywords = {brain,coding,inference,message-passing,nonlinear,nuisance,population code,redundant,theory}
}

@article{pitti_boucenna_2020,
  title = {Gated Spiking Neural Network Using {{Iterative Free}}-{{Energy Optimization}} and Rank-Order Coding for Structure Learning in Memory Sequences ({{INFERNO GATE}})},
  author = {Pitti, Alexandre and Quoy, Mathias and Lavandier, Catherine and Boucenna, Sofiane},
  year = {2020},
  month = jan,
  volume = {121},
  pages = {242--258},
  issn = {08936080},
  doi = {10.1016/j.neunet.2019.09.023},
  abstract = {We present a framework based on iterative free-energy optimization with spiking neural networks for modeling the fronto-striatal system (PFC-BG) for the generation and recall of audio memory sequences. In line with neuroimaging studies carried out in the PFC, we propose a genuine coding strategy using the gain-modulation mechanism to represent abstract sequences based solely on the rank and location of items within them. Based on this mechanism, we show that we can construct a repertoire of neurons sensitive to the temporal structure in sequences from which we can represent any novel sequences. Free-energy optimization is then used to explore and to retrieve the missing indices of the items in the correct order for executive control and compositionality. We show that the gain-modulation mechanism permits the network to be robust to variabilities and to have long-term dependencies as it implements a gated recurrent neural network. This model, called Inferno Gate, is an extension of the neural architecture Inferno standing for Iterative Free-Energy Optimization of Recurrent Neural Networks with Gating or Gain-modulation. In experiments performed with an audio database of ten thousand MFCC vectors, Inferno Gate is capable of encoding efficiently and retrieving chunks of fifty items length. We then discuss the potential of our network to model the features of working memory in the PFC-BG loop for structural learning, goal-direction and hierarchical reinforcement learning.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2JE8AE4P\\Pitti et al. - 2020 - Gated spiking neural network using Iterative Free-.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\DKWD2D6S\\Pitti et al. - 2020 - Gated spiking neural network using Iterative Free-.pdf},
  journal = {Neural Networks},
  language = {en}
}

@article{place_eichenbaum_2016,
  title = {Bidirectional Prefrontal-Hippocampal Interactions Support Context-Guided Memory},
  author = {Place, Ryan and Farovik, Anja and Brockmann, Marco and Eichenbaum, Howard B},
  year = {2016},
  volume = {19},
  pages = {992--994},
  issn = {1097-6256},
  doi = {10.1038/nn.4327},
  abstract = {We compared the dynamics of hippocampal and prefrontal interactions in rats as they used spatial contexts to guide the retrieval of object memories. Functional connectivity analysis indicated a flow of contextual information from the hippocampus to prefrontal cortex upon the rat's entry into the spatial context. Conversely, upon the onset of object sampling, the direction of information flow reversed, consistent with prefrontal control over the retrieval of context-appropriate hippocampal memory representations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L4WU2X95\\Place et al. - 2016 - Bidirectional prefrontal-hippocampal interactions support context-guided memory.pdf},
  journal = {Nature Neuroscience},
  number = {8},
  pmid = {27322417}
}

@article{plomp_levelt_1965,
  title = {Tonal {{Consonance}} and {{Critical Bandwidth}}},
  author = {Plomp, R and Levelt, W},
  year = {1965},
  pages = {548--560},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RX6Y8Q78\\Plomp, Levelt - 1965 - Tonal Consonance and Critical Bandwidth.pdf},
  number = {April}
}

@article{poeppel_pylkkanen_2012,
  title = {Towards a New Neurobiology of Language.},
  author = {Poeppel, David and Emmorey, Karen and Hickok, Gregory and Pylkk{\"a}nen, Liina},
  year = {2012},
  volume = {32},
  pages = {14125--14131},
  issn = {1529-2401},
  doi = {10.1523/JNEUROSCI.3244-12.2012},
  abstract = {Theoretical advances in language research and the availability of increasingly high-resolution experimental techniques in the cognitive neurosciences are profoundly changing how we investigate and conceive of the neural basis of speech and language processing. Recent work closely aligns language research with issues at the core of systems neuroscience, ranging from neurophysiological and neuroanatomic characterizations to questions about neural coding. Here we highlight, across different aspects of language processing (perception, production, sign language, meaning construction), new insights and approaches to the neurobiology of language, aiming to describe promising new areas of investigation in which the neurosciences intersect with linguistic research more closely than before. This paper summarizes in brief some of the issues that constitute the background for talks presented in a symposium at the Annual Meeting of the Society for Neuroscience. It is not a comprehensive review of any of the issues that are discussed in the symposium.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WUDW4WQM\\Poeppel et al. - 2012 - Towards a new neurobiology of language.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\YVJWS8Y8\\Poeppel et al. - 2012 - Towards a new neurobiology of language(2).pdf},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  keywords = {Animals,Brain,Brain: physiology,Humans,Language,Neural Pathways,Neural Pathways: physiology,Sign Language,Speech,Speech Perception,Speech Perception: physiology,Speech: physiology},
  number = {41},
  pmid = {23055482}
}

@article{poirazi_papoutsi_2020,
  title = {Illuminating Dendritic Function with Computational Models},
  author = {Poirazi, Panayiota and Papoutsi, Athanasia},
  year = {2020},
  month = may,
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/s41583-020-0301-7},
  abstract = {Dendrites have always fascinated researchers: from the artistic drawings by Ramon y Cajal to the beautiful recordings of today{$\mkern1mu$}, neuroscientists have been striving to unravel the mysteries of these structures. Theoretical work in the 1960s predicted important dendritic effects on neuronal processing, establishing computational modelling as a powerful technique for their investigation. Since then, modelling of dendrites has been instrumental in driving neuroscience research in a targeted manner, providing experimentally testable predictions that range from the subcellular level to the systems level, and their relevance extends to fields beyond neuroscience, such as machine learning and artificial intelligence. Validation of modelling predictions often requires \textemdash{} and drives \textemdash{} new technological advances, thus closing the loop with theory-d riven experimentation that moves the field forward. This Review features the most important, to our understanding, contributions of modelling of dendritic computations, including those pending experimental verification, and highlights studies of successful interactions between the modelling and experimental neuroscience communities.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\A45XN4DV\\Poirazi and Papoutsi - 2020 - Illuminating dendritic function with computational.pdf},
  journal = {Nature Reviews Neuroscience},
  language = {en}
}

@article{poldrack_gabrieli_1999,
  title = {Functional {{Specialization}} for {{Semantic}} and {{Phonological Processing}} in the {{Left Inferior Prefrontal Cortex}} 1},
  author = {Poldrack, Russell A and Wagner, Anthony D and Prull, Matthew W and Desmond, John E and Glover, Gary H and Gabrieli, John D.E. E},
  year = {1999},
  volume = {35},
  pages = {15--35},
  issn = {10538119},
  doi = {10.1006/nimg.1999.0441},
  abstract = {Neuroimaging and neuropsychological studies have implicated left inferior prefrontal cortex (LIPC) in both semantic and phonological processing. In this study, functional magnetic resonance imaging was used to examine whether separate LIPC regions participate in each of these types of processing. Performance of a semantic decision task resulted in extensive LIPC activation compared to a perceptual control task. Phonological processing of words and pseudowords in a syllable-counting task resulted in activation of the dorsal aspect of the left inferior frontal gyrus near the inferior frontal sulcus (BA 44/45) compared to a perceptual control task, with greater activation for nonwords compared to words. In a direct comparison of semantic and phonological tasks, semantic processing preferentially activated the ventral aspect of the left inferior frontal gyrus (BA 47/45). A review of the literature demonstrated a similar distinction between left prefrontal regions involved in semantic processing and phonological/lexical processing. The results suggest that a distinct region in the left inferior frontal cortex is involved in semantic processing, whereas other regions may subserve phonological processes engaged during both semantic and phonological tasks.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EBX79CAE\\Poldrack et al. - 1999 - Functional Specialization for Semantic and Phonological Processing in the Left Inferior Prefrontal Cortex 1.pdf},
  journal = {NeuroImage},
  number = {1},
  pmid = {10385578}
}

@article{ponzi_wickens_2013,
  title = {Optimal {{Balance}} of the {{Striatal Medium Spiny Neuron Network}}},
  author = {Ponzi, Adam and Wickens, Jeffery R.},
  year = {2013},
  volume = {9},
  issn = {1553734X},
  doi = {10.1371/journal.pcbi.1002954},
  abstract = {Author SummaryThe striatum forms the main input to the Basal Ganglia (BG), a subcortical structure involved in reinforcement learning and action selection. It is composed of medium spiny neurons (MSNs) which inhibit each other through a network of collaterals, receive excitatory projections from the cerebral cortex, and are the only cells which project outside the striatum. Because of its inhibitory structure, the MSN network is often thought to act selectively, transmitting the most active cortical inputs downstream in the BG while suppressing others. However, studies show that local MSN network connections are too sparse and weak to perform global selection and their function remains puzzling. Here we investigate a different hypothesis. Rather than generating a static stimulus dependent activity pattern, we suggest the MSN network is optimized to generate stimulus dependent dynamical activity patterns for long time periods after variations in cortical excitation. We demonstrate, using simulations, that the MSN network has special characteristics. It is neither too stable to respond in a dynamically complex temporally extended way to cortical variations, nor is it too unstable to respond in a consistent repeatable way. We discuss how these properties may be utilized in temporally delayed reinforcement learning tasks strongly recruiting the striatum.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TEJI2VAC\\Ponzi, Wickens - 2013 - Optimal Balance of the Striatal Medium Spiny Neuron Network.pdf},
  journal = {PLoS Computational Biology},
  number = {4},
  pmid = {23592954}
}

@article{popov_miller_2018,
  title = {Time {{Course}} of {{Brain Network Reconfiguration Supporting Inhibitory Control}}},
  author = {Popov, Tzvetan and Westner, Britta U and Silton, Rebecca L and Sass, Sarah M and Spielberg, Jeffrey M and Rockstroh, Brigitte and Heller, Wendy and Miller, Gregory A},
  year = {2018},
  pages = {2639--17},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.2639-17.2018},
  abstract = {Hemodynamic research has recently clarified key nodes and links in brain networks implementing inhibitory control. Although fMRI methods are optimized for identifying the structure of brain networks, the relatively slow temporal course of fMRI limits the ability to characterize network operation. The latter is crucial for developing a mechanistic understanding of how brain networks shift dynamically to support inhibitory control. To address this critical gap, we applied spectrally resolved Granger causality (GC) and random forest machine learning tools to human EEG data in two large samples of adults (test sample n ϭ 96, replication sample n ϭ 237, total N ϭ 333, both sexes) who performed a color\textendash word Stroop task. Time\textendash frequency analysis confirmed that recruitment of inhibitory control accom-panied by slower behavioral responses was related to changes in theta and alpha/beta power. GC analyses revealed directionally asym-metric exchanges within frontal and between frontal and parietal brain areas: top-down influence of superior frontal gyrus (SFG) over both dorsal ACC (dACC) and inferior frontal gyrus (IFG), dACC control over middle frontal gyrus (MFG), and frontal\textendash parietal exchanges (IFG, precuneus, MFG). Predictive analytics confirmed a combination of behavioral and brain-derived variables as the best set of predictors of inhibitory control demands, with SFG theta bearing higher classification importance than dACC theta and posterior beta tracking the onset of behavioral response. The present results provide mechanistic insight into the biological implementation of a psychological phenomenon: inhibitory control is implemented by dynamic routing processes during which the target response is up-regulated via theta-mediated effective connectivity within key PFC nodes and via beta-mediated motor preparation.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PFD5XZYT\\Popov et al. - 2018 - Time Course of Brain Network Reconfiguration Supporting Inhibitory Control.pdf},
  journal = {The Journal of Neuroscience},
  keywords = {alpha,eeg,Granger causality,inhibitory control,machine learning,neuronal oscillations,theta},
  pmid = {29636394}
}

@article{porr_miller_2019,
  title = {Forward Propagation Closed Loop Learning},
  author = {Porr, Bernd and Miller, Paul},
  year = {2019},
  month = may,
  pages = {105971231985107},
  issn = {1059-7123, 1741-2633},
  doi = {10.1177/1059712319851070},
  abstract = {For an autonomous agent, the inputs are the sensory data that inform the agent of the state of the world, and the outputs are their actions, which act on the world and consequently produce new sensory inputs. The agent only knows of its own actions via their effect on future inputs; therefore desired states, and error signals, are most naturally defined in terms of the inputs. Most machine learning algorithms, however, operate in terms of desired outputs. For example, backpropagation takes target output values and propagates the corresponding error backwards through the network in order to change the weights. In closed loop settings, it is far more obvious how to define desired sensory inputs than desired actions, however. To train a deep network using errors defined in the input space would call for an algorithm that can propagate those errors forwards through the network, from input layer to output layer, in much the same way that activations are propagated. In this article, we present a novel learning algorithm which performs such `forward-propagation' of errors. We demonstrate its performance, first in a simple line follower and then in a 1st person shooter game.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\C9JRSIL7\\Porr and Miller - 2019 - Forward propagation closed loop learning.pdf},
  journal = {Adaptive Behavior},
  language = {en}
}

@article{potjans_diesmann_2014,
  title = {The {{Cell}}-{{Type Specific Cortical Microcircuit}}: {{Relating Structure}} and {{Activity}} in a {{Full}}-{{Scale Spiking Network Model}}},
  shorttitle = {The {{Cell}}-{{Type Specific Cortical Microcircuit}}},
  author = {Potjans, Tobias C. and Diesmann, Markus},
  year = {2014},
  month = mar,
  volume = {24},
  pages = {785--806},
  issn = {1460-2199, 1047-3211},
  doi = {10.1093/cercor/bhs358},
  abstract = {In the past decade, the cell-type specific connectivity and activity of local cortical networks have been characterized experimentally to some detail. In parallel, modeling has been established as a tool to relate network structure to activity dynamics. While available comprehensive connectivity maps (Thomson, West, et al. 2002; Binzegger et al. 2004) have been used in various computational studies, prominent features of the simulated activity such as the spontaneous firing rates do not match the experimental findings. Here, we analyze the properties of these maps to compile an integrated connectivity map, which additionally incorporates insights on the specific selection of target types. Based on this integrated map, we build a full-scale spiking network model of the local cortical microcircuit. The simulated spontaneous activity is asynchronous irregular and cell-type specific firing rates are in agreement with in vivo recordings in awake animals, including the low rate of layer 2/3 excitatory cells. The interplay of excitation and inhibition captures the flow of activity through cortical layers after transient thalamic stimulation. In conclusion, the integration of a large body of the available connectivity data enables us to expose the dynamical consequences of the cortical microcircuitry.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\N6WPV4Z6\\Potjans and Diesmann - 2014 - The Cell-Type Specific Cortical Microcircuit Rela.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\SJR8BHLP\\Potjans and Diesmann - 2014 - The Cell-Type Specific Cortical Microcircuit Rela.pdf},
  journal = {Cerebral Cortex},
  language = {en},
  number = {3}
}

@article{pouget_sejnowski_1997,
  title = {Spatial {{Transformations}} in the {{Parietal Cortex Using Basis Functions}}},
  author = {Pouget, Alexandre and Sejnowski, Terrence J.},
  year = {1997},
  month = mar,
  volume = {9},
  pages = {222--237},
  issn = {0898-929X, 1530-8898},
  doi = {10.1162/jocn.1997.9.2.222},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WPKBHJ2V\\Pouget and Sejnowski - 1997 - Spatial Transformations in the Parietal Cortex Usi.pdf},
  journal = {Journal of Cognitive Neuroscience},
  keywords = {gain field,transform},
  language = {en},
  number = {2}
}

@article{pratte_tong_2017,
  title = {Integrating Theoretical Models with Functional Neuroimaging},
  author = {Pratte, Michael S. and Tong, Frank},
  year = {2017},
  volume = {76},
  pages = {80--93},
  issn = {10960880},
  doi = {10.1016/j.jmp.2016.06.008},
  abstract = {The development of mathematical models to characterize perceptual and cognitive processes dates back almost to the inception of the field of psychology. Since the 1990s, human functional neuroimaging has provided for rapid empirical and theoretical advances across a variety of domains in cognitive neuroscience. In more recent work, formal modeling and neuroimaging approaches are being successfully combined, often producing models with a level of specificity and rigor that would not have been possible by studying behavior alone. In this review, we highlight examples of recent studies that utilize this combined approach to provide novel insights into the mechanisms underlying human cognition. The studies described here span domains of perception, attention, memory, categorization, and cognitive control, employing a variety of analytic and model-inspired approaches. Across these diverse studies, a common theme is that individually tailored, creative solutions are often needed to establish compelling links between multi-parameter models and complex sets of neural data. We conclude that future developments in model-based cognitive neuroscience will have great potential to advance our theoretical understanding and ability to model both low-level and high-level cognitive processes.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RTAFKJVV\\Pratte, Tong - 2017 - Integrating theoretical models with functional neuroimaging.pdf},
  journal = {Journal of Mathematical Psychology},
  pmid = {28286346}
}

@article{premack_premack_2015,
  title = {Is {{Language}} the {{Key}} to {{Human Intelligence}}? {{Author}}(s): {{David Premack Source}}:},
  author = {Premack, David},
  year = {2015},
  volume = {303},
  pages = {318--320},
  doi = {10.1126/science.1093993},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QG7VJDUF\\Premack - 2015 - Is Language the Key to Human Intelligence Author(s) David Premack Source.pdf},
  number = {5656}
}

@article{preston_eichenbaum_2013,
  title = {Interplay of Hippocampus and Prefrontal Cortex in Memory},
  author = {Preston, Alison R and Eichenbaum, Howard B},
  year = {2013},
  volume = {23},
  pages = {R764----R773},
  issn = {09609822},
  doi = {10.1016/j.cub.2013.05.041},
  abstract = {Recent studies on the hippocampus and the prefrontal cortex have considerably advanced our understanding of the distinct roles of these brain areas in the encoding and retrieval of memories, and of how they interact in the prolonged process by which new memories are consolidated into our permanent storehouse of knowledge. These studies have led to a new model of how the hippocampus forms and replays memories and how the prefrontal cortex engages representations of the meaningful contexts in which related memories occur, as well as how these areas interact during memory retrieval. Furthermore, they have provided new insights into how interactions between the hippocampus and prefrontal cortex support the assimilation of new memories into pre-existing networks of knowledge, called schemas, and how schemas are modified in this process as the foundation of memory consolidation. ?? 2013 Elsevier Ltd.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Q8T7LJQ9\\Preston, Eichenbaum - 2013 - Interplay of hippocampus and prefrontal cortex in memory.pdf},
  journal = {Current Biology},
  number = {17},
  pmid = {24028960}
}

@article{purcell_palmeri_2017,
  title = {Relating Accumulator Model Parameters and Neural Dynamics},
  author = {Purcell, Braden A and Palmeri, Thomas J},
  year = {2017},
  volume = {76},
  pages = {156--171},
  issn = {10960880},
  doi = {10.1016/j.jmp.2016.07.001},
  abstract = {Accumulator models explain decision-making as an accumulation of evidence to a response threshold. Specific model parameters are associated with specific model mechanisms, such as the time when accumulation begins, the average rate of evidence accumulation, and the threshold. These mechanisms determine both the within-trial dynamics of evidence accumulation and the predicted behavior. Cognitive modelers usually infer what mechanisms vary during decision-making by seeing what parameters vary when a model is fitted to observed behavior. The recent identification of neural activity with evidence accumulation suggests that it may be possible to directly infer what mechanisms vary from an analysis of how neural dynamics vary. However, evidence accumulation is often noisy, and noise complicates the relationship between accumulator dynamics and the underlying mechanisms leading to those dynamics. To understand what kinds of inferences can be made about decision-making mechanisms based on measures of neural dynamics, we measured simulated accumulator model dynamics while systematically varying model parameters. In some cases, decision-making mechanisms can be directly inferred from dynamics, allowing us to distinguish between models that make identical behavioral predictions. In other cases, however, different parameterized mechanisms produce surprisingly similar dynamics, limiting the inferences that can be made based on measuring dynamics alone. Analyzing neural dynamics can provide a powerful tool to resolve model mimicry at the behavioral level, but we caution against drawing inferences based solely on neural analyses. Instead, simultaneous modeling of behavior and neural dynamics provides the most powerful approach to understand decision-making and likely other aspects of cognition and perception.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2CM5ACAV\\Purcell, Palmeri - 2017 - Relating accumulator model parameters and neural dynamics.pdf},
  journal = {Journal of Mathematical Psychology},
  keywords = {Decision making,Neural models,Response time},
  pmid = {6438559}
}

@article{qian_wang_2018,
  title = {Communicated by {{Kunling Geng Nonlinear Modeling}} of {{Neural Interaction}} for {{Spike Prediction Using}} the {{Staged Point}}-{{Process Model Gang Pan}}},
  author = {Qian, Cunle and Zhang, Shaomin and Xing, Dong and Li, Hongbao and Zheng, Xiaoxiang and Wang, Yiwen},
  year = {2018},
  volume = {30},
  pages = {3189--3226},
  doi = {10.1162/neco_a_01137},
  abstract = {Neurons communicate nonlinearly through spike activities. Generalized linear models (GLMs) describe spike activities with a cascade of a linear combination across inputs, a static nonlinear function, and an inhomoge-neous Bernoulli or Poisson process, or Cox process if a self-history term is considered. This structure considers the output nonlinearity in spike 3190 C. Qian et al. generation but excludes the nonlinear interaction among input neurons. Recent studies extend GLMs by modeling the interaction among input neurons with a quadratic function, which considers the interaction between every pair of input spikes. However, quadratic effects may not fully capture the nonlinear nature of input interaction. We therefore propose a staged point-process model to describe the nonlinear interaction among inputs using a few hidden units, which follows the idea of artificial neural networks. The output firing probability conditioned on inputs is formed as a cascade of two linear-nonlinear (a linear combination plus a static nonlinear function) stages and an inhomogeneous Bernoulli process. Parameters of this model are estimated by maximizing the log likelihood on output spike trains. Unlike the iterative reweighted least squares algorithm used in GLMs, where the performance is guaranteed by the concave condition, we propose a modified Levenberg-Marquardt (L-M) algorithm, which directly calculates the Hessian matrix of the log likelihood , for the nonlinear optimization in our model. The proposed model is tested on both synthetic data and real spike train data recorded from the dorsal premotor cortex and primary motor cortex of a monkey performing a center-out task. Performances are evaluated by discrete-time rescaled Kolmogorov-Smirnov tests, where our model statistically out-performs a GLM and its quadratic extension, with a higher goodness-of-fit in the prediction results. In addition, the staged point-process model describes nonlinear interaction among input neurons with fewer parameters than quadratic models, and the modified L-M algorithm also demonstrates fast convergence.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\H52ERNW6\\Qian et al. - 2018 - Communicated by Kunling Geng Nonlinear Modeling of Neural Interaction for Spike Prediction Using the Staged Point-P.pdf},
  journal = {Neural Computation}
}

@article{qiu_lee_2019,
  title = {A {{Neurally}}-{{Inspired Hierarchical Prediction Network}} for {{Spatiotemporal Sequence Learning}} and {{Prediction}}},
  author = {Qiu, Jielin and Huang, Ge and Lee, Tai Sing},
  year = {2019},
  month = jan,
  abstract = {In this paper we developed a hierarchical network model, called Hierarchical Prediction Network (HPNet), to understand how spatiotemporal memories might be learned and encoded in the recurrent circuits in the visual cortical hierarchy for predicting future video frames. This neurally inspired model operates in the analysis-by-synthesis framework. It contains a feed-forward path that computes and encodes spatiotemporal features of successive complexity and a feedback path for the successive levels to project their interpretations to the level below. Within each level, the feedforward path and the feedback path intersect in a recurrent gated circuit, instantiated in a LSTM module, to generate a prediction or explanation of the incoming signals. The network learns its internal model of the world by minimizing the errors of its prediction of the incoming signals at each level of the hierarchy. We found that hierarchical interaction in the network increases semantic clustering of global movement patterns in the population codes of the units along the hierarchy, even in the earliest module. This facilitates the learning of relationships among movement patterns, yielding state-of-the-art performance in long range video sequence predictions in the benchmark datasets. The network model automatically reproduces a variety of prediction suppression and familiarity suppression neurophysiological phenomena observed in the visual cortex, suggesting that hierarchical prediction might indeed be an important principle for representational learning in the visual cortex.},
  archivePrefix = {arXiv},
  eprint = {1901.09002},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MAIJJTCK\\Qiu et al. - 2019 - A Neurally-Inspired Hierarchical Prediction Networ.pdf},
  journal = {arXiv:1901.09002 [cs]},
  language = {en},
  primaryClass = {cs}
}

@article{qiu_lee_2019a,
  title = {Visual {{Sequence Learning}} in {{Hierarchical Prediction Networks}} and {{Primate Visual Cortex}}},
  author = {Qiu, Jielin and Huang, Ge and Lee, Tai Sing},
  year = {2019},
  pages = {12},
  abstract = {In this paper we developed a computational hierarchical network model to understand the spatiotemporal sequence learning effects observed in the primate visual cortex. The model is a hierarchical recurrent neural model that learns to predict video sequences using the incoming video signals as teaching signals. The model performs fast feedforward analysis using a deep convolutional neural network with sparse convolution and feedback synthesis using a stack of LSTM modules. The network learns a representational hierarchy by minimizing its prediction errors of the incoming signals at each level of the hierarchy. We found that recurrent feedback in this network lead to the development of semantic cluster of global movement patterns in the population codes of the units at the lower levels of the hierarchy. These representations facilitate the learning of relationship among movement patterns, yielding state-of-the-art performance in long range video sequence predictions on benchmark datasets. Without further tuning, this model automatically exhibits the neurophysiological correlates of visual sequence memories that we observed in the early visual cortex of awake monkeys, suggesting the principle of self-supervised prediction learning might be relevant to understanding the cortical mechanisms of representational learning.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6Q2GING6\\Qiu et al. - Visual Sequence Learning in Hierarchical Predictio.pdf},
  language = {en}
}

@article{qu_tang_2019,
  title = {Probabilistic {{Logic Neural Networks}} for {{Reasoning}}},
  author = {Qu, Meng and Tang, Jian},
  year = {2019},
  month = jun,
  abstract = {Knowledge graph reasoning, which aims at predicting the missing facts through reasoning with the observed facts, is critical to many applications. Such a problem has been widely explored by traditional logic rule-based approaches and recent knowledge graph embedding methods. A principled logic rule-based approach is the Markov Logic Network (MLN), which is able to leverage domain knowledge with first-order logic and meanwhile handle their uncertainty. However, the inference of MLNs is usually very difficult due to the complicated graph structures. Different from MLNs, knowledge graph embedding methods (e.g. TransE, DistMult) learn effective entity and relation embeddings for reasoning, which are much more effective and efficient. However, they are unable to leverage domain knowledge. In this paper, we propose the probabilistic Logic Neural Network (pLogicNet), which combines the advantages of both methods. A pLogicNet defines the joint distribution of all possible triplets by using a Markov logic network with first-order logic, which can be efficiently optimized with the variational EM algorithm. In the E-step, a knowledge graph embedding model is used for inferring the missing triplets, while in the M-step, the weights of logic rules are updated based on both the observed and predicted triplets. Experiments on multiple knowledge graphs prove the effectiveness of pLogicNet over many competitive baselines.},
  archivePrefix = {arXiv},
  eprint = {1906.08495},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L2JSM9ET\\Qu_Tang_2019_Probabilistic_Logic_Neural_Networks_for_Reasoning.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\ZJLXLLPC\\1906.html},
  journal = {arXiv:1906.08495 [cs, stat]},
  primaryClass = {cs, stat}
}

@article{quax_tiesinga_2017,
  title = {Top-down Control of Cortical Gamma-Band Communication via Pulvinar Induced Phase Shifts in the Alpha Rhythm},
  author = {Quax, Silvan and Jensen, Ole and Tiesinga, Paul},
  editor = {Bush, Daniel},
  year = {2017},
  month = may,
  volume = {13},
  pages = {e1005519},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1005519},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CRDDA9LP\\Quax et al. - 2017 - Top-down control of cortical gamma-band communicat.pdf},
  journal = {PLOS Computational Biology},
  language = {en},
  number = {5}
}

@article{rabinowitz_botvinick_2018,
  title = {Machine {{Theory}} of {{Mind}}},
  author = {Rabinowitz, Neil C. and Perbet, Frank and Song, H. Francis and Zhang, Chiyuan and Eslami, S. M. Ali and Botvinick, Matthew},
  year = {2018},
  month = feb,
  abstract = {Theory of mind (ToM; Premack \& Woodruff, 1978) broadly refers to humans' ability to represent the mental states of others, including their desires, beliefs, and intentions. We propose to train a machine to build such models too. We design a Theory of Mind neural network \textendash{} a ToMnet \textendash{} which uses meta-learning to build models of the agents it encounters, from observations of their behaviour alone. Through this process, it acquires a strong prior model for agents' behaviour, as well as the ability to bootstrap to richer predictions about agents' characteristics and mental states using only a small number of behavioural observations. We apply the ToMnet to agents behaving in simple gridworld environments, showing that it learns to model random, algorithmic, and deep reinforcement learning agents from varied populations, and that it passes classic ToM tasks such as the ``SallyAnne'' test (Wimmer \& Perner, 1983; BaronCohen et al., 1985) of recognising that others can hold false beliefs about the world. We argue that this system \textendash{} which autonomously learns how to model other agents in its world \textendash{} is an important step forward for developing multi-agent AI systems, for building intermediating technology for machine-human interaction, and for advancing the progress on interpretable AI.},
  archivePrefix = {arXiv},
  eprint = {1802.07740},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YMGBX9YQ\\Rabinowitz et al. - 2018 - Machine Theory of Mind.pdf},
  journal = {arXiv:1802.07740 [cs]},
  language = {en},
  primaryClass = {cs}
}

@article{radulescu_ballard_2019,
  title = {Holistic {{Reinforcement Learning}}: {{The Role}} of {{Structure}} and {{Attention}}},
  shorttitle = {Holistic {{Reinforcement Learning}}},
  author = {Radulescu, Angela and Niv, Yael and Ballard, Ian},
  year = {2019},
  month = apr,
  volume = {23},
  pages = {278--292},
  issn = {13646613},
  doi = {10.1016/j.tics.2019.01.010},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KXNUAN9T\\Radulescu et al. - 2019 - Holistic Reinforcement Learning The Role of Struc.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\UHIUUTWT\\Radulescu et al. - 2019 - Holistic Reinforcement Learning The Role of Struc.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\YQS88PGE\\Radulescu et al. - 2019 - Holistic Reinforcement Learning The Role of Struc.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {4}
}

@article{rahwan_wellman_2019,
  title = {Machine Behaviour},
  author = {Rahwan, Iyad and Cebrian, Manuel and Obradovich, Nick and Bongard, Josh and Bonnefon, Jean-Fran{\c c}ois and Breazeal, Cynthia and Crandall, Jacob W. and Christakis, Nicholas A. and Couzin, Iain D. and Jackson, Matthew O. and Jennings, Nicholas R. and Kamar, Ece and Kloumann, Isabel M. and Larochelle, Hugo and Lazer, David and McElreath, Richard and Mislove, Alan and Parkes, David C. and Pentland, Alex `Sandy' and Roberts, Margaret E. and Shariff, Azim and Tenenbaum, Joshua B. and Wellman, Michael},
  year = {2019},
  month = apr,
  volume = {568},
  pages = {477--486},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/s41586-019-1138-y},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9QE88VL2\\Rahwan et al. - 2019 - Machine behaviour.pdf},
  journal = {Nature},
  language = {en},
  number = {7753}
}

@article{rangel_aimone_2013,
  title = {A Hypothesis for Temporal Coding of Young and Mature Granule Cells.},
  author = {Rangel, Lara M and Quinn, Laleh K and a Chiba, Andrea and Gage, Fred H and Aimone, James B},
  year = {2013},
  month = jan,
  volume = {7},
  pages = {75},
  issn = {1662-4548},
  doi = {10.3389/fnins.2013.00075},
  abstract = {While it has been hypothesized that adult neurogenesis (NG) plays a role in the encoding of temporal information at long time-scales, the temporal relationship of immature cells to the highly rhythmic network activity of the hippocampus has been largely unexplored. Here, we present a theory for how the activity of immature adult-born granule cells relates to hippocampal oscillations. Our hypothesis is that theta rhythmic (5-10 Hz) excitatory and inhibitory inputs into the hippocampus could differentially affect young and mature granule cells due to differences in intrinsic physiology and synaptic inhibition between the two cell populations. Consequently, immature cell activity may occur at broader ranges of theta phase than the activity of their mature counterparts. We describe how this differential influence on young and mature granule cells could separate the activity of differently aged neurons in a temporal coding regime. Notably, this process could have considerable implications on how the downstream CA3 region interprets the information conveyed by young and mature granule cells. To begin to investigate the phasic behavior of granule cells, we analyzed in vivo recordings of the rat dentate gyrus (DG), observing that the temporal behavior of granule cells with respect to the theta rhythm is different between rats with normal and impaired levels of NG. Specifically, in control animals, granule cells exhibit both strong and weak coupling to the phase of the theta rhythm. In contrast, the distribution of phase relationships in NG-impaired rats is shifted such that they are significantly stronger. These preliminary data support our hypothesis that immature neurons could distinctly affect the temporal dynamics of hippocampal encoding.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JNJTKK7G\\Rangel et al. - 2013 - A hypothesis for temporal coding of young and mature granule cells.pdf},
  journal = {Frontiers in neuroscience},
  keywords = {dentate gyrus,granule cells,h,hippocampus,oscillations,temporal coding},
  number = {May},
  pmid = {23717259}
}

@article{rangel_eichenbaum_2016,
  title = {Rhythmic Coordination of Hippocampal Neurons during Associative Memory Processing},
  author = {Rangel, Lara M and Rueckemann, Jon W and Riviere, Pamela D and Keefe, Katherine R and Porter, Blake S and Heimbuch, Ian S and Budlong, Carl H and Eichenbaum, Howard B},
  year = {2016},
  volume = {5},
  pages = {1--24},
  issn = {2050084X},
  doi = {10.7554/eLife.09849},
  abstract = {\{\textbackslash textless\}p\{\textbackslash textgreater\}Hippocampal oscillations are dynamic, with unique oscillatory frequencies present during different behavioral states. To examine the extent to which these oscillations reflect neuron engagement in distinct local circuit processes that are important for memory, we recorded single cell and local field potential activity from the CA1 region of the hippocampus as rats performed a context-guided odor-reward association task. We found that theta (4\textendash 12 Hz), beta (15\textendash 35 Hz), low gamma (35\textendash 55 Hz), and high gamma (65\textendash 90 Hz) frequencies exhibited dynamic amplitude profiles as rats sampled odor cues. Interneurons and principal cells exhibited unique engagement in each of the four rhythmic circuits in a manner that related to successful performance of the task. Moreover, principal cells coherent to each rhythm differentially represented task dimensions. These results demonstrate that distinct processing states arise from the engagement of rhythmically identifiable circuits, which have unique roles in organizing task-relevant processing in the hippocampus.\{\textbackslash textless\}/p\{\textbackslash textgreater\}},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\G9DFG63W\\Rangel et al. - 2016 - Rhythmic coordination of hippocampal neurons during associative memory processing.pdf},
  journal = {eLife},
  number = {JANUARY2016},
  pmid = {26751780}
}

@article{ranti_badre_2015,
  title = {Parallel Temporal Dynamics in Hierarchical Cognitive Control},
  author = {Ranti, Carolyn and Chatham, Christopher H and Badre, David},
  year = {2015},
  volume = {142},
  pages = {205--229},
  issn = {18737838},
  doi = {10.1016/j.cognition.2015.05.003},
  abstract = {Cognitive control allows us to follow abstract rules in order to choose appropriate responses given our desired outcomes. Cognitive control is often conceptualized as a hierarchical decision process, wherein decisions made at higher, more abstract levels of control asymmetrically influence lower-level decisions. These influences could evolve sequentially across multiple levels of a hierarchical decision, consistent with much prior evidence for central bottlenecks and seriality in decision-making processes. However, here, we show that multiple levels of hierarchical cognitive control are processed primarily in parallel. Human participants selected responses to stimuli using a complex, multiply contingent (third order) rule structure. A response deadline procedure allowed assessment of the accuracy and timing of decisions made at each level of the hierarchy. In contrast to a serial decision process, error rates across levels of the decision mostly declined simultaneously and at identical rates, with only a slight tendency to complete the highest level decision first. Simulations with a biologically plausible neural network model demonstrate how such parallel processing could emerge from a previously developed hierarchically nested frontostriatal architecture. Our results support a parallel processing model of cognitive control, in which uncertainty on multiple levels of a decision is reduced simultaneously.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VBLL243Z\\Ranti, Chatham, Badre - 2015 - Parallel temporal dynamics in hierarchical cognitive control.pdf},
  journal = {Cognition},
  keywords = {Basal ganglia,Computational model,Executive function,Prefrontal cortex,Serial vs. parallel},
  pmid = {26051820}
}

@article{rao_ballard_1999,
  title = {Predictive Coding in the Visual Cortex: A Functional Interpretation of Some Extra-Classical Receptive-Field Effects},
  shorttitle = {Predictive Coding in the Visual Cortex},
  author = {Rao, Rajesh P. N. and Ballard, Dana H.},
  year = {1999},
  month = jan,
  volume = {2},
  pages = {79--87},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/4580},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CB5PXF8P\\Rao and Ballard - 1999 - Predictive coding in the visual cortex a function.pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {1}
}

@article{rao_rao_1990,
  title = {Hierarchical {{Bayesian Inference}} in {{Networks}} of {{Spiking Neurons}}},
  author = {Rao, Rajesh P},
  year = {1990},
  pages = {8},
  abstract = {There is growing evidence from psychophysical and neurophysiological studies that the brain utilizes Bayesian principles for inference and decision making. An important open question is how Bayesian inference for arbitrary graphical models can be implemented in networks of spiking neurons. In this paper, we show that recurrent networks of noisy integrate-and-fire neurons can perform approximate Bayesian inference for dynamic and hierarchical graphical models. The membrane potential dynamics of neurons is used to implement belief propagation in the log domain. The spiking probability of a neuron is shown to approximate the posterior probability of the preferred state encoded by the neuron, given past inputs. We illustrate the model using two examples: (1) a motion detection network in which the spiking probability of a direction-selective neuron becomes proportional to the posterior probability of motion in a preferred direction, and (2) a two-level hierarchical network that produces attentional effects similar to those observed in visual cortical areas V2 and V4. The hierarchical model offers a new Bayesian interpretation of attentional modulation in V2 and V4.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5TX4D9Y9\\Rao - Hierarchical Bayesian Inference in Networks of Spi.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\VGUH88J2\\Rao - Hierarchical Bayesian Inference in Networks of Spi.pdf},
  language = {en}
}

@article{raposo_battaglia_2017,
  title = {Discovering Objects and Their Relations from Entangled Scene Representations},
  author = {Raposo, David and Santoro, Adam and Barrett, David and Pascanu, Razvan and Lillicrap, Timothy and Battaglia, Peter},
  year = {2017},
  pages = {1--16},
  abstract = {Our world can be succinctly and compactly described as structured scenes of objects and relations. A typical room, for example, contains salient objects such as tables, chairs and books, and these objects typically relate to each other by their underlying causes and semantics. This gives rise to correlated features, such as position, function and shape. Humans exploit knowledge of objects and their relations for learning a wide spectrum of tasks, and more generally when learning the structure underlying observed data. In this work, we introduce relation networks (RNs) - a general purpose neural network architecture for object-relation reasoning. We show that RNs are capable of learning object relations from scene description data. Furthermore, we show that RNs can act as a bottleneck that induces the factorization of objects from entangled scene description inputs, and from distributed deep representations of scene images provided by a variational autoencoder. The model can also be used in conjunction with differentiable memory mechanisms for implicit relation discovery in one-shot learning tasks. Our results suggest that relation networks are a potentially powerful architecture for solving a variety of problems that require object relation reasoning.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NLQRAPKX\\Raposo et al. - 2017 - Discovering objects and their relations from entangled scene representations.pdf}
}

@article{rasmus_berglund_2015,
  title = {Semi-{{Supervised Learning}} with {{Ladder Network}}},
  author = {Rasmus, Antti and Valpola, Harri and Berglund, Mathias},
  year = {2015},
  pages = {1--17},
  issn = {10495258},
  doi = {10.1017/CBO9781107415324.004},
  abstract = {We combine supervised learning with unsupervised learning in deep neural networks. The proposed model is trained to simultaneously minimize the sum of supervised and unsupervised cost functions by backpropagation, avoiding the need for layer-wise pretraining. Our work builds on top of the Ladder network proposed by Valpola (2015) which we extend by combining the model with supervision. We show that the resulting model reaches state-of-the-art performance in various tasks: MNIST and CIFAR-10 classification in a semi-supervised setting and permutation invariant MNIST in both semi-supervised and full-labels setting.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AHPLGYME\\Unknown - Unknown - Semi-Supervised Learning with Ladder Networks.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\IA8WXUF3\\Lewandowski, Co-investigator, Lewandowski - 2015 - No Title No Title(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\MIQBBNSL\\Lewandowski, Co-investigator, Lewandowski - 2015 - No Title No Title.pdf},
  journal = {arXiv},
  keywords = {icle},
  pmid = {25246403}
}

@article{rasmussen_eliasmith_2011,
  title = {A {{Neural Model}} of {{Rule Generation}} in {{Inductive Reasoning}}},
  author = {Rasmussen, Daniel and Eliasmith, Chris},
  year = {2011},
  month = jan,
  volume = {3},
  pages = {140--153},
  issn = {17568757},
  doi = {10.1111/j.1756-8765.2010.01127.x},
  abstract = {Inductive reasoning is a fundamental and complex aspect of human intelligence. In particular, how do subjects, given a set of particular examples, generate general descriptions of the rules governing that set? We present a biologically plausible method for accomplishing this task and implement it in a spiking neuron model. We demonstrate the success of this model by applying it to the problem domain of Raven's Progressive Matrices, a widely used tool in the field of intelligence testing. The model is able to generate the rules necessary to correctly solve Raven's items, as well as recreate many of the experimental effects observed in human subjects.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IE4UYN2H\\Rasmussen and Eliasmith - 2011 - A Neural Model of Rule Generation in Inductive Rea.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\ZELLFX3H\\Rasmussen and Eliasmith - 2011 - A Neural Model of Rule Generation in Inductive Rea.pdf},
  journal = {Topics in Cognitive Science},
  language = {en},
  number = {1}
}

@article{rasmussen_eliasmith_2014,
  title = {A Spiking Neural Model Applied to the Study of Human Performance and Cognitive Decline on {{Raven}}'s {{Advanced Progressive Matrices}}},
  author = {Rasmussen, Daniel and Eliasmith, Chris},
  year = {2014},
  volume = {42},
  pages = {53--82},
  issn = {01602896},
  doi = {10.1016/j.intell.2013.10.003},
  abstract = {We present a spiking neural model capable of solving a popular test of intelligence, Raven's Advanced Progressive Matrices (RPM). The central features of this model are its ability to dynamically generate the rules needed to solve the RPM and its biologically detailed implementation in spiking neurons. We describe the rule generation processes, and demonstrate the model's ability to use the resulting rules to solve the RPM with similar performance and error patterns to human subjects. Investigating the rules in more detail, we show that they successfully capture abstract patterns in the data, enabling them to generalize to novel matrices. We also show that the same model can be used to solve a separate reasoning task, and demonstrates the expected positive correlation in performance across tasks. Finally, we demonstrate the advantages of the biologically detailed implementation by using the model to connect behavioral and neurophysiological data. Specifically, we investigate two neurophysiological explanations of cognitive decline in aging: neuron loss and representational "dedifferentiation". We show that manipulations to the model that reflect these neurophysiological hypotheses result in performance changes that match observed human behavioral data.?? 2013 Elsevier Inc.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\C9QIAAEG\\Rasmussen and Eliasmith - 2014 - A spiking neural model applied to the study of hum.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\FCPKZKAS\\Rasmussen, Eliasmith - 2014 - A spiking neural model applied to the study of human performance and cognitive decline on Raven's Advanced.pdf},
  journal = {Intelligence},
  keywords = {aging,Cognitive decline,Raven's Progressive Matrices,Spiking neural model,Vector symbolic architectures},
  number = {1}
}

@article{rasmussen_eliasmith_2017,
  title = {A Neural Model of Hierarchical Reinforcement Learning},
  author = {Rasmussen, Daniel and Voelker, Aaron and Eliasmith, Chris},
  editor = {Cymbalyuk, Gennady},
  year = {2017},
  month = jul,
  volume = {12},
  pages = {e0180234},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0180234},
  abstract = {We develop a novel, biologically detailed neural model of reinforcement learning (RL) processes in the brain. This model incorporates a broad range of biological features that pose challenges to neural RL, such as temporally extended action sequences, continuous environments involving unknown time delays, and noisy/imprecise computations. Most significantly, we expand the model into the realm of hierarchical reinforcement learning (HRL), which divides the RL process into a hierarchy of actions at different levels of abstraction. Here we implement all the major components of HRL in a neural model that captures a variety of known anatomical and physiological properties of the brain. We demonstrate the performance of the model in a range of different environments, in order to emphasize the aim of understanding the brain's general reinforcement learning ability. These results show that the model compares well to previous modelling work and demonstrates improved performance as a result of its hierarchical ability. We also show that the model's behaviour is consistent with available data on human hierarchical RL, and generate several novel predictions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LP3YSSBX\\Rasmussen et al. - 2017 - A neural model of hierarchical reinforcement learn.pdf},
  journal = {PLOS ONE},
  language = {en},
  number = {7}
}

@article{rasmussen_rasmussen_2018,
  title = {{{NengoDL}}: {{Combining}} Deep Learning and Neuromorphic Modelling Methods},
  author = {Rasmussen, Daniel},
  year = {2018},
  abstract = {NengoDL is a software framework designed to combine the strengths of neuromorphic modelling and deep learning. NengoDL allows users to construct biologically detailed neural models, intermix those models with deep learning elements (such as convolutional networks), and then efficiently simulate those models in an easy-to-use, unified framework. In addition, NengoDL allows users to apply deep learning training methods to optimize the parameters of biological neural models. In this paper we present basic usage examples, benchmarking, and details on the key implementation elements of NengoDL. More details can be found at https://www.nengo.ai/nengo-dl.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GJQULJ7V\\Rasmussen - 2018 - NengoDL Combining deep learning and neuromorphic modelling methods.pdf}
}

@book{rasmussen_rasmussen_2018a,
  title = {Application {{Data}} ( 63 ) {{Continuation}} of Application {{No}}. 14 / 094 , 142 , Filed On},
  author = {Rasmussen, Daniel Halden},
  year = {2018},
  volume = {904},
  abstract = {Methods , systems and apparatus that provide for perceptual , cognitive , and motor behaviors in an integrated system implemented using neural architectures. Components of the system communicate using artificial neurons that implement neural networks. The connections between these networks form representations-referred to as semantic pointers which model the various firing patterns of biological neural network connections. Semantic pointers can be thought of as elements of a neural vector space , and can implement a form of abstraction level filtering or compression , in which high dimensional structures can be abstracted one or more times thereby reducing the number of dimensions needed to rep resent a particular structure .},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\92JHIDU3\\Rasmussen - 2013 - Application Data ( 63 ) Continuation of application No. 14 094 , 142 , filed on.pdf}
}

@article{ratcliff_childers_2016,
  title = {A Single Trial Analysis of {{EEG}} in Recognition Memory: {{Tracking}} the Neural Correlates of Memory Strength},
  author = {Ratcliff, Roger and Sederberg, Per B and Smith, Troy A and Childers, Russ},
  year = {2016},
  volume = {93},
  pages = {128--141},
  issn = {18733514},
  doi = {10.1016/j.neuropsychologia.2016.09.026},
  abstract = {Recent work in perceptual decision-making has shown that although two distinct neural components differentiate experimental conditions (e.g., did you see a face or a car), only one tracked the evidence guiding the decision process. In the memory literature, there is a distinction between a fronto-central evoked potential measured with EEG beginning at 350 ms that seems to track familiarity and a late parietal evoked potential that peaks at 600 ms that tracks recollection. Here, we applied single-trial regressor analysis (similar to multivariate pattern analysis, MVPA) and diffusion decision modeling to EEG and behavioral data from two recognition memory experiments to test whether these two components contribute to the recognition decision process. The regressor analysis only involved whether an item was studied or not and did not involve any use of the behavioral data. Only late EEG activity distinguishes studied from not studied items that peaks at about 600 ms following each test item onset predicted the diffusion model drift rate derived from the behavioral choice and reaction times (but only for studied items). When drift rate was made a linear function of the trial-level regressor values, the estimate for studied items was different than zero. This showed that the later EEG activity indexed the trial-to-trial variability in drift rate for studied items. Our results provide strong evidence that only a single EEG component reflects evidence being used in the recegnition decision process.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CNUYDG3L\\Ratcliff et al. - 2016 - A single trial analysis of EEG in recognition memory Tracking the neural correlates of memory strength.pdf},
  journal = {Neuropsychologia},
  keywords = {Diffusion model,eeg,Reaction time,Recognition memory,Single-trial regressor}
}

@article{ratcliff_mckoon_2008,
  title = {The {{Diffusion Decision Model}}: {{Theory}} and {{Data}} for {{Two}}-{{Choice Decision Tasks}}},
  author = {Ratcliff, Roger and McKoon, Gail},
  year = {2008},
  volume = {20},
  pages = {873--922},
  issn = {0899-7667},
  doi = {10.1162/neco.2008.12-06-420},
  abstract = {The diffusion decision model allows detailed explanations of behavior in two-choice discrimination tasks. In this article, the model is reviewed to show how it translates behavioral data-accuracy, mean response times, and response time distributions-into components of cognitive processing. Three experiments are used to illustrate experimental manipulations of three components: stimulus difficulty affects the quality of information on which a decision is based; instructions emphasizing either speed or accuracy affect the criterial amounts of information that a subject requires before initiating a response; and the relative proportions of the two stimuli affect biases in drift rate and starting point. The experiments also illustrate the strong constraints that ensure the model is empirically testable and potentially falsifiable. The broad range of applications of the model is also reviewed, including research in the domains of aging and neurophysiology.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XZDVGYIG\\Ratcliff, Mckoon - Unknown - The Diffusion Decision Model Theory and Data for Two-Choice Decision Tasks.pdf},
  journal = {Neural Computation},
  number = {4},
  pmid = {18085991}
}

@article{ratcliff_mckoon_2016,
  title = {Diffusion {{Decision Model}}: {{Current Issues}} and {{History}}},
  author = {Ratcliff, Roger and Smith, Philip L and Brown, Scott D and Mckoon, Gail},
  year = {2016},
  volume = {20},
  pages = {260--281},
  doi = {10.1016/j.tics.2016.01.007},
  abstract = {There is growing interest in diffusion models to represent the cognitive and neural processes of speeded decision making. Sequential-sampling models like the diffusion model have a long history in psychology. They view decision making as a process of noisy accumulation of evidence from a stimulus. The standard model assumes that evidence accumulates at a constant rate during the second or two it takes to make a decision. This process can be linked to the behaviors of populations of neurons and to theories of optimality. Diffusion models have been used successfully in a range of cognitive tasks and as psychometric tools in clinical research to examine individual differences. In this review, we relate the models to both earlier and more recent research in psychology. Modeling Simple Decision Making Decision making is intimately involved in all of our everyday activities. Many decisions are made rapidly and at a low level cognitively, for example, deciding whether to drive left or right round a car in front. Others, such as deciding which candidate to vote for or which car to buy, are made at a higher level with prolonged deliberation. The diffusion models we discuss are of the former type. In the real world, they involve a rapid matching of a perceptual representation to stored knowledge in memory, which allows us to identify things in our immediate surroundings and determine how we should respond to them. Much of what we have learned about such decisions comes from laboratory tasks in which people are asked to make fast two-choice decisions. The measures of performance are typically response times (RTs) and the probabilities of making the two choices. Researchers are usually interested in how and why RTs and choice probabilities change across experimental conditions, for example, whether a person tries to respond as quickly as possible or as accurately as possible. There have been a moderate number of models for these tasks and most assume accumulation of noisy evidence to decision criteria representing each of the two choices. The models can include one versus two accumulators (see Glossary), decision rules that are relative or absolute, models with drift rate constant or varying over time, discrete or continuous time evidence, stochastic versus deterministic evidence, and models with inhibition and decay. Ratcliff and Smith [1] showed the relationships between the models along with a detailed evaluation of the models (Figure 1, Key Figure).},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6MZ8Z5AJ\\Ratcliff et al. - 2016 - Diffusion Decision Model Current Issues and History.pdf},
  journal = {Trends in Cognitive Sciences},
  keywords = {diffusion model,nonstationarity,optimality,response time}
}

@article{ratcliff_sajda_2009,
  title = {Quality of Evidence for Perceptual Decision Making Is Indexed by Trial-to-Trial Variability of the {{EEG}}},
  author = {Ratcliff, Roger and Philiastides, Marios G and Sajda, Paul},
  year = {2009},
  volume = {106},
  pages = {6539--6544},
  issn = {0027-8424},
  doi = {10.1073/pnas.0812589106},
  abstract = {A fundamental feature of how we make decisions is that our responses are variable in the choices we make and the time it takes to make them. This makes it impossible to determine, for a single trial of an experiment, the quality of the evidence on which a decision is based. Even for stimuli from a single experimental condition, it is likely that stimulus and encoding differences lead to differences in the quality of evidence. In the research reported here, with a simple "face"/"car" perceptual discrimination task, we obtained late (decision-related) and early (stimulus-related) single-trial EEG component amplitudes that discriminated between faces and cars within and across conditions. We used the values of these amplitudes to sort the response time and choice within each experimental condition into more-face-like and less-face-like groups and then fit the diffusion model for simple decision making (a well-established model in cognitive psychology) to the data in each group separately. The results show that dividing the data on a trial-by-trial basis by using the late-component amplitude produces differences in the estimates of evidence used in the decision process. However, dividing the data on the basis of the early EEG component amplitude or the times of the peak amplitudes of either component did not index the information used in the decision process. The results we present show that a single-trial EEG neurophysiological measure for nominally identical stimuli can be used to sort behavioral response times and choices into those that index the quality of decision-relevant evidence.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ICSJQWWS\\Ratcliff, Philiastides, Sajda - 2009 - Quality of evidence for perceptual decision making is indexed by trial-to-trial variability of th.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  number = {16},
  pmid = {19342495}
}

@article{raudies_hasselmo_2012,
  title = {Modeling {{Boundary Vector Cell Firing Given Optic Flow}} as a {{Cue}}},
  author = {Raudies, Florian and Hasselmo, Michael E},
  year = {2012},
  volume = {8},
  pages = {1--17},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1002553},
  abstract = {Boundary vector cells in entorhinal cortex fire when a rat is in locations at a specific distance from walls of an environment. This firing may originate from memory of the barrier location combined with path integration, or the firing may depend upon the apparent visual input image stream. The modeling work presented here investigates the role of optic flow, the apparent change of patterns of light on the retina, as input for boundary vector cell firing. Analytical spherical flow is used by a template model to segment walls from the ground, to estimate self-motion and the distance and allocentric direction of walls, and to detect drop-offs. Distance estimates of walls in an empty circular or rectangular box have a mean error of less than or equal to two centimeters. Integrating these estimates into a visually driven boundary vector cell model leads to the firing patterns characteristic for boundary vector cells. This suggests that optic flow can influence the firing of boundary vector cells.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PQCVSRJ5\\Raudies and Hasselmo - 2012 - Modeling Boundary Vector Cell Firing Given Optic F.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\YRY8YEIH\\Raudies, Hasselmo - 2012 - Modeling boundary vector cell firing given optic flow as a cue.pdf},
  journal = {PLoS Computational Biology},
  keywords = {Animals,Computational Biology,Computer Simulation,Entorhinal Cortex,Entorhinal Cortex: cytology,Entorhinal Cortex: physiology,Evoked Potentials,Models,Neurological,Photic Stimulation,Rats,Visual,Visual Pathways,Visual Pathways: physiology},
  number = {6},
  pmid = {22761557}
}

@article{raudies_hasselmo_2014,
  title = {A Model of Hippocampal Spiking Responses to Items during Learning of a Context-Dependent Task {{A}} Model of Hippocampal Spiking Responses to Items during Learning of a Context-Dependent Task},
  author = {Raudies, Florian and Hasselmo, Michael E},
  year = {2014},
  doi = {10.3389/fnsys.2014.00178},
  abstract = {Single unit recordings in the rat hippocampus have demonstrated shifts in the specificity of spiking activity during learning of a contextual item-reward association task. In this task, rats received reward for responding to different items dependent upon the context an item appeared in, but not dependent upon the location an item appears at. Initially, neurons in the rat hippocampus primarily show firing based on place, but as the rat learns the task this firing became more selective for items. We simulated this effect using a simple circuit model with discrete inputs driving spiking activity representing place and item followed sequentially by a discrete representation of the motor actions involving a response to an item (digging for food) or the movement to a different item (movement to a different pot for food). We implemented spiking replay in the network representing neural activity observed during sharp-wave ripple events, and modified synaptic connections based on a simple representation of spike-timing dependent synaptic plasticity. This simple network was able to consistently learn the context- dependent responses, and transitioned from dominant coding of place to a gradual increase in specificity to items consistent with analysis of the experimental data. In addition, the model showed an increase in specificity toward context. The increase of selectivity in the model is accompanied by an increase in binariness of the synaptic weights for cells that are part of the functional network. Keywords:},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2UUS8JYD\\Raudies, Hasselmo - 2014 - A model of hippocampal spiking responses to items during learning of a context-dependent task A model of hipp.pdf},
  journal = {Frontiers in systems neuroscience}
}

@article{raudies_hasselmo_2014a,
  title = {Deep Belief Networks Learn Context Dependent Behavior},
  author = {Raudies, Florian and Zilli, Eric A and Hasselmo, Michael E},
  year = {2014},
  volume = {9},
  issn = {19326203},
  doi = {10.1371/journal.pone.0093250},
  abstract = {With the goal of understanding behavioral mechanisms of generalization, we analyzed the ability of neural networks to generalize across context. We modeled a behavioral task where the correct responses to a set of specific sensory stimuli varied systematically across different contexts. The correct response depended on the stimulus (A,B,C,D) and context quadrant (1,2,3,4). The possible 16 stimulus-context combinations were associated with one of two responses (X,Y), one of which was correct for half of the combinations. The correct responses varied symmetrically across contexts. This allowed responses to previously unseen stimuli (probe stimuli) to be generalized from stimuli that had been presented previously. By testing the simulation on two or more stimuli that the network had never seen in a particular context, we could test whether the correct response on the novel stimuli could be generated based on knowledge of the correct responses in other contexts. We tested this generalization capability with a Deep Belief Network (DBN), Multi-Layer Perceptron (MLP) network, and the combination of a DBN with a linear perceptron (LP). Overall, the combination of the DBN and LP had the highest success rate for generalization.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BUSFD8CX\\Raudies, Zilli, Hasselmo - 2014 - Deep belief networks learn context dependent behavior.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\HP48SPTK\\Raudies, Zilli, Hasselmo - 2014 - Deep belief networks learn context dependent behavior.pdf},
  journal = {PLoS ONE},
  number = {3},
  pmid = {24671178}
}

@article{raudies_hasselmo_2015,
  title = {Differences in {{Visual}}-{{Spatial Input May Underlie Different Compression Properties}} of {{Firing Fields}} for {{Grid Cell Modules}} in {{Medial Entorhinal Cortex}}},
  author = {Raudies, Florian and Hasselmo, Michael E},
  year = {2015},
  volume = {11},
  pages = {e1004596},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1004596},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MWEX3H24\\Raudies, Hasselmo - 2015 - Differences in Visual-Spatial Input May Underlie Different Compression Properties of Firing Fields for Grid C.pdf},
  journal = {PLOS Computational Biology},
  number = {11}
}

@article{raudies_hasselmo_2015a,
  title = {Head Direction Is Coded More Strongly than Movement Direction in a Population of Entorhinal Neurons},
  author = {Raudies, Florian and Brandon, Mark P. and Chapman, G William and Hasselmo, Michael E},
  year = {2015},
  volume = {1621},
  pages = {355--367},
  issn = {18726240},
  doi = {10.1016/j.brainres.2014.10.053},
  abstract = {The spatial firing pattern of entorhinal grid cells may be important for navigation. Many different computational models of grid cell firing use path integration based on movement direction and the associated movement speed to drive grid cells. However, the response of neurons to movement direction has rarely been tested, in contrast to multiple studies showing responses of neurons to head direction. Here, we analyzed the difference between head direction and movement direction during rat movement and analyzed cells recorded from entorhinal cortex for their tuning to movement direction. During foraging behavior, movement direction differs significantly from head direction. The analysis of neuron responses shows that only 5 out of 758 medial entorhinal cells show significant coding for both movement direction and head direction when evaluating periods of rat behavior with speeds above 10 cm/s and ??30?? angular difference between movement and head direction. None of the cells coded movement direction alone. In contrast, 21 cells in this population coded only head direction during behavioral epochs with these constraints, indicating much stronger coding of head direction in this population. This suggests that the movement direction signal required by most grid cell models may arise from other brain structures than the medial entorhinal cortex.},
  copyright = {All rights reserved},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ND72TI7K\\Raudies et al. - 2015 - Head direction is coded more strongly than movement direction in a population of entorhinal neurons.pdf},
  journal = {Brain Research},
  keywords = {Attractor model,Entorhinal cortex,Grid cell,Movement direction,Velocity controlled oscillator model},
  pmid = {25451111}
}

@article{raudies_hasselmo_2017,
  title = {A Model of Symbolic Processing in {{Raven}}'s Progressive Matrices},
  author = {Raudies, Florian and Hasselmo, Michael E},
  year = {2017},
  issn = {2212683X},
  doi = {10.1016/j.bica.2017.07.003},
  abstract = {Raven's progressive matrices probe the capacity to discover a common rule in a 3 by 3 matrix of stimuli by requiring the correct selection of a probe stimulus for one stimulus location intentionally left blank. This task is purely visual and excludes verbal cues. We propose a model of the performance of this task that classifies a variety of visual stimuli, either as rotated, scaled, or with elements added or subtracted or otherwise altered within each of the 3 by 3 matrix's fields. In our model, Q-learning uses a state space based on the transitions between fields of the 3 by 3 matrix of stimuli. Actions are modeled as alterations of visual stimuli between these matrix's fields. Using Q-learning our model successfully selects the correct probe stimulus from eight choices offered in the task.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\C5QMQ4JV\\Raudies, Hasselmo - 2017 - A model of symbolic processing in Raven's progressive matrices.pdf},
  journal = {Biologically Inspired Cognitive Architectures},
  keywords = {Associative memory,Cognitive model,Q-learning,Raven's progressive matrices}
}

@book{raven_court_2004,
  title = {Raven Manual: {{Section}} 3. {{Standard}} Progressive Matrices},
  author = {Raven, J. and Raven, J.C. and Court, J.H.},
  year = {2004},
  doi = {10.1007/978-1-4615-0153-4_11},
  abstract = {2000 edition, updated 2004},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NLD7PXZU\\Unknown - 2003 - Raven's Manual.pdf},
  isbn = {1-85639-020-9}
}

@techreport{recanatesi_shea-brown_2018,
  title = {Predictive Learning Extracts Latent Space Representations from Sensory Observations},
  author = {Recanatesi, Stefano and Farrell, Matthew and Lajoie, Guillaume and Deneve, Sophie and Rigotti, Mattia and {Shea-Brown}, Eric},
  year = {2018},
  month = nov,
  institution = {{Neuroscience}},
  doi = {10.1101/471987},
  abstract = {Neural networks have achieved many recent successes in solving sequential processing and planning tasks. Their success is often  ascribed to the emergence of the task's low-dimensional latent structure in the network activity - i.e., in the learned neural representations. Similarly, biological neural circuits and in particular the hippocampus may produce representations that organize semantically related episodes. Here, we investigate the hypothesis that representations with low-dimensional latent structure, reflecting such semantic organization, result from learning to predict observations about the world. Specifically, we ask whether and when network mechanisms for sensory prediction coincide with those for extracting the underlying latent variables. Using a recurrent neural network model trained to predict a sequence of observations in a simulated spatial navigation task, we show that network dynamics exhibit low-dimensional but nonlinearly transformed representations of sensory inputs that capture the latent structure of the sensory environment. We quantify these results using nonlinear measures of intrinsic dimensionality which highlight the importance of the predictive aspect of neural representations, and provide mathematical arguments for when and why these representations emerge. We focus throughout on how our results can aid the analysis and interpretation of experimental data.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\63RL35WI\\Recanatesi et al. - 2018 - Predictive learning extracts latent space represen.pdf},
  language = {en},
  type = {Preprint}
}

@article{redinbaugh_saalmann_2020,
  title = {Thalamus {{Modulates Consciousness}} via {{Layer}}-{{Specific Control}} of {{Cortex}}},
  author = {Redinbaugh, Michelle J. and Phillips, Jessica M. and Kambi, Niranjan A. and Mohanta, Sounak and Andryk, Samantha and Dooley, Gaven L. and Afrasiabi, Mohsen and Raz, Aeyal and Saalmann, Yuri B.},
  year = {2020},
  month = feb,
  pages = {S0896627320300052},
  issn = {08966273},
  doi = {10.1016/j.neuron.2020.01.005},
  abstract = {Functional MRI and electrophysiology studies suggest that consciousness depends on large-scale thalamocortical and corticocortical interactions. However, it is unclear how neurons in different cortical layers and circuits contribute. We simultaneously recorded from central lateral thalamus (CL) and across layers of the frontoparietal cortex in awake, sleeping, and anesthetized macaques. We found that neurons in thalamus and deep cortical layers are most sensitive to changes in consciousness level, consistent across different anesthetic agents and sleep. Deep-layer activity is sustained by interactions with CL. Consciousness also depends on deep-layer neurons providing feedback to superficial layers (not to deep layers), suggesting that long-range feedback and intracolumnar signaling are important. To show causality, we stimulated CL in anesthetized macaques and effectively restored arousal and wake-like neural processing. This effect was location and frequency specific. Our findings suggest layer-specific thalamocortical correlates of consciousness and inform how targeted deep brain stimulation can alleviate disorders of consciousness.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FV2SMJXE\\Redinbaugh et al. - 2020 - Thalamus Modulates Consciousness via Layer-Specifi.pdf},
  journal = {Neuron},
  language = {en}
}

@article{redish_redish_2016,
  title = {Vicarious Trial and Error},
  author = {Redish, A. David},
  year = {2016},
  volume = {17},
  pages = {147--159},
  issn = {1471-003X},
  doi = {10.1038/nrn.2015.30},
  abstract = {Tolman's tropistic robot, the "Schematic Sowbug," designed to account for certain facts of "vicarious trial and error" behavior (VTE), fails to do so satisfactorily and employs a mechanism which is not consistent with other behavior mechanisms disclosed by research. An hypothesis based upon Hull's principles of behavior is proposed, postulating that a VTE movement is an incomplete or preparatory response. VTE is not a special form of behavior occurring in a discrimination situation, but is simply a succession of the incomplete and preparatory responses seen when animals are learning to respond to a situation which does not call for a choice. Deductions from this hypothesis are confirmed by data presented from the behavior of rats in a learning situation involving no choice between alternative responses. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CCP6ECID\\Redish - 2016 - Vicarious trial and error.pdf},
  journal = {Nature Reviews Neuroscience},
  number = {3},
  pmid = {14900300}
}

@article{reed_lee_2015,
  title = {Deep {{Visual Analogy}}-{{Making}}},
  author = {Reed, Scott E. and Zhang, Yi and Zhang, Yuting and Lee, Honglak},
  year = {2015},
  pages = {1252--1260},
  issn = {10495258},
  abstract = {In addition to identifying the content within a single image, relating images and generating related images are critical tasks for image understanding. Recently, deep convolutional networks have yielded breakthroughs in predicting image la-bels, annotations and captions, but have only just begun to be used for generat-ing high-quality images. In this paper we develop a novel deep network trained end-to-end to perform visual analogy making, which is the task of transforming a query image according to an example pair of related images. Solving this problem requires both accurately recognizing a visual relationship and generating a trans-formed query image accordingly. Inspired by recent advances in language mod-eling, we propose to solve visual analogies by learning to map images to a neural embedding in which analogical reasoning is simple, such as by vector subtraction and addition. In experiments, our model effectively models visual analogies on several datasets: 2D shapes, animated video game sprites, and 3D car models.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\S9A3DXKZ\\Reed et al. - 2015 - Deep Visual Analogy-Making.pdf},
  journal = {Advances in Neural Information Processing Systems}
}

@article{reeves_fine_2005,
  title = {The Role of Attention in Binding Shape to Color},
  author = {Reeves, Adam and Fuller, Heather and Fine, Elisabeth M},
  year = {2005},
  volume = {45},
  pages = {3343--3355},
  doi = {10.1016/j.visres.2005.07.041},
  abstract = {Pictures of easily-identiWable objects with novel colors (e.g. a blue frog) or of forms with arbitrary colors (e.g. a green triangle) were presented brieXy at 10.6\textdegree{} eccentricity. Stimuli had strong outlines and vivid Wll colors (red, green, yellow, blue, or purple). The same pic-tures were repeated once in each block of 30 trials for 6, 9, or 12 blocks, and recognition was probed after each block. Shapes were acquired quickly, within 3\textendash 4 blocks, whether attention was focused on the pictures or split to a demanding foveal task. Color-shape acqui-sition was also fast with focused attention, but stabilized at a low level with split attention. Delaying the foveal task restored color-shape acquisition. We suggest that attention facilitates the creation and maintenance of novel color-shape bindings in the visual periphery; with-out attention, binding is less eVective.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BLI85GFK\\Reeves, Fuller, Fine - 2005 - The role of attention in binding shape to color.pdf},
  journal = {Vision Research},
  keywords = {Binding,Color,Shape}
}

@article{regev_hasson_2018,
  title = {Propagation of Information along the Cortical Hierarchy as a Function of Attention While Reading and Listening to Stories},
  author = {Regev, Mor and Simony, Erez and Lee, Katherine and Tan, Kean Ming and Chen, Janice and Hasson, Uri},
  year = {2018},
  pages = {291526},
  doi = {10.1101/291526},
  abstract = {How does attention route information from sensory to high-order areas as a function of task, within the relatively fixed topology of the brain? In this study, participants were simultaneously presented with two unrelated stories - one spoken and one written - and asked to attend one while ignoring the other. We used fMRI and a novel inter-subject correlation analysis to track the spread of information along the processing hierarchy as a function of task. Processing the unattended spoken (written) information was confined to auditory (visual) cortices. In contrast, attending to the spoken (written) story enhanced the stimulus-selective responses in early sensory regions and allowed it to spread into higher-order areas. Surprisingly, we found that the story-specific spoken (written) responses for the attended story also reached the opposite secondary visual (auditory) regions. These results demonstrate how attention enhances the processing of attended input and allows it to propagate across brain areas.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DCYRVH5H\\Regev et al. - 2018 - Propagation of information along the cortical hierarchy as a function of attention while reading and listening to.pdf},
  journal = {bioRxiv}
}

@article{regev_hasson_2018a,
  title = {Propagation of {{Information Along}} the {{Cortical Hierarchy}} as a {{Function}} of {{Attention While Reading}} and {{Listening}} to {{Stories}}},
  author = {Regev, Mor and Simony, Erez and Lee, Katherine and Ming Tan, Kean and Chen, Janice and Hasson, Uri},
  year = {2018},
  pages = {1--18},
  doi = {10.1093/cercor/bhy282},
  abstract = {How does attention route information from sensory to high-order areas as a function of task, within the relatively fixed topology of the brain? In this study, participants were simultaneously presented with 2 unrelated stories-one spoken and one written-and asked to attend one while ignoring the other. We used fMRI and a novel intersubject correlation analysis to track the spread of information along the processing hierarchy as a function of task. Processing the unattended spoken (written) information was confined to auditory (visual) cortices. In contrast, attending to the spoken (written) story enhanced the stimulus-selective responses in sensory regions and allowed it to spread into higher-order areas. Surprisingly, we found that the story-specific spoken (written) responses for the attended story also reached secondary visual (auditory) regions of the unattended sensory modality. These results demonstrate how attention enhances the processing of attended input and allows it to propagate across brain areas.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SFCECDBQ\\Regev et al. - 2018 - Propagation of Information Along the Cortical Hierarchy as a Function of Attention While Reading and Listening to.pdf},
  journal = {Cerebral Cortex}
}

@article{reinhart_nguyen_2019,
  title = {Working Memory Revived in Older Adults by Synchronizing Rhythmic Brain Circuits},
  author = {Reinhart, Robert M. G. and Nguyen, John A.},
  year = {2019},
  month = may,
  volume = {22},
  pages = {820--827},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-019-0371-x},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VX699NWY\\Reinhart and Nguyen - 2019 - Working memory revived in older adults by synchron.pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {5}
}

@article{reinhold_brecht_2019,
  title = {Behavioral and Neural Correlates of Hide-and-Seek in Rats},
  author = {Reinhold, Annika Stefanie and {Sanguinetti-Scheck}, Juan Ignacio and Hartmann, Konstantin and Brecht, Michael},
  year = {2019},
  month = sep,
  volume = {365},
  pages = {1180--1183},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aax4705},
  abstract = {Evolutionary, cognitive, and neural underpinnings of mammalian play are not yet fully elucidated. We played hide-and-seek, an elaborate role-play game, with rats. We did not offer food rewards but engaged in playful interactions after finding or being found. Rats quickly learned the game and learned to alternate between hiding versus seeking roles. They guided seeking by vision and memories of past hiding locations and emitted game event\textendash specific vocalizations. When hiding, rats vocalized infrequently and they preferred opaque over transparent hiding enclosures, a preference not observed during seeking. Neuronal recordings revealed intense prefrontal cortex activity that varied with game events and trial types (``hide'' versus ``seek'') and might instruct role play. The elaborate cognitive capacities for hide-and-seek in rats suggest that this game might be evolutionarily old.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PL44XYSA\\Reinhold et al. - 2019 - Behavioral and neural correlates of hide-and-seek .pdf},
  journal = {Science},
  language = {en},
  number = {6458}
}

@article{renno-costa_tort_2017,
  title = {Place and {{Grid Cells}} in a {{Loop}}: {{Implications}} for {{Memory Function}} and {{Spatial Coding}}},
  shorttitle = {Place and {{Grid Cells}} in a {{Loop}}},
  author = {{Renn{\'o}-Costa}, C{\'e}sar and Tort, Adriano B.L.},
  year = {2017},
  month = aug,
  volume = {37},
  pages = {8062--8076},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.3490-16.2017},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AV62PLKB\\Rennó-Costa and Tort - 2017 - Place and Grid Cells in a Loop Implications for M.pdf},
  journal = {The Journal of Neuroscience},
  language = {en},
  number = {34}
}

@article{rensink_rensink_2000,
  title = {The {{Dynamic Representation}} of {{Scenes}}},
  author = {Rensink, Ronald A},
  year = {2000},
  volume = {7},
  pages = {17--42},
  issn = {1350-6285},
  doi = {10.1080/135062800394667},
  abstract = {One of the more compelling impressions provided by vision is that of a coherent, richly-detailed world where everything is present simultaneously. Indeed, this impression is so compelling that we tend to ascribe these properties not only to the external world, but to our internal representations as well. But results from several recent experiments argue against this latter ascription. For example, changes in images of real-world scenes often go unnoticed when made during a saccade, flicker, blink, or movie cut. This "change blindness" provides strong evidence against the idea that our brains contain a picture-like representation of the scene that is everywhere detailed and coherent. How then do we represent a scene? It is argued here that focused attention provides spatiotemporal coherence for the stable representation of one object at a time. It is then argued that the allocation of attention can be coordinated to create a "virtual representation". In such a scheme, a stable object representation is formed whenever needed, making it appear to higher levels as if all objects in the scene are represented in detail simultaneously.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DQJUZTG2\\Rensink - 2000 - The Dynamic Representation of Scenes.pdf},
  journal = {Visual Cognition},
  number = {1-3},
  pmid = {12670395}
}

@article{reynolds_desimone_1999,
  title = {The {{Role}} of {{Neural Mechanisms}} of {{Attention}} in {{Solving}} the {{Binding Problem}}},
  author = {Reynolds, John H and Desimone, Robert},
  year = {1999},
  month = sep,
  volume = {24},
  pages = {19--29},
  issn = {08966273},
  doi = {10.1016/S0896-6273(00)80819-3},
  abstract = {For purposes of this review, we will define the binding problem as the problem of how the visual system cor- rectly links up all the different features of complex objects. For example, when viewing a person seated in a blue car, one effortlessly sees that the person\"is nose belongs to his face and not to the car, and that the car, but not the nose, is blue. To fully understand the solution to this problem requires a good neurobiological theory of object recognition, which does not exist. We will therefore follow the lead of the computer engineer, who, when asked to describe how he would write a computer program to recognize a chicken, replied, \"ifirst, assume spherical chicken.\"i Thus, in this review we will make some assumptions that simplify the binding problem in order to appreciate how neural mechanisms of attention provide a partial solution.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\38L8VYF5\\Reynolds, Desimone - 1999 - The Role of Neural Mechanisms Review of Attention in Solving the Binding Problem less impaired on less atten.pdf},
  journal = {Neuron},
  number = {1},
  pmid = {10677024}
}

@article{reynolds_heeger_2009,
  title = {The {{Normalization Model}} of {{Attention}}},
  author = {Reynolds, John H and Heeger, David J},
  year = {2009},
  volume = {61},
  pages = {168--185},
  issn = {08966273},
  doi = {10.1016/j.neuron.2009.01.002},
  abstract = {Attention has been found to have a wide variety of effects on the responses of neurons in visual cortex. We describe a model of attention that exhibits each of these different forms of attentional modulation, depending on the stimulus conditions and the spread (or selectivity) of the attention field in the model. The model helps reconcile proposals that have been taken to represent alternative theories of attention. We argue that the variety and complexity of the results reported in the literature emerge from the variety of empirical protocols that were used, such that the results observed in any one experiment depended on the stimulus conditions and the subject's attentional strategy, a notion that we define precisely in terms of the attention field in the model, but that has not typically been completely under experimental control. \{\textcopyright\} 2009 Elsevier Inc. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NBG7SISI\\Reynolds, Heeger - 2009 - The Normalization Model of Attention.pdf},
  journal = {Neuron},
  number = {2},
  pmid = {19186161}
}

@article{ricardosato_paulo_2006,
  title = {A Method to Produce Evolving Functional Connectivity Maps during the Course of an {{fMRI}} Experiment Using Wavelet-Based Time-Varying {{Granger}} Causality},
  author = {Ricardo Sato, Jo{\~a}o and Amaro Junior, Edson and Yasumasa Takahashi, Daniel and {de Maria Felix}, Marcelo and John Brammer, Michael and Alberto Morettin, Pedro and Paulo, S{\~a}o},
  year = {2006},
  doi = {10.1016/j.neuroimage.2005.11.039},
  abstract = {Functional magnetic resonance imaging (fMRI) is widely used to identify neural correlates of cognitive tasks. However, the analysis of functional connectivity is crucial to understanding neural dynamics. Although many studies of cerebral circuitry have revealed adaptative behavior, which can change during the course of the experiment, most of contemporary connectivity studies are based on correlational analysis or structural equations analysis, assuming a time-invariant connectivity structure. In this paper, a novel method of continuous time-varying connectivity analysis is proposed, based on the wavelet expansion of functions and vector autoregressive model (wavelet dynamic vector autoregressive-DVAR). The model also allows iden-tification of the direction of information flow between brain areas, extending the Granger causality concept to locally stationary processes. Simulation results show a good performance of this approach even using short time intervals. The application of this new approach is illustrated with fMRI data from a simple AB motor task experiment.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KN4K7ZUH\\Ricardo Sato et al. - 2006 - A method to produce evolving functional connectivity maps during the course of an fMRI experiment using wav.pdf},
  keywords = {Connectivity,Dynamic,fmri,Time-varying}
}

@article{rich_lee_2014,
  title = {Place Cells. {{Large}} Environments Reveal the Statistical Structure Governing Hippocampal Representations.},
  author = {Rich, P Dylan and Liaw, Hua-Peng and Lee, Albert K},
  year = {2014},
  volume = {345},
  pages = {814--817},
  issn = {1095-9203},
  doi = {10.1126/science.1255635},
  abstract = {The rules governing the formation of spatial maps in the hippocampus have not been determined. We investigated the large-scale structure of place field activity by recording hippocampal neurons in rats exploring a previously unencountered 48-meter-long track. Single-cell and population activities were well described by a two-parameter stochastic model. Individual neurons had their own characteristic propensity for forming fields randomly along the track, with some cells expressing many fields and many exhibiting few or none. Because of the particular distribution of propensities across cells, the number of neurons with fields scaled logarithmically with track length over a wide, ethological range. These features constrain hippocampal memory mechanisms, may allow efficient encoding of environments and experiences of vastly different extents and durations, and could reflect general principles of population coding.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LAUEKNDA\\Rich, Liaw, Lee - 2014 - Place cells. Large environments reveal the statistical structure governing hippocampal representations.pdf},
  journal = {Science},
  keywords = {hippocampus,place cell},
  number = {6198},
  pmid = {25124440}
}

@article{rich_wallis_2016,
  title = {What Stays the Same in Orbitofrontal Cortex},
  author = {Rich, Erin L and Wallis, Jonathan D},
  year = {2016},
  volume = {19},
  pages = {768--770},
  issn = {1097-6256},
  doi = {10.1038/nn.4305},
  abstract = {Researchers show that orbitofrontal neurons perform the same value-related computations across different decisions. Value computations are therefore a critical feature around which orbitofrontal representations are organized.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UYNNLKP4\\Rich, Wallis - 2016 - What stays the same in orbitofrontal cortex.pdf},
  journal = {Nature Neuroscience},
  number = {6},
  pmid = {27227365}
}

@article{rich_wallis_2017,
  title = {Spatiotemporal Dynamics of Information Encoding Revealed in Orbitofrontal High-Gamma},
  author = {Rich, Erin L and Wallis, Joni D},
  year = {2017},
  volume = {8},
  pages = {1139},
  issn = {2041-1723},
  doi = {10.1038/s41467-017-01253-5},
  abstract = {High-gamma signals mirror the tuning and temporal profiles of neurons near a recording electrode in sensory and motor areas. These frequencies appear to aggregate local neuronal activity, but it is unclear how this relationship affects information encoding in high-gamma activity (HGA) in cortical areas where neurons are heterogeneous in selectivity and temporal responses, and are not functionally clustered. Here we report that populations of neurons and HGA recorded from the orbitofrontal cortex (OFC) encode similar information, although there is little correspondence between signals recorded by the same electrode. HGA appears to aggregate heterogeneous neuron activity, such that the spiking of a single cell corresponds to only small increases in HGA. Interestingly, large-scale spatiotemporal dynamics are revealed in HGA, but less apparent in the population of single neurons. Overall, HGA is closely related to neuron activity in OFC, and provides a unique means of studying large-scale spatiotemporal dynamics of information processing.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HMGK5SE2\\Rich, Wallis - 2017 - Spatiotemporal dynamics of information encoding revealed in orbitofrontal high-gamma.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\YYLWYEDI\\Rich, Wallis - 2017 - Spatiotemporal dynamics of information encoding revealed in orbitofrontal high-gamma.pdf},
  journal = {Nature Communications},
  number = {1}
}

@article{richards_kording_2019,
  title = {A Deep Learning Framework for Neuroscience},
  author = {Richards, Blake A. and Lillicrap, Timothy P. and Beaudoin, Philippe and Bengio, Yoshua and Bogacz, Rafal and Christensen, Amelia and Clopath, Claudia and Costa, Rui Ponte and {de Berker}, Archy and Ganguli, Surya and Gillon, Colleen J. and Hafner, Danijar and Kepecs, Adam and Kriegeskorte, Nikolaus and Latham, Peter and Lindsay, Grace W. and Miller, Kenneth D. and Naud, Richard and Pack, Christopher C. and Poirazi, Panayiota and Roelfsema, Pieter and Sacramento, Jo{\~a}o and Saxe, Andrew and Scellier, Benjamin and Schapiro, Anna C. and Senn, Walter and Wayne, Greg and Yamins, Daniel and Zenke, Friedemann and Zylberberg, Joel and Therien, Denis and Kording, Konrad P.},
  year = {2019},
  month = nov,
  volume = {22},
  pages = {1761--1770},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-019-0520-2},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L9BBPC9P\\Richards et al. - 2019 - A deep learning framework for neuroscience.pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {11}
}

@article{richards_lillicrap_2019,
  title = {Dendritic Solutions to the Credit Assignment Problem},
  author = {Richards, Blake A and Lillicrap, Timothy P},
  year = {2019},
  month = feb,
  volume = {54},
  pages = {28--36},
  issn = {09594388},
  doi = {10.1016/j.conb.2018.08.003},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4LRJ3EXJ\\Richards and Lillicrap - 2019 - Dendritic solutions to the credit assignment probl.pdf},
  journal = {Current Opinion in Neurobiology},
  language = {en}
}

@article{richardson_hakim_2003,
  title = {From {{Subthreshold}} to {{Firing}}-{{Rate Resonance}}},
  author = {Richardson, Magnus J. E. and Brunel, Nicolas and Hakim, Vincent},
  year = {2003},
  month = may,
  volume = {89},
  pages = {2538--2554},
  issn = {0022-3077, 1522-1598},
  doi = {10.1152/jn.00955.2002},
  abstract = {First published December 27, 2002; 10.1152/jn.00955.2002. Many types of neurons exhibit subthreshold resonance. However, little is known about whether this frequency preference influences spike emission. Here, the link between subthreshold resonance and firing rate is examined in the framework of conductance-based models. A classification of the subthreshold properties of a general class of neurons is first provided. In particular, a class of neurons is identified in which the input impedance exhibits a suppression at a nonzero low frequency as well as a peak at higher frequency. The analysis is then extended to the effect of subthreshold resonance on the dynamics of the firing rate. The considered input current comprises a background noise term, mimicking the massive synaptic bombardment in vivo. Of interest is the modulatory effect an additional weak oscillating current has on the instantaneous firing rate. When the noise is weak and firing regular, the frequency most preferentially modulated is the firing rate itself. Conversely, when the noise is strong and firing irregular, the modulation is strongest at the subthreshold resonance frequency. These results are demonstrated for two specific conductance-based models and for a generalization of the integrate-and-fire model that captures subthreshold resonance. They suggest that resonant neurons are able to communicate their frequency preference to postsynaptic targets when the level of noise is comparable to that prevailing in vivo.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Q9W8FFUZ\\Richardson et al. - 2003 - From Subthreshold to Firing-Rate Resonance.pdf},
  journal = {Journal of Neurophysiology},
  language = {en},
  number = {5}
}

@article{richler_gauthier_2012,
  title = {Meanings, Mechanisms, and Measures of Holistic Processing.},
  author = {Richler, Jennifer J and Palmeri, Thomas J and Gauthier, Isabel},
  year = {2012},
  month = jan,
  volume = {3},
  pages = {553},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2012.00553},
  abstract = {Few concepts are more central to the study of face recognition than holistic processing. Progress toward understanding holistic processing is challenging because the term "holistic" has many meanings, with different researchers addressing different mechanisms and favoring different measures. While in principle the use of different measures should provide converging evidence for a common theoretical construct, convergence has been slow to emerge. We explore why this is the case. One challenge is that "holistic processing" is often used to describe both a theoretical construct and a measured effect, which may not have a one-to-one mapping. Progress requires more than greater precision in terminology regarding different measures of holistic processing or different hypothesized mechanisms of holistic processing. Researchers also need to be explicit about what meaning of holistic processing they are investigating so that it is clear whether different researchers are describing the same phenomenon or not. Face recognition differs from object recognition, and not all meanings of holistic processing are equally suited to help us understand that important difference.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\F6MG58WM\\Richler, Palmeri, Gauthier - 2012 - Meanings, mechanisms, and measures of holistic processing.pdf},
  journal = {Frontiers in psychology},
  keywords = {face percep,face perception,face processing,face recognition,for years,holistic processing,holistic processing has been,makes face recognition special,many studies pro-,object recognition,of holistic processing and,there is,unfortunately,used to explain what,vide only verbal descriptions},
  number = {December},
  pmid = {23248611}
}

@article{richter_bressler_2018,
  title = {Top-down Beta Oscillatory Signaling Conveys Behavioral Context in Early Visual Cortex},
  author = {Richter, Craig G and Coppola, Richard and Bressler, Steven L},
  year = {2018},
  volume = {8},
  pages = {6991},
  issn = {20452322},
  doi = {10.1038/s41598-018-25267-1},
  abstract = {Top-down modulation of sensory processing is a critical neural mechanism subserving a number of important cognitive roles. Principally, top-down influences appear to inform lower-order sensory systems of the current 'task at hand', and thus may convey behavioral context to these systems. Accumulating evidence indicates that top-down cortical influences are carried by directed interareal synchronization of oscillatory neuronal populations. An important question currently under investigation by a number of laboratories is whether the information conveyed by directed interareal synchronization depends on the frequency band in which it is conveyed. Recent results point to the beta frequency band as being particularly important for conveying task-related information. However, little is known about the nature of the information conveyed by top-down directed influences. To investigate the information content of top-down directed beta-frequency influences, we measured spectral Granger Causality using local field potentials recorded from microelectrodes chronically implanted in visual cortical areas V1, V4, and TEO, and then applied multivariate pattern analysis to the spatial patterns of top-down spectral Granger Causality in the visual cortex. We decoded behavioral context by discriminating patterns of top-down (V4/TEO -\textbackslash textgreater V1) beta-peak spectral Granger Causality for two different task rules governing the correct responses to visual stimuli. The results indicate that top-down directed influences in visual cortex are carried by beta oscillations, and differentiate current task demands even before visual stimulus processing. They suggest that top-down beta-frequency oscillatory processes may coordinate the processing of sensory information by conveying global knowledge states to early levels of the sensory cortical hierarchy independently of bottom-up stimulus-driven processing.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6RBTT4Q4\\Richter, Coppola, Bressler - 2018 - Top-down beta oscillatory signaling conveys behavioral context in early visual cortex OPEN.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\FTCN97X4\\Richter, Coppola, Bressler - 2018 - Top-down beta oscillatory signaling conveys behavioral context in early visual cortex OPEN.pdf},
  journal = {Scientific Reports},
  number = {1},
  pmid = {29725028}
}

@article{richter_fries_2017,
  title = {Top-{{Down Beta Enhances Bottom}}-{{Up Gamma}}},
  author = {Richter, Craig G and Thompson, William H and Conrado, X and Bosman, A and Fries, X Pascal},
  year = {2017},
  doi = {10.1523/JNEUROSCI.3771-16.2017},
  abstract = {Several recent studies have demonstrated that the bottom-up signaling of a visual stimulus is subserved by interareal gamma-band synchronization, whereas top-down influences are mediated by alpha-beta band synchronization. These processes may implement top-down control of stimulus processing if top-down and bottom-up mediating rhythms are coupled via cross-frequency interaction. To test this possibility, we investigated Granger-causal influences among awake macaque primary visual area V1, higher visual area V4, and parietal control area 7a during attentional task performance. Top-down 7a-to-V1 beta-band influences enhanced visually driven V1-to-V4 gamma-band influences. This enhancement was spatially specific and largest when beta-band activity preceded gamma-band activity by ϳ0.1 s, suggesting a causal effect of top-down processes on bottom-up processes. We propose that this cross-frequency interaction mechanistically subserves the attentional control of stimulus selection.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\F483WAI6\\Richter et al. - 2017 - Top-down beta enhances bottom-up gamma.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\QKPGYMIS\\Richter et al. - Unknown - Top-Down Beta Enhances Bottom-Up Gamma.pdf},
  keywords = {attention,beta,gamma,Granger causality,oscillation,synchronization}
}

@article{riddle_desposito_2019,
  title = {Causal {{Evidence}} for the {{Role}} of {{Neuronal Oscillations}} in {{Top}}\textendash{{Down}} and {{Bottom}}\textendash{{Up Attention}}},
  author = {Riddle, Justin and Hwang, Kai and Cellier, Dillan and Dhanani, Sofia and D'Esposito, Mark},
  year = {2019},
  month = may,
  volume = {31},
  pages = {768--779},
  issn = {0898-929X, 1530-8898},
  doi = {10.1162/jocn_a_01376},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MZ4QDRVI\\Riddle et al. - 2019 - Causal Evidence for the Role of Neuronal Oscillati.pdf},
  journal = {Journal of Cognitive Neuroscience},
  language = {en},
  number = {5}
}

@article{riddle_desposito_2020,
  title = {Causal {{Evidence}} for a {{Role}} of {{Theta}} and {{Alpha Oscillations}} in the {{Control}} of {{Working Memory}}},
  author = {Riddle, Justin and Scimeca, Jason M. and Cellier, Dillan and Dhanani, Sofia and D'Esposito, Mark},
  year = {2020},
  month = apr,
  pages = {S0960982220302724},
  issn = {09609822},
  doi = {10.1016/j.cub.2020.02.065},
  abstract = {Working memory (WM) relies on the prioritization of relevant information and suppression of irrelevant information [1, 2]. Prioritizing relevant information has been linked to theta frequency neural oscillations in lateral prefrontal cortex and suppressing irrelevant information has been linked to alpha oscillations in occipito-parietal cortex [3,11]. Here, we used a retrospective-cue WM paradigm to manipulate prioritization and suppression task demands designed to drive theta oscillations in prefrontal cortex and alpha oscillations in parietal cortex, respectively. To causally test the role of these neural oscillations, we applied rhythmic transcranial magnetic stimulation (TMS) in either theta or alpha frequency to prefrontal and parietal regions identified using functional MRI. The effect of rhythmic TMS on WM performance was dependent on whether the TMS frequency matched or mismatched the expected underlying task-driven oscillations of the targeted region. Functional MRI in the targeted regions predicted subsequent TMS effects across subjects supporting a model by which theta oscillations are excitatory to neural activity, and alpha oscillations are inhibitory. Together, these results causally establish dissociable roles for prefrontal theta oscillations and parietal alpha oscillations in the control of internally maintained WM representations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HNVAZKPA\\Riddle et al. - 2020 - Causal Evidence for a Role of Theta and Alpha Osci.pdf},
  journal = {Current Biology},
  language = {en}
}

@techreport{riddle_riddle_2018,
  title = {Causal {{Evidence}} for {{Neural Oscillations}} in {{Cognition}}},
  author = {Riddle, Justin M},
  year = {2018},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ATVKU4H4\\Riddle - 2018 - Causal Evidence for Neural Oscillations in Cognition.pdf}
}

@article{riesenhuber_poggio_2002,
  title = {Neural Mechanisms of Object Recognition},
  author = {Riesenhuber, Maximilian and Poggio, Tomaso},
  year = {2002},
  volume = {12},
  pages = {162--168},
  issn = {09594388},
  doi = {10.1016/S0959-4388(02)00304-5},
  abstract = {Single-unit recordings from behaving monkeys and human functional magnetic resonance imaging studies have continued to provide a host of experimental data on the properties and mechanisms of object recognition in cortex. Recent advances in object recognition, spanning issues regarding invariance, selectivity, representation and levels of recognition have allowed us to propose a putative model of object recognition in cortex.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UNULAYS6\\Riesenhuber, Poggio - 2002 - Neural mechanisms of object recognition.pdf},
  journal = {Current Opinion in Neurobiology},
  keywords = {Animals,Frontal Lobe,Frontal Lobe: physiology,Haplorhini,Humans,Neural Networks (Computer),Recognition (Psychology),Recognition (Psychology): physiology,Temporal Lobe,Temporal Lobe: physiology,Visual Cortex,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology},
  number = {2},
  pmid = {12015232}
}

@book{ritchey_ranganath_2015,
  title = {Cortico-Hippocampal Systems Involved in Memory and Cognition},
  author = {Ritchey, Maureen and a. Libby, Laura and Ranganath, Charan},
  year = {2015},
  edition = {First},
  volume = {219},
  publisher = {{Elsevier B.V.}},
  doi = {10.1016/bs.pbr.2015.04.001},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HNM4WU9K\\Ritchey, Libby, Ranganath - 2015 - Cortico-hippocampal systems involved in memory and cognition The PMAT framework.pdf},
  isbn = {5-307-57886-5},
  keywords = {default network,Default network,episodic memory,Episodic memory,functional connectivity,Functional connectivity,hours have been devoted,medial temporal lobes,Medial temporal lobes,millions of words and,of the hip-,parahippocampal cortex,Parahippocampal cortex,perirhinal cortex,Perirhinal cortex,retro-,Retrosplenial cortex,splenial cortex,to characterizing the role}
}

@incollection{ritchey_ranganath_2015a,
  title = {Cortico-Hippocampal Systems Involved in Memory and Cognition: {{The PMAT}} Framework},
  booktitle = {Progress in {{Brain Research}}},
  author = {Ritchey, Maureen and Libby, Laura A. and Ranganath, Charan},
  year = {2015},
  volume = {219},
  pages = {45--64},
  doi = {10.1016/bs.pbr.2015.04.001},
  abstract = {In this chapter, we review evidence that the cortical pathways to the hippocampus appear to extend from two large-scale cortical systems: a posterior medial (PM) system that includes the parahippocampal cortex and retrosplenial cortex, and an anterior temporal (AT) system that includes the perirhinal cortex. This "PMAT" framework accounts for differences in the anatomical and functional connectivity of the medial temporal lobes, which may underpin differences in cognitive function between the systems. The PM and AT systems make distinct contributions to memory and to other cognitive domains, and convergent findings suggest that they are involved in processing information about contexts and items, respectively. In order to support the full complement of memory-guided behavior, the two systems must interact, and the hippocampal and ventromedial prefrontal cortex may serve as sites of integration between the two systems. We conclude that when considering the "connected hippocampus," inquiry should extend beyond the medial temporal lobes to include the large-scale cortical systems of which they are a part.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\I3GM3IY7\\Ritchey, Libby, Ranganath - 2015 - Cortico-hippocampal systems involved in memory and cognition The PMAT framework.pdf},
  isbn = {978-0-444-63549-5},
  keywords = {Default network,Episodic memory,Functional connectivity,Medial temporal lobes,Parahippocampal cortex,Perirhinal cortex,Retrosplenial cortex},
  pmid = {26072233}
}

@article{ritchey_ranganath_2018,
  title = {Dissociable Medial Temporal Pathways for Encoding Emotional Item and Context Information},
  author = {Ritchey, Maureen and Wang, Shao-Fang and Yonelinas, Andrew P and Ranganath, Charan},
  year = {2018},
  pages = {248294},
  issn = {0378-5173},
  doi = {10.1101/248294},
  abstract = {Emotional experiences are typically remembered with a greater sense of recollection than neutral experiences, but memory benefits for emotional items do not typically extend to their source contexts. Item and source memory have been attributed to different subregions of the medial temporal lobes (MTL), but it is unclear how emotional item recollection fits into existing models of MTL function and, in particular, what is the role of the hippocampus. To address these issues, we used high-resolution fMRI to examine MTL contributions to successful emotional item and context encoding. The results showed that emotional items were recollected more often than neutral items. Whereas amygdala and PRC activity supported the recollection advantage for emotional items, hippocampal and PHC activity predicted subsequent source memory for both types of items, reflecting a double dissociation between anterior and posterior MTL regions. We next tested whether amygdala activity during encoding modulated the relationship between MTL activity and subsequent memory outcomes. The amygdala and PRC played complementary roles in supporting subsequent item recollection, in that lower amygdala activity was associated with more memory dependence on PRC. In contrast, the amygdala and hippocampus played synergistic roles in supporting subsequent source memory, in that higher amygdala activity amplified the relation of hippocampal activity to subsequent source memory. The results suggest that emotion-related enhancements in item recollection are supported by an amygdala-perirhinal pathway, which is separable from the hippocampal pathway that binds items to their source context.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\X8XK62QL\\Ritchey et al. - Unknown - Dissociable medial temporal pathways for encoding emotional item and context information.pdf},
  journal = {bioRxiv},
  pmid = {27864418}
}

@article{rodriguez_varela_1999,
  title = {Perception's Shadow: Long-Distance Synchronization of Human Brain Activity},
  author = {Rodriguez, E and George, N and Lachaux, J P and Martinerie, J and Renault, B and Varela, F J},
  year = {1999},
  volume = {397},
  pages = {430--433},
  issn = {0028-0836},
  doi = {10.1038/17120},
  abstract = {Transient periods of synchronization of oscillating neuronal discharges in the frequency range 30-80 Hz (gamma oscillations) have been proposed to act as an integrative mechanism that may bring a widely distributed set of neurons together into a coherent ensemble that underlies a cognitive act. Results of several experiments in animals provide support for this idea. In humans, gamma oscillations have been described both on the scalp (measured by electroencephalography and magnetoencephalography) and in intracortical recordings, but no direct participation of synchrony in a cognitive task has been demonstrated so far. Here we record electrical brain activity from subjects who are viewing ambiguous visual stimuli (perceived either as faces or as meaningless shapes). We show for the first time, to our knowledge, that only face perception induces a long-distance pattern of synchronization, corresponding to the moment of perception itself and to the ensuing motor response. A period of strong desynchronization marks the transition between the moment of perception and the motor response. We suggest that this desynchronization reflects a process of active uncoupling of the underlying neural ensembles that is necessary to proceed from one cognitive state to another.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7UJL67KG\\Rodriguez et al. - 1999 - Perception's shadow long-distance synchronization of human brain activity.pdf},
  journal = {Nature},
  keywords = {Cognition/*physiology,Electroencephalography,Face,Female,Humans,Male,Reaction Time,Visual Perception/*physiology},
  number = {6718},
  pmid = {9989408}
}

@article{rodu_kass_1962,
  title = {{{INNOVATIVE METHODOLOGY Detecting}} Multivariate Cross-Correlation between Brain Regions},
  author = {Rodu, Jordan and Klein, Natalie and Brincat, Scott L and Miller, Earl K and Kass, Robert E},
  year = {1962},
  volume = {120},
  doi = {10.1152/jn.00869.2017.-The},
  abstract = {Rodu J, Klein N, Brincat SL, Miller EK, Kass RE. Detecting multivariate cross-correlation between brain regions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L7GGKMNG\\Rodu et al. - 1962 - INNOVATIVE METHODOLOGY Detecting multivariate cross-correlation between brain regions.pdf},
  journal = {J Neurophysiol}
}

@article{roedigeriii_geraci_2002,
  title = {Processing Approaches to Cognition: The Impetus from the Levels-of-Processing Framework.},
  author = {Roediger III, Henry L and Gallo, David A and Geraci, Lisa},
  year = {2002},
  volume = {10},
  pages = {319--332},
  issn = {0965-8211},
  doi = {10.1080/09658210224000144},
  abstract = {Processing approaches to cognition have a long history, from act psychology to the present, but perhaps their greatest boost was given by the success and dominance of the levels-of-processing framework. We review the history of processing approaches, and explore the influence of the levels-of-processing approach, the procedural approach advocated by Paul Kolers, and the transfer-appropriate processing framework. Processing approaches emphasise the procedures of mind and the idea that memory storage can be usefully conceptualised as residing in the same neural units that originally processed information at the time of encoding. Processing approaches emphasise the unity and interrelatedness of cognitive processes and maintain that they can be dissected into separate faculties only by neglecting the richness of mental life. We end by pointing to future directions for processing approaches.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GTQXDSQS\\Roediger III, Gallo, Geraci - 2002 - Processing approaches to cognition the impetus from the levels-of-processing framework.pdf},
  journal = {Memory},
  number = {5-6},
  pmid = {12396644}
}

@article{roelfsema_holtmaat_2017,
  ids = {roelfsema\_holtmaat\_2018},
  title = {Control of Synaptic Plasticity in Deep Cortical Networks},
  author = {Roelfsema, Pieter R and Holtmaat, Anthony},
  year = {2017},
  pages = {1--25},
  issn = {1471-003X},
  doi = {10.1038/nrn.2018.6},
  abstract = {Humans and many other animals have an enormous capacity to learn about sensory stimuli and to master new skills. Yet, many of the mechanisms that enable us to learn remain to be understood. One of greatest challenges of systems neuroscience is to explain how synaptic connections change to support maximally adaptive behavior. Here we will give an overview of factors that determine the change in the strength of synapses, with a focus on synaptic plasticity in sensory cortices. We review the influence of neuromodulators and feedback connections on synaptic plasticity, and suggest a specific framework in which these factors can interact to improve the functioning of the entire network.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\B9KW8D8R\\Roelfsema and Holtmaat - 2018 - Control of synaptic plasticity in deep cortical ne.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\WCBPJWCR\\Roelfsema and Holtmaat - 2018 - Control of synaptic plasticity in deep cortical ne.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\WFEMDIRU\\Roelfsema, Holtmaat - 2017 - Control of synaptic plasticity in deep cortical networks.pdf}
}

@article{rogers_mcclelland_2014,
  title = {Parallel {{Distributed Processing}} at 25: {{Further Explorations}} in the {{Microstructure}} of {{Cognition}}},
  author = {Rogers, Timothy T and McClelland, James L},
  year = {2014},
  volume = {38},
  pages = {1024--1077},
  issn = {03640213},
  doi = {10.1111/cogs.12148},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9DCUNW3Q\\Rogers, McClelland - 2014 - Parallel Distributed Processing at 25 Further Explorations in the Microstructure of Cognition.pdf},
  journal = {Cognitive Science},
  keywords = {cognition,cognitive control,connectionist models,language,learning,memory,neural networks,perception},
  number = {6}
}

@article{rogerson_silva_2014,
  title = {Synaptic Tagging during Memory Allocation},
  author = {Rogerson, Thomas and Cai, Denise J. and Frank, Adam and Sano, Yoshitake and Shobe, Justin and {Lopez-Aranda}, Manuel F. and Silva, Alcino J.},
  year = {2014},
  month = mar,
  volume = {15},
  pages = {157--169},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn3667},
  abstract = {There is now compelling evidence that the allocation of memory to specific neurons (neuronal allocation) and synapses (synaptic allocation) in a neurocircuit is not random and that instead specific mechanisms, such as increases in neuronal excitability and synaptic tagging and capture, determine the exact sites where memories are stored. We propose an integrated view of these processes, such that neuronal allocation, synaptic tagging and capture, spine clustering and metaplasticity reflect related aspects of memory allocation mechanisms. Importantly, the properties of these mechanisms suggest a set of rules that profoundly affect how memories are stored and recalled.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\G9RBMNDZ\\Rogerson et al. - 2014 - Synaptic tagging during memory allocation.pdf},
  journal = {Nature Reviews Neuroscience},
  language = {en},
  number = {3}
}

@article{rohrer_pashler_2007,
  title = {Increasing {{Retention Without Increasing Study Time}}},
  author = {Rohrer, Doug and Pashler, Harold},
  year = {2007},
  month = aug,
  volume = {16},
  pages = {183--186},
  issn = {0963-7214, 1467-8721},
  doi = {10.1111/j.1467-8721.2007.00500.x},
  abstract = {Because people forget much of what they learn, students could benefit from learning strategies that yield long-lasting knowledge. Yet surprisingly little is known about how long-term retention is most efficiently achieved. Here we examine how retention is affected by two variables: the duration of a study session and the temporal distribution of study time across multiple sessions. Our results suggest that a single session devoted to the study of some material should continue long enough to ensure that mastery is achieved but that immediate further study of the same material is an inefficient use of time. Our data also show that the benefit of distributing a fixed amount of study time across two study sessions\textemdash the spacing effect\textemdash depends jointly on the interval between study sessions and the interval between study and test. We discuss the practical implications of both findings, especially in regard to mathematics learning.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BKA8CQC5\\Rohrer and Pashler - 2007 - Increasing Retention Without Increasing Study Time.pdf},
  journal = {Current Directions in Psychological Science},
  language = {en},
  number = {4}
}

@article{rolls_mills_2019,
  title = {The {{Generation}} of {{Time}} in the {{Hippocampal Memory System}}},
  author = {Rolls, Edmund T. and Mills, Patrick},
  year = {2019},
  month = aug,
  volume = {28},
  pages = {1649-1658.e6},
  issn = {22111247},
  doi = {10.1016/j.celrep.2019.07.042},
  abstract = {We propose that ramping time cells in the lateral entorhinal cortex can be produced by synaptic adaptation and demonstrate this in an integrate-and-fire attractor network model. We propose that competitive networks in the hippocampal system can convert these entorhinal ramping cells into hippocampal time cells and demonstrate this in a competitive network. We propose that this conversion is necessary to provide orthogonal hippocampal time representations to encode the temporal sequence of events in hippocampal episodic memory, and we support that with analytic arguments. We demonstrate that this processing can produce hippocampal neuronal ensembles that not only show replay of the sequence later on, but can also do this in reverse order in reverse replay. This research addresses a major issue in neuroscience: the mechanisms by which time is encoded in the brain and how the time representations are then useful in the hippocampal memory of events and their order.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XMLTT2EQ\\Rolls and Mills - 2019 - The Generation of Time in the Hippocampal Memory S.pdf},
  journal = {Cell Reports},
  language = {en},
  number = {7}
}

@book{rolls_rolls_2015,
  title = {Diluted Connectivity in Pattern Association Networks Facilitates the Recall of Information from the Hippocampus to the Neocortex},
  author = {Rolls, Edmund T},
  year = {2015},
  edition = {First},
  volume = {219},
  publisher = {{Elsevier B.V.}},
  doi = {10.1016/bs.pbr.2015.03.007},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\H4UWZUAG\\Rolls - 2015 - Diluted connectivity in pattern association networks facilitates the recall of information from the hippocampus to the ne.pdf},
  keywords = {Autoassociation,Backprojections,CA1,CA3,Cortical backprojections,Dentate granule cells,Diluted cortical connectivity,Episodic memory,Hippocampus,Memory,Pattern association,Recall}
}

@article{rolls_rolls_2019,
  title = {Spatial Coordinate Transforms Linking the Allocentric Hippocampal and Egocentric Parietal Primate Brain Systems for Memory, Action in Space, and Navigation},
  author = {Rolls, Edmund T.},
  year = {2019},
  month = nov,
  pages = {hipo.23171},
  issn = {1050-9631, 1098-1063},
  doi = {10.1002/hipo.23171},
  abstract = {A theory and model of spatial coordinate transforms in the dorsal visual system through the parietal cortex that enable an interface via posterior cingulate and related retrosplenial cortex to allocentric spatial representations in the primate hippocampus is described. First, a new approach to coordinate transform learning in the brain is proposed, in which the traditional gain modulation is complemented by temporal trace rule competitive network learning. It is shown in a computational model that the new approach works much more precisely than gain modulation alone, by enabling neurons to represent the different combinations of signal and gain modulator more accurately. This understanding may have application to many brain areas where coordinate transforms are learned. Second, a set of coordinate transforms is proposed for the dorsal visual system/parietal areas that enables a representation to be formed in allocentric spatial view coordinates. The input stimulus is merely a stimulus at a given position in retinal space, and the gain modulation signals needed are eye position, head direction, and place, all of which are present in the primate brain. Neurons that encode the bearing to a landmark are involved in the coordinate transforms. Part of the importance here is that the coordinates of the allocentric view produced in this model are the same as those of spatial view cells that respond to allocentric view recorded in the primate hippocampus and parahippocampal cortex. The result is that information from the dorsal visual system can be used to update the spatial input to the hippocampus in the appropriate allocentric coordinate frame, including providing for idiothetic update to allow for self-motion. It is further shown how hippocampal spatial view cells could be useful for the transform from hippocampal allocentric coordinates to egocentric coordinates useful for actions in space and for navigation.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LXC95PAK\\Rolls - 2019 - Spatial coordinate transforms linking the allocent.pdf},
  journal = {Hippocampus},
  language = {en}
}

@article{rombouts_roelfsema_2015,
  title = {How {{Attention Can Create Synaptic Tags}} for the {{Learning}} of {{Working Memories}} in {{Sequential Tasks}}},
  author = {Rombouts, Jaldert O and Bohte, Sander M and Roelfsema, Pieter R},
  year = {2015},
  volume = {11},
  pages = {1004060},
  doi = {10.1371/journal.pcbi.1004060},
  abstract = {Intelligence is our ability to learn appropriate responses to new stimuli and situations. Neu-rons in association cortex are thought to be essential for this ability. During learning these neurons become tuned to relevant features and start to represent them with persistent activity during memory delays. This learning process is not well understood. Here we develop a biologically plausible learning scheme that explains how trial-and-error learning induces neuronal selectivity and working memory representations for task-relevant information. We propose that the response selection stage sends attentional feedback signals to earlier processing levels, forming synaptic tags at those connections responsible for the stimulus-response mapping. Globally released neuromodulators then interact with tagged synapses to determine their plasticity. The resulting learning rule endows neural networks with the capacity to create new working memory representations of task relevant information as persistent activity. It is remarkably generic: it explains how association neurons learn to store task-relevant information for linear as well as non-linear stimulus-response mappings, how they become tuned to category boundaries or analog variables, depending on the task demands , and how they learn to integrate probabilistic evidence for perceptual decisions. Author Summary Working memory is a cornerstone of intelligence. Most, if not all, tasks that one can imagine require some form of working memory. The optimal solution of a working memory task depends on information that was presented in the past, for example choosing the right direction at an intersection based on a roadsign some hundreds of meters before. Interestingly , animals like monkeys readily learn difficult working memory tasks, just by receiving rewards such as fruit juice when they perform the desired behavior. Neurons in association areas in the brain play an important role in this process; these areas integrate PLOS perceptual and memory information to support decision-making. Some of these association neurons become tuned to relevant features and memorize the information that is required later as a persistent elevation of their activity. It is, however, not well understood how these neurons acquire their task-relevant tuning. Here we formulate a simple biologically plausible learning mechanism that can explain how a network of neurons can learn a wide variety of working memory tasks by trial-and-error learning. We also show that the solutions learned by the model are comparable to those found in animals when they are trained on similar tasks.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CUUFXGAY\\Rombouts, Bohte, Roelfsema - 2015 - How Attention Can Create Synaptic Tags for the Learning of Working Memories in Sequential Tasks.pdf},
  journal = {Computational Biology},
  number = {3}
}

@article{romo_brody_2002,
  title = {Neuronal Correlates of Decision-Making in Secondary Somatosensory Cortex},
  author = {Romo, Ranulfo and Hern{\'a}ndez, Adri{\'a}n and Zainos, Antonio and Lemus, Luis and Brody, Carlos D.},
  year = {2002},
  month = nov,
  volume = {5},
  pages = {1217--1225},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn950},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LPW8KA6M\\Romo et al. - 2002 - Neuronal correlates of decision-making in secondar.pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {11}
}

@article{romo_salinas_2003,
  title = {Flutter {{Discrimination}}: Neural Codes, Perception, Memory and Decision Making},
  shorttitle = {Flutter {{Discrimination}}},
  author = {Romo, Ranulfo and Salinas, Emilio},
  year = {2003},
  month = mar,
  volume = {4},
  pages = {203--218},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn1058},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NQLUC42M\\Romo and Salinas - 2003 - Flutter Discrimination neural codes, perception, .pdf},
  journal = {Nature Reviews Neuroscience},
  language = {en},
  number = {3}
}

@techreport{rose_rose_2020,
  title = {The {{Dynamic Processing Model}} of {{Working Memory}}},
  author = {Rose, Nathan},
  year = {2020},
  month = jan,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/975zk},
  abstract = {Recent shifts in the understanding of how the mind and brain retain information in working memory (WM) call for revision to traditional theories. Evidence for the existence of dynamic, ``activity-silent'' short-term retention processes in the brain diverge from conventional models that have argued that information is always retained in WM by sustained neural activity in buffers. Such evidence comes from the use of machine-learning analytic approaches to decode patterns of brain activity and the simultaneous administration of transcranial magnetic stimulation (TMS) to causally manipulate brain activity in specific areas and time-points. TMS has been used to 'ping' brain areas and reactivate latent representations retained in WM and affect memory performance. These findings argue for a supplement to the sustained retention mechanisms associated with attending to information in WM. Moreover, brain decoding methods reveal that dynamic levels of representational codes are retained in WM, which vary according to task context, from perceptual/sensory codes in posterior areas to more abstract, recoded representations distributed across frontal-parietal regions. A Dynamic Processing Model of WM is advanced to account for the overall pattern of results.Keywords: activity-silent, short-term memory, working memory, sensory-motor recruitment},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BTS7WE48\\Rose - 2020 - The Dynamic Processing Model of Working Memory.pdf},
  language = {en},
  type = {Preprint}
}

@article{rosenthal_soto_2018,
  title = {Learning Multiple Concurrent Higher-Order Visual Sequences in Human Primary Visual Cortex},
  author = {Rosenthal, Clive R and Mallik, Indira and {Caballero-Gaudes}, Cesar and Sereno, Marty and Soto, David},
  year = {2018},
  doi = {10.1101/261255},
  abstract = {Learning and memory are known to be supported by a network in-volving the medial temporal lobe and linked neocortical regions. Emerg-ing evidence indicates that primary sensory regions (i.e., V1) may be also contribute to recognition memory processes, but this has been only tested with a single visuospatial sequence as the target memorandum . The present study used functional magnetic resonance imaging to test the capacity of human V1 to support the learning of multiple, concur-rent and complex visual sequences involving discontinous (second-order) associations. Two peripheral, task-irrelevant but structured sequences of orientated gratings appeared simultaneously in right and left visual fields alongside a central, task-relevant sequence that was in the focus of spatial attention. Pseudorandom sequences were interspersed amongst the three complex structured sequences with different asynchronies. We found that a network involving the precuneus and V1 was involved in learning the structured sequence presented at central fixation, whereas right V1 was modulated by repeated exposure to a concurrent structured sequence pre-sented in the left visual field. The same result was not found in left V1. These results indicate that human V1 can support the learning of multiple concurrent sequences involving complex discontinuous inter-item associations, even those that are goal-irrelevant.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EMPNHMFM\\Rosenthal et al. - 2018 - Learning multiple concurrent higher-order visual sequences in human primary visual cortex.pdf}
}

@article{rossant_brette_2011,
  title = {Fitting Neuron Models to Spike Trains},
  author = {Rossant, Cyrille and Goodman, Dan F M and Fontaine, Bertrand and Platkiewicz, Jonathan and Magnusson, Anna K and Brette, Romain},
  year = {2011},
  volume = {5},
  pages = {1--8},
  issn = {16624548},
  doi = {10.3389/fnins.2011.00009},
  abstract = {Computational modeling is increasingly used to understand the function of neural circuits in systems neuroscience. These studies require models of individual neurons with realistic input-output properties. Recently, it was found that spiking models can accurately predict the precisely timed spike trains produced by cortical neurons in response to somatically injected currents, if properly fitted. This requires fitting techniques that are efficient and flexible enough to easily test different candidate models. We present a generic solution, based on the Brian simulator (a neural network simulator in Python), which allows the user to define and fit arbitrary neuron models to electrophysiological recordings. It relies on vectorization and parallel computing techniques to achieve efficiency. We demonstrate its use on neural recordings in the barrel cortex and in the auditory brainstem, and confirm that simple adaptive spiking models can accurately predict the response of cortical neurons. Finally, we show how a complex multicompartmental model can be reduced to a simple effective spiking model.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ETMKZ8UJ\\Rossant et al. - 2011 - Fitting neuron models to spike trains.pdf},
  journal = {Frontiers in Neuroscience},
  keywords = {Optimization,Parallel computing,Python,Simulation,Spiking models},
  number = {FEB},
  pmid = {21415925}
}

@article{rossant_harris_2016,
  title = {Spike Sorting for Large, Dense Electrode Arrays},
  author = {Rossant, Cyrille and Kadir, Shabnam N and Goodman, Dan F M and Schulman, John and Hunter, Maximilian L D and Saleem, Aman B and Grosmark, Andres and Belluscio, Mariano and Denfield, George H and Ecker, Alexander S and Tolias, Andreas S and Solomon, Samuel and Buzs{\'a}ki, Gy{\"o}rgy and Carandini, Matteo and Harris, Kenneth D},
  year = {2016},
  volume = {19},
  pages = {634--641},
  issn = {1097-6256},
  doi = {10.1038/nn.4268},
  abstract = {Developments in microfabrication technology have enabled the production of neural electrode arrays with hundreds of closely-spaced recording sites, and electrodes with thousands of sites are currently under development. These probes will in principle allow the simultaneous recording of very large numbers of neurons. However, use of this technology requires the development of techniques for decoding the spike times of the recorded neurons, from the raw data captured from the probes. There currently exists no practical solution to this problem of ``spike sorting'' for large, dense electrode arrays. Here, we present a set of novel tools to solve this problem, implemented in a suite of practical, user-friendly, open-source software. We validate these methods on data from rat cortex, demonstrating error rates as low as 5\{\%\}.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VUQB279S\\Rossant et al. - 2016 - Spike sorting for large, dense electrode arrays.pdf},
  journal = {Nature Neuroscience},
  number = {4},
  pmid = {26974951}
}

@techreport{rostami_nawrot_2020,
  title = {Spiking Neural Network Model of Motor Cortex with Joint Excitatory and Inhibitory Clusters Reflects Task Uncertainty, Reaction Times, and Variability Dynamics},
  author = {Rostami, Vahid and Rost, Thomas and Riehle, Alexa and {van Albada}, Sacha J. and Nawrot, Martin P.},
  year = {2020},
  month = feb,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.02.27.968339},
  abstract = {Both neural activity and behavior of highly trained animals are strikingly variable across repetition of behavioral trials. The neural variability consistently decreases during behavioral tasks, in both sensory and motor cortices. The behavioral variability, on the other hand, changes depending on the difficulty of the task and animal performance.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\63SR35SY\\Rostami et al. - 2020 - Spiking neural network model of motor cortex with .pdf},
  language = {en},
  type = {Preprint}
}

@article{rothman_silver_2018,
  title = {{{NeuroMatic}}: {{An Integrated Open}}-{{Source Software Toolkit}} for {{Acquisition}}, {{Analysis}} and {{Simulation}} of {{Electrophysiological Data}}},
  author = {Rothman, Jason S. and Silver, R. Angus},
  year = {2018},
  volume = {12},
  pages = {1--21},
  issn = {1662-5196},
  doi = {10.3389/fninf.2018.00014},
  abstract = {Acquisition, analysis and simulation of electrophysiological properties of the nervous system require multiple software packages. This makes it difficult to conserve experimental metadata and track the analysis performed. It also complicates certain experimental approaches such as online analysis. To address this, we developed NeuroMatic, an open-source software toolkit that performs data acquisition (episodic, continuous and triggered recordings), data analysis (spike rasters, spontaneous event detection, curve fitting, stationarity) and simulations (stochastic synaptic transmission, synaptic short-term plasticity, integrate-and-fire and Hodgkin-Huxley-like single-compartment models). The merging of a wide range of tools into a single package facilitates a more integrated style of research, from the development of online analysis functions during data acquisition, to the simulation of synaptic conductance trains during dynamic-clamp experiments. Moreover, NeuroMatic has the advantage of working within Igor Pro, a platform-independent environment that includes an extensive library of built-in functions, a history window for reviewing the user's workflow and the ability to produce publication-quality graphics. Since its original release, NeuroMatic has been used in a wide range of scientific studies and its user base has grown considerably. NeuroMatic version 3.0 can be found at http://www.neuromatic.thinkrandom.com and https://github.com/SilverLabUCL/NeuroMatic.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Q6TDNB42\\Rothman, Silver - 2018 - NeuroMatic An Integrated Open-Source Software Toolkit for Acquisition, Analysis and Simulation of Electrophysio.pdf},
  journal = {Frontiers in Neuroinformatics},
  keywords = {code,data acquisitio,data acquisition,data analysis,detection,electrophysiology,igor pro,neural simulations,patch clamping,spike detection,spontaneous event},
  number = {April},
  pmid = {29670519}
}

@article{rotter_diesmann_1999,
  title = {Exact Digital Simulation of Time-Invariant Linear Systems with Applications to Neuronal Modeling.},
  author = {Rotter, S and Diesmann, M},
  year = {1999},
  month = nov,
  volume = {81},
  pages = {381--402},
  issn = {0340-1200},
  abstract = {An efficient new method for the exact digital simulation of time-invariant linear systems is presented. Such systems are frequently encountered as models for neuronal systems, or as submodules of such systems. The matrix exponential is used to construct a matrix iteration, which propagates the dynamic state of the system step by step on a regular time grid. A large and general class of dynamic inputs to the system, including trains of delta-pulses, can be incorporated into the exact simulation scheme. An extension of the proposed scheme presents an attractive alternative for the approximate simulation of networks of integrate-and-fire neurons with linear sub-threshold integration and non-linear spike generation. The performance of the proposed method is analyzed in comparison with a number of multi-purpose solvers. In simulations of integrate-and-fire neurons, Exact Integration systematically generates the smallest error with respect to both sub-threshold dynamics and spike timing. For the simulation of systems where precise spike timing is important, this results in a practical advantage in particular at moderate integration step sizes.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WRJQTKVQ\\Rotter, Diesmann - 1999 - Exact digital simulation of time-invariant linear systems with applications to neuronal modeling.pdf},
  journal = {Biological cybernetics},
  keywords = {Animals,Computer Simulation,Cybernetics,Evoked Potentials,Humans,Linear Models,Models,Nerve Net,Nerve Net: physiology,Neurological,Neurons,Neurons: physiology,Time Factors},
  number = {5-6},
  pmid = {10592015}
}

@article{rougier_oreilly_2005,
  title = {Prefrontal Cortex and Flexible Cognitive Control: Rules without Symbols.},
  author = {Rougier, Nicolas P and Noelle, David C and Braver, Todd S and Cohen, Jonathan D and O'Reilly, Randall C},
  year = {2005},
  volume = {102},
  pages = {7338--7343},
  issn = {0027-8424},
  doi = {10.1073/pnas.0502455102},
  abstract = {Human cognitive control is uniquely flexible and has been shown to depend on prefrontal cortex (PFC). But exactly how the biological mechanisms of the PFC support flexible cognitive control remains a profound mystery. Existing theoretical models have posited powerful task-specific PFC representations, but not how these develop. We show how this can occur when a set of PFC-specific neural mechanisms interact with breadth of experience to self organize abstract rule-like PFC representations that support flexible generalization in novel tasks. The same model is shown to apply to benchmark PFC tasks (Stroop and Wisconsin card sorting), accurately simulating the behavior of neurologically intact and frontally damaged people.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\G4CA3P48\\Rougier et al. - 2005 - Prefrontal cortex and flexible cognitive control rules without symbols.pdf},
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  number = {20},
  pmid = {15883365}
}

@article{roux_buzsaki_2017,
  title = {Sharp Wave Ripples during Learning Stabilize the Hippocampal Spatial Map},
  author = {Roux, Lisa and Hu, Bo and Eichler, Ronny and Stark, Eran and Buzs{\'a}ki, Gy{\"o}rgy},
  year = {2017},
  month = jun,
  volume = {20},
  pages = {845--853},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn.4543},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZUJZ8HEU\\Roux et al. - 2017 - Sharp wave ripples during learning stabilize the h.pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {6}
}

@article{roux_uhlhaas_2014,
  title = {Working Memory and Neural Oscillations: Alpha\textendash Gamma versus Theta\textendash Gamma Codes for Distinct {{WM}} Information?},
  shorttitle = {Working Memory and Neural Oscillations},
  author = {Roux, Fr{\'e}d{\'e}ric and Uhlhaas, Peter J.},
  year = {2014},
  month = jan,
  volume = {18},
  pages = {16--25},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2013.10.010},
  abstract = {Neural oscillations at different frequencies have recently been related to a wide range of basic and higher cognitive processes. One possible role of oscillatory activity is to assure the maintenance of information in working memory (WM). Here we review the possibility that rhythmic activity at theta, alpha, and gamma frequencies serve distinct functional roles during WM maintenance. Specifically, we propose that gamma-band oscillations are generically involved in the maintenance of WM information. By contrast, alpha-band activity reflects the active inhibition of task-irrelevant information, whereas theta-band oscillations underlie the organization of sequentially ordered WM items. Finally, we address the role of cross-frequency coupling (CFC) in enabling alpha\textendash gamma and theta\textendash gamma codes for distinct WM information.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SXINN2DH\\Roux_Uhlhaas_2014_Working_memory_and_neural_oscillations.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\4R8KAWKW\\S1364661313002313.html},
  journal = {Trends in Cognitive Sciences},
  number = {1}
}

@article{roy_wager_2012,
  title = {Ventromedial Prefrontal-Subcortical Systems and the Generation of Affective Meaning},
  author = {Roy, Mathieu and Shohamy, Daphna and Wager, Tor D.},
  year = {2012},
  month = mar,
  volume = {16},
  pages = {147--156},
  issn = {13646613},
  doi = {10.1016/j.tics.2012.01.005},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ITFIAI6Z\\Roy et al. - 2012 - Ventromedial prefrontal-subcortical systems and th.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {3}
}

@article{rubin_ziv_2019,
  title = {Revealing Neural Correlates of Behavior without Behavioral Measurements},
  author = {Rubin, Alon and Sheintuch, Liron and {Brande-Eilat}, Noa and Pinchasof, Or and Rechavi, Yoav and Geva, Nitzan and Ziv, Yaniv},
  year = {2019},
  month = dec,
  volume = {10},
  pages = {4745},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-12724-2},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IT6SKWAP\\Rubin et al. - 2019 - Revealing neural correlates of behavior without be.pdf},
  journal = {Nature Communications},
  language = {en},
  number = {1}
}

@article{rueckauer_liu_2017,
  title = {Conversion of Continuous-Valued Deep Networks to Efficient Event-Driven Networks for Image Classification},
  author = {Rueckauer, Bodo and Lungu, Iulia Alexandra and Hu, Yuhuang and Pfeiffer, Michael and Liu, Shih Chii},
  year = {2017},
  volume = {11},
  issn = {1662453X},
  doi = {10.3389/fnins.2017.00682},
  abstract = {Spiking neural networks (SNNs) can potentially offer an efficient way of doing inference because the neurons in the networks are sparsely activated and computations are event-driven. Previous work showed that simple continuous-valued deep Convolutional Neural Networks (CNNs) can be converted into accurate spiking equivalents. These networks did not include certain common operations such as max-pooling, softmax, batch-normalization and Inception-modules. This paper presents spiking equivalents of these operations therefore allowing conversion of nearly arbitrary CNN architectures. We show conversion of popular CNN architectures, including VGG-16 and Inception-v3, into SNNs that produce the best results reported to date on MNIST, CIFAR-10 and the challenging ImageNet dataset. SNNs can trade off classification error rate against the number of available operations whereas deep continuous-valued neural networks require a fixed number of operations to achieve their classification error rate. From the examples of LeNet for MNIST and BinaryNet for CIFAR-10, we show that with an increase in error rate of a few percentage points, the SNNs can achieve more than 2x reductions in operations compared to the original CNNs. This highlights the potential of SNNs in particular when deployed on power-efficient neuromorphic spiking neuron chips, for use in embedded applications.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\35PYMCL4\\Rueckauer et al. - 2017 - Conversion of continuous-valued deep networks to efficient event-driven networks for image classification.pdf},
  journal = {Frontiers in Neuroscience},
  keywords = {Artificial neural network,Deep learning,Deep networks,Object classification,Spiking network conversion,Spiking neural network},
  number = {DEC}
}

@article{rugg_wilding_2000,
  title = {Retrieval Processing and Episodic Memory},
  author = {Rugg, Michael D and Wilding, Edward L},
  year = {2000},
  volume = {4},
  pages = {108--115},
  issn = {13646613},
  doi = {10.1016/S1364-6613(00)01445-5},
  abstract = {The emergence of brain imaging has had a major impact on research into the cognitive and neural bases of human memory. An area in which this impact has been particularly strong is retrieval processing - the processes engaged when attempting to retrieve information during a memory test. Several different classes of retrieval process - such as 'mode', 'effort' and 'success' - have been invoked to account for findings from neuroimaging studies of episodic retrieval. In this article we discuss how these different kinds of process, along with a fourth kind associated with 'retrieval orientation', can be investigated in brain imaging experiments. We then review studies of retrieval processing, and assess how well their designs match up to our proposed criteria for dissociating the neural correlates of different classes of retrieval process. We conclude that few studies have used designs that permit these different kinds of process to be independently identified, and that presently there is little evidence to indicate which kinds of processing can be fractionated in terms of their neural correlates. ?? 2000 Elsevier Science Ltd.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\22ZCMPXE\\Rugg, Wilding - 2000 - Retrieval processing and episodic memory.pdf},
  journal = {Trends in Cognitive Sciences},
  number = {3},
  pmid = {10689345}
}

@article{runyan_harvey_2017,
  title = {Distinct Timescales of Population Coding across Cortex},
  author = {Runyan, Caroline A. and Piasini, Eugenio and Panzeri, Stefano and Harvey, Christopher D.},
  year = {2017},
  month = aug,
  volume = {548},
  pages = {92--96},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature23020},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9EG3GJKP\\Runyan et al. - 2017 - Distinct timescales of population coding across co.pdf},
  journal = {Nature},
  language = {en},
  number = {7665}
}

@article{russek_daw_2017,
  title = {Predictive Representations Can Link Model-Based Reinforcement Learning to Model-Free Mechanisms},
  author = {Russek, Evan M. and Momennejad, Ida and Botvinick, Matthew M and Gershman, Samuel J and Daw, Nathaniel D},
  year = {2017},
  volume = {13},
  issn = {15537358},
  doi = {10.1371/journal.pcbi.1005768},
  abstract = {Humans and animals are capable of evaluating actions by considering their long-run future rewards through a process described using model-based reinforcement learning (RL) algorithms. The mechanisms by which neural circuits perform the computations prescribed by model-based RL remain largely unknown; however, multiple lines of evidence suggest that neural circuits supporting model-based behavior are structurally homologous to and overlapping with those thought to carry out model-free temporal difference (TD) learning. Here, we lay out a family of approaches by which model-based computation may be built upon a core of TD learning. The foundation of this framework is the successor representation, a predictive state representation that, when combined with TD learning of value predictions, can produce a subset of the behaviors associated with model-based learning at a fraction of the computational cost. Using simulations, we delineate the precise behavioral capabilities enabled by evaluating actions using this approach, and compare them to those demonstrated by biological organisms. We then introduce two new algorithms that build upon the successor representation while progressively mitigating its limitations. Because this framework can account for the full range of observed putatively model-based behaviors while still utilizing a core TD framework, we suggest that it represents a neurally plausible family of mechanisms for model-based evaluation. Author Summary According to standard models, when confronted with a choice, animals and humans rely on two separate, distinct processes to come to a decision. One process deliberatively evaluates the consequences of each candidate action and is thought to underlie the ability to flexibly come up with novel plans. The other process gradually increases the propensity to perform behaviors that were previously successful and is thought to underlie automatically executed, habitual reflexes. Although computational principles and animal behavior support this dichotomy, at the neural level, there is little evidence supporting a clean segregation. For instance, although dopamine \textemdash{} famously implicated in drug addiction and Parkinson's disease \textemdash{} currently only has a well-defined role in the automatic process, evidence suggests that it also plays a role in the deliberative process. In this work, we present a computational framework for resolving this mismatch. We show that the types of behaviors associated with either process could result from a common learning mechanism applied to different strategies for how populations of neurons could represent candidate actions. In addition to demonstrating that this account can produce the full range of flexible behavior observed in the empirical literature, we suggest experiments that could detect the various approaches within this framework.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UTSHKHN8\\Russek 1☯ et al. - Unknown - Predictive representations can link model- based reinforcement learning to model-free mechanisms.pdf},
  journal = {PLoS Computational Biology},
  number = {9},
  pmid = {28945743}
}

@article{russin_bengio_2019,
  title = {Compositional Generalization in a Deep Seq2seq Model by Separating Syntax and Semantics},
  author = {Russin, Jake and Jo, Jason and O'Reilly, Randall C. and Bengio, Yoshua},
  year = {2019},
  month = may,
  abstract = {Standard methods in deep learning for natural language processing fail to capture the compositional structure of human language that allows for systematic generalization outside of the training distribution. However, human learners readily generalize in this way, e.g. by applying known grammatical rules to novel words. Inspired by work in neuroscience suggesting separate brain systems for syntactic and semantic processing, we implement a modification to standard approaches in neural machine translation, imposing an analogous separation. The novel model, which we call Syntactic Attention, substantially outperforms standard methods in deep learning on the SCAN dataset, a compositional generalization task, without any hand-engineered features or additional supervision. Our work suggests that separating syntactic from semantic learning may be a useful heuristic for capturing compositional structure.},
  archivePrefix = {arXiv},
  eprint = {1904.09708},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CFBLVWNF\\Russin et al. - 2019 - Compositional generalization in a deep seq2seq mod.pdf},
  journal = {arXiv:1904.09708 [cs, stat]},
  language = {en},
  primaryClass = {cs, stat}
}

@article{rusu_pennartz_2019,
  title = {Learning, Memory and Consolidation Mechanisms for Behavioral Control in Hierarchically Organized Cortico-basal Ganglia Systems},
  author = {Rusu, Silviu I. and Pennartz, Cyriel M. A.},
  year = {2019},
  month = oct,
  pages = {hipo.23167},
  issn = {1050-9631, 1098-1063},
  doi = {10.1002/hipo.23167},
  abstract = {This article aims to provide a synthesis on the question how brain structures cooperate to accomplish hierarchically organized behaviors, characterized by low-level, habitual routines nested in larger sequences of planned, goal-directed behavior. The functioning of a connected set of brain structures\textemdash prefrontal cortex, hippocampus, striatum, and dopaminergic mesencephalon\textemdash is reviewed in relation to two important distinctions: (a) goal-directed as opposed to habitual behavior and (b) model-based and model-free learning. Recent evidence indicates that the orbitomedial prefrontal cortices not only subserve goal-directed behavior and model-based learning, but also code the ``landscape'' (task space) of behaviorally relevant variables. While the hippocampus stands out for its role in coding and memorizing world state representations, it is argued to function in model-based learning but is not required for coding of action\textendash outcome contingencies, illustrating that goal-directed behavior is not congruent with model-based learning. While the dorsolateral and dorsomedial striatum largely conform to the dichotomy between habitual versus goal-directed behavior, ventral striatal functions go beyond this distinction. Next, we contextualize findings on coding of reward-prediction errors by ventral tegmental dopamine neurons to suggest a broader role of mesencephalic dopamine cells, viz. in behavioral reactivity and signaling unexpected sensory changes. We hypothesize that goal-directed behavior is hierarchically organized in interconnected cortico-basal ganglia loops, where a limbic-affective prefrontal-ventral striatal loop controls action selection in a dorsomedial prefrontal\textendash striatal loop, which in turn regulates activity in sensorimotor-dorsolateral striatal circuits. This structure for behavioral organization requires alignment with mechanisms for memory formation and consolidation. We propose that frontal corticothalamic circuits form a high-level loop for memory processing that initiates and temporally organizes nested activities in lower-level loops, including the hippocampus and the ripple-associated replay it generates. The evidence on hierarchically organized behavior converges with that on consolidation mechanisms in suggesting a frontal-to-caudal directionality in processing control.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6PDC27J3\\Rusu and Pennartz - 2019 - Learning, memory and consolidation mechanisms for .pdf},
  journal = {Hippocampus},
  language = {en}
}

@article{sacramento_senn_2017,
  title = {Dendritic Error Backpropagation in Deep Cortical Microcircuits},
  author = {Sacramento, Jo{\~a}o and Costa, Rui Ponte and Bengio, Yoshua and Senn, Walter},
  year = {2017},
  month = dec,
  abstract = {Animal behaviour depends on learning to associate sensory stimuli with the desired motor command. Understanding how the brain orchestrates the necessary synaptic modifications across different brain areas has remained a longstanding puzzle. Here, we introduce a multi-area neuronal network model in which synaptic plasticity continuously adapts the network towards a global desired output. In this model synaptic learning is driven by a local dendritic prediction error that arises from a failure to predict the top-down input given the bottom-up activities. Such errors occur at apical dendrites of pyramidal neurons where both long-range excitatory feedback and local inhibitory predictions are integrated. When local inhibition fails to match excitatory feedback an error occurs which triggers plasticity at bottom-up synapses at basal dendrites of the same pyramidal neurons. We demonstrate the learning capabilities of the model in a number of tasks and show that it approximates the classical error backpropagation algorithm. Finally, complementing this cortical circuit with a disinhibitory mechanism enables attention-like stimulus denoising and generation. Our framework makes several experimental predictions on the function of dendritic integration and cortical microcircuits, is consistent with recent observations of cross-area learning, and suggests a biological implementation of deep learning.},
  archivePrefix = {arXiv},
  eprint = {1801.00062},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6N94N862\\Sacramento et al. - 2017 - Dendritic error backpropagation in deep cortical m.pdf},
  journal = {arXiv:1801.00062 [cs, q-bio]},
  language = {en},
  primaryClass = {cs, q-bio}
}

@article{sacramento_senn_2018,
  title = {Dendritic Cortical Microcircuits Approximate the Backpropagation Algorithm},
  author = {Sacramento, Jo{\~a}o and Costa, Rui Ponte and Bengio, Yoshua and Senn, Walter},
  year = {2018},
  pages = {12},
  abstract = {Deep learning has seen remarkable developments over the last years, many of them inspired by neuroscience. However, the main learning mechanism behind these advances \textendash{} error backpropagation \textendash{} appears to be at odds with neurobiology. Here, we introduce a multilayer neuronal network model with simplified dendritic compartments in which error-driven synaptic plasticity adapts the network towards a global desired output. In contrast to previous work our model does not require separate phases and synaptic learning is driven by local dendritic prediction errors continuously in time. Such errors originate at apical dendrites and occur due to a mismatch between predictive input from lateral interneurons and activity from actual top-down feedback. Through the use of simple dendritic compartments and different cell-types our model can represent both error and normal activity within a pyramidal neuron. We demonstrate the learning capabilities of the model in regression and classification tasks, and show analytically that it approximates the error backpropagation algorithm. Moreover, our framework is consistent with recent observations of learning between brain areas and the architecture of cortical microcircuits. Overall, we introduce a novel view of learning on dendritic cortical circuits and on how the brain may solve the long-standing synaptic credit assignment problem.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2MSLLQI9\\Sacramento et al. - Dendritic cortical microcircuits approximate the b.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\TEGVKCBR\\Sacramento et al. - Dendritic cortical microcircuits approximate the b.pdf},
  language = {en}
}

@article{sadaghiani_esposito_2018,
  title = {Lesions to the {{Fronto}}-{{Parietal Network Impact Alpha}}-{{Band Phase Synchrony}} and {{Cognitive Control}}},
  author = {Sadaghiani, Sepideh and Dombert, Pascasie L and L{\o}vstad, Marianne and Funderud, Ingrid and Meling, Torstein R and Endestad, Tor and Knight, Robert T and Solbakk, Anne-Kristin and Esposito, Mark D '},
  year = {2018},
  pages = {1--11},
  doi = {10.1093/cercor/bhy296},
  abstract = {Long-range phase synchrony in the {$\alpha$}-oscillation band (near 10 Hz) has been proposed to facilitate information integration across anatomically segregated regions. Which areas may top-down regulate such cross-regional integration is largely unknown. We previously found that the moment-to-moment strength of high-{$\alpha$} band (10-12 Hz) phase synchrony co-varies with activity in a fronto-parietal (FP) network. This network is critical for adaptive cognitive control functions such as cognitive flexibility required during set-shifting. Using electroencephalography (EEG) in 23 patients with focal frontal lobe lesions (resected tumors), we tested the hypothesis that the FP network is necessary for modulation of high-{$\alpha$} band phase synchrony. Global phase-synchrony was measured using an adaptation of the phase-locking value (PLV) in a sliding window procedure, which allowed for measurement of changes in EEG-based resting-state functional connectivity across time. As hypothesized, the temporal modulation (range and standard deviation) of high-{$\alpha$} phase synchrony was reduced as a function of FP network lesion extent, mostly due to dorsolateral prefrontal cortex (dlPFC) lesions. Furthermore, patients with dlPFC lesions exhibited reduced cognitive flexibility as measured by the Trail-Making Test (set-shifting). Our findings provide evidence that the FP network is necessary for modulatory control of high-{$\alpha$} band long-range phase synchrony, and linked to cognitive flexibility.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4Z9NWEDF\\Sadaghiani et al. - 2018 - Lesions to the Fronto-Parietal Network Impact Alpha-Band Phase Synchrony and Cognitive Control.pdf},
  journal = {Cerebral Cortex},
  keywords = {alpha oscillations,cognitive flexibility,dorsolateral prefrontal cortex,fronto-parietal network,lesion}
}

@article{sadeh_moscovitch_2014,
  title = {How We Forget May Depend on How We Remember},
  author = {Sadeh, Talya and Ozubko, Jason D and Winocur, Gordon and Moscovitch, Morris},
  year = {2014},
  volume = {18},
  pages = {26--36},
  issn = {13646613},
  doi = {10.1016/j.tics.2013.10.008},
  abstract = {Recent developments reveal that memories relying on the hippocampus are relatively resistant to interference, but sensitive to decay. The hippocampus is vital to recollection, a form of memory involving reinstatement of a studied item within its spatial-temporal context. An additional form of memory known as familiarity does not involve contextual reinstatement, but a feeling of acquaintance with the studied items. Familiarity depends more on extrahippocampal structures that do not have the properties promoting resistance to interference. These notions led to the novel hypothesis that the causes of forgetting depend on the memories' nature: memories depending on recollection are more vulnerable to decay than interference, whereas for memories depending on familiarity, the reverse is true. This review provides comprehensive evidence for this hypothesis. ?? 2013 Elsevier Ltd.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GPN37VZQ\\Sadeh et al. - 2014 - How we forget may depend on how we remember.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\RLJLBTJC\\Sadeh et al. - 2014 - How we forget may depend on how we remember.docx},
  journal = {Trends in Cognitive Sciences},
  keywords = {Decay,Familiarity,Forgetting,Hippocampus,Interference,Recollection},
  number = {1},
  pmid = {24246135}
}

@article{sadtler_batista_2014,
  title = {Neural Constraints on Learning},
  author = {Sadtler, Patrick T and Quick, Kristin M and Golub, Matthew D and Chase, Steven M and Ryu, Stephen I and {Tyler-Kabara}, Elizabeth C and Yu, Byron M and Batista, Aaron P},
  year = {2014},
  volume = {512},
  doi = {10.1038/nature13665},
  abstract = {Learning, whether motor, sensory or cognitive, requires networks of neurons to generate new activity patterns. As some behaviours are easier to learn than others 1,2 , we asked if some neural activity patterns are easier to generate than others. Here we investigate whether an existing network constrains the patterns that a subset of its neurons is capable of exhibiting, and if so, what principles define this constraint. We employed a closed-loop intracortical brain-computer interface learning paradigm in which Rhesus macaques (Macaca mulatta) controlled a computer cursor by modulating neural activity patterns in the primary motor cortex. Using the brain-computer interface paradigm , we could specify and alter how neural activity mapped to cursor velocity. At the start of each session, we observed the characteristic activity patterns of the recorded neural population. The activity of a neural population can be represented in a high-dimensional space (termed the neural space), wherein each dimension corresponds to the activity of one neuron. These characteristic activity patterns comprise a low-dimensional subspace (termed the intrinsic manifold) within the neural space. The intrinsic manifold presumably reflects constraints imposed by the underlying neural circuitry. Here we show that the animals could readily learn to proficiently control the cursor using neural activity patterns that were within the intrinsic manifold. However, animals were less able to learn to proficiently control the cursor using activity patterns that were outside of the intrinsic mani-fold. These results suggest that the existing structure of a network can shape learning. On a timescale of hours, it seems to be difficult to learn to generate neural activity patterns that are not consistent with the existing network structure. These findings offer a network-level explanation for the observation that we are more readily able to learn new skills when they are related to the skills that we already possess 3,4. Some behaviours are easier to learn than others 1-4. We hypothesized that the ease or difficulty with which an animal can learn a new behaviour is determined by the current properties of the networks of neurons governing the behaviour. We tested this hypothesis in the context of brain-computer interface (BCI) learning. In a BCI paradigm, the user controls a cursor on a computer screen by generating activity patterns across a population of neurons. A BCI offers advantages for studying learning because we can observe all of the neurons that directly control an action, and we can fully specify the mapping from neural activity to action. This allowed us to define which activity patterns would lead to task success and to test whether subjects were capable of generating them. Previous studies have shown that BCI learning can be remarkably extensive 5-10},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2HVUL2L2\\Sadtler et al. - 2014 - Neural constraints on learning.pdf},
  journal = {Nature}
}

@article{saffran_newport_1996,
  title = {Statistical {{Learning}} by 8-{{Month}}-{{Old Infants}}},
  author = {Saffran, Jenny R. and Aslin, Richard N. and Newport, Elissa L.},
  year = {1996},
  volume = {274},
  pages = {1926--1928},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HB2WPFU9\\Saffran et al. - 1996 - Statistical Learning by 8-Month-Old Infants.pdf},
  journal = {Science, New Series},
  language = {en},
  number = {5294}
}

@article{sagarin_lee_2014,
  title = {An {{Ethical Approach}} to {{Peeking}} at {{Data}}.},
  author = {Sagarin, Brad J and Ambler, James K and Lee, Ellen M},
  year = {2014},
  volume = {9},
  pages = {293--304},
  issn = {1745-6924},
  doi = {10.1177/1745691614528214},
  abstract = {When data analyses produce encouraging but nonsignificant results, researchers often respond by collecting more data. This may transform a disappointing dataset into a publishable study, but it does so at the cost of increasing the Type I error rate. How big of a problem is this, and what can we do about it? To answer the first question, we estimate the Type I error inflation based on the initial sample size, the number of participants used to augment the dataset, the critical value for determining significance (typically .05), and the maximum p value within the initial sample such that the dataset would be augmented. With one round of augmentation, Type I error inflation maximizes at .0975 with typical values from .0564 to .0883. To answer the second question, we review methods of adjusting the critical value to allow augmentation while maintaining p \{\textbackslash textless\} .05, but we note that such methods must be applied a priori. For the common occurrence of post-hoc dataset augmentation, we develop a new statistic, paugmented , that represents the magnitude of the resulting Type I error inflation. We argue that the disclosure of post-hoc dataset augmentation via paugmented elevates such augmentation from a questionable research practice to an ethical research decision.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZWT3ZTFE\\Sagarin, Ambler, Lee - 2014 - An Ethical Approach to Peeking at Data.pdf},
  journal = {Perspectives on psychological science : a journal of the Association for Psychological Science},
  keywords = {ethics,god loves the,p,p values,research methods,rosnow and rosenthal,significance testing,surely},
  number = {3},
  pmid = {26173265}
}

@article{saggar_saron_2012,
  title = {Intensive Training Induces Longitudinal Changes in Meditation State-Related {{EEG}} Oscillatory Activity.},
  author = {Saggar, Manish and King, Brandon G and Zanesco, Anthony P and a Maclean, Katherine and Aichele, Stephen R and Jacobs, Tonya L and a Bridwell, David and Shaver, Phillip R and Rosenberg, Erika L and Sahdra, Baljinder K and Ferrer, Emilio and Tang, Akaysha C and Mangun, George R and Wallace, B Alan and Miikkulainen, Risto and Saron, Clifford D},
  year = {2012},
  month = jan,
  volume = {6},
  pages = {256},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2012.00256},
  abstract = {The capacity to focus one's attention for an extended period of time can be increased through training in contemplative practices. However, the cognitive processes engaged during meditation that support trait changes in cognition are not well characterized. We conducted a longitudinal wait-list controlled study of intensive meditation training. Retreat participants practiced focused attention (FA) meditation techniques for three months during an initial retreat. Wait-list participants later undertook formally identical training during a second retreat. Dense-array scalp-recorded electroencephalogram (EEG) data were collected during 6 min of mindfulness of breathing meditation at three assessment points during each retreat. Second-order blind source separation, along with a novel semi-automatic artifact removal tool (SMART), was used for data preprocessing. We observed replicable reductions in meditative state-related beta-band power bilaterally over anteriocentral and posterior scalp regions. In addition, individual alpha frequency (IAF) decreased across both retreats and in direct relation to the amount of meditative practice. These findings provide evidence for replicable longitudinal changes in brain oscillatory activity during meditation and increase our understanding of the cortical processes engaged during meditation that may support long-term improvements in cognition.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Y5T7WXYG\\Saggar et al. - 2012 - Intensive training induces longitudinal changes in meditation state-related EEG oscillatory activity.pdf},
  journal = {Frontiers in human neuroscience},
  keywords = {attention,beta,depends critically on the,eeg,goal-directed behavior,individual,individual alpha frequency,individuals vary considerably in,manage,meditation,sustain attention,the successful execution of,their ability to flexibly,training},
  number = {September},
  pmid = {22973218}
}

@article{saito_sadoshima_2016,
  title = {{{HHS Public Access}}},
  author = {Saito, Toshiro and Sadoshima, Junichi},
  year = {2016},
  volume = {116},
  pages = {1477--1490},
  issn = {1527-5418},
  doi = {10.1161/CIRCRESAHA.116.303790.The},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GDDCYZFD\\Saito, Sadoshima - 2016 - HHS Public Access.pdf},
  keywords = {autophagy,mitophagy,parkin,pink1},
  number = {8},
  pmid = {24655651}
}

@article{sajikumar_frey_2004,
  title = {Late-Associativity, Synaptic Tagging, and the Role of Dopamine during {{LTP}} and {{LTD}}},
  author = {Sajikumar, Sreedharan and Frey, Julietta U},
  year = {2004},
  volume = {82},
  pages = {12--25},
  issn = {10747427},
  doi = {10.1016/j.nlm.2004.03.003},
  abstract = {Protein synthesis-dependent, synapse input-specific late phases of long-term potentiation (LTP) and depression (LTD) may underlie memory formation at the cellular level. Recently, it was described that the induction of LTP can mark a specifically activated synapse by a synaptic tag to capture synapse non-specific plasticity-related proteins (PRPs) and thus maintaining input-specific LTP for prolonged periods. Here we show in rat hippocampal slices in vitro, that the induction of protein synthesis-dependent late-LTD is also characterized by synaptic tagging and that heterosynaptic induction of either LTD or LTP on two sets of independent synaptic inputs S1 and S2 can lead to late-associative interactions: early-LTD in S2 was transformed into a late-LTD, if late-LTP was induced in S1. The synthesis of process-independent PRPs by late-LTP in S1 was sufficient to transform early- into late-LTD in S2 when process-specific synaptic tags were set. We name this new associative property of cellular information processing 'cross-tagging.' \textcopyright{} 2004 Elsevier Inc. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GS7MLEPI\\Sajikumar, Frey - 2004 - Late-associativity, synaptic tagging, and the role of dopamine during LTP and LTD.pdf},
  journal = {Neurobiology of Learning and Memory},
  keywords = {Cross-tagging,Heterosynaptic late-associativity,Long-term depression,Long-term potentiation,Protein synthesis,Synaptic tagging},
  number = {1},
  pmid = {15183167}
}

@article{salamone_mirolli_2016,
  title = {{{GoalDirected Behavior}} and {{Instrumental Devaluation}}: {{A Neural SystemLevel Computational Model}}},
  author = {Salamone, John D and Ito, Etsuro and Kim, Jee Hyun and Baldassarre, Gianluca and Mannella, Francesco and Mirolli, Marco},
  year = {2016},
  volume = {10},
  pages = {1813389181},
  issn = {1662-5153},
  doi = {10.3389/fnbeh.2016.00181},
  abstract = {Devaluation is the key experimental paradigm used to demonstrate the presence of instrumental behaviors guided by goals in mammals. We propose a neural systemlevel computational model to address the question of which brain mechanisms allow the current value of rewards to control instrumental actions. The model pivots on and shows the computational soundness of the hypothesis for which the internal representation of instrumental manipulanda (e.g., levers) activate the representation of rewards (or " actionoutcomes " , e.g., foods) while attributing to them a value which depends on the current internal state of the animal (e.g., satiation for some but not all foods). The model also proposes an initial hypothesis of the integrated system of key brain components supporting this process and allowing the recalled outcomes to bias action selection: (a) the subsystem formed by the basolateral amygdala and insular cortex acquiring the manipulandaoutcomes associations and attributing the current value to the outcomes; (b) three basal gangliacortical loops selecting respectively goals, associative sensory representations, and actions; (c) the corticocortical and striatonigrostriatal neural pathways supporting the selection, and selection learning, of actions based on habits and goals. The model reproduces and explains the results of several devaluation experiments carried out with control rats and rats with preand posttraining lesions of the basolateral amygdala, the nucleus accumbens core, the prelimbic cortex, and the dorsomedial striatum. The results support the soundness of the hypotheses of the model and show its capacity to integrate, at the systemlevel, the operations of the key brain structures underlying devaluation. Based on its hypotheses and predictions, the model also represents an operational framework to support the design and analysis of new experiments on the motivational aspects of goaldirected behavior. Keywords: computational systemlevel model based on leaky firingrate neurons, goaldirected and habitual processes, Pavlovian processes, learning, devaluation behavioral experiments with rats, brain system based on basolateralamygdala and nucleusaccumbens and multiple basalganglia thalamo cortex loops, instrumental manipulanda and cues, reward satiety and value},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CN76I9QH\\Salamone et al. - 2016 - GoalDirected Behavior and Instrumental Devaluation A Neural SystemLevel Computational Model.pdf},
  journal = {Frontiers in Behavioral Neuroscience Front. Behav. Neurosci},
  keywords = {brain system based on,computational system-level model based,computational system-level model based on leaky fi,devaluation behavioral experiments with,goal-directed and habitual,instrumental,learning,loops,manipulanda and cues,multiple basal-ganglia thalamo cortex,on leaky firing-rate neurons,pavlovian processes,processes,rats,reward satiety and value},
  number = {10},
  pmid = {27803652}
}

@incollection{salovey_salovey_2000,
  title = {Results {{That Get Results}}},
  booktitle = {Guide to Publishing in Psychology Journals},
  author = {Salovey, Peter},
  year = {2000},
  pages = {121--132},
  abstract = {Many psychologists think the Results section is the driest part of any journal article, that the idea in this portion of the manuscript is simply to present the data and move on For students reading journal articles as class assignments, the Results section is often the one skipped. It is considered boring at best, inscrutable at worst, and whatever one needs to know is slirnmarized in the opening paragraphs of the Discussion anyway It does not have to be this way, however In this chapter; I argue that there are techniques for writing a Results section that at least make it readable, if not thrilling.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SWXUXWFE\\Salovey - 2000 - Results That Get Results.pdf}
}

@article{salvucci_anderson_2001,
  title = {Integrating Analogical Mapping and General Problem Solving: {{The}} Path-Mapping Theory},
  author = {Salvucci, Dario D. and Anderson, John R.},
  year = {2001},
  volume = {25},
  pages = {67--110},
  issn = {03640213},
  doi = {10.1016/S0364-0213(00)00035-5},
  abstract = {This article describes the path-mapping theory of how humans integrate analogical mapping and general problem solving. The theory posits that humans represent analogs with declarative roles, map analogs by lower-level retrieval of analogous role paths, and coordinate mappings with higher-level organizational knowledge. Implemented in the ACT-R cognitive architecture, the path-mapping theory enables models of analogical mapping behavior to incorporate and interface with other problem-solving knowledge. Path-mapping models thus can include task-specific skills such as encoding analogs or generating responses, and can make behavioral predictions at the level of real-world metrics such as latency or correctness. We show that the path-mapping theory can successfully account for the major phenomena addressed by previous theories of analogy. We also describe a path-mapping model that can account for subjects' incremental eye-movement and typing behavior in a story-mapping task. We discuss extensions and implications of this work to other areas of analogy and problem-solving research. \textcopyright{} 2001 Cognitive Science Society, Inc. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HDCEMNIK\\Salvucci, Anderson - 2001 - Integrating analogical mapping and general problem solving The path-mapping theory.pdf},
  journal = {Cognitive Science},
  number = {1}
}

@article{sanders_gershman_2020,
  title = {Hippocampal Remapping as Hidden State Inference},
  author = {Sanders, Honi and Wilson, Matthew A and Gershman, Samuel J},
  year = {2020},
  month = jun,
  volume = {9},
  pages = {e51140},
  issn = {2050-084X},
  doi = {10.7554/eLife.51140},
  abstract = {Cells in the hippocampus tuned to spatial location (place cells) typically change their tuning when an animal changes context, a phenomenon known as remapping. A fundamental challenge to understanding remapping is the fact that what counts as a ``context change'' has never been precisely defined. Furthermore, different remapping phenomena have been classified on the basis of how much the tuning changes after different types and degrees of context change, but the relationship between these variables is not clear. We address these ambiguities by formalizing remapping in terms of hidden state inference. According to this view, remapping does not directly reflect objective, observable properties of the environment, but rather subjective beliefs about the hidden state of the environment. We show how the hidden state framework can resolve a number of puzzles about the nature of remapping.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AD3UUJHM\\Sanders et al. - 2020 - Hippocampal remapping as hidden state inference.pdf},
  journal = {eLife},
  language = {en}
}

@article{sanders_lisman_2018,
  title = {Temporal Coding and Rate Remapping: {{Representation}} of Non-Spatial Information in the Hippocampus},
  author = {Sanders, Honi and Ji, Daoyun and Sasaki, Takuya and Leutgeb, Jill K and Wilson, Matthew A and Lisman, John E},
  year = {2018},
  issn = {10509631},
  doi = {10.1002/hipo.23020},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GRWNWBR8\\Sanders et al. - 2018 - Temporal coding and rate remapping Representation of non-spatial information in the hippocampus.pdf},
  journal = {Hippocampus},
  keywords = {corresponding author,honi sanders 43 vassar,overdispersion,phase precession,place cells,room 46-5233,street,theta rhythm,theta sequence}
}

@article{sanh_ruder_2018,
  title = {A {{Hierarchical Multi}}-Task {{Approach}} for {{Learning Embeddings}} from {{Semantic Tasks}}},
  author = {Sanh, Victor and Wolf, Thomas and Ruder, Sebastian},
  year = {2018},
  month = nov,
  abstract = {Much effort has been devoted to evaluate whether multi-task learning can be leveraged to learn rich representations that can be used in various Natural Language Processing (NLP) down-stream applications. However, there is still a lack of understanding of the settings in which multi-task learning has a significant effect. In this work, we introduce a hierarchical model trained in a multi-task learning setup on a set of carefully selected semantic tasks. The model is trained in a hierarchical fashion to introduce an inductive bias by supervising a set of low level tasks at the bottom layers of the model and more complex tasks at the top layers of the model. This model achieves state-of-the-art results on a number of tasks, namely Named Entity Recognition, Entity Mention Detection and Relation Extraction without hand-engineered features or external NLP tools like syntactic parsers. The hierarchical training supervision induces a set of shared semantic representations at lower layers of the model. We show that as we move from the bottom to the top layers of the model, the hidden states of the layers tend to represent more complex semantic information.},
  archivePrefix = {arXiv},
  eprint = {1811.06031},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Z7BW59FZ\\sanh_et_al_2018_a_hierarchical_multi-task_approach_for_learning_embeddings_from_semantic_tasks.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\JZS7ZA8C\\1811.html},
  journal = {arXiv:1811.06031 [cs]},
  primaryClass = {cs}
}

@article{santoro_lillicrap_2018,
  title = {Relational Recurrent Neural Networks},
  author = {Santoro, Adam and Faulkner, Ryan and Raposo, David and Rae, Jack and Chrzanowski, Mike and Weber, Th{\'e}ophane and Wierstra, Daan and Vinyals, Oriol and Pascanu, Razvan and Lillicrap, Timothy},
  year = {2018},
  abstract = {Memory-based neural networks model temporal data by leveraging an ability to remember information for long periods. It is unclear, however, whether they also have an ability to perform complex relational reasoning with the information they remember. Here, we first confirm our intuitions that standard memory architectures may struggle at tasks that heavily involve an understanding of the ways in which entities are connected \textendash{} i.e., tasks involving relational reasoning. We then improve upon these deficits by using a new memory module \textendash{} a Relational Memory Core (RMC) \textendash{} which employs multi-head dot product attention to allow memories to interact. Finally, we test the RMC on a suite of tasks that may profit from more capable relational reasoning across sequential information, and show large gains in RL domains (e.g. Mini PacMan), program evaluation, and language modeling, achieving state-of-the-art results on the WikiText-103, Project Gutenberg, and GigaWord datasets.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7HZ3R8PS\\Santoro et al. - Unknown - Relational recurrent neural networks.pdf}
}

@article{santos-pata_verschure_2019,
  title = {Modulating Grid Cell Scale and Intrinsic Frequencies via Slow High-Threshold Conductances: {{A}} Simplified Model},
  shorttitle = {Modulating Grid Cell Scale and Intrinsic Frequencies via Slow High-Threshold Conductances},
  author = {{Santos-Pata}, Diogo and Zucca, Riccardo and {L{\'o}pez-Carral}, H{\'e}ctor and Verschure, Paul F.M.J.},
  year = {2019},
  month = nov,
  volume = {119},
  pages = {66--73},
  issn = {08936080},
  doi = {10.1016/j.neunet.2019.06.011},
  abstract = {Grid cells in the medial entorhinal cortex (MEC) have known spatial periodic firing fields which provide a metric for the representation of self-location and path planning. The hexagonal tessellation pattern of grid cells scales up progressively along the MEC's layer II dorsal-to-ventral axis. This scaling gradient has been hypothesized to originate either from inter-population synaptic dynamics as postulated by attractor networks, or from projected theta frequency waves to different axis levels, as in oscillatory models. Alternatively, cellular dynamics and specifically slow high-threshold conductances have been proposed to have an impact on the grid cell scale. To test the hypothesis that intrinsic hyperpolarization-activated cation currents account for both the scaled gradient and the oscillatory frequencies observed along the dorsal-to-ventral axis, we have modeled and analyzed data from a population of grid cells simulated with spiking neurons interacting through low-dimensional attractor dynamics. We observed that the intrinsic neuronal membrane properties of simulated cells were sufficient to induce an increase in grid scale and potentiate differences in the membrane potential oscillatory frequency. Overall, our results suggest that the after-spike dynamics of cation currents may play a major role in determining the grid cells' scale and that oscillatory frequencies are a consequence of intrinsic cellular properties that are specific to different levels of the dorsal-to-ventral axis in the MEC layer II.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7GNK2EIJ\\Santos-Pata et al. - 2019 - Modulating grid cell scale and intrinsic frequenci.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\EEBDKMU6\\Santos-Pata et al. - 2019 - Modulating grid cell scale and intrinsic frequenci.pdf},
  journal = {Neural Networks},
  language = {en}
}

@article{sarafyazd_jazayeri_2019,
  title = {Hierarchical Reasoning by Neural Circuits in the Frontal Cortex},
  author = {Sarafyazd, Morteza and Jazayeri, Mehrdad},
  year = {2019},
  month = may,
  volume = {364},
  pages = {eaav8911},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aav8911},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QIVTVYEK\\Sarafyazd and Jazayeri - 2019 - Hierarchical reasoning by neural circuits in the f.pdf},
  journal = {Science},
  language = {en},
  number = {6441}
}

@article{sardi_kanter_2017,
  title = {New {{Types}} of {{Experiments Reveal}} That a {{Neuron Functions}} as {{Multiple Independent Threshold Units}}},
  author = {Sardi, Shira and Vardi, Roni and Sheinin, Anton and Goldental, Amir and Kanter, Ido},
  year = {2017},
  volume = {7},
  pages = {18036},
  issn = {20452322},
  doi = {10.1038/s41598-017-18363-1},
  abstract = {Neurons are the computational elements that compose the brain and their fundamental principles of activity are known for decades. According to the long-lasting computational scheme, each neuron sums the incoming electrical signals via its dendrites and when the membrane potential reaches a certain threshold the neuron typically generates a spike to its axon. Here we present three types of experiments, using neuronal cultures, indicating that each neuron functions as a collection of independent threshold units. The neuron is anisotropically activated following the origin of the arriving signals to the membrane, via its dendritic trees. The first type of experiments demonstrates that a single neuron's spike waveform typically varies as a function of the stimulation location. The second type reveals that spatial summation is absent for extracellular stimulations from different directions. The third type indicates that spatial summation and subtraction are not achieved when combining intra- and extra- cellular stimulations, as well as for nonlocal time interference, where the precise timings of the stimulations are irrelevant. Results call to re-examine neuronal functionalities beyond the traditional framework, and the advanced computational capabilities and dynamical properties of such complex systems.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LSY2JI2N\\Sardi et al. - 2017 - New Types of Experiments Reveal that a Neuron Functions as Multiple Independent Threshold Units OPEN.pdf},
  journal = {Scientific Reports},
  number = {1},
  pmid = {29269849}
}

@article{sarel_ulanovsky_2017,
  title = {Vectorial Representation of Spatial Goals in the Hippocampus of Bats},
  author = {Sarel, Ayelet and Finkelstein, Arseny and Las, Liora and Ulanovsky, Nachum},
  year = {2017},
  volume = {355},
  issn = {10959203},
  doi = {10.1126/science.aak9589},
  abstract = {To navigate, animals need to represent not only their own position and orientation, but also the location of their goal. Neural representations of an animal's own position and orientation have been extensively studied. However, it is unknown how navigational goals are encoded in the brain.We recorded from hippocampal CA1 neurons of bats flying in complex trajectories toward a spatial goal.We discovered a subpopulation of neurons with angular tuning to the goal direction. Many of these neurons were tuned to an occluded goal, suggesting that goal-direction representation is memory-based.We also found cells that encoded the distance to the goal, often in conjunction with goal direction. The goal- direction and goal-distance signals make up a vectorial representation of spatial goals, suggesting a previously unrecognized neuronal mechanism for goal-directed navigation. N},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\F7VKP7C8\\Sarel et al. - 2017 - Vectorial representation of spatial goals in the hippocampus of bats.pdf},
  journal = {Science},
  number = {6321},
  pmid = {28082589}
}

@article{sarkar_howard_2019,
  title = {Scale-Dependent {{Relationships}} in {{Natural Language}}},
  author = {Sarkar, Aakash and Howard, Marc},
  year = {2019},
  month = dec,
  abstract = {Natural language exhibits statistical dependencies at a wide range of scales. For instance, the mutual information between words in natural language decays like a power law with the temporal lag between them. However, many statistical learning models applied to language impose a sampling scale while extracting statistical structure. For instance, Word2Vec constructs a vector embedding that maximizes the prediction between a target word and the context words that appear nearby in the corpus. The size of the context is chosen by the user and defines a strong scale; relationships over much larger temporal scales would be invisible to the algorithm. This paper examines the family of Word2Vec embeddings generated while systematically manipulating the sampling scale used to define the context around each word. The primary result is that different linguistic relationships are preferentially encoded at different scales. Different scales emphasize different syntactic and semantic relations between words.Moreover, the neighborhoods of a given word in the embeddings change significantly depending on the scale. These results suggest that any individual scale can only identify a subset of the meaningful relationships a word might have, and point toward the importance of developing scale-free models of semantic meaning.},
  archivePrefix = {arXiv},
  eprint = {1912.07506},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3MET9X6A\\Sarkar and Howard - 2019 - Scale-dependent Relationships in Natural Language.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\II3S7PEU\\1912.html},
  journal = {arXiv:1912.07506 [cs]},
  primaryClass = {cs}
}

@article{sarnthein_vonstein_1998,
  title = {Synchronization between Prefrontal and Posterior Association Cortex during Human Working Memory},
  author = {Sarnthein, J and Petsche, H and Rappelsberger, P and Shaw, G L and {von Stein}, A.},
  year = {1998},
  volume = {95},
  pages = {7092--7096},
  issn = {0027-8424},
  doi = {10.1073/pnas.95.12.7092},
  abstract = {We measured coherence between the electroencephalogram at different scalp sites while human subjects performed delayed response tasks. The tasks required the retention of either verbalizable strings of characters or abstract line drawings. In both types of tasks, a significant enhancement in coherence in the \$\th eta\$ range (47 Hz) was found between prefrontal and posterior electrodes during 4-s retention intervals. During 6-s perception intervals, far fewer increases in \$\th eta\$ coherence were found. Also in other frequency bands, coherence increased; however, the patterns of enhancement made a relevance for working memory processes seem unlikely. Our results suggest that working memory involves synchronization between prefrontal and posterior association cortex by phase-locked, low frequency (47 Hz) brain activity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5SEX6AAJ\\Sarnthein et al. - 1998 - Synchronization between prefrontal and posterior association cortex during human working memory.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  number = {12},
  pmid = {9618544}
}

@article{sato_toichi_2016,
  title = {Rapid Gamma Oscillations in the Inferior Occipital Gyrus in Response to Eyes},
  author = {Sato, Wataru and Kochiyama, Takanori and Uono, Shota and Matsuda, Kazumi and Usui, Keiko and Usui, Naotaka and Inoue, Yushi and Toichi, Motomi},
  year = {2016},
  volume = {6},
  issn = {20452322},
  doi = {10.1038/srep36321},
  abstract = {Eyes are an indispensable communication medium for human social interactions. Although previous neuroscientific evidence suggests the activation of the inferior occipital gyrus (IOG) during eye processing, the temporal profile of this activation remains unclear. To investigate this issue, we analyzed intracranial electroencephalograms of the IOG during the presentation of eyes and mosaics, in either averted or straight directions. Time-frequency statistical parametric mapping analyses revealed greater gamma-band activation in the right IOG beginning at 114 ms in response to eyes relative to mosaics, irrespective of their averted or straight direction. These results suggest that gamma oscillations in the right IOG are involved in the early stages of eye processing, such as eye detection.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\A6MYXCRU\\Sato et al. - 2016 - Rapid gamma oscillations in the inferior occipital gyrus in response to eyes.pdf},
  journal = {Scientific Reports},
  pmid = {27805017}
}

@article{saunders_kozma_2019,
  title = {Locally Connected Spiking Neural Networks for Unsupervised Feature Learning},
  author = {Saunders, Daniel J. and Patel, Devdhar and Hazan, Hananel and Siegelmann, Hava T. and Kozma, Robert},
  year = {2019},
  month = nov,
  volume = {119},
  pages = {332--340},
  issn = {08936080},
  doi = {10.1016/j.neunet.2019.08.016},
  abstract = {In recent years, spiking neural networks (SNNs) have demonstrated great success in completing various machine learning tasks. We introduce a method for learning image features with locally connected layers in SNNs using a spike-timing-dependent plasticity (STDP) rule. In our approach, sub-networks compete via inhibitory interactions to learn features from different locations of the input space. These locally-connected SNNs (LC-SNNs) manifest key topological features of the spatial interaction of biological neurons. We explore a biologically inspired n-gram classification approach allowing parallel processing over various patches of the image space. We report the classification accuracy of simple two-layer LC-SNNs on two image datasets, which respectively match state-of-art performance and are the first results to date. LC-SNNs have the advantage of fast convergence to a dataset representation, and they require fewer learnable parameters than other SNN approaches with unsupervised learning. Robustness tests demonstrate that LC-SNNs exhibit graceful degradation of performance despite the random deletion of large numbers of synapses and neurons. Our results have been obtained using the BindsNET library, which allows efficient machine learning implementations of spiking neural networks.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CJ62HDJA\\Saunders et al. - 2019 - Locally connected spiking neural networks for unsu.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\NFPXIYAQ\\Saunders et al. - 2019 - Locally connected spiking neural networks for unsu.pdf},
  journal = {Neural Networks},
  language = {en}
}

@article{sauseng_birbaumer_2005,
  title = {A Shift of Visual Spatial Attention Is Selectively Associated with Human {{EEG}} Alpha Activity},
  author = {Sauseng, P. and Klimesch, W. and Stadler, W. and Schabus, M. and Doppelmayr, M. and Hanslmayr, S. and Gruber, W. R. and Birbaumer, N.},
  year = {2005},
  volume = {22},
  pages = {2917--2926},
  issn = {0953816X},
  doi = {10.1111/j.1460-9568.2005.04482.x},
  abstract = {Abstract Event-related potentials and ongoing oscillatory electroencephalogram (EEG) activity were measured while subjects performed a cued visual spatial attention task. They were instructed to shift their attention to either the left or right visual hemifield according to a cue, which could be valid or invalid. Thereafter, a peripheral target had to be evaluated. At posterior parietal brain areas early components of the event-related potential (P1 and N1) were higher when the cue had been valid compared with invalid. An anticipatory attention effect was found in EEG alpha magnitude at parieto-occipital electrode sites. Starting 200 ms before target onset alpha amplitudes were significantly stronger suppressed at sites contralateral to the attended visual hemifield than ipsilateral to it. In addition, phase coupling between prefrontal and posterior parietal electrode sites was calculated. It was found that prefrontal cortex shows stronger phase coupling with posterior sites that are contralateral to the attended hemifield than ipsilateral sites. The results suggest that a shift of attention selectively modulates excitability of the contralateral posterior parietal cortex and that this posterior modulation of alpha activity is controlled by prefrontal regions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UWHXS5MC\\Sauseng et al. - 2005 - A shift of visual spatial attention is selectively associated with human EEG alpha activity.pdf},
  journal = {European Journal of Neuroscience},
  keywords = {Directed attention,Event-related potentials,Oscillations,Phase coherence,Posterior parietal cortex},
  number = {11},
  pmid = {16324126}
}

@article{savin_deneve_2014,
  title = {Spatio-Temporal {{Representations}} of {{Uncertainty}} in {{Spiking Neural Networks}}},
  author = {Savin, Cristina and Den{\`e}ve, Sophie},
  year = {2014},
  pages = {9},
  abstract = {It has been long argued that, because of inherent ambiguity and noise, the brain needs to represent uncertainty in the form of probability distributions. The neural encoding of such distributions remains however highly controversial. Here we present a novel circuit model for representing multidimensional real-valued distributions using a spike based spatio-temporal code. Our model combines the computational advantages of the currently competing models for probabilistic codes and exhibits realistic neural responses along a variety of classic measures. Furthermore, the model highlights the challenges associated with interpreting neural activity in relation to behavioral uncertainty and points to alternative populationlevel approaches for the experimental validation of distributed representations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5RMH7YVU\\Savin and Denève - Spatio-temporal Representations of Uncertainty in .pdf},
  language = {en}
}

@unpublished{savinov_gelly_2018,
  title = {Episodic {{Curiousity Through Reachability}}},
  author = {Savinov, Nikolay and Raichuk, Anton and Marinier, Rapha{\"e}l and Vincent, Damien and Pollefeys, Marc and Lillicrap, Timothy and Gelly, Sylvain},
  year = {2018},
  abstract = {Rewards are sparse in the real world and most today's reinforcement learning algorithms struggle with such sparsity. One solution to this problem is to allow the agent to create rewards for itself-thus making rewards dense and more suitable for learning. In particular, inspired by curious behaviour in animals, observing something novel could be rewarded with a bonus. Such bonus is summed up with the real task reward-making it possible for RL algorithms to learn from the combined reward. We propose a new curiosity method which uses episodic memory to form the novelty bonus. To determine the bonus, the current observation is compared with the observations in memory. Crucially, the comparison is done based on how many environment steps it takes to reach the current observation from those in memory-which incorporates rich information about environment dynamics. This allows us to overcome the known "couch-potato" issues of prior work-when the agent finds a way to instantly gratify itself by exploiting actions which lead to unpredictable consequences. We test our approach in visually rich 3D environments in VizDoom and DMLab. In VizDoom, our agent learns to successfully navigate to a distant goal at least 2 times faster than the state-of-the-art curiosity method ICM. In DMLab, our agent generalizes well to new procedurally generated levels of the game-reaching the goal at least 2 times more frequently than ICM on test mazes with very sparse reward.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VWQJDJZ5\\Savinov et al. - Unknown - EPISODIC CURIOSITY THROUGH REACHABILITY.pdf}
}

@article{saxe_ganguli_2013,
  title = {Exact Solutions to the Nonlinear Dynamics of Learning in Deep Linear Neural Networks},
  author = {Saxe, Andrew M and McClelland, James L and Ganguli, Surya},
  year = {2013},
  pages = {1--9},
  abstract = {Despite the widespread practical success of deep learning methods, our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse. We attempt to bridge the gap between the theory and practice of deep learning by systematically analyzing learning dynamics for the restricted case of deep linear neural networks. Despite the linearity of their input-output map, such networks have nonlinear gradient descent dynamics on weights that change with the addition of each new hidden layer. We show that deep linear networks exhibit nonlinear learning phenomena similar to those seen in simulations of nonlinear networks, including long plateaus followed by rapid transitions to lower error solutions, and faster convergence from greedy unsupervised pretraining initial conditions than from random initial conditions. We provide an analytical description of these phenomena by finding new exact solutions to the nonlinear dynamics of deep learning. Our theoretical analysis also reveals the surprising finding that as the depth of a network approaches infinity, learning speed can nevertheless remain finite: for a special class of initial conditions on the weights, very deep networks incur only a finite, depth independent, delay in learning speed relative to shallow networks. We show that, under certain conditions on the training data, unsupervised pretraining can find this special class of initial conditions, while scaled random Gaussian initializations cannot. We further exhibit a new class of random orthogonal initial conditions on weights that, like unsupervised pre-training, enjoys depth independent learning times. We further show that these initial conditions also lead to faithful propagation of gradients even in deep nonlinear networks, as long as they operate in a special regime known as the edge of chaos.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WKZEZRJ6\\Saxe, McClelland, Ganguli - 2013 - Exact solutions to the nonlinear dynamics of learning in deep linear neural networks.pdf},
  journal = {Advances in Neural Information Processing Systems}
}

@techreport{saxe_ganguli_2018,
  title = {A Mathematical Theory of Semantic Development in Deep Neural Networks},
  author = {Saxe, Andrew M and Mcclelland, James L and Ganguli, Surya},
  year = {2018},
  abstract = {An extensive body of empirical research has revealed remarkable regularities in the acquisition, organization, deployment, and neu-ral representation of human semantic knowledge, thereby raising a fundamental conceptual question: what are the theoretical principles governing the ability of neural networks to acquire, organize , and deploy abstract knowledge by integrating across many individual experiences? We address this question by mathematically analyzing the nonlinear dynamics of learning in deep linear networks. We find exact solutions to this learning dynamics that yield a conceptual explanation for the prevalence of many disparate phenomena in semantic cognition, including the hierarchical differentiation of concepts through rapid developmental transitions, the ubiquity of semantic illusions between such transitions , the emergence of item typicality and category coherence as factors controlling the speed of semantic processing, changing patterns of inductive projection over development, and the conservation of semantic similarity in neural representations across species. Thus, surprisingly, our simple neural model qualitatively recapitulates many diverse regularities underlying semantic development , while providing analytic insight into how the statistical structure of an environment can interact with nonlinear deep learning dynamics to give rise to these regularities. semantic cognition | neural networks | hierarchical generative models Abbreviations: SVD, singular value decomposition H uman cognition relies on a rich reservoir of semantic knowledge enabling us to organize and reason about our complex sensory world [1-4]. This semantic knowledge allows us to answer basic questions from memory (i.e. "Do birds have feathers?"), and relies fundamentally on neural mechanisms that can organize individual items, or entities (i.e. Canary, Robin) into higher order conceptual categories (i.e. Birds) that include items with similar features, or properties. This knowledge of individual entities and their conceptual groupings into categories or other ontologies is not present in infancy, but develops during childhood [1, 5], and in adults, it powerfully guides the deployment of appropriate inductive generalizations. The acquisition, organization, deployment, and neural representation of semantic knowledge has been intensively studied, yielding many well-documented empirical phenomena. For example, during acquisition, broader categorical distinctions are generally learned before finer-grained distinctions [1, 5], and long periods of relative sta-sis can be followed by abrupt conceptual reorganization [6, 7]. Intriguingly , during these periods of developmental stasis, children can strongly believe illusory, incorrect facts about the world [2]. Also, many psychophysical studies of performance in semantic tasks have revealed empirical regularities governing the organization of semantic knowledge. In particular, category membership is a graded quantity, with some items being more or less typical members of a category (i.e. a sparrow is a more typical bird than a penguin). The notion of item typicality is both highly reproducible across individuals [8, 9] and correlates with performance on a diversity of semantic tasks [10-14]. Moreover, certain categories themselves are thought to be highly coherent (i.e. the set of things that are Dogs), in contrast to less coherent categories (i.e. the set of things that are Blue). More coherent categories play a privileged role in the organization of our semantic knowledge; coherent categories are the ones that are most easily learned and represented [8, 15, 16]. Also, the organization of semantic knowledge powerfully guides its deployment in novel situations, where one must make inductive generalizations about novel items and properties [2, 3]. Indeed, studies of children reveal that their inductive generalizations systematically change over development, often becoming more specific with age [2, 3, 17-19]. Finally, recent neuroscientific studies have begun to shed light on the organization of semantic knowledge in the brain. The method of representational similarity analysis [20,21] has revealed that the similarity structure of neural population activity patterns in high level cortical areas often reflect the semantic similarity structure of stimuli , for instance by differentiating inanimate objects from animate ones [22-26]. And strikingly, studies have found that such neural similarity structure is preserved across human subjects, and even between humans and monkeys [27, 28]. This wealth of empirical phenomena raises a fundamental conceptual question about how neural circuits, upon experiencing many individual encounters with specific items, can over developmental time scales extract abstract semantic knowledge consisting of useful categories that can then guide our ability to reason about the world and inductively generalize. While a diverse set of theories have been advanced to explain human semantic development, there is currently no analytic, mathematical theory of neural circuits that can account for the diverse phenomena described above. Interesting non-neural accounts for the discovery of abstract semantic structure include for example the conceptual "theory-theory" [2, 16-18], and computational Bayesian [29] approaches. However, neither currently proposes a neural implementation that can infer abstract concepts from a stream of specific examples. In contrast, much prior work has shown, through simulations, that neural networks can gradually extract semantic structure by incrementally adjusting synaptic weights via error-corrective learning [4,30-37]. However, in contrast to the computational transparency enjoyed by Bayesian approaches, the theoretical principles governing how even simple artificial neural networks extract semantic knowledge from their ongoing stream of experience, embed this knowledge in their synaptic weights, and use these weights to perform inductive generalization, remains obscure. In this work, our fundamental goal is to fill this gap by employing an exceedingly simple class of neural networks, namely deep linear networks. Surprisingly, we find that this model class can qualitatively account for a diversity of phenomena involving semantic cog-nition described above. Indeed, we build upon a considerable neural network literature [30-37] addressing such phenomena through simulations of more complex nonlinear networks. We build particularly on the integrative, simulation-based treatment of semantic cognition in [4], often using the same modeling strategy in a simpler linear set-1-11},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8H5NLNRJ\\Saxe, Mcclelland, Ganguli - 2018 - A mathematical theory of semantic development in deep neural networks.pdf}
}

@article{saxena_cunningham_2019,
  title = {Towards the Neural Population Doctrine},
  author = {Saxena, Shreya and Cunningham, John P},
  year = {2019},
  month = apr,
  volume = {55},
  pages = {103--111},
  issn = {09594388},
  doi = {10.1016/j.conb.2019.02.002},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4QDL66KB\\Saxena and Cunningham - 2019 - Towards the neural population doctrine.pdf},
  journal = {Current Opinion in Neurobiology},
  language = {en}
}

@article{scellier_bengio_2017,
  title = {Equilibrium {{Propagation}}: {{Bridging}} the {{Gap Between Energy}}-{{Based Models}} and {{Backpropagation}}},
  shorttitle = {Equilibrium {{Propagation}}},
  author = {Scellier, Benjamin and Bengio, Yoshua},
  year = {2017},
  month = mar,
  abstract = {We introduce Equilibrium Propagation, a learning framework for energy-based models. It involves only one kind of neural computation, performed in both the first phase (when the prediction is made) and the second phase of training (after the target or prediction error is revealed). Although this algorithm computes the gradient of an objective function just like Backpropagation, it does not need a special computation or circuit for the second phase, where errors are implicitly propagated. Equilibrium Propagation shares similarities with Contrastive Hebbian Learning and Contrastive Divergence while solving the theoretical issues of both algorithms: our algorithm computes the gradient of a well defined objective function. Because the objective function is defined in terms of local perturbations, the second phase of Equilibrium Propagation corresponds to only nudging the prediction (fixed point, or stationary distribution) towards a configuration that reduces prediction error. In the case of a recurrent multi-layer supervised network, the output units are slightly nudged towards their target in the second phase, and the perturbation introduced at the output layer propagates backward in the hidden layers. We show that the signal 'back-propagated' during this second phase corresponds to the propagation of error derivatives and encodes the gradient of the objective function, when the synaptic update corresponds to a standard form of spike-timing dependent plasticity. This work makes it more plausible that a mechanism similar to Backpropagation could be implemented by brains, since leaky integrator neural computation performs both inference and error back-propagation in our model. The only local difference between the two phases is whether synaptic changes are allowed or not. We also show experimentally that multi-layer recurrently connected networks with 1, 2 and 3 hidden layers can be trained by Equilibrium Propagation on the permutation-invariant MNIST task.},
  archivePrefix = {arXiv},
  eprint = {1602.05179},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3R2F4H68\\Scellier and Bengio - 2017 - Equilibrium Propagation Bridging the Gap Between .pdf;C\:\\Users\\wchapman\\Zotero\\storage\\TGABRN9J\\Scellier and Bengio - 2017 - Equilibrium Propagation Bridging the Gap between .pdf},
  journal = {arXiv:1602.05179 [cs]},
  language = {en},
  primaryClass = {cs}
}

@article{schack_witte_1999,
  title = {Instantaneous {{EEG}} Coherence Analysis during the {{Stroop}} Task},
  author = {Schack, B and Chen, A C N and Mescha, S and Witte, H},
  year = {1999},
  volume = {110},
  pages = {1410--1426},
  abstract = {Objective: In the present study the Stroop effect is analyzed by means of EEG coherence analysis in addition to traditional analysis of behavioral data (reaction time) and ERP analysis. Data from 10 normal subjects are examined. Methods: In particular, a special dynamic approach for a continuous coherence estimation is applied to investigate the procedural evolution of functional cortical relationships during the Stroop task. Results: The frequency band of 13{$\pm$}20 Hz is found to be sensitive to the discrimination between the congruent and the incongruent task conditions on the basis of instantaneous coherence analysis. The magnitude of coherence values within the time interval of late potentials and the maximal coherence values are used to assess the strength of interaction between distinct areas of the cortex. Higher coherences are observed within the left frontal and left parietal areas, as well as between them for the incongruent situation in comparison with the congruent situation. Furthermore, the time-points of maximal coherence allows a procedural discrimination between both situations. The peak synchrony described by the time-points of maximal coherence correlates strongly with the reaction times mainly within the frontal area and between fronto-parietal areas in the incongruent case, whereas this correlation is restricted to the right hemisphere in the congruent case.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HU8DPZCX\\Schack et al. - 1999 - Instantaneous EEG coherence analysis during the Stroop task.pdf},
  journal = {Human Brain Mapping},
  keywords = {event-related potentials,frontal and parietal area,hemispheres,instantaneous eeg coherence,of the cortex,stroop task}
}

@article{schapiro_norman_2016,
  title = {Complementary Learning Systems within the Hippocampus : {{A}} Neural Network Modeling Approach to Reconciling Episodic Memory with Statistical Learning},
  author = {Schapiro, Anna C and {Turk-browne}, Nicholas B and Botvinick, Matthew M and Norman, Kenneth A},
  year = {2016},
  pages = {1--21},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EU8IEU8P\\Schapiro et al. - 2016 - Complementary learning systems within the hippocampus A neural network modeling approach to reconciling episod.pdf}
}

@article{scheeringa_fries_2017,
  title = {Cortical Layers, Rhythms and {{BOLD}} Signals},
  author = {Scheeringa, Ren E and Fries, Pascal},
  year = {2017},
  doi = {10.1016/j.neuroimage.2017.11.002},
  abstract = {A B S T R A C T This review investigates how laminar fMRI can complement insights into brain function derived from the study of rhythmic neuronal synchronization. Neuronal synchronization in various frequency bands plays an important role in neuronal communication between brain areas, and it does so on the backbone of layer-specific interareal anatomical projections. Feedforward projections originate predominantly in supragranular cortical layers and terminate in layer 4, and this pattern is reflected in inter-laminar and interareal directed gamma-band influences. Thus, gamma-band synchronization likely subserves feedforward signaling. By contrast, anatomical feedback projections originate predominantly in infragranular layers and terminate outside layer 4, and this pattern is reflected in inter-laminar and interareal directed alpha-and/or beta-band influences. Thus, alpha-beta band synchronization likely subserves feedback signaling. Furthermore, these rhythms explain part of the BOLD signal, with independent contributions of alpha-beta and gamma. These findings suggest that laminar fMRI can provide us with a potentially useful method to test some of the predictions derived from the study of neuronal synchronization. We review central findings regarding the role of layer-specific neuronal synchronization for brain function, and regarding the link between neuronal synchronization and the BOLD signal. We discuss the role that laminar fMRI could play by comparing it to invasive and non-invasive electrophysiological recordings. Compared to direct electrophysiological recordings, this method provides a metric of neuronal activity that is slow and indirect, but that is uniquely non-invasive and layer-specific with potentially whole brain coverage.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\T8K9IC3Y\\Scheeringa, Fries - 2017 - Cortical layers, rhythms and BOLD signals.pdf}
}

@article{schendan_stern_2003,
  title = {An {{fMRI Study}} of the {{Role}} of the {{Medial Temporal Lobe}} in {{Implicit}} and {{Explicit Sequence Learning}}},
  author = {Schendan, Haline E and Searl, Meghan M and Melrose, Rebecca J and Stern, Chantal E},
  year = {2003},
  month = mar,
  volume = {37},
  pages = {1013--1025},
  issn = {08966273},
  doi = {10.1016/S0896-6273(03)00123-5},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7YBPJSAA\\Schendan et al. - 2003 - An fMRI Study of the Role of the Medial Temporal L.pdf},
  journal = {Neuron},
  language = {en},
  number = {6}
}

@article{schendan_stern_2007,
  title = {Mental Rotation and Object Categorization Share a Common Network of Prefrontal and Dorsal and Ventral Regions of Posterior Cortex},
  author = {Schendan, Haline E. and Stern, Chantal E.},
  year = {2007},
  month = apr,
  volume = {35},
  pages = {1264--1277},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2007.01.012},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\27F8KQQG\\Schendan and Stern - 2007 - Mental rotation and object categorization share a .pdf},
  journal = {NeuroImage},
  language = {en},
  number = {3}
}

@book{schiff_schiff_2012,
  title = {Neural {{Control Engineering}}: {{The Emerging Intersection Between Control Theory}} and {{Neuroscience}}},
  author = {Schiff, Steven J},
  year = {2012},
  doi = {10.1063/PT.3.1824},
  abstract = {Over the past sixty years, powerful methods of model-based control engineering have been responsible for such dramatic advances in engineering systems as autolanding aircraft, autonomous vehicles, and even weather forecasting. Over those same decades, our models of the nervous system have evolved from single-cell membranes to neuronal networks to large-scale models of the human brain. Yet until recently control theory was completely inapplicable to the types of nonlinear models being developed in neuroscience. The revolution in nonlinear control engineering in the late 1990s has made the intersection of control theory and neuroscience possible. In Neural Control Engineering, Steven Schiff seeks to bridge the two fields, examining the application of new methods in nonlinear control engineering to neuroscience. After presenting extensive material on formulating computational neuroscience models in a control environment \textendash{} including some fundamentals of the algorithms helpful in crossing the divide from intuition to effective application \textendash{} Schiff examines a range of applications, including brain-machine interfaces and neural stimulation. He reports on research that he and his colleagues have undertaken showing that nonlinear control theory methods can be applied to models of single cells, small neuronal networks, and large-scale networks in disease states of Parkinson's disease and epilepsy. With Neural Control Engineering the reader acquires a working knowledge of the fundamentals of control theory and computational neuroscience sufficient not only to understand the literature in this trandisciplinary area but also to begin working to advance the field. The book will serve as an essential guide for scientists in either biology or engineering and for physicians who wish to gain expertise in these areas.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L59CN7AS\\Schiff - 2012 - Neural Control Engineering The Emerging Intersection Between Control Theory and Neuroscience.pdf},
  isbn = {0-262-01537-4}
}

@article{schmidhuber_schmidhuber_2014,
  title = {Deep {{Learning}} in {{Neural Networks}}: {{An Overview}}},
  author = {Schmidhuber, Juergen},
  year = {2014},
  month = apr,
  pages = {75},
  abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarises relevant work, much of it from the previous millennium. Shallow and deep learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \{\&\} evolutionary computation, and indirect search for short programs encoding deep and large networks.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2WKKK7VS\\Schmidhuber - 2014 - Deep Learning in Neural Networks An Overview.pdf}
}

@article{schmidt_aron_2019,
  title = {Beta {{Oscillations}} in {{Working Memory}}, {{Executive Control}} of {{Movement}} and {{Thought}}, and {{Sensorimotor Function}}},
  author = {Schmidt, Robert and Herrojo Ruiz, Maria and Kilavik, Bj{\o}rg E. and Lundqvist, Mikael and Starr, Philip A and Aron, Adam R.},
  year = {2019},
  month = oct,
  volume = {39},
  pages = {8231--8238},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1163-19.2019},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DXCIAIT9\\Schmidt et al. - 2019 - Beta Oscillations in Working Memory, Executive Con.pdf},
  journal = {The Journal of Neuroscience},
  language = {en},
  number = {42}
}

@article{schmidt_markus_2013,
  title = {Dissociation between Dorsal and Ventral Hippocampal Theta Oscillations during Decision-Making.},
  author = {Schmidt, Brandy and Hinman, James R and Jacobson, Tara K and Szkudlarek, Emily and Argraves, Melissa and a Escab{\'i}, Monty and Markus, Etan J},
  year = {2013},
  month = apr,
  volume = {33},
  pages = {6212--6224},
  issn = {1529-2401},
  doi = {10.1523/JNEUROSCI.2915-12.2013},
  abstract = {Hippocampal theta oscillations are postulated to support mnemonic processes in humans and rodents. Theta oscillations facilitate encoding and spatial navigation, but to date, it has been difficult to dissociate the effects of volitional movement from the cognitive demands of a task. Therefore, we examined whether volitional movement or cognitive demands exerted a greater modulating factor over theta oscillations during decision-making. Given the anatomical, electrophysiological, and functional dissociations along the dorsal-ventral axis, theta oscillations were simultaneously recorded in the dorsal and ventral hippocampus in rats trained to switch between place and motor-response strategies. Stark differences in theta characteristics were found between the dorsal and ventral hippocampus in frequency, power, and coherence. Theta power increased in the dorsal, but decreased in the ventral hippocampus, during the decision-making epoch. Interestingly, the relationship between running speed and theta power was uncoupled during the decision-making epoch, a phenomenon limited to the dorsal hippocampus. Theta frequency increased in both the dorsal and ventral hippocampus during the decision epoch, although this effect was greater in the dorsal hippocampus. Despite these differences, ventral hippocampal theta was responsive to the navigation task; theta frequency, power, and coherence were all affected by cognitive demands. Theta coherence increased within the dorsal hippocampus during the decision-making epoch on all three tasks. However, coherence selectively increased throughout the hippocampus (dorsal to ventral) on the task with new hippocampal learning. Interestingly, most results were consistent across tasks, regardless of hippocampal-dependent learning. These data indicate increased integration and cooperation throughout the hippocampus during information processing.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VL93PQ4I\\Schmidt et al. - 2013 - Dissociation between dorsal and ventral hippocampal theta oscillations during decision-making.pdf},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  keywords = {Animals,Attention,Decision Making,Decision Making: physiology,Electrodes,Evoked Potentials,Evoked Potentials: physiology,Exploratory Behavior,Hippocampus,Hippocampus: anatomy {\&} histology,Hippocampus: anatomy \& histology,Hippocampus: physiology,Implanted,Inbred F344,Male,Maze Learning,Memory,Rats,Reinforcement Schedule,Reward,Short-Term,Short-Term: physiology,Spatial Behavior,Spatial Behavior: physiology,Theta Rhythm,Theta Rhythm: physiology},
  number = {14},
  pmid = {23554502}
}

@article{schmidt_vanalbada_2017,
  title = {Multi-Scale Account of the Network Structure of Macaque Visual Cortex},
  author = {Schmidt, Maximilian and Bakker, Rembrandt and Hilgetag, Claus C. and Diesmann, Markus and {van Albada}, Sacha J.},
  year = {2017},
  month = nov,
  issn = {1863-2653, 1863-2661},
  doi = {10.1007/s00429-017-1554-4},
  abstract = {Cortical network structure has been extensively characterized at the level of local circuits and in terms of long-range connectivity, but seldom in a manner that integrates both of these scales. Furthermore, while the connectivity of cortex is known to be related to its architecture, this knowledge has not been used to derive a comprehensive cortical connectivity map. In this study, we integrate data on cortical architecture and axonal tracing data into a consistent multi-scale framework of the structure of one hemisphere of macaque vision-related cortex. The connectivity model predicts the connection probability between any two neurons based on their types and locations within areas and layers. Our analysis reveals regularities of cortical structure. We confirm that cortical thickness decays with cell density.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WX6PLNKZ\\Schmidt et al. - 2017 - Multi-scale account of the network structure of ma.pdf},
  journal = {Brain Structure and Function},
  language = {en}
}

@article{schmitt_halassa_2017,
  title = {Thalamic Amplification of Cortical Connectivity Sustains Attentional Control},
  author = {Schmitt, L Ian and Wimmer, Ralf D and Nakajima, Miho and Happ, Michael and Mofakham, Sima and Halassa, Michael M},
  year = {2017},
  volume = {545},
  pages = {219--223},
  issn = {0028-0836},
  doi = {10.1038/nature22073},
  abstract = {Although interactions between the thalamus and cortex are critical for cognitive function, the exact contribution of the thalamus to these interactions remains unclear. Recent studies have shown diverse connectivity patterns across the thalamus, but whether this diversity translates to thalamic functions beyond relaying information to or between cortical regions is unknown. Here we show, by investigating the representation of two rules used to guide attention in the mouse prefrontal cortex (PFC), that the mediodorsal thalamus sustains these representations without relaying categorical information. Specifically, mediodorsal input amplifies local PFC connectivity, enabling rule-specific neural sequences to emerge and thereby maintain rule representations. Consistent with this notion, broadly enhancing PFC excitability diminishes rule specificity and behavioural performance, whereas enhancing mediodorsal excitability improves both. Overall, our results define a previously unknown principle in neuroscience; thalamic control of functional cortical connectivity. This function, which is dissociable from categorical information relay, indicates that the thalamus has a much broader role in cognition than previously thought.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L4TB6DJM\\Schmitt et al. - 2017 - Thalamic amplification of cortical connectivity sustains attentional control.pdf},
  journal = {Nature},
  number = {7653},
  pmid = {28467827}
}

@article{schnitzler_gross_2005,
  title = {Normal and {{Pathological Oscillatory Comminication}} in the {{Brain}}},
  author = {Schnitzler, Alfons and Gross, Joachim},
  year = {2005},
  volume = {6},
  doi = {10.1038/nrn1650},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TH7PTBNB\\Schnitzler, Gross - 2005 - Normal and Pathological Oscillatory Comminication in the Brain.pdf},
  journal = {Nature Reviews Neuroscience},
  number = {April}
}

@article{schomburg_buzsaki_2014,
  title = {Theta {{Phase Segregation}} of {{Input}}-{{Specific Gamma Patterns}} in {{Entorhinal}}-{{Hippocampal Networks}}},
  author = {Schomburg, Erik W and {Fern??ndez-Ruiz}, Antonio and Mizuseki, Kenji and Ber??nyi, Antal and Anastassiou, Costas A and Koch, Christof and Buzs{\'a}ki, Gy{\"o}rgy},
  year = {2014},
  volume = {84},
  pages = {470--485},
  issn = {10974199},
  doi = {10.1016/j.neuron.2014.08.051},
  abstract = {Precisely how rhythms support neuronal communication remains obscure. We investigated interregional coordination of gamma oscillations using high-density electrophysiological recordings in the rat hippocampus and entorhinal cortex. We found that 30-80Hz gamma dominated CA1 local field potentials (LFPs) on the descending phase of CA1 theta waves during navigation, with 60-120Hz gamma at the theta peak. These signals corresponded to CA3 and entorhinal input, respectively. Above 50Hz, interregional phase-synchronization of principal cell spikes occurred mostly for LFPs in the axonal target domain. CA1 pyramidal cells were phase-locked mainly to fast gamma (\{\textbackslash textgreater\}100Hz) LFP patterns restricted to CA1, which were strongest at the theta trough. While theta phase coordination of spiking across entorhinal-hippocampal regions depended on memory demands, LFP gamma patterns below 100Hz in the hippocampus were consistently layer specific and largely reflected afferent activity. Gamma synchronization as a mechanism for interregional communication thus rapidly loses efficacy at higher frequencies.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2WZ7GP7X\\Schomburg et al. - 2014 - Theta Phase Segregation of Input-Specific Gamma Patterns in Entorhinal-Hippocampal Networks.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\8LBF9GM8\\Schomburg et al. - 2014 - Theta Phase Segregation of Input-Specific Gamma Patterns in Entorhinal-Hippocampal Networks(2).pdf},
  journal = {Neuron},
  number = {2},
  pmid = {25263753}
}

@article{schott_bethge_2018,
  title = {Robust {{Perception}} through {{Analysis}} by {{Synthesis}}},
  author = {Schott, Lukas and Rauber, Jonas and Brendel, Wieland and Bethge, Matthias},
  year = {2018},
  abstract = {The intriguing susceptibility of deep neural networks to minimal input perturbations suggests that the gap between human and machine perception is still large. We here argue that despite much effort, even on MNIST the most successful defenses are still far away from the robustness of human perception. We here reconsider MNIST and establish a novel defense that is inspired by the abundant feedback connections present in the human visual cortex. We suggest that this feedback plays a role in estimating the likelihood of a sensory stimulus with respect to the hidden causes inferred by the cortex and allow the brain to mute distracting patterns. We implement this analysis by synthesis idea in the form of a discriminatively fine-tuned Bayesian classifier using a set of class-conditional variational autoe ncoders (VAEs). To evaluate model robustness we go to great length to find maximally effective adversarial attacks, including decision-based, score-based and gradient-based attacks. The results suggest that this ansatz yields state-of-the-art robustness on MNIST against L0, L2 and L infinity perturbations and we demonstrate that most adversarial examples are strongly perturbed towards the perceptual boundary between the original and the adversarial class.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PSDU5J27\\Schott et al. - Unknown - Robust Perception through Analysis by Synthesis.pdf},
  journal = {arXiv}
}

@article{schreiner_gremel_2018,
  title = {Orbital {{Frontal Cortex Projections}} to {{Secondary Motor Cortex Mediate Exploitation}} of {{Learned Rules}}},
  author = {Schreiner, Drew C and Gremel, Christina M},
  year = {2018},
  volume = {8},
  pages = {10979},
  issn = {20452322},
  doi = {10.1038/s41598-018-29285-x},
  abstract = {Animals face the dilemma between exploiting known opportunities and exploring new ones, a decision-making process supported by cortical circuits. While different types of learning may bias exploration, the circumstances and the degree to which bias occurs is unclear. We used an instrumental lever press task in mice to examine whether learned rules generalize to exploratory situations and the cortical circuits involved. We first trained mice to press one lever for food and subsequently assessed how that learning influenced pressing of a second novel lever. Using outcome devaluation procedures we found that novel lever exploration was not dependent on the food value associated with the trained lever. Further, changes in the temporal uncertainty of when a lever press would produce food did not affect exploration. Instead, accrued experience with the instrumental contingency was strongly predictive of test lever pressing with a positive correlation between experience and trained lever exploitation, but not novel lever exploration. Chemogenetic attenuation of orbital frontal cortex (OFC) projection into secondary motor cortex (M2) biased novel lever exploration, suggesting that experience increases OFC-M2 dependent exploitation of learned associations but leaves exploration constant. Our data suggests exploitation and exploration are parallel decision-making systems that do not necessarily compete.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BD9VLSWB\\Schreiner, Gremel - 2018 - Orbital Frontal Cortex Projections to Secondary Motor Cortex Mediate Exploitation of Learned Rules OPEN.pdf},
  journal = {Scientific Reports},
  number = {1}
}

@article{schultz_schultz_2016,
  title = {Dopamine {{Reward Prediction Error Coding}}},
  author = {Schultz, Wolfram},
  year = {2016},
  volume = {18},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PHWYU3I5\\Schultz - 2016 - Dopamine Reward Prediction Error Coding.pdf},
  journal = {Dialogues in Clinical Neuroscience},
  number = {1}
}

@article{schulz_gershman_2019,
  title = {The Algorithmic Architecture of Exploration in the Human Brain},
  author = {Schulz, Eric and Gershman, Samuel J.},
  year = {2019},
  volume = {55},
  pages = {7--14},
  issn = {09594388},
  doi = {10.1016/j.conb.2018.11.003},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ULY76AEY\\Schulz, Gershman - 2019 - The algorithmic architecture of exploration in the human brain.pdf},
  journal = {Current Opinion in Neurobiology}
}

@article{schwalger_gerstner_2017,
  title = {Towards a Theory of Cortical Columns: {{From}} Spiking Neurons to Interacting Neural Populations of Finite Size},
  shorttitle = {Towards a Theory of Cortical Columns},
  author = {Schwalger, Tilo and Deger, Moritz and Gerstner, Wulfram},
  editor = {Graham, Lyle J.},
  year = {2017},
  month = apr,
  volume = {13},
  pages = {e1005507},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1005507},
  abstract = {Neural population equations such as neural mass or field models are widely used to study brain activity on a large scale. However, the relation of these models to the properties of single neurons is unclear. Here we derive an equation for several interacting populations at the mesoscopic scale starting from a microscopic model of randomly connected generalized integrate-and-fire neuron models. Each population consists of 50 \textendash{} 2000 neurons of the same type but different populations account for different neuron types. The stochastic population equations that we find reveal how spike-history effects in single-neuron dynamics such as refractoriness and adaptation interact with finite-size fluctuations on the population level. Efficient integration of the stochastic mesoscopic equations reproduces the statistical behavior of the population activities obtained from microscopic simulations of a full spiking neural network model. The theory describes nonlinear emergent dynamics such as finite-size-induced stochastic transitions in multistable networks and synchronization in balanced networks of excitatory and inhibitory neurons. The mesoscopic equations are employed to rapidly integrate a model of a cortical microcircuit consisting of eight neuron types, which allows us to predict spontaneous population activities as well as evoked responses to thalamic input. Our theory establishes a general framework for modeling finite-size neural population dynamics based on single cell and synapse parameters and offers an efficient approach to analyzing cortical circuits and computations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MD866HHJ\\Schwalger et al. - 2017 - Towards a theory of cortical columns From spiking.pdf},
  journal = {PLOS Computational Biology},
  language = {en},
  number = {4}
}

@article{schwemmer_shea-brown_2015,
  title = {Constructing Precisely Computing Networks with Biophysical Spiking Neurons},
  author = {Schwemmer, Michael A. and Fairhall, Adrienne L. and Den{\'e}ve, Sophie and {Shea-Brown}, Eric T.},
  year = {2015},
  month = jul,
  abstract = {While spike timing has been shown to carry detailed stimulus information at the sensory periphery, its possible role in network computation is less clear. Most models of computation by neural networks are based on population firing rates. In equivalent spiking implementations, firing is assumed to be random such that averaging across populations of neurons recovers the rate-based approach. Recently, however, Den\textbackslash 'eve and colleagues have suggested that the spiking behavior of neurons may be fundamental to how neuronal networks compute, with precise spike timing determined by each neuron's contribution to producing the desired output. By postulating that each neuron fires in order to reduce the error in the network's output, it was demonstrated that linear computations can be carried out by networks of integrate-and-fire neurons that communicate through instantaneous synapses. This left open, however, the possibility that realistic networks, with conductance-based neurons with subthreshold nonlinearity and the slower timescales of biophysical synapses, may not fit into this framework. Here, we show how the spike-based approach can be extended to biophysically plausible networks. We then show that our network reproduces a number of key features of cortical networks including irregular and Poisson-like spike times and a tight balance between excitation and inhibition. Lastly, we discuss how the behavior of our model scales with network size, or with the number of neurons "recorded" from a larger computing network. These results significantly increase the biological plausibility of the spike-based approach to network computation.},
  archivePrefix = {arXiv},
  eprint = {1411.3191},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\B6KENGXN\\Schwemmer et al. - 2015 - Constructing precisely computing networks with bio.pdf},
  journal = {arXiv:1411.3191 [q-bio]},
  language = {en},
  primaryClass = {q-bio}
}

@article{schyns_gosselin_2002,
  title = {{{SHOW ME THE FEATURES}}! {{Understanding Recognition From}} the {{Use}} of {{Visual Information}}},
  author = {Schyns, Philippe G and Bonnar, Lizann and Gosselin, Fr{\'e}d{\'e}ric},
  year = {2002},
  volume = {13},
  pages = {402--409},
  issn = {0956-7976},
  doi = {10.1111/1467-9280.00472},
  abstract = {\textemdash{} We propose an approach that allows a rigorous under-standing of the visual categorization and recognition process without asking direct questions about unobservable memory representations. Our approach builds on the selective use of visual information in rec-ognition and a new method (Bubbles) to depict and measure what this information is. We examine three face-recognition tasks (identity, gen-der, expressive or not) and establish the componential and holistic in-formation responsible for recognition performance. On the basis of this information, we derive task-specific gradients of probability for the allocation of attention to the different regions of the face. In recent years, most face-, object-, and scene-recognition research-ers have gathered around a common agenda: to understand the struc-ture of representations in memory. A number of fundamental issues have been articulated, and researchers typically ask questions such as the following: Are face, object, and scene representations viewpoint What is the entry point to recognition (Tanaka \{\&\} Tay-lor, 1991)? What is the format of memory representations, and does it change uniformly across the levels of a hierarchy (Jolicoeur, 1990)? To address these complex issues, categorization and recognition re-searchers should be equipped with methodologies of a commensurate power\textemdash methodologies that can assign the credit for behavioral per-formance (e.g., viewpoint dependence, configural effects, color, speed of categorization, point of entry, expertise effects) to specific proper-ties of the representations of visual events in memory. However, the relationship between behavior and representations is tenuous, making representational issues the most difficult to approach experimentally. In this article, we propose an alternative approach that allows a rig-orous understanding of the recognition process without asking direct questions about unobservable memory representations. Our analysis builds on the selective use of diagnostic information, an important but neglected component of recognition. People who recognize visual events do not use all the information impinging on the retina, but instead use only the elements that are most useful (i.e., diagnostic) for the task at hand. In most instances, this information is not available to conscious experience, but the vi-sual system knows what it is, and how to selectively extract diagnostic information from the visual array to perform multiple categorizations of the same input (e.g., Schyns \{\&\} Oliva, 1999). Our main epistemological point is that one can acquire knowledge about the recognition process by carefully studying diagnostic infor-mation without asking questions (or even making assumptions) about memory representations (see also Schyns, 1998). This is a powerful approach because the information used encompasses all the visual features 1 that mediate the recognition task at hand. These features therefore have a dual role. For high-level vision, they reflect the infor-mation required from memory to categorize the stimulus. For low-level vision, they specify which information to extract from the visual array. In short, the features involved in a recognition task bridge be-tween memory and the visual array. They set the agenda for high-and low-level vision. Now, let us see what these features are.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KZTJIPFW\\Schyns, Bonnar, Gosselin - 2002 - SHOW ME THE FEATURES! Understanding Recognition From the Use of Visual Information.pdf},
  journal = {Tarr \{\&\} Pinker Troje \{\&\} B\{\"u\}lthoff},
  number = {5}
}

@article{scott_tank_2017,
  title = {Fronto-Parietal {{Cortical Circuits Encode Accumulated Evidence}} with a {{Diversity}} of {{Timescales}}},
  author = {Scott, Benjamin B and Constantinople, Christine M and Akrami, Athena and Hanks, Timothy D and Brody, Carlos D and Tank, David W},
  year = {2017},
  volume = {95},
  pages = {385--398.e5},
  issn = {10974199},
  doi = {10.1016/j.neuron.2017.06.013},
  abstract = {Decision-making in dynamic environments often involves accumulation of evidence, in which new information is used to update beliefs and select future actions. Using in vivo cellular resolution imaging in voluntarily head-restrained rats, we examined the responses of neurons in frontal and parietal cortices during a pulse-based accumulation of evidence task. Neurons exhibited activity that predicted the animal's upcoming choice, previous choice, and graded responses that reflected the strength of the accumulated evidence. The pulsatile nature of the stimuli enabled characterization of the responses of neurons to a single quantum (pulse) of evidence. Across the population, individual neurons displayed extensive heterogeneity in the dynamics of responses to pulses. The diversity of responses was sufficiently rich to form a temporal basis for accumulated evidence estimated from a latent variable model. These results suggest that heterogeneous, often transient sensory responses distributed across the fronto-parietal cortex may support working memory on behavioral timescales. Video Abstract [Figure presented] Leading models of decision-making postulate that individual fronto-parietal neurons encode accumulated sensory evidence with stable changes in firing rate. Using cellular resolution calcium imaging during a pulse-based accumulation task, Scott et al. reveal that stable representations of accumulated evidence in rat fronto-parietal cortex instead arise from neuronal populations with temporally diverse responses.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZAB42Q3G\\Scott et al. - 2017 - Fronto-parietal Cortical Circuits Encode Accumulated Evidence with a Diversity of Timescales(2).pdf},
  journal = {Neuron},
  keywords = {calcium imaging,decision-making,drift diffusion model,head restraint,multiphoton fluorescence microscopy,neocortex,neural coding,rodent,working-memory},
  number = {2},
  pmid = {28669543}
}

@article{seeholzer_gerstner_2019,
  title = {Stability of Working Memory in Continuous Attractor Networks under the Control of Short-Term Plasticity},
  author = {Seeholzer, Alexander and Deger, Moritz and Gerstner, Wulfram},
  editor = {Burak, Yoram},
  year = {2019},
  month = apr,
  volume = {15},
  pages = {e1006928},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1006928},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JR9ITMLQ\\Seeholzer et al. - 2019 - Stability of working memory in continuous attracto.pdf},
  journal = {PLOS Computational Biology},
  language = {en},
  number = {4}
}

@article{seelig_jayaraman_2015,
  title = {Neural Dynamics for Landmark Orientation and Angular Path Integration},
  author = {Seelig, Johannes D and Jayaraman, Vivek},
  year = {2015},
  volume = {521},
  pages = {186--191},
  issn = {0028-0836},
  doi = {10.1038/nature14446},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RPYHWHSC\\Seelig, Jayaraman - 2015 - Neural dynamics for landmark orientation and angular path integration.pdf},
  journal = {Nature},
  number = {7551}
}

@article{segaert_hagoort_2018,
  title = {Binding Language: Structuring Sentences through Precisely Timed Oscillatory Mechanisms},
  shorttitle = {Binding Language},
  author = {Segaert, Katrien and Mazaheri, Ali and Hagoort, Peter},
  year = {2018},
  month = oct,
  volume = {48},
  pages = {2651--2662},
  issn = {0953816X},
  doi = {10.1111/ejn.13816},
  abstract = {Syntactic binding refers to combining words into larger structures. Using EEG, we investigated the neural processes involved in syntactic binding. Participants were auditorily presented two-word sentences (i.e. pronoun and pseudoverb such as `I grush' and `she grushes', for which syntactic binding can take place) and wordlists (i.e. two pseudoverbs such as `pob grush' and `pob grushes', for which no binding occurs). Comparing these two conditions, we targeted syntactic binding while minimising contributions of semantic binding and of other cognitive processes such as working memory. We found a converging pattern of results using two distinct analysis approaches: one approach using frequency bands as defined in previous literature, and one data-driven approach in which we looked at the entire range of frequencies between 3 and 30 Hz without the constraints of pre-defined frequency bands. In the syntactic binding (relative to the wordlist) condition, a power increase was observed in the alpha and beta frequency range shortly preceding the presentation of the target word that requires binding, which was maximal over frontal-central electrodes. Our interpretation is that these signatures reflect that language comprehenders expect the need for binding to occur. Following the presentation of the target word in a syntactic binding context (relative to the wordlist condition), an increase in alpha power maximal over a left-lateralised cluster of frontal-temporal electrodes was observed. We suggest that this alpha increase relates to syntactic binding taking place. Taken together, our findings suggest that increases in alpha and beta power are reflections of distinct the neural processes underlying syntactic binding.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7Z6DT453\\Segaert et al. - 2018 - Binding language structuring sentences through pr.pdf},
  journal = {European Journal of Neuroscience},
  language = {en},
  number = {7}
}

@article{sellers_frhlich_2016,
  title = {Oscillatory {{Dynamics}} in the {{Frontoparietal Attention Network}} during {{Sustained Attention}} in the {{Ferret}}},
  author = {Sellers, Kristin K and Yu, Chunxiu and Zhou, Zhe Charles and Stitt, Iain and Li, Yuhui and {Radtke-Schuller}, Susanne and Alagapan, Sankaraleengam and Fr??hlich, Flavio},
  year = {2016},
  volume = {16},
  pages = {2864--2874},
  issn = {22111247},
  doi = {10.1016/j.celrep.2016.08.055},
  abstract = {Sustained attention requires the coordination of neural activity across multiple cortical areas in the frontoparietal network, in particular the prefrontal cortex (PFC) and posterior parietal cortex (PPC). Previous work has demonstrated that activity in these brain regions is coordinated by neuronal oscillations of the local field potential (LFP). However, the underlying coordination of activity in terms of organization of single unit (SU) spiking activity has remained poorly understood, particularly in the freely moving animal. We found that long-range functional connectivity between anatomically connected PFC and PPC was mediated by oscillations in the theta frequency band. SU activity in PFC was phase locked to theta oscillations in PPC, and spiking activity in PFC and PPC was locked to local high-gamma activity. Together, our results support a model in which frequency-specific synchronization mediates functional connectivity between and within PFC and PPC of the frontoparietal attention network in the freely moving animal.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MWNWK9TM\\Sellers et al. - 2016 - Oscillatory Dynamics in the Frontoparietal Attention Network during Sustained Attention in the Ferret.pdf},
  journal = {Cell Reports},
  number = {11},
  pmid = {27626658}
}

@article{semedo_kohn_2019,
  title = {Cortical {{Areas Interact}} through a {{Communication Subspace}}},
  author = {Semedo, Jo{\~a}o D. and Zandvakili, Amin and Machens, Christian K. and Yu, Byron M. and Kohn, Adam},
  year = {2019},
  month = apr,
  volume = {102},
  pages = {249-259.e4},
  issn = {08966273},
  doi = {10.1016/j.neuron.2019.01.026},
  abstract = {Most brain functions involve interactions among multiple, distinct areas or nuclei. For instance, visual processing in primates requires the appropriate relaying of signals across many distinct cortical areas. Yet our understanding of how populations of neurons in interconnected brain areas communicate is in its infancy. Here we investigate how trial-to-trial fluctuations of population responses in primary visual cortex (V1) are related to simultaneously recorded population responses in area V2. Using dimensionality reduction methods, we find that V1-V2 interactions occur through a communication subspace: V2 fluctuations are related to a small subset of V1 population activity patterns, distinct from the largest fluctuations shared among neurons within V1. In contrast, interactions between subpopulations within V1 are less selective. We propose that the communication subspace may be a general, population-level mechanism by which activity can be selectively routed across brain areas.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ML8N9YAN\\Semedo et al. - 2019 - Cortical Areas Interact through a Communication Su.pdf},
  journal = {Neuron},
  language = {en},
  number = {1}
}

@article{sengupta_penny_2016,
  title = {Gradient-Based {{MCMC}} Samplers for Dynamic Causal Modelling},
  author = {Sengupta, Biswa and Friston, Karl J and Penny, Will D},
  year = {2016},
  volume = {125},
  pages = {1107--1118},
  issn = {10959572},
  doi = {10.1016/j.neuroimage.2015.07.043},
  abstract = {In this technical note, we derive two MCMC (Markov chain Monte Carlo) samplers for dynamic causal models (DCMs). Specifically, we use (a) Hamiltonian MCMC (HMC-E) where sampling is simulated using Hamilton's equation of motion and (b) Langevin Monte Carlo algorithm (LMC-R and LMC-E) that simulates the Langevin diffusion of samples using gradients either on a Euclidean (E) or on a Riemannian (R) manifold. While LMC-R requires minimal tuning, the implementation of HMC-E is heavily dependent on its tuning parameters. These parameters are therefore optimised by learning a Gaussian process model of the time-normalised sample correlation matrix. This allows one to formulate an objective function that balances tuning parameter exploration and exploitation, furnishing an intervention-free inference scheme. Using neural mass models (NMMs)\textemdash a class of biophysically motivated DCMs\textemdash we find that HMC-E is statistically more efficient than LMC-R (with a Riemannian metric); yet both gradient-based samplers are far superior to the random walk Metropolis algorithm, which proves inadequate to steer away from dynamical instability.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PSHNRJEA\\Sengupta, Friston, Penny - 2016 - Gradient-based MCMC samplers for dynamic causal modelling.pdf},
  journal = {NeuroImage},
  pmid = {26213349}
}

@article{sengupta_roy_2018,
  title = {Going {{Deeper}} in {{Spiking Neural Networks}}: {{VGG}} and {{Residual Architectures}}},
  author = {Sengupta, Abhronil and Ye, Yuting and Wang, Robert and Liu, Chiao and Roy, Kaushik},
  year = {2018},
  month = feb,
  abstract = {Over the past few years, Spiking Neural Networks (SNNs) have become popular as a possible pathway to enable low-power event-driven neuromorphic hardware. However, their application in machine learning have largely been limited to very shallow neural network architectures for simple problems. In this paper, we propose a novel algorithmic technique for generating an SNN with a deep architecture, and demonstrate its effectiveness on complex visual recognition problems such as CIFAR-10 and ImageNet. Our technique applies to both VGG and Residual network architectures, with significantly better accuracy than the state-of-the-art. Finally, we present analysis of the sparse event-driven computations to demonstrate reduced hardware overhead when operating in the spiking domain.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4TMJJC6N\\Sengupta et al. - Unknown - Going Deeper in Spiking Neural Networks VGG and Residual Architectures.pdf},
  journal = {arXiv}
}

@article{senzai_buzsaki_2019,
  title = {Layer-{{Specific Physiological Features}} and {{Interlaminar Interactions}} in the {{Primary Visual Cortex}} of the {{Mouse}}},
  author = {Senzai, Yuta and {Fernandez-Ruiz}, Antonio and Buzs{\'a}ki, Gy{\"o}rgy},
  year = {2019},
  month = feb,
  volume = {101},
  pages = {500-513.e5},
  issn = {08966273},
  doi = {10.1016/j.neuron.2018.12.009},
  abstract = {The relationship between mesoscopic local field potentials (LFPs) and single-neuron firing in the multi-layered neocortex is poorly understood. Simultaneous recordings from all layers in the primary visual cortex (V1) of the behaving mouse revealed functionally defined layers in V1. The depth of maximum spike power and sink-source distributions of LFPs provided consistent laminar landmarks across animals. Coherence of gamma oscillations (30\textendash 100 Hz) and spikeLFP coupling identified six physiological layers and further sublayers. Firing rates, burstiness, and other electrophysiological features of neurons displayed unique layer and brain state dependence. Spike transmission strength from layer 2/3 cells to layer 5 pyramidal cells and interneurons was stronger during waking compared with non-REM sleep but stronger during non-REM sleep among deep-layer excitatory neurons. A subset of deep-layer neurons was active exclusively in the DOWN state of non-REM sleep. These results bridge mesoscopic LFPs and singleneuron interactions with laminar structure in V1.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VXRZC5GV\\Senzai et al. - 2019 - Layer-Specific Physiological Features and Interlam.pdf},
  journal = {Neuron},
  language = {en},
  number = {3}
}

@article{seo_averbeck_2012,
  title = {Action {{Selection}} and {{Action Value}} in {{Frontal}}-{{Striatal Circuits}}},
  author = {Seo, Moonsang and Lee, Eunjeong and Averbeck, Bruno B.},
  year = {2012},
  month = jun,
  volume = {74},
  pages = {947--960},
  issn = {08966273},
  doi = {10.1016/j.neuron.2012.03.037},
  abstract = {The role that frontal-striatal circuits play in normal behavior remains unclear. Two of the leading hypotheses suggest that these circuits are important for action selection or reinforcement learning. To examine these hypotheses we carried out an experiment in which monkeys had to select actions in two different task conditions. In the first (random) condition actions were selected on the basis of perceptual inference. In the second (fixed) condition the animals used reinforcement from previous trials to select actions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CE47YL8Y\\Seo et al. - 2012 - Action Selection and Action Value in Frontal-Stria.pdf},
  journal = {Neuron},
  language = {en},
  number = {5}
}

@article{serre_riesenhuber_2007,
  title = {Robust {{Object Recognition}} with {{Cortex}}-{{Like Mechanisms}}},
  author = {Serre, Thomas and Wolf, Lior and Bileschi, Stanley and Riesenhuber, Maximilian},
  year = {2007},
  volume = {29},
  pages = {411--426},
  issn = {0162-8828},
  doi = {http://dx.doi.org/10.1109/TPAMI.2007.56},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\F6RX376L\\Serre et al. - 2007 - Robust Object Recognition with Cortex-Like Mechanisms.pdf},
  journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  number = {3}
}

@article{sestieri_corbetta_2017,
  title = {The Contribution of the Human Posterior Parietal Cortex to Episodic Memory},
  author = {Sestieri, Carlo and Shulman, Gordon L and Corbetta, Maurizio},
  year = {2017},
  volume = {18},
  pages = {183--192},
  issn = {1471-003X},
  doi = {10.1038/nrn.2017.6},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3DB76D6Y\\Sestieri, Shulman, Corbetta - 2017 - The contribution of the human posterior parietal cortex to episodic memory.pdf},
  journal = {Nature Reviews Neuroscience},
  number = {3},
  pmid = {28209980}
}

@article{seth_seth_2010,
  title = {A {{MATLAB}} Toolbox for {{Granger}} Causal Connectivity Analysis},
  author = {Seth, Anil K},
  year = {2010},
  volume = {186},
  pages = {262--273},
  issn = {01650270},
  doi = {10.1016/j.jneumeth.2009.11.020},
  abstract = {Assessing directed functional connectivity from time series data is a key challenge in neuroscience. One approach to this problem leverages a combination of Granger causality analysis and network theory. This article describes a freely available MATLAB toolbox - 'Granger causal connectivity analysis' (GCCA) - which provides a core set of methods for performing this analysis on a variety of neuroscience data types including neuroelectric, neuromagnetic, functional MRI, and other neural signals. The toolbox includes core functions for Granger causality analysis of multivariate steady-state and event-related data, functions to preprocess data, assess statistical significance and validate results, and to compute and display network-level indices of causal connectivity including 'causal density' and 'causal flow'. The toolbox is deliberately small, enabling its easy assimilation into the repertoire of researchers. It is however readily extensible given proficiency with the MATLAB language. ?? 2009 Elsevier B.V. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\94F7XLSB\\Seth - 2010 - A MATLAB toolbox for Granger causal connectivity analysis.pdf},
  journal = {Journal of Neuroscience Methods},
  keywords = {Causal density,Granger causality,MATLAB,Network theory,Toolbox},
  number = {2},
  pmid = {19961876}
}

@article{seung_seung_2003,
  title = {Learning in {{Spiking Neural Networks}} by {{Reinforcement}} of {{Stochastics Transmission}}},
  author = {Seung, Sebastian},
  year = {2003},
  volume = {40},
  pages = {1063--1073},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7NNNXIRL\\Seung - 2003 - Learning in Spiking Neural Networks by Reinforcement of Stochastics Transmission.pdf},
  journal = {Neuron}
}

@article{shadlen_newsome_2001,
  title = {Neural {{Basis}} of a {{Perceptual Decision}} in the {{Parietal Cortex}} ({{Area LIP}}) of the {{Rhesus Monkey}}},
  author = {Shadlen, Michael N. and Newsome, William T.},
  year = {2001},
  month = oct,
  volume = {86},
  pages = {1916--1936},
  issn = {0022-3077, 1522-1598},
  doi = {10.1152/jn.2001.86.4.1916},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GIH7CEPI\\Shadlen and Newsome - 2001 - Neural Basis of a Perceptual Decision in the Parie.pdf},
  journal = {Journal of Neurophysiology},
  language = {en},
  number = {4}
}

@article{shahabi_moghimi_2013,
  title = {Investigating the Effective Brain Networks Related to Working Memory Using a Modified Directed Transfer Function},
  author = {Shahabi, Hossein and Moghimi, Sahar and Moghimi, Ali},
  year = {2013},
  pages = {1398--1401},
  issn = {19483546},
  doi = {10.1109/NER.2013.6696204},
  abstract = {We utilized a combination of orthogonal least squares (OLS) algorithm and short-time direct directed transfer function (SdDTF) for evaluating the effective brain networks. Directional changes in connectivity among brain regions were assessed during two states, resting and working memory (WM). Our results demonstrated an increase in the strength of connectivity between frontal and parietal regions and a decrease in the strength of connectivity between the regions of the default mode network, during task engagement. Connectivity was prominent in the low frequency bands, theta and alpha. Furthermore, during the WM task, theta oscillations increased in the frontal lobe while a reduction was observed in the alpha band. \textcopyright{} 2013 IEEE.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9TQAYNAW\\Shahabi, Moghimi, Moghimi - 2013 - Investigating the effective brain networks related to working memory using a modified directed transf.pdf},
  journal = {International IEEE/EMBS Conference on Neural Engineering, NER},
  keywords = {Cognitive Enginee,Neural Computation and Modeling}
}

@article{shanahan_garnelo_2019,
  title = {An {{Explicitly Relational Neural Network Architecture}}},
  author = {Shanahan, Murray and Nikiforou, Kyriacos and Creswell, Antonia and Kaplanis, Christos and Barrett, David and Garnelo, Marta},
  year = {2019},
  month = may,
  abstract = {With a view to bridging the gap between deep learning and symbolic AI, we present a novel end-to-end neural network architecture that learns to form propositional representations with an explicitly relational structure from raw pixel data. In order to evaluate and analyse the architecture, we introduce a family of simple visual relational reasoning tasks of varying complexity. We show that the proposed architecture, when pre-trained on a curriculum of such tasks, learns to generate reusable representations that better facilitate subsequent learning on previously unseen tasks when compared to a number of baseline architectures. The workings of a successfully trained model are visualised to shed some light on how the architecture functions.},
  archivePrefix = {arXiv},
  eprint = {1905.10307},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QBWSSU8I\\shanahan_et_al_2019_an_explicitly_relational_neural_network_architecture.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\E6B3T96M\\1905.html},
  journal = {arXiv:1905.10307 [cs, stat]},
  primaryClass = {cs, stat}
}

@article{sharma_nadkarni_2018,
  title = {Biophysical Basis of Alpha Rhythm Disruption in {{Alzheimer}}'s Disease},
  author = {Sharma, Rohan and Nadkarni, Suhita},
  year = {2018},
  month = jul,
  doi = {10.1101/335471},
  abstract = {Alpha is one of the most prominent rhythms (7.5-12.5 Hz) detected in electroencephalography (EEG) during wakeful relaxation with closed eyes. In response to elevated ambient acetylcholine levels, a subclass of thalamic pacemaker cells generate alpha. This rhythm is intrinsic to the cell and is robustly orchestrated by an interplay of hyperpolarization activated cyclic nucleotide gated channels (HCN) and calcium-ion channels. It has been shown that decreased expression of HCN is correlated to Alzheimer's Diseased (AD). In early stages of AD, alpha is known to be down-regulated and lowered in coherence. We use this well characterized and quantified rhythm to understand the changes in ion channel properties that lead to disruption of alpha as seen in AD in a biophysically detailed network model of the thalamo-cortical circuit that generates the alpha-rhythm. Our computational model allows us to explore the causal links between alpha rhythms, HCN channels and amyloid-beta aggregation. The most commonly used drugs(acetylcholinesterase inhibitors) in AD increase the duration and level of acetylcholine and provide temporary symptomatic relief in a limited cases. Our simulations show how increasing acetylcholine can provide rescue for small range of aberrant HCN. The model predicts that lowering of the alpha-rhythm can modify the network activity in the thalamo-cortical circuit and lead to an increase in the inhibitory drive to the thalamus.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5VZ3AVWT\\Sharma and Nadkarni - 2018 - Biophysical basis of alpha rhythm disruption in Al.pdf},
  journal = {bioRxiv},
  language = {en}
}

@article{sharpe_schoenbaum_2017,
  title = {Dopamine Transients Are Sufficient and Necessary for Acquisition of Model-Based Associations},
  author = {Sharpe, Melissa J and Chang, Chun Yun and Liu, Melissa A and Batchelor, Hannah M and Mueller, Lauren E and Jones, Joshua L and Niv, Yael and Schoenbaum, Geoffrey},
  year = {2017},
  volume = {20},
  issn = {1097-6256},
  doi = {10.1038/nn.4538},
  abstract = {Associative learning is driven by prediction errors. Dopamine transients correlate with these errors, which current interpretations limit to endowing cues with a scalar quantity reflecting the value of future rewards. We tested whether dopamine might act more broadly to support learning of an associative model of the environment. Using sensory preconditioning, we show that prediction errors underlying stimulus-stimulus learning can be blocked behaviorally and reinstated by optogenetically activating dopamine neurons. We further show that suppressing the firing of these neurons across the transition prevents normal stimulus-stimulus learning. These results establish that the acquisition of model-based information about transitions between nonrewarding events is also driven by prediction errors and that, contrary to existing canon, dopamine transients are both sufficient and necessary to support this type of learning. Our findings open new possibilities for how these biological signals might support associative learning in the mammalian brain in these and other contexts.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\R6AYBQI7\\Sharpe et al. - 2017 - Dopamine transients are sufficient and necessary for acquisition of model-based associations.pdf},
  journal = {Nature Neuroscience},
  number = {5},
  pmid = {28368385}
}

@article{shay_hasselmo_2015,
  title = {Rebound Spiking in Layer {{II}} Medial Entorhinal Cortex Stellate Cells: {{Possible}} Mechanism of Grid Cell Function},
  author = {Shay, Christopher F. and Ferrante, Michele and Chapman, G William and Hasselmo, Michael E},
  year = {2015},
  issn = {10959564},
  doi = {10.1016/j.nlm.2015.09.004},
  abstract = {Rebound spiking properties of medial entorhinal cortex (mEC) stellate cells induced by inhibition may underlie their functional properties in awake behaving rats, including the temporal phase separation of distinct grid cells and differences in grid cell firing properties. We investigated rebound spiking properties using whole cell patch recording in entorhinal slices, holding cells near spiking threshold and delivering sinusoidal inputs, superimposed with realistic inhibitory synaptic inputs to test the capacity of cells to selectively respond to specific phases of inhibitory input. Stellate cells showed a specific phase range of hyperpolarizing inputs that elicited spiking, but non-stellate cells did not show phase specificity. In both cell types, the phase range of spiking output occurred between the peak and subsequent descending zero crossing of the sinusoid. The phases of inhibitory inputs that induced spikes shifted earlier as the baseline sinusoid frequency increased, while spiking output shifted to later phases. Increases in magnitude of the inhibitory inputs shifted the spiking output to earlier phases. Pharmacological blockade of h-current abolished the phase selectivity of hyperpolarizing inputs eliciting spikes. A network computational model using cells possessing similar rebound properties as found in vitro produces spatially periodic firing properties resembling grid cell firing when a simulated animal moves along a linear track. These results suggest that the ability of mEC stellate cells to fire rebound spikes in response to a specific range of phases of inhibition could support complex attractor dynamics that provide completion and separation to maintain spiking activity of specific grid cell populations.},
  copyright = {All rights reserved},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LFMBE5W3\\Shay et al. - 2015 - Rebound spiking in layer II medial entorhinal cortex stellate cells Possible mechanism of grid cell function(2).pdf},
  journal = {Neurobiology of Learning and Memory},
  keywords = {H-current,Inhibition,Oscillations,Resonance},
  pmid = {26385258}
}

@article{shea_frith_2019,
  title = {The {{Global Workspace Needs Metacognition}}},
  author = {Shea, Nicholas and Frith, Chris D.},
  year = {2019},
  month = jul,
  volume = {23},
  pages = {560--571},
  issn = {13646613},
  doi = {10.1016/j.tics.2019.04.007},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CL5MXUVN\\Shea and Frith - 2019 - The Global Workspace Needs Metacognition.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {7}
}

@book{shea_shea_2018,
  title = {Representation in {{Cognitive Science}}},
  author = {Shea, Nicholas},
  year = {2018},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RPZ8I489\\Shea - Unknown - Representation in Cognitive Science.pdf}
}

@article{shein_shein_2017,
  title = {A Spiking Neural Network of State Transition Probabilities in Model-Based Reinforcement Learning},
  author = {Shein, Mariah},
  year = {2017},
  pages = {69},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5PQTZSE5\\Shein - Unknown - A spiking neural network of state transition probabilities in model-based reinforcement learning.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\FXGNXWZ7\\Shein - Unknown - A spiking neural network of state transition probabilities in model-based reinforcement learning.pdf}
}

@article{shenoyhandiru_guan_2017,
  title = {{{EEG}} Source Space Analysis of the Supervised Factor Analytic Approach for the Classification of Multi-Directional Arm Movement},
  author = {Shenoy Handiru, Vikram and Vinod, A P and Guan, Cuntai},
  year = {2017},
  volume = {14},
  pages = {046008},
  issn = {1741-2560},
  doi = {10.1088/1741-2552/aa6baf},
  abstract = {Objective . In electroencephalography (EEG)-based brain\textendash computer interface (BCI) systems for motor control tasks the conventional practice is to decode motor intentions by using scalp EEG. However, scalp EEG only reveals certain limited information about the complex tasks of movement with a higher degree of freedom. Therefore, our objective is to investigate the effectiveness of source-space EEG in extracting relevant features that discriminate arm movement in multiple directions. Approach . We have proposed a novel feature extraction algorithm based on supervised factor analysis that models the data from source-space EEG. To this end, we computed the features from the source dipoles confined to Brodmann areas of interest (BA4a, BA4p and BA6). Further, we embedded class-wise labels of multi-direction (multi-class) source-space EEG to an unsupervised factor analysis to make it into a supervised learning method. Main Results . Our approach provided an average decoding accuracy of 71\% for the classification of hand movement in four orthogonal directions, that is significantly higher (\textbackslash textgreater10\%) than the classification accuracy obtained using state-of-the-art spatial pattern features in sensor space. Also, the group analysis on the spectral characteristics of source-space EEG indicates that the slow cortical potentials from a set of cortical source dipoles reveal discriminative information regarding the movement parameter, direction. Significance . This study presents evidence that low-frequency components in the source space play an important role in movement kinematics, and thus it may lead to new strategies for BCI-based neurorehabilitation.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2PJIC2VU\\Shenoy Handiru, Vinod, Guan - 2017 - EEG source space analysis of the supervised factor analytic approach for the classification of mult.pdf},
  journal = {Journal of Neural Engineering},
  number = {4}
}

@article{shepard_shepard_1982,
  title = {Geometrical Approximations to the Structure of Musical Pitch},
  author = {Shepard, Roger N},
  year = {1982},
  volume = {89},
  pages = {335--353},
  issn = {0033-295X},
  doi = {10.1037/0033-295X.89.4.305},
  abstract = {Suggests that rectilinear scales of pitch can account for the similarity of tones close together in frequency but not for the heightened relations at special intervals that arise when the tones are interpreted musically. Increasingly adequate accounts of musical pitch are provided by increasingly generalized, geometrically regular helical structures: a simple helix, a double helix, and a double helix wound around a torus in 4 dimensions or around a higher-order helical cylinder in 5 dimensions. A 2-dimensional "melodic map" of these double-helical structures provides for optimally compact representations of musical scales and melodies. A 2-dimensional "harmonic map," obtained by an affine transformation of the melodic map, provides for optimally compact representations of chords and harmonic relations. It is isomorphic to the toroidal structure that C. L. Krumhansl and F. J. Kessler (see record 1982-27246-001) use to represent the psychological relations among musical keys. (127 ref)},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PTPFV8WP\\Burton - 1963 - Psychological review.pdf},
  journal = {Psychological Review},
  number = {4},
  pmid = {7134331}
}

@article{sheremata_somers_2010,
  title = {Hemispheric Asymmetry in Visuotopic Posterior Parietal Cortex Emerges with Visual Short-Term Memory Load.},
  author = {Sheremata, Summer L and Bettencourt, Katherine C and Somers, David C},
  year = {2010},
  month = sep,
  volume = {30},
  pages = {12581--12588},
  issn = {1529-2401},
  doi = {10.1523/JNEUROSCI.2689-10.2010},
  abstract = {Visual short-term memory (VSTM) briefly maintains a limited sampling from the visual world. Activity in the intraparietal sulcus (IPS) tightly correlates with the number of items stored in VSTM. This activity may occur in or near to multiple distinct visuotopically mapped cortical areas that have been identified in IPS. To understand the topographic and spatial properties of VSTM, we investigated VSTM activity in visuotopic IPS regions using functional magnetic resonance imaging. VSTM drove areas IPS0-2, but largely spared IPS3-4. Under visual stimulation, these areas in both hemispheres code the contralateral visual hemifield. In contrast to the hemispheric symmetry observed with visual stimulation, an asymmetry emerged during VSTM with increasing memory load. The left hemisphere exhibited load-dependent activity only for contralateral memory items; right hemisphere activity reflected VSTM load regardless of visual-field location. Our findings demonstrate that VSTM induces a switch in spatial representation in right hemisphere IPS from contralateral to full-field coding. The load dependence of right hemisphere effects argues that memory-dependent and/or attention-dependent processes drive this change in spatial processing. This offers a novel means for investigating spatial-processing impairments in hemispatial neglect.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PCPBFIPZ\\Sheremata, Bettencourt, Somers - 2010 - Hemispheric asymmetry in visuotopic posterior parietal cortex emerges with visual short-term mem.pdf},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  keywords = {Attention,Attention: physiology,Brain Mapping,Computer-Assisted,Female,Functional Laterality,Functional Laterality: physiology,Humans,Image Processing,Magnetic Resonance Imaging,Male,Memory,Parietal Lobe,Parietal Lobe: physiology,Photic Stimulation,Psychomotor Performance,Psychomotor Performance: physiology,Short-Term,Short-Term: physiology,Visual Cortex,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology},
  number = {38},
  pmid = {20861364}
}

@article{sherfey_kopell_2018,
  title = {Flexible Resonance in Prefrontal Networks with Strong Feedback Inhibition},
  author = {Sherfey, Jason S. and Ardid, Salva and Hass, Joachim and Hasselmo, Michael E. and Kopell, Nancy J.},
  editor = {Doiron, Brent},
  year = {2018},
  month = aug,
  volume = {14},
  pages = {e1006357},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1006357},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZJBL5T2K\\Sherfey et al. - 2018 - Flexible resonance in prefrontal networks with str.pdf},
  journal = {PLOS Computational Biology},
  language = {en},
  number = {8}
}

@techreport{sherfey_kopell_2019,
  title = {Prefrontal Oscillations Modulate the Propagation of Neuronal Activity Required for Working Memory},
  author = {Sherfey, Jason S. and Ardid, Salva and Miller, Earl K. and Hasselmo, Michael E. and Kopell, Nancy J.},
  year = {2019},
  month = jan,
  institution = {{Neuroscience}},
  doi = {10.1101/531574},
  abstract = {Abstract           Cognition involves using attended information, maintained in working memory (WM), to guide action. During a cognitive task, a correct response requires flexible, selective gating so that only the appropriate information flows from WM to downstream effectors that carry out the response. In this work, we used biophysically-detailed modeling to explore the hypothesis that network oscillations in prefrontal cortex (PFC), leveraging local inhibition, can independently gate responses to items in WM. The key role of local inhibition was to control the period between spike bursts in the outputs, and to produce an oscillatory response no matter whether the WM item was maintained in an asynchronous or oscillatory state. We found that the WM item that induced an oscillatory population response in the PFC output layer with the shortest period between spike bursts was most reliably propagated. The network resonant frequency (i.e., the input frequency that produces the largest response) of the output layer can be flexibly tuned by varying the excitability of deep layer principal cells. Our model suggests that experimentally-observed modulation of PFC beta-frequency (15-30 Hz) and gamma-frequency (30-80 Hz) oscillations could leverage network resonance and local inhibition to govern the flexible routing of signals in service to cognitive processes like gating outputs from working memory and the selection of rule-based actions. Importantly, we show for the first time that nonspecific changes in deep layer excitability can tune the output gate's resonant frequency, enabling the specific selection of signals encoded by populations in asynchronous or fast oscillatory states. More generally, this represents a dynamic mechanism by which adjusting network excitability can govern the propagation of asynchronous and oscillatory signals throughout neocortex.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JAABW27T\\Sherfey et al. - 2019 - Prefrontal oscillations modulate the propagation o.pdf},
  language = {en},
  type = {Preprint}
}

@article{sherfey_sherfey_2017,
  title = {Prefrontal Rhythms for Cognitive Control},
  author = {Sherfey, Jason S},
  year = {2017},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YISNEFPN\\Sherfey - Prefrontal rhythms for cognitive control.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\YKYHETPN\\Sherfey - 2017 - Prefrontal rhythms for cognitive control.pdf}
}

@book{sherman_guillery_2006,
  title = {Exploring the {{Thalamus}} and {{Its Role}} in {{Cortical Function}}, {{Second Edition}}},
  author = {Sherman, S Murray and Guillery, R W},
  year = {2006},
  publisher = {{Springer-Verlag}},
  address = {{Cambridge, MA}},
  abstract = {The thalamus is a group of cells placed centrally in the brain that serve a critical role in controlling how both sensory and motor signals are passed from one part of the cerebral cortex to another. Essentially, all information reaching the cerebral cortex and thus consciousness is relayed through the thalamus. The role of the thalamus in controlling the flow of information (such as visual, auditory, and motor) to the cortex has only recently begun to be understood. This book provides an in-depth look at the function of the thalamus and its role as relayer of information to the cerebral cortex. The authors explore how the thalamus controls messages that are passed to the cortex and they introduce the novel suggestion that the thalamus serves a critical role in controlling how messages pass from one part of the cortex to another. Exploring the Thalamus is a comprehensive, up-to-date reference for researchers. It discusses problems concerning the function and structure of the thalamus and concludes each chapter with thought-provoking questions regarding future research.Key Features: Focuses on thalamocortical interrelationships Discusses important problems concerning the function and structure of the thalamus Concludes each chapter with thought-provoking questions requiring future research},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IJT48BKU\\Sherman, Guillery - 2006 - Exploring the Thalamus and Its Role in Cortical Function, Second Edition.pdf},
  isbn = {978-0-262-51344-9}
}

@book{sherman_guillery_2006a,
  title = {Exploring the {{Thalamus}} and {{Its Role}} in {{Cortical Function}}},
  author = {Sherman, S. M. and Guillery, R. W.},
  year = {2006},
  doi = {10.1007/0-387-22733-4_12},
  abstract = {The thalamus is a group of cells placed centrally in the brain that serve a critical role in controlling how both sensory and motor signals are passed from one part of the cerebral cortex to another. Essentially, all information reaching the cerebral cortex and thus consciousness is relayed through the thalamus. The role of the thalamus in controlling the flow of information (such as visual, auditory, and motor) to the cortex has only recently begun to be understood. This book provides an in-depth look at the function of the thalamus and its role as relayer of information to the cerebral cortex. The authors explore how the thalamus controls messages that are passed to the cortex and they introduce the novel suggestion that the thalamus serves a critical role in controlling how messages pass from one part of the cortex to another. Exploring the Thalamus is a comprehensive, up-to-date reference for researchers. It discusses problems concerning the function and structure of the thalamus and concludes each chapter with thought-provoking questions regarding future research.Key Features: Focuses on thalamocortical interrelationships Discusses important problems concerning the function and structure of the thalamus Concludes each chapter with thought-provoking questions requiring future research},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\76XJELRI\\Sherman, Guillery - 2006 - Exploring the Thalamus and Its Role in Cortical Function.pdf},
  isbn = {978-0-12-305460-9},
  pmid = {11998968}
}

@article{sherman_jones_2016,
  title = {Neural Mechanisms of Transient Neocortical Beta Rhythms: {{Converging}} Evidence from Humans, Computational Modeling, Monkeys, and Mice},
  author = {Sherman, Maxwell A and Lee, Shane and Law, Robert and Haegens, Saskia and Thorn, Catherine A and H{\"a}m{\"a}l{\"a}inen, Matti S and Moore, Christopher I and Jones, Stephanie R},
  year = {2016},
  doi = {10.1073/pnas.1604135113},
  abstract = {Human neocortical 15-29-Hz beta oscillations are strong predictors of perceptual and motor performance. However, the mechanistic origin of beta in vivo is unknown, hindering understanding of its functional role. Combining human magnetoencephalography (MEG), computational modeling, and laminar recordings in animals, we present a new theory that accounts for the origin of spontaneous neocortical beta. In our MEG data, spontaneous beta activity from somatosensory and frontal cortex emerged as noncontinuous beta events typically lasting \textbackslash textless150 ms with a stereotypical waveform. Computational modeling uniquely designed to infer the electrical currents underlying these signals showed that beta events could emerge from the integration of nearly synchronous bursts of ex-citatory synaptic drive targeting proximal and distal dendrites of pyramidal neurons, where the defining feature of a beta event was a strong distal drive that lasted one beta period ({$\sim$}50 ms). This beta mechanism rigorously accounted for the beta event profiles ; several other mechanisms did not. The spatial location of synaptic drive in the model to supragranular and infragranular layers was critical to the emergence of beta events and led to the prediction that beta events should be associated with a specific laminar current profile. Laminar recordings in somatosensory neocortex from anesthetized mice and awake monkeys supported these predictions, suggesting this beta mechanism is conserved across species and recording modalities. These findings make several predictions about optimal states for perceptual and motor performance and guide causal interventions to modulate beta for optimal function. beta rhythm | magnetoencephalography | computational modeling | sensorimotor processing | Parkinson's disease B eta band rhythms (15-29 Hz) are a commonly observed activity pattern in the brain. They are found with magneto-encephalography (MEG) (1-4), EEG (5, 6), and local field potential (LFP) recordings from neocortex (7-9) and are preserved across species (10). Local beta oscillations and their coordination between regions are implicated in numerous functions, including sensory perception, selective attention, and motor planning and initiation (2, 3, 6, 7, 9, 11-15). Neocortical beta oscillations are disrupted in various neuropathologies, most notably Parkinson's disease (PD), in which treatments that alleviate motor symptoms also reverse the neocortical beta disruption (16, 17). Although associations between beta and performance suggest a crucial role in brain function, beta rhythmicity might not be important per se but instead may be an epiphenomenal consequence of other important processes. Discovering how beta emerges at the cellular and network levels is crucial to understanding why beta is such a clear predictor of performance in many domains. A major, unresolved point of debate concerns the locus of beta generation. One prominent view is that beta is generated in basal ganglia and thalamic structures and that neocortical beta is an entrained reflection of these inputs. Alternatively, beta may emerge within the neocortex as a consequence of internal dynamics. An intermediate view, supported by the model presented here, is that beta emerges in the neocortex but is dependent on extrinsic synaptic drive that could originate from basal ganglia/ thalamus. Consistent with the first view, beta has been robustly observed in LFP signals from basal ganglia nuclei including the subthalamic nucleus, striatum, and globus pallidus (18, 19), and computational models have proposed mechanisms by which beta rhythms can emerge via interactions within and between these circuits (20, 21). Other studies have suggested that the neocortex itself has unique properties that generate beta rhythms through spike-mediated synaptic and electrical interactions within local circuits (22-25) or that beta in early-sensory neocortical areas could be driven in a top-down manner from frontal cortex during attentive states (26). Understanding the temporal and spectral nature of a specific beta signal is critical to uncovering its mechanism of generation and its role in the precise local circuit and context in which it is observed. A common view of beta "rhythms" is that they are sustained in time for many cycles, up to seconds in duration. The view of beta as a sustained rhythm is consistent with several papers that have reported what appears to be a continuous, high-power increase in beta activity, for example during a planning or Significance Neocortical beta is one of the most prominent signatures of neural activity measured noninvasively in humans. Beta expression is a strong predictor of healthy and pathological perceptual and motor performance. However, there is considerable debate as to whether beta itself is causally important in information and disease processes. Key to resolving this debate is understanding the neural mechanisms inducing beta. Here, building on prior work, we combined human magneto-encephalography, computational modeling, and laminar recordings in mice and monkeys to establish and test a new theory explaining the emergence of spontaneous transient neocortical beta events in somatosensory and frontal cortex. Our results enable a principled understanding of neocortical beta and can help guide studies seeking to understand its relation to function. Author contributions: M.A.S., S.L., C.I.M., and S.R.J. designed research; M.A.S., S.L., R.L., S.H., and C.A.T. performed research; M.A.S., S.L., and M.S.H. contributed new reagents/analytic tools; M.A.S., R.L., and S.H. analyzed data; and M.A.S., S.L., C.I.M., and S.R.J. wrote the paper.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SK7YDLEA\\Sherman et al. - 2016 - Neural mechanisms of transient neocortical beta rhythms Converging evidence from humans, computational modeli(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\ZWP2CS7R\\Sherman et al. - 2016 - Neural mechanisms of transient neocortical beta rhythms Converging evidence from humans, computational modeli(2).pdf},
  keywords = {beta,model}
}

@article{sherrill_stern_2015,
  title = {Functional Connections between Optic Flow Areas and Navigationally Responsive Brain Regions during Goal-Directed Navigation},
  author = {Sherrill, Katherine R and Chrastil, Elizabeth R and Ross, Robert S and Erdem, U{\v g}ur M and Hasselmo, Michael E and Stern, Chantal E},
  year = {2015},
  volume = {118},
  pages = {386--396},
  issn = {10959572},
  doi = {10.1016/j.neuroimage.2015.06.009},
  abstract = {Recent computational models suggest that visual input from optic flow provides information about egocentric (navigator-centered) motion and influences firing patterns in spatially tuned cells during navigation. Computationally, self-motion cues can be extracted from optic flow during navigation. Despite the importance of optic flow to navigation, a functional link between brain regions sensitive to optic flow and brain regions important for navigation has not been established in either humans or animals. Here, we used a beta-series correlation methodology coupled with two fMRI tasks to establish this functional link during goal-directed navigation in humans. Functionally defined optic flow sensitive cortical areas V3A, V6, and hMT+ were used as seed regions. fMRI data was collected during a navigation task in which participants updated position and orientation based on self-motion cues to successfully navigate to an encoded goal location. The results demonstrate that goal-directed navigation requiring updating of position and orientation in the first person perspective involves a cooperative interaction between optic flow sensitive regions V3A, V6, and hMT+ and the hippocampus, retrosplenial cortex, posterior parietal cortex, and medial prefrontal cortex. These functional connections suggest a dynamic interaction between these systems to support goal-directed navigation.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\47BI2EYQ\\Sherrill et al. - 2015 - Functional connections between optic flow areas and navigationally responsive brain regions during goal-directe.pdf},
  journal = {NeuroImage},
  keywords = {FMRI,Hippocampus,MT,Retrosplenial cortex,V3A,V6},
  pmid = {26054874}
}

@article{sherrill_stern_2018,
  title = {Structural Differences in Hippocampal and Entorhinal Gray Matter Volume Support Individual Difference in First-Person Navigational Ability},
  author = {Sherrill, Katherine R and Chrastil, Elizabeth R and Aselcioglu, Irem and Hasselmo, Michael E and Stern, Chantal E},
  year = {2018},
  issn = {0306-4522},
  doi = {10.1016/j.neuroscience.2018.04.006},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L7HMRI6N\\Sherrill et al. - 2018 - Structural differences in hippocampal and entorhinal gray matter volume support individual difference in first-.pdf},
  journal = {Neuroscience},
  keywords = {human,mri,navigation,structural,thalamus,vbm},
  number = {April}
}

@article{shi_woo_2015,
  ids = {shi.woo.2015a},
  title = {Convolutional {{LSTM Network}}: {{A Machine Learning Approach}} for {{Precipitation Nowcasting}}},
  author = {Shi, Xingjian and Chen, Zhourong and Wang, Hao and Yeung, Dit-Yan and Wong, Wai-kin and Woo, Wang-chun},
  year = {2015},
  pages = {9},
  abstract = {The goal of precipitation nowcasting is to predict the future rainfall intensity in a local region over a relatively short period of time. Very few previous studies have examined this crucial and challenging weather forecasting problem from the machine learning perspective. In this paper, we formulate precipitation nowcasting as a spatiotemporal sequence forecasting problem in which both the input and the prediction target are spatiotemporal sequences. By extending the fully connected LSTM (FC-LSTM) to have convolutional structures in both the input-to-state and state-to-state transitions, we propose the convolutional LSTM (ConvLSTM) and use it to build an end-to-end trainable model for the precipitation nowcasting problem. Experiments show that our ConvLSTM network captures spatiotemporal correlations better and consistently outperforms FC-LSTM and the state-of-theart operational ROVER algorithm for precipitation nowcasting.},
  archivePrefix = {arXiv},
  eprint = {1506.04214},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LS6K3CRX\\Shi et al. - 2015 - Convolutional LSTM Network A Machine Learning App.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\WKT9XSBB\\Shi et al. - Convolutional LSTM Network A Machine Learning App.pdf},
  language = {en}
}

@article{shimamura_shimamura_2014,
  title = {Remembering the {{Past}}},
  author = {Shimamura, Arthur P.},
  year = {2014},
  month = aug,
  volume = {23},
  pages = {257--263},
  issn = {0963-7214},
  doi = {10.1177/0963721414536181},
  abstract = {Our ability to remember past events requires effic; such as the time; place; people; thoughts; and feelings associated with a past experience. Ne; medial temporal lobe; and ventral posterior parietal cortex that interac; I present an analysis of the neural correlates of ; along with a theoretical framework; Cortical Binding of Relational Activity (CoBRA); that integrates the dynamic links between efficien},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VW7QYU2E\\Shimamura - 2014 - Remembering the Past.pdf},
  journal = {Current Directions in Psychological Science},
  keywords = {encoding,episodic memory,for dinner last night,if you were able,in my case,it is likely,paella,parietal cortex,retrieval recollection,to retrieve the information},
  number = {4}
}

@article{shimoura_roque_2018,
  title = {Reimplementation of the {{Potjans}}-{{Diesmann}} Cortical Microcircuit Model: From {{NEST}} to {{Brian}}},
  shorttitle = {Reimplementation of the {{Potjans}}-{{Diesmann}} Cortical Microcircuit Model},
  author = {Shimoura, Renan Oliveira and Kamiji, Nilton Liuji and Pena, Rodrigo Felipe de Oliveira and Cordeiro, Vinicius Lima and Ceballos, Cesar Celis and Romaro, Cecilia and Roque, Antonio Carlos},
  year = {2018},
  month = jan,
  doi = {10.1101/248401},
  abstract = {This work targets the replicability of computational models to provide the community with tested and proven open-source models to be used in new studies and implementations. The Potjans-Diesmann model describes a cortical microcircuit containing two cell types (excitatory and inhibitory) distributed in four layers, and represents the cortical network below a surface of 1 mm                          . The original implementation of the Potjans-Diesmann model was based on the NEST simulator and our goal here was to re-implement the model in the Brian 2 simulator and obtain the same results presented in the reference article. We did not replicate analyses that involve changes in the network structure. Our replicated network model presents activity dynamic patterns very similar to the ones observed in the original model, with comparisons made in terms of firing rates and synchrony and irregularity measures. In conclusion, the Potjans-Diesmann model was successfully replicated in a different platform than the one in which it was originally implemented.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\C9AZCGRX\\Shimoura et al. - 2018 - Reimplementation of the Potjans-Diesmann cortical .pdf},
  journal = {bioRxiv},
  language = {en}
}

@techreport{shinder_taube_2018,
  title = {Three-Dimensional {{Tuning}} of {{Head Direction Cells}} in {{Rats}}},
  author = {Shinder, Michael E and Taube, Jeffrey S},
  year = {2018},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JH8WHVYA\\Shinder, Taube - 2018 - Three-dimensional Tuning of Head Direction Cells in Rats.pdf}
}

@article{shipp_shipp_2007,
  title = {Structure and Function of the Cerebral Cortex},
  author = {Shipp, Stewart},
  year = {2007},
  month = jun,
  volume = {17},
  pages = {R443-R449},
  issn = {09609822},
  doi = {10.1016/j.cub.2007.03.044},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RC6PKQIZ\\Shipp - 2007 - Structure and function of the cerebral cortex.pdf},
  journal = {Current Biology},
  language = {en},
  number = {12}
}

@article{shlens_shlens_2014,
  title = {Notes on {{Generalized Linear Models}} of {{Neurons}}},
  author = {Shlens, Jonathon},
  year = {2014},
  pages = {1--7},
  abstract = {Experimental neuroscience increasingly requires tractable models for analyzing and predicting the behavior of neurons and networks. The generalized linear model (GLM) is an increasingly popular statistical framework for analyzing neural data that is flexible, exhibits rich dynamic behavior and is computationally tractable (Paninski, 2004; Pillow et al., 2008; Truccolo et al., 2005). What follows is a brief summary of the primary equations governing the application of GLM's to spike trains with a few sentences linking this work to the larger statistical literature. Latter sections include extensions of a basic GLM to model spatio-temporal receptive fields as well as network activity in an arbitrary numbers of neurons.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XPWBDQIZ\\Shlens - 2014 - Notes on Generalized Linear Models of Neurons.pdf},
  journal = {Systems Neurobiology Laboratory, Salk Insitute for \textbackslash ldots}
}

@incollection{shrestha_orchard_2018,
  title = {{{SLAYER}}: {{Spike Layer Error Reassignment}} in {{Time}}},
  shorttitle = {{{SLAYER}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 31},
  author = {Shrestha, Sumit Bam and Orchard, Garrick},
  editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and {Cesa-Bianchi}, N. and Garnett, R.},
  year = {2018},
  pages = {1412--1421},
  publisher = {{Curran Associates, Inc.}},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MS45FEVX\\Shrestha et al. - 2018 - SLAYER Spike Layer Error Reassignment in Time.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\B9K4NPS2\\Shrestha et al. - 2018 - SLAYER Spike Layer Error Reassignment in Time.html}
}

@article{shukla_wright_2018,
  title = {Computing {{Generalized Matrix Inverse}} on {{Spiking Neural Substrate}}},
  author = {Shukla, Rohit and Khoram, Soroosh and Jorgensen, Erik and Li, Jing and Lipasti, Mikko and Wright, Stephen},
  year = {2018},
  volume = {12},
  issn = {1662-453X},
  doi = {10.3389/fnins.2018.00115},
  abstract = {Emerging neural hardware substrates, such as IBM's TrueNorth Neurosynaptic System, can provide an appealing platform for deploying numerical algorithms. For example, a recurrent Hopfield neural network can be used to find the Moore-Penrose generalized inverse of a matrix, thus enabling a broad class of linear optimizations to be solved efficiently, at low energy cost. However, deploying numerical algorithms on hardware platforms that severely limit the range and precision of representation for numeric quantities can be quite challenging. This paper discusses these challenges and proposes a rigorous mathematical framework for reasoning about range and precision on such substrates. The paper derives techniques for normalizing inputs and properly quantizing synaptic weights originating from arbitrary systems of linear equations, so that solvers for those systems can be implemented in a provably correct manner on hardware-constrained neural substrates. The analytical model is empirically validated on the IBM TrueNorth platform, and results show that the guarantees provided by the framework for range and precision hold under experimental conditions. Experiments with optical flow demonstrate the energy benefits of deploying a reduced-precision and energy-efficient generalized matrix inverse engine on the IBM TrueNorth platform, reflecting 10{$\square$} to 100{$\square$} improvement over FPGA and ARM core baselines.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L29BQ5HI\\shukla_et_al_2018_computing_generalized_matrix_inverse_on_spiking_neural_substrate.pdf},
  journal = {Frontiers in Neuroscience},
  language = {English}
}

@article{sidor_mcclung_2015,
  title = {In Vivo {{Optogenetic Stimulation}} of the {{Rodent Central Nervous System}}},
  author = {Sidor, Michelle M and Davidson, Thomas J and Tye, Kay M and Warden, Melissa R and Diesseroth, Karl and a. McClung, Colleen},
  year = {2015},
  pages = {1--8},
  issn = {1940-087X},
  doi = {10.1126/science.1259591},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IAN3FJ28\\Sidor et al. - 2015 - In vivo Optogenetic Stimulation of the Rodent Central Nervous System.pdf},
  journal = {Journal of Visualized Experiments}
}

@article{siegel_miller_2015,
  title = {Cortical Information Flow during Flexible Sensorimotor Decisions},
  author = {Siegel, Markus and Buschman, Timothy J and Miller, Earl K},
  year = {2015},
  volume = {348},
  pages = {1352--1355},
  issn = {10959203},
  doi = {10.1126/science.aab0551},
  abstract = {During flexible behavior, multiple brain regions encode sensory inputs, the current task, and choices. It remains unclear how these signals evolve. We simultaneously recorded neuronal activity from six cortical regions [middle temporal area (MT), visual area four (V4), inferior temporal cortex (IT), lateral intraparietal area (LIP), prefrontal cortex (PFC), and frontal eye fields (FEF)] of monkeys reporting the color or motion of stimuli. After a transient bottom-up sweep, there was a top-down flow of sustained task information from frontoparietal to visual cortex. Sensory information flowed from visual to parietal and prefrontal cortex. Choice signals developed simultaneously in frontoparietal regions and travelled to FEF and sensory cortex. This suggests that flexible sensorimotor choices emerge in a frontoparietal network from the integration of opposite flows of sensory and task information.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\22E7534J\\Siegel, Buschman, Miller - 2015 - Cortical information flow during flexible sensorimotor decisions(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\7XYJVAQ5\\Siegel, Buschman, Miller - 2015 - Cortical information flow during flexible sensorimotor decisions.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\EJBIZFWK\\Siegel et al. - 2015 - Cortical information flow during flexible sensorim.pdf},
  journal = {Science},
  number = {6241},
  pmid = {26089513}
}

@techreport{siegle_koch_2019,
  title = {A Survey of Spiking Activity Reveals a Functional Hierarchy of Mouse Corticothalamic Visual Areas},
  author = {Siegle, Joshua H. and Jia, Xiaoxuan and Durand, S{\'e}verine and Gale, Sam and Bennett, Corbett and Graddis, Nile and Heller, Greggory and Ramirez, Tamina K. and Choi, Hannah and Luviano, Jennifer A. and Groblewski, Peter A. and Ahmed, Ruweida and Arkhipov, Anton and Bernard, Amy and Billeh, Yazan N. and Brown, Dillan and Buice, Michael A. and Cain, Nicolas and Caldejon, Shiella and Casal, Linzy and Cho, Andrew and Chvilicek, Maggie and Cox, Timothy C. and Dai, Kael and Denman, Daniel J. and {de Vries}, Saskia E. J. and Dietzman, Roald and Esposito, Luke and Farrell, Colin and Feng, David and Galbraith, John and Garrett, Marina and Gelfand, Emily C. and Hancock, Nicole and Harris, Julie A. and Howard, Robert and Hu, Brian and Hytnen, Ross and Iyer, Ramakrishnan and Jessett, Erika and Johnson, Katelyn and Kato, India and Kiggins, Justin and Lambert, Sophie and Lecoq, Jerome and Ledochowitsch, Peter and Lee, Jung Hoon and Leon, Arielle and Li, Yang and Liang, Elizabeth and Long, Fuhui and Mace, Kyla and Melchior, Jose and Millman, Daniel and Mollenkopf, Tyler and Nayan, Chelsea and Ng, Lydia and Ngo, Kiet and Nguyen, Thuyahn and Nicovich, Philip R. and North, Kat and Ocker, Gabriel Koch and Ollerenshaw, Doug and Oliver, Michael and Pachitariu, Marius and Perkins, Jed and Reding, Melissa and Reid, David and Robertson, Miranda and Ronellenfitch, Kara and Seid, Sam and Slaughterbeck, Cliff and Stoecklin, Michelle and Sullivan, David and Sutton, Ben and Swapp, Jackie and Thompson, Carol and Turner, Kristen and Wakeman, Wayne and Whitesell, Jennifer D. and Williams, Derric and Williford, Ali and Young, Rob and Zeng, Hongkui and Naylor, Sarah and Phillips, John W. and Reid, R. Clay and Mihalas, Stefan and Olsen, Shawn R. and Koch, Christof},
  year = {2019},
  month = oct,
  institution = {{Neuroscience}},
  doi = {10.1101/805010},
  abstract = {Abstract                        The mammalian visual system, from retina to neocortex, has been extensively studied at both anatomical and functional levels. Anatomy indicates the cortico-thalamic system is hierarchical, but characterization of cellular-level functional interactions across multiple levels of this hierarchy is lacking, partially due to the challenge of simultaneously recording activity across numerous regions. Here, we describe a large, open dataset (part of the             Allen Brain Observatory             ) that surveys spiking from units in six cortical and two thalamic regions responding to a battery of visual stimuli. Using spike cross-correlation analysis, we find that inter-area functional connectivity mirrors the anatomical hierarchy from the             Allen Mouse Brain Connectivity Atlas             . Classical functional measures of hierarchy, including visual response latency, receptive field size, phase-locking to a drifting grating stimulus, and autocorrelation timescale are all correlated with the anatomical hierarchy. Moreover, recordings during a visual task support the behavioral relevance of hierarchical processing. Overall, this dataset and the hierarchy we describe provide a foundation for understanding coding and dynamics in the mouse cortico-thalamic visual system.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Y9TPWLKL\\Siegle et al. - 2019 - A survey of spiking activity reveals a functional .pdf},
  language = {en},
  type = {Preprint}
}

@article{sikos_kim_2009,
  title = {On the {{Road}} to {{Conventionalization}} : {{Analyses}} of {{Nominal Coercion}}},
  author = {Sikos, Les and Nielsen, Rodney D and Rood, Travis and Michaelis, Laura A and Palmer, Martha and Kim, Albert E},
  year = {2009},
  pages = {715078},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4VXH9ITA\\Sikos et al. - 2009 - On the Road to Conventionalization Analyses of Nominal Coercion.pdf},
  number = {March}
}

@article{sikos_palmer_2008,
  title = {Figurative {{Language}} : `` {{Meaning}} '' Is Often More than Just a Sum of the Parts},
  author = {Sikos, Les and Brown, Susan Windisch and Kim, Albert E and Michaelis, Laura A and Palmer, Martha},
  year = {2008},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\R75HDRF6\\Sikos et al. - 2008 - Figurative Language “ Meaning ” is often more than just a sum of the parts.pdf},
  keywords = {Technical Report FS-08-04},
  number = {Speaks}
}

@article{silva_ghaharamani_2007,
  title = {Analogical Reasoning with Relational {{Bayesian}} Sets},
  author = {Silva, Ricardo and Heller, KA and Ghaharamani, Z},
  year = {2007},
  volume = {26},
  pages = {3--28},
  issn = {15324435},
  doi = {10.1002/pfi.4170300209},
  abstract = {Analogical reasoning depends fundamentally on the ability to learn and generalize about relations between objects. There are many ways in which objects can be related, making automated analogical reasoning very chal- lenging. Here we develop an approach which, given a set of pairs of related objects S = A1:B1,A2:B2,...,AN:BN, measures how well other pairs A:B fit in with the set S. This addresses the question: is the relation between objects A and B analogous to those relations found in S? We recast this classi- cal problem as a problem of Bayesian analy- sis of relational data. This problem is non- trivial because direct similarity between ob- jects is not a good way of measuring analo- gies. For instance, the analogy between an electron around the nucleus of an atom and a planet around the Sun is hardly justified by isolated, non-relational, comparisons of an electron to a planet, and a nucleus to the Sun. We develop a generative model for predicting the existence of relationships and extend the framework of Ghahramani and Heller (2005) to provide a Bayesian measure for how anal- ogous a relation is to other relations. This sheds new light on an old problem, which we motivate and illustrate through practical ap- plications in exploratory data analysis.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FW7MV4QK\\Silva, Heller, Ghaharamani - 2007 - Analogical reasoning with relational Bayesian sets.pdf},
  journal = {11th International Conference on Artificial Intelligence and Statistics AISTATS},
  keywords = {analogy,bayesian inference,information retrieval},
  number = {2}
}

@article{silver_hassabis_2016,
  title = {Mastering the Game of {{Go}} with Deep Neural Networks and Tree Search},
  author = {Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  year = {2016},
  doi = {10.1038/nature16961},
  abstract = {All games of perfect information have an optimal value function, v * (s), which determines the outcome of the game, from every board position or state s, under perfect play by all players. These games may be solved by recursively computing the optimal value function in a search tree containing approximately b d possible sequences of moves, where b is the game's breadth (number of legal moves per position) and d is its depth (game length). In large games, such as chess (b {$\approx$} 35, d {$\approx$} 80) 1 and especially Go (b {$\approx$} 250, d {$\approx$} 150) 1 , exhaustive search is infeasible 2,3 , but the effective search space can be reduced by two general principles. First, the depth of the search may be reduced by position evaluation: truncating the search tree at state s and replacing the subtree below s by an approximate value function v(s) {$\approx$} v * (s) that predicts the outcome from state s. This approach has led to superhuman performance in chess 4 , checkers 5 and othello 6 , but it was believed to be intractable in Go due to the complexity of the game 7 . Second, the breadth of the search may be reduced by sampling actions from a policy p(a|s) that is a prob-ability distribution over possible moves a in position s. For example, Monte Carlo rollouts 8 search to maximum depth without branching at all, by sampling long sequences of actions for both players from a policy p. Averaging over such rollouts can provide an effective position evaluation, achieving superhuman performance in backgammon 8 and Scrabble 9 , and weak amateur level play in Go 10 . Monte Carlo tree search (MCTS) 11,12 uses Monte Carlo rollouts to estimate the value of each state in a search tree. As more simu-lations are executed, the search tree grows larger and the relevant values become more accurate. The policy used to select actions during search is also improved over time, by selecting children with higher values. Asymptotically, this policy converges to optimal play, and the evaluations converge to the optimal value function 12 . The strongest current Go programs are based on MCTS, enhanced by policies that are trained to predict human expert moves 13 . These policies are used to narrow the search to a beam of high-probability actions, and to sample actions during rollouts. This approach has achieved strong amateur play 13\textendash 15 . However, prior work has been limited to shallow policies 13\textendash 15 or value functions 16 based on a linear combination of input features. Recently, deep convolutional neural networks have achieved unprec-edented performance in visual domains: for example, image classifica-tion 17 , face recognition 18 , and playing Atari games 19 . They use many layers of neurons, each arranged in overlapping tiles, to construct increasingly abstract, localized representations of an image 20 . We employ a similar architecture for the game of Go. We pass in the board position as a 19 \texttimes{} 19 image and use convolutional layers to construct a representation of the position. We use these neural networks to reduce the effective depth and breadth of the search tree: evaluating positions using a value network, and sampling actions using a policy network. We train the neural networks using a pipeline consisting of several stages of machine learning (Fig. 1). We begin by training a supervised learning (SL) policy network p {$\sigma$} directly from expert human moves. This provides fast, efficient learning updates with immediate feedback and high-quality gradients. Similar to prior work 13,15},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L383YX2J\\Silver et al. - 2016 - Mastering the game of Go with deep neural networks and tree search.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\Q2GWE4TZ\\Silver et al. - 2016 - Mastering the game of Go with deep neural networks and tree search.pdf}
}

@article{simons_levin_1998,
  title = {Failure to Detect Changes to People during a Real-World Interaction},
  author = {Simons, Daniel J. and Levin, Daniel T.},
  year = {1998},
  month = dec,
  volume = {5},
  pages = {644--649},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/BF03208840},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\E3T2RTUJ\\Simons and Levin - 1998 - Failure to detect changes to people during a real-.pdf},
  journal = {Psychonomic Bulletin \& Review},
  language = {en},
  number = {4}
}

@book{singer_singer_2019,
  title = {The Neocortex},
  editor = {Singer, W.},
  year = {2019},
  publisher = {{The MIT Press}},
  address = {{Cambridge, MA}},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DKSPS7VM\\Singer - 2019 - The neocortex.pdf},
  isbn = {978-0-262-04324-3},
  language = {en},
  lccn = {QP383.12 .N44 2019},
  series = {Str\"ungmann Forum Reports}
}

@article{singh_ahn_2019,
  title = {Sequential {{Neural Processes}}},
  author = {Singh, Gautam and Yoon, Jaesik and Son, Youngsung and Ahn, Sungjin},
  year = {2019},
  month = jun,
  abstract = {Neural processes combine the strengths of neural networks and Gaussian processes to achieve both flexible learning and fast prediction of stochastic processes. However, neural processes do not consider the temporal dependency structure of underlying processes and thus are limited in modeling a large class of problems with temporal structure. In this paper, we propose Sequential Neural Processes (SNP). By incorporating temporal state-transition model into neural processes, the proposed model extends the potential of neural processes to modeling dynamic stochastic processes. In applying SNP to dynamic 3D scene modeling, we also introduce the Temporal Generative Query Networks. To our knowledge, this is the first 4D model that can deal with temporal dynamics of 3D scenes. In experiments, we evaluate the proposed methods in dynamic (non-stationary) regression and 4D scene inference and rendering.},
  archivePrefix = {arXiv},
  eprint = {1906.10264},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\49LC5NJT\\Singh_et_al_2019_Sequential_Neural_Processes.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\L6D5M7MI\\1906.html},
  journal = {arXiv:1906.10264 [cs, stat]},
  primaryClass = {cs, stat}
}

@article{singh_singh_2006,
  title = {Higher-{{Dimensional Neurons Explain}} the {{Tuning}} and {{Dynamics}} of {{Working Memory Cells}}},
  author = {Singh, Ray},
  year = {2006},
  volume = {26},
  pages = {3667--3678},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.4864-05.2006},
  abstract = {Measurements of neural activity in working memory during a somatosensory discrimination task show that the content of working memory is not only stimulus dependent but also strongly time varying. We present a biologically plausible neural model that reproduces the wide variety of characteristic responses observed in those experiments. Central to our model is a heterogeneous ensemble of two-dimensional neurons that are hypothesized to simultaneously encode two distinct stimuli dimensions. We demonstrate that the spiking activity of each neuron in the population can be understood as the result of a two-dimensional state space trajectory projected onto the tuning curve of the neuron. The wide variety of observed responses is thus a natural consequence of a population of neurons with a diverse set of preferred stimulus vectors and response functions in this two-dimensional space. In addition, we propose a taxonomy of network topologies that will generate the two-dimensional trajectory necessary to exploit this population. We conclude by proposing some experimental indicators to help distinguish among these possibilities.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CZVZTFQQ\\Singh - 2006 - Higher-Dimensional Neurons Explain the Tuning and Dynamics of Working Memory Cells.pdf},
  journal = {Journal of Neuroscience},
  keywords = {cognitive,computational model,neural dynamics,population coding,reward uncertainty,working-memory},
  number = {14},
  pmid = {16597721}
}

@article{singh_singh_2012,
  title = {Which "Neural Activity" Do You Mean? {{fMRI}}, {{MEG}}, Oscillations and Neurotransmitters},
  author = {Singh, Krish D.},
  year = {2012},
  volume = {62},
  pages = {1121--1130},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2012.01.028},
  abstract = {Over the last 20. years, BOLD-FMRI has proved itself to be a powerful and versatile tool for the study of the neural substrate underpinning many of our cognitive and perceptual functions. However, exactly how it is coupled to the underlying neurophysiology, and how this coupling varies across the brain, across tasks and across individuals is still unclear. The story is further complicated by the fact that within the same cortical region, multiple evoked and induced oscillatory effects may be modulated during task execution, supporting different cognitive roles, and any or all of these may have metabolic demands that then drive the BOLD response. In this paper I shall concentrate on one experimental approach to shedding light on this problem i.e. the execution of the same experimental tasks using MEG and fMRI in order to reveal which electrophysiological responses best match the BOLD response spatially, temporally and functionally. The results demonstrate a rich and complex story that does not fit with a simplistic view of BOLD reflecting "neural activity" and suggests that we could consider the coupling between BOLD and the various parameters of neural function as an ill-posed inverse problem. Finally, I describe recent work linking individual variability in both cortical oscillations and the BOLD-fMRI response to variability in endogenous GABA concentration. ?? 2012 Elsevier Inc.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\I3YAFC6K\\Singh - 2012 - Which neural activity do you mean fMRI, MEG, oscillations and neurotransmitters.pdf},
  journal = {NeuroImage},
  keywords = {Behaviour,FMRI,GABA,MEG,Oscillations,Variability,Vision},
  number = {2},
  pmid = {22248578}
}

@article{sinz_tolias_2019,
  title = {Engineering a {{Less Artificial Intelligence}}},
  author = {Sinz, Fabian H. and Pitkow, Xaq and Reimer, Jacob and Bethge, Matthias and Tolias, Andreas S.},
  year = {2019},
  month = sep,
  volume = {103},
  pages = {967--979},
  issn = {08966273},
  doi = {10.1016/j.neuron.2019.08.034},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IC3IG3EH\\Sinz et al. - 2019 - Engineering a Less Artificial Intelligence.pdf},
  journal = {Neuron},
  language = {en},
  number = {6}
}

@article{skaggs_barnes_1996,
  title = {Theta Phase Precession in Hippocampal Neuronal Populations and the Compression of Temporal Sequences},
  author = {Skaggs, William E and McNaughton, Bruce L and a. Wilson, Matthew and a. Barnes, Carol},
  year = {1996},
  volume = {6},
  pages = {149--172},
  issn = {10509631},
  doi = {10.1002/(SICI)1098-1063(1996)6:2<149::AID-HIPO6>3.0.CO;2-K},
  abstract = {O'Keefe and Recce [1993] Hippocampus 3:317-330 described an interaction between the hippocampal theta rhythm and the spatial firing of pyramidal cells in the CA1 region of the rat hippocampus: they found that a cell's spike activity advances to earlier phases of the theta cycle as the rat passes through the cell's place field. The present study makes use of large-scale parallel recordings to clarify and extend this finding in several ways: 1) Most CA1 pyramidal cells show maximal activity at the same phase of the theta cycle. Although individual units exhibit deeper modulation, the depth of modulation of CA1 population activity is about 50\{\%\}. The peak firing of inhibitory interneurons in CA1 occurs about 60 degrees in advance of the peak firing of pyramidal cells, but different interneurons vary widely in their peak phases. 2) The first spikes, as the rat enters a pyramidal cell's place field, come 90 degrees-120 degrees after the phase of maximal pyramidal cell population activity, near the phase where inhibition is least. 3) The phase advance is typically an accelerating, rather than linear, function of position within the place field. 4) These phenomena occur both on linear tracks and in two-dimensional environments where locomotion is not constrained to specific paths. 5) In two-dimensional environments, place-related firing is more spatially specific during the early part of the theta cycle than during the late part. This is also true, to a lesser extent, on a linear track. Thus, spatial selectivity waxes and wanes over the theta cycle. 6) Granule cells of the fascia dentata are also modulated by theta. The depth of modulation for the granule cell population approaches 100\{\%\}, and the peak activity of the granule cell population comes about 90 degrees earlier in the theta cycle than the peak firing of CA1 pyramidal cells. 7) Granule cells, like pyramidal cells, show robust phase precession. 8) Cross-correlation analysis shows that portions of the temporal sequence of CA1 pyramidal cell place fields are replicated repeatedly within individual theta cycles, in highly compressed form. The compression ratio can be as much as 10:1. These findings indicate that phase precession is a very robust effect, distributed across the entire hippocampal population, and that it is likely to be inherited from the fascia dentata or an earlier stage in the hippocampal circuit, rather than generated intrinsically within CA1. It is hypothesized that the compression of temporal sequences of place fields within individual theta cycles permits the use of long-term potentiation for learning of sequential structure, thereby giving a temporal dimension to hippocampal memory traces.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SP6P2ILL\\Skaggs et al. - 1996 - Theta phase precession in hippocampal neuronal populations and the compression of temporal sequences.pdf},
  journal = {Hippocampus},
  keywords = {CA1,Fascia dentata,Long-term potentiation,Phase coding,Place cells},
  number = {2},
  pmid = {8797016}
}

@article{skelin_mcnaughton_2018,
  title = {Hippocampal Coupling with Cortical and Subcortical Structures in the Context of Memory Consolidation},
  author = {Skelin, Ivan and Kilianski, Scott and Mcnaughton, Bruce L},
  year = {2018},
  issn = {10747427},
  doi = {10.1016/j.nlm.2018.04.004},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4ERSFSIV\\Skelin, Kilianski, Mcnaughton - 2018 - Hippocampal coupling with cortical and subcortical structures in the context of memory consolidat.pdf},
  journal = {Neurobiology of Learning and Memory},
  keywords = {cortex,hippocampus,likely mediated through reactivation,memory consolidation,memory consolidation is a,of neural activity,process of gradual memory,ripples,sharp wave,slow oscillations,spindles,strengthening},
  pmid = {29660400}
}

@article{sloman_sloman_1996,
  title = {The Empirical Case for Two Systems of Reasoning.},
  author = {Sloman, Steven A},
  year = {1996},
  volume = {119},
  pages = {3--22},
  issn = {0033-2909},
  doi = {10.1037/0033-2909.119.1.3},
  abstract = {Distinctions have been proposed between systems of reasoning for centuries. This article distills properties shared by many of these distinctions and characterizes the resulting systems in light of recent findings and theoretical developments. One system is associative because its computations reflect similarity structure and relations of temporal contiguity. The other is "rule based" because it operates on symbolic structures that have logical content and variables and because its computations have the properties that are normally assigned to rules. The systems serve complementary functions and can simultaneously generate different solutions to a reasoning problem. The rule-based system can suppress the associative system but not completely inhibit it. The article reviews evidence in favor of the distinction and its characterization.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\B63U2YDT\\Sloman - 1996 - The empirical case for two systems of reasoning.pdf},
  journal = {Psychological Bulletin},
  number = {1},
  pmid = {1394}
}

@article{smith_nichols_2018,
  title = {{{NeuroView Statistical Challenges}} in ''{{Big Data}}'' {{Human Neuroimaging}}},
  author = {Smith, Stephen M and Nichols, Thomas E},
  year = {2018},
  doi = {10.1016/j.neuron.2017.12.018},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CJIHRDNZ\\Smith, Nichols - 2018 - NeuroView Statistical Challenges in ''Big Data'' Human Neuroimaging.pdf}
}

@article{smith_smith_2010,
  title = {Neuromorphic Systems: Past, Present and Future.},
  author = {Smith, Leslie S},
  year = {2010},
  month = jan,
  volume = {657},
  pages = {167--182},
  issn = {0065-2598},
  doi = {10.1007/978-0-387-79100-5_9},
  abstract = {Neuromorphic systems are implementations in silicon of elements of neural systems. The idea of electronic implementation is not new, but modern microelectronics has provided opportunities for producing systems for both sensing and neural modelling that can be mass produced straightforwardly. We review the the history of neuromorphic systems, and discuss the range of neuromorphic systems that have been developed. We discuss recent ideas for overcoming some of the problems, particularly providing effective adaptive synapses in large numbers.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9GDBIKJW\\Smith - 2010 - Neuromorphic systems past, present and future.pdf},
  journal = {Advances in experimental medicine and biology},
  keywords = {Animals,Brain,Brain: cytology,Brain: physiology,Humans,Models,Neural Networks (Computer),Neural Pathways,Neural Pathways: physiology,Neurological,Neurons,Neurons: physiology,Sensation,Sensation: physiology,Synapses,Synapses: physiology},
  pmid = {20020347}
}

@article{smolen_byrne_2016,
  title = {The Right Time to Learn: Mechanisms and Optimization of Spaced Learning},
  author = {Smolen, Paul and Zhang, Yili and Byrne, John H},
  year = {2016},
  volume = {17},
  pages = {77--88},
  issn = {1471-003X},
  doi = {10.1038/nrn.2015.18},
  abstract = {For many types of learning, spaced training, which involves repeated long inter-trial intervals, leads to more robust memory formation than does massed training, which involves short or no intervals. Several cognitive theories have been proposed to explain this superiority, but only recently have data begun to delineate the underlying cellular and molecular mechanisms of spaced training, and we review these theories and data here. Computational models of the implicated signalling cascades have predicted that spaced training with irregular inter-trial intervals can enhance learning. This strategy of using models to predict optimal spaced training protocols, combined with pharmacotherapy, suggests novel ways to rescue impaired synaptic plasticity and learning.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PDFXKNIM\\Smolen, Zhang, Byrne - 2016 - The right time to learn mechanisms and optimization of spaced learning.pdf},
  journal = {Nature Reviews Neuroscience},
  number = {2},
  pmid = {26806627}
}

@article{snyder_anderson_1998,
  title = {Seperate Body-and-World Referenced Representations of Visual Space in Parietal Cortex},
  author = {Snyder, Lawrence H and Grieve, Kenneth L and Brotchie, Peter and Anderson, Richard A},
  year = {1998},
  month = aug,
  volume = {394},
  pages = {887--890},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8B89SPTK\\29777.pdf},
  journal = {Nature}
}

@article{snyder_munakata_2010,
  title = {Neural Inhibition Enables Selection during Language Processing.},
  author = {Snyder, Hannah R and Hutchison, Natalie and Nyhus, Erika and Curran, Tim and Banich, Marie T and O'Reilly, Randall C and Munakata, Yuko},
  year = {2010},
  volume = {107},
  pages = {16483--16488},
  issn = {0027-8424},
  doi = {10.1073/pnas.1002291107},
  abstract = {Whether grocery shopping or choosing words to express a thought, selecting between options can be challenging, especially for people with anxiety. We investigate the neural mechanisms supporting selection during language processing and its breakdown in anxiety. Our neural network simulations demonstrate a critical role for competitive, inhibitory dynamics supported by GABAergic interneurons. As predicted by our model, we find that anxiety (associated with reduced neural inhibition) impairs selection among options and associated prefrontal cortical activity, even in a simple, nonaffective verb-generation task, and the GABA agonist midazolam (which increases neural inhibition) improves selection, whereas retrieval from semantic memory is unaffected when selection demands are low. Neural inhibition is key to choosing our words.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NBMAMUTC\\Snyder et al. - 2010 - Neural inhibition enables selection during language processing.pdf},
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  number = {38},
  pmid = {20813959}
}

@article{sodickson_bean_1996,
  title = {{{GABAB}} Receptor-Activated Inwardly Rectifying Potassium Current in Dissociated Hippocampal {{CA3}} Neurons.},
  author = {Sodickson, Deborah L and Bean, Bruce P},
  year = {1996},
  volume = {16},
  pages = {6374--6385},
  issn = {0270-6474},
  abstract = {GABA and the GABAB receptor agonist baclofen activated a potassium conductance in acutely dissociated hippocampal CA3 neurons. Baclofen-activated current required internal GTP, was purely potassium selective, and showed strong inward rectification. As with acetylcholine-activated current in atrial myocytes, external Cs+ blocked inward but not outward current in a highly voltage-dependent manner, whereas Ba2+ blocked with no voltage dependence. Unlike the cardiac current, however, the baclofen-activated current showed no intrinsic voltage-dependent relaxation. With fast solution exchange, current was activated by baclofen or GABA with a lag of approximately 50 msec followed by an exponential phase (time constant approximately 225 msec at saturating agonist concentrations); deactivation was preceded by a lag of approximately 150 msec and occurred with a time constant of approximately 1 sec. GABA activated the potassium conductance with a half maximally effective concentration (EC50) of 1.6 microM, much lower than that for activation of GABAA receptor-activated chloride current in the same cells (EC50 approximately 25 microM). At low GABA concentrations, activation of the GABAB current had a Hill coefficient of 1.4-2.1, suggesting cooperativity in the receptor-to-channel pathway. Although the maximal conductance activated by GABAB receptors is much smaller than that activated by GABAA receptors, its higher sensitivity to GABA and slower time course make it well suited to respond to low concentrations of extra-synaptic GABA.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XZBUZRZ6\\Sodickson, Bean - 1996 - GABAB receptor-activated inwardly rectifying potassium current in dissociated hippocampal CA3 neurons.pdf},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  number = {20},
  pmid = {8815916}
}

@article{sohal_sohal_2016,
  title = {How {{Close Are We}} to {{Understanding What}} (If {{Anything}}) {{Oscillations Do}} in {{Cortical Circuits}}?},
  author = {Sohal, V S},
  year = {2016},
  volume = {36},
  pages = {10489--10495},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.0990-16.2016},
  abstract = {\$\textbackslash gamma\$ oscillations, which can be identified by rhythmic electrical signals {$\sim$}30-100 Hz, consist of interactions between excitatory and inhibitory neurons that result in rhythmic inhibition capable of entraining firing within local cortical circuits. Many possible mechanisms have been described through which \$\textbackslash gamma\$ oscillations could act on cortical circuits to modulate their responses to input, alter their patterns of activity, and/or enhance the efficacy of their outputs onto downstream targets. Recently, several studies have observed changes in behavior after optogenetically manipulating neocortical \$\textbackslash gamma\$ oscillations. Now, future studies should determine whether these manipulations elicit physiological correlates associated with specific mechanisms through which \$\textbackslash gamma\$ oscillations are hypothesized to modulate cortical circuit function. There are numerous such mechanisms, so identifying which ones are actually engaged by optogenetic manipulations known to affect behavior would help flesh out exactly how \$\textbackslash gamma\$ oscillations contribute to cortical circuit function under normal and/or pathological conditions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LG9BNV36\\Sohal - 2016 - How Close Are We to Understanding What (if Anything) Oscillations Do in Cortical Circuits.pdf},
  journal = {Journal of Neuroscience},
  number = {41},
  pmid = {27733600}
}

@article{sohn_jazayeri_2019,
  title = {Bayesian {{Computation}} through {{Cortical Latent Dynamics}}},
  author = {Sohn, Hansem and Narain, Devika and Meirhaeghe, Nicolas and Jazayeri, Mehrdad},
  year = {2019},
  month = sep,
  volume = {103},
  pages = {934-947.e5},
  issn = {08966273},
  doi = {10.1016/j.neuron.2019.06.012},
  abstract = {Statistical regularities in the environment create prior beliefs that we rely on to optimize our behavior when sensory information is uncertain. Bayesian theory formalizes how prior beliefs can be leveraged and has had a major impact on models of perception, sensorimotor function, and cognition. However, it is not known how recurrent interactions among neurons mediate Bayesian integration. By using a timeinterval reproduction task in monkeys, we found that prior statistics warp neural representations in the frontal cortex, allowing the mapping of sensory inputs to motor outputs to incorporate prior statistics in accordance with Bayesian inference. Analysis of recurrent neural network models performing the task revealed that this warping was enabled by a low-dimensional curved manifold and allowed us to further probe the potential causal underpinnings of this computational strategy. These results uncover a simple and general principle whereby prior beliefs exert their influence on behavior by sculpting cortical latent dynamics.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZXD4BK72\\Sohn et al. - 2019 - Bayesian Computation through Cortical Latent Dynam.pdf},
  journal = {Neuron},
  language = {en},
  number = {5}
}

@article{sohn_jazayeri_2019a,
  title = {Bayesian {{Computation}} through {{Cortical Latent Dynamics}}},
  author = {Sohn, Hansem and Narain, Devika and Meirhaeghe, Nicolas and Jazayeri, Mehrdad},
  year = {2019},
  month = sep,
  volume = {103},
  pages = {934-947.e5},
  issn = {08966273},
  doi = {10.1016/j.neuron.2019.06.012},
  abstract = {Statistical regularities in the environment create prior beliefs that we rely on to optimize our behavior when sensory information is uncertain. Bayesian theory formalizes how prior beliefs can be leveraged and has had a major impact on models of perception, sensorimotor function, and cognition. However, it is not known how recurrent interactions among neurons mediate Bayesian integration. By using a timeinterval reproduction task in monkeys, we found that prior statistics warp neural representations in the frontal cortex, allowing the mapping of sensory inputs to motor outputs to incorporate prior statistics in accordance with Bayesian inference. Analysis of recurrent neural network models performing the task revealed that this warping was enabled by a low-dimensional curved manifold and allowed us to further probe the potential causal underpinnings of this computational strategy. These results uncover a simple and general principle whereby prior beliefs exert their influence on behavior by sculpting cortical latent dynamics.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UYSI45FF\\Sohn et al. - 2019 - Bayesian Computation through Cortical Latent Dynam.pdf},
  journal = {Neuron},
  language = {en},
  number = {5}
}

@book{solem_solem_2012,
  title = {Programming {{Computer Vision}} with {{Python}}},
  author = {Solem, Jan Erik},
  year = {2012},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HUN9C4BY\\Solem - 2012 - Programming Computer Vision with Python.pdf}
}

@article{solstad_moser_2008,
  title = {Representation of {{Geometric Bordersin}} the {{Entorhinal Cortex}}},
  author = {Solstad, Trygve and Boccara, Charlotte N. and Kropff, Emilio and Moser, May Britt and Moser, Edvard I.},
  year = {2008},
  volume = {322},
  pages = {1865--1868},
  issn = {0036-8075},
  doi = {10.1126/science.1166466},
  abstract = {We report the existence of an entorhinal cell type that fires when an animal is close to the borders of the proximal environment. The orientation-specific edge-apposing activity of these "border cells" is maintained when the environment is stretched and during testing in enclosures of different size and shape in different rooms. Border cells are relatively sparse, making up less than 10\% of the local cell population, but can be found in all layers of the medial entorhinal cortex as well as the adjacent parasubiculum, often intermingled with head-direction cells and grid cells. Border cells may be instrumental in planning trajectories and anchoring grid fields and place fields to a geometric reference frame.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5FCD78HJ\\Solstad et al. - 2008 - Representation of Geometric Bordersin the Entorhinal Cortex.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\AVFWDGMK\\Solstad et al. - 2008 - Representation of Geometric Bordersin the Entorhinal Cortex(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\KTX7I429\\Yilmaz et al. - 2008 - Representation of Geometric Borders.pdf},
  journal = {Science (New York, N.Y.)},
  keywords = {Animals,Brain Mapping,Cues,Electrophysiology,Entorhinal Cortex,Entorhinal Cortex: cytology,Entorhinal Cortex: physiology,Long-Evans,Male,Neurons,Neurons: physiology,Orientation,Rats,Space Perception},
  number = {December},
  pmid = {19095945}
}

@article{solway_botvinick_2012,
  title = {Goal-Directed Decision Making as Probabilistic Inference: {{A}} Computational Framework and Potential Neural Correlates},
  author = {Solway, Alec and Botvinick, Matthew M},
  year = {2012},
  volume = {119},
  pages = {120--154},
  issn = {0033295X},
  doi = {10.1037/a0026435},
  abstract = {Recent work has given rise to the view that reward-based decision making is governed by two key controllers: a habit system, which stores stimulus-response associations shaped by past reward, and a goal-oriented system that selects actions based on their anticipated outcomes. The current literature provides a rich body of computational theory addressing habit formation, centering on temporal-difference learning mechanisms. Less progress has been made toward formalizing the processes involved in goal-directed decision making. We draw on recent work in cognitive neuroscience, animal conditioning, cognitive and developmental psychology, and machine learning to outline a new theory of goal-directed decision making. Our basic proposal is that the brain, within an identifiable network of cortical and subcortical structures, implements a probabilistic generative model of reward, and that goal-directed decision making is effected through Bayesian inversion of this model. We present a set of simulations implementing the account, which address benchmark behavioral and neuroscientific findings, and give rise to a set of testable predictions. We also discuss the relationship between the proposed framework and other models of decision making, including recent models of perceptual choice, to which our theory bears a direct connection.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\225TCIMC\\Solway, Botvinick - 2012 - Goal-Directed Decision Making as Probabilistic Inference A Computational Framework and Potential Neural Corre.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\RCK3R3U3\\Solway, Botvinick - 2012 - Goal-Directed Decision Making as Probabilistic Inference A Computational Framework and Potential Neural Corre.pdf},
  journal = {Psychological Review},
  keywords = {Decision making,Neuroeconomics,Planning,Probabilistic inference,Reward},
  number = {1},
  pmid = {22229491}
}

@article{solway_botvinick_2014,
  title = {Optimal {{Behavioral Hierarchy}}},
  author = {Solway, Alec and Diuk, Carlos and C{\'o}rdova, Natalia and Yee, Debbie and Barto, Andrew G. and Niv, Yael and Botvinick, Matthew M.},
  year = {2014},
  volume = {10},
  pages = {1003779},
  issn = {15537358},
  doi = {10.1371/journal.pcbi.1003779},
  abstract = {Human behavior has long been recognized to display hierarchical structure: actions fit together into subtasks, which cohere into extended goal-directed activities. Arranging actions hierarchically has well established benefits, allowing behaviors to be represented efficiently by the brain, and allowing solutions to new tasks to be discovered easily. However, these payoffs depend on the particular way in which actions are organized into a hierarchy, the specific way in which tasks are carved up into subtasks. We provide a mathematical account for what makes some hierarchies better than others, an account that allows an optimal hierarchy to be identified for any set of tasks. We then present results from four behavioral experiments, suggesting that human learners spontaneously discover optimal action hierarchies.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GC2L4PLC\\Solway et al. - 2014 - Optimal Behavioral Hierarchy.pdf},
  journal = {PLoS Computational Biology},
  number = {8},
  pmid = {25122479}
}

@article{soman_chakravarthy_2018,
  title = {A Unified Hierarchical Oscillatory Network Model of Head Direction Cells, Spatially Periodic Cells, and Place Cells},
  author = {Soman, Karthik and Muralidharan, Vignesh and Chakravarthy, Vaddadi Srinivasa},
  year = {2018},
  volume = {47},
  pages = {1266--1281},
  issn = {14609568},
  doi = {10.1111/ejn.13918},
  abstract = {Spatial cells in the hippocampal complex play a pivotal role in the navigation of an animal. Exact neural principles behind these spatial cell responses have not been completely unraveled yet. Here we present two models for spatial cells namely the Velocity Driven Oscillatory Network and Locomotor Driven Oscillatory Network. Both models have basically three stages in common such as direction encoding stage, path integration stage and a stage of unsupervised learning of path integration values. In the first model, the following three stages are implemented: head direction layer, frequency modulation by a layer of oscillatory neurons, and an unsupervised stage that extracts the Principal Components from the oscillator outputs. In the second model, a refined version of the first model, the stages are: extraction of velocity representation from the locomotor input, frequency modulation by a layer of oscillators, and two cascaded unsupervised stages consisting of the lateral anti-hebbian network. The principal component stage of Velocity Driven Oscillatory Network, exhibits grid cell-like spatially periodic responses including hexagonal firing fields. Locomotor Driven Oscillatory Network shows the emergence of spatially periodic grid cells and periodically active border like cells in its lower layer; place cell responses are found in its higher layer. This model shows the inheritance of phase precession from grid cell to place cell in both one and two dimensional spaces. It also shows a novel result on the influence of locomotion rhythms on the grid cell activity. The study thus presents a comprehensive, unifying hierarchical model for hippocampal spatial cells. This article is protected by copyright. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\P73SGYED\\Soman, Muralidharan, Chakravarthy - 2018 - A unified hierarchical oscillatory network model of head direction cells, spatially periodic.pdf},
  journal = {European Journal of Neuroscience},
  keywords = {grid cells,head direction cells,hippocampus,lateral anti-hebbian network,path integration,place cells},
  number = {10},
  pmid = {29575125}
}

@book{sommariva_marzetti_2017,
  title = {A {{Comparative Study}} of the {{Robustness}} of {{Frequency}}-{{Domain Connectivity Measures}} to {{Finite Data Length}}},
  author = {Sommariva, Sara and Sorrentino, Alberto and Piana, Michele and Pizzella, Vittorio and Marzetti, Laura},
  year = {2017},
  doi = {10.1007/s10548-017-0609-4},
  abstract = {In this work we use numerical simulation to investigate how the temporal length of the data affects the reliability of the estimates of brain connectivity from EEG time\textendash series. We assume that the neural sources follow a stable MultiVariate AutoRegressive model, and consider three connectivity metrics: Imaginary part of Coherency (IC), generalized Partial Directed Coherence (gPDC) and frequency\textendash domain Granger Causality (fGC). In order to assess the statistical significance of the estimated values, we use the surrogate data test by generating phase\textendash randomized and autoregressive surrogate data. We first consider the ideal case where we know the source time courses exactly. Here we show how, expectedly, even exact knowledge of the source time courses is not sufficient to provide reliable estimates of the connectivity when the number of samples gets small; however, while gPDC and fGC tend to provide a larger number of false positives, the IC becomes less sensitive to the presence of connectivity. Then we proceed with more realistic simulations, where the source time courses are estimated using eLORETA, and the EEG signal is affected by biological noise of increasing intensity. Using the ideal case as a reference, we show that the impact of biological noise on IC estimates is qualitatively different from the impact on gPDC and fGC.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SZPM29J8\\Sommariva et al. - 2017 - A Comparative Study of the Robustness of Frequency-Domain Connectivity Measures to Finite Data Length.pdf},
  isbn = {0-12-345678-9},
  keywords = {Dynamic functional connectivity,eeg,Frequency-domain granger causality,Generalized partial directed coherence,Imaginary part of coherency,Surrogate data}
}

@article{soreq_hampshire_2019,
  title = {Dynamic Network Coding of Working-Memory Domains and Working-Memory Processes},
  author = {Soreq, Eyal and Leech, Robert and Hampshire, Adam},
  year = {2019},
  month = dec,
  volume = {10},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-08840-8},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LM3LZXTZ\\Soreq et al. - 2019 - Dynamic network coding of working-memory domains a.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\QRR87PTZ\\Soreq et al. - 2019 - Dynamic network coding of working-memory domains a.pdf},
  journal = {Nature Communications},
  language = {en},
  number = {1}
}

@article{sorokin_burtsev_2018,
  title = {Episodic Memory Transfer for Multi-Task Reinforcement Learning},
  author = {Sorokin, Artyom Y. and Burtsev, Mikhail S.},
  year = {2018},
  month = oct,
  volume = {26},
  pages = {91--95},
  issn = {2212683X},
  doi = {10.1016/j.bica.2018.09.003},
  abstract = {Episodic memory plays important role in animal behavior. It allows to reuse general skills for solution of specific tasks in changing environment. This beneficial feature of biological cognitive systems is still not incorporated successfully in an artificial neural architectures. In this paper we propose a neural architecture with shared episodic memory for multi-task reinforcement learning (SEM-PAAC). This architecture extends Parallel Advantage Actor Critic (PAAC) with two recurrent sub-networks for separate tracking of environment and task states. The first subnetwork store episodic memory and the second one allows task specific execution of policy. Experiments in the Taxi domain demonstrated that SEM-PAAC has the same performance as PAAC when subtasks are solved separately. On the other hand when subtasks are solved jointly for completing full Taxi task SEM-PAAC is significantly better due to reuse of episodic memory. Proposed architecture also successfully learned to predict task completion. This is a step towards more autonomous agents for multitask problems.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WA3EQ5DN\\Sorokin and Burtsev - 2018 - Episodic memory transfer for multi-task reinforcem.pdf},
  journal = {Biologically Inspired Cognitive Architectures},
  language = {en}
}

@article{sosa_frank_2019,
  title = {Dorsal and {{Ventral Hippocampal Sharp}}-{{Wave Ripples Activate Distinct Nucleus Accumbens Networks}}},
  author = {Sosa, Marielena and Joo, Hannah R. and Frank, Loren M.},
  year = {2019},
  month = dec,
  pages = {S0896627319310086},
  issn = {08966273},
  doi = {10.1016/j.neuron.2019.11.022},
  abstract = {Memories of positive experiences link places, events, and reward outcomes. These memories recruit interactions between the hippocampus and nucleus accumbens (NAc). Both dorsal and ventral hippocampus (dH and vH) project to the NAc, but it remains unknown whether dH and vH act in concert or separately to engage NAc representations related to space and reward. We recorded simultaneously from the dH, vH, and NAc of rats during an appetitive spatial task and focused on hippocampal sharpwave ripples (SWRs) to identify times of memory reactivation across brain regions. Here, we show that dH and vH awake SWRs occur asynchronously and activate distinct and opposing patterns of NAc spiking. Only NAc neurons activated during dH SWRs were tuned to task- and reward-related information. These temporally and anatomically separable hippocampal-NAc interactions point to distinct channels of mnemonic processing in the NAc, with the dH-NAc channel specialized for spatial task and reward information.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8C7Z42K3\\Sosa et al. - 2019 - Dorsal and Ventral Hippocampal Sharp-Wave Ripples .pdf},
  journal = {Neuron},
  language = {en}
}

@book{spence_spence_1996,
  title = {The {{Cognitive Neurosciences}}},
  author = {Spence, S},
  year = {1996},
  volume = {312},
  doi = {10.1136/bmj.312.7024.193},
  abstract = {Each edition of this classic reference has proved to be a benchmark in the developing field of cognitive neuroscience . The third edition of The Cognitive Neurosciences continues to chart new directions in the study of the biologic underpinnings of complex cognition\textemdash the ...},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9QRMCG2J\\Spence - 1996 - The Cognitive Neurosciences.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\KEKT7NAS\\Gazzaniga - 2009 - The cognitive neurosciences.pdf},
  isbn = {978-0-262-01341-3},
  pmid = {23961910}
}

@article{spiers_barry_2014,
  title = {Neural Systems Supporting Navigation},
  author = {Spiers, Hugo J and Barry, Caswell},
  year = {2014},
  month = sep,
  pages = {1--9},
  issn = {23521546},
  doi = {10.1016/j.cobeha.2014.08.005},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4PEJAUQ7\\Spiers, Barry - 2014 - Neural systems supporting navigation.pdf},
  journal = {Current Opinion in Behavioral Sciences},
  number = {2014}
}

@article{squire_morris_2015,
  title = {Memory {{Consolidation}}},
  author = {Squire, Larry R and Genzel, Lisa and Wixted, John T and Morris, Richard G M and Wisted, John T and Morris, Richard G M},
  year = {2015},
  volume = {7},
  pages = {a021766},
  issn = {1943-0264},
  doi = {10.1101/cshperspect.a021766},
  abstract = {Conscious memory for a newexperience is initially dependent on information stored in both the hippocampus and neocortex. Systems consolidation is the process by which the hippo- campus guides the reorganization of the information stored in the neocortex such that it eventually becomes independent of the hippocampus. Early evidence for systems consoli- dation was provided by studies of retrograde amnesia, which found that damage to the hippocampus-impaired memories formed in the recent past, but typically spared memories formed in the more remote past. Systems consolidation has been found to occur for both episodic and semantic memories and for both spatial and nonspatial memories, although empirical inconsistencies and theoretical disagreements remain about these issues. Recent work has begun to characterize the neural mechanisms that underlie the dialogue between the hippocampus and neocortex (e.g., ``neural replay,'' which occurs during sharp wave ripple activity). New work has also identified variables, such as the amount of preexisting knowledge, that affect the rate of consolidation.The increasing use of molecular genetic tools (e.g., optogenetics) can be expected to further improve understanding of the neural mech- anisms underlying consolidation.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NLK88FC8\\Squire et al. - 2015 - Memory Consolidation.pdf},
  journal = {Cold Spring Harbor Perspectives in Biology},
  keywords = {but the understanding of,cellular consolidation,consoli-,date has a long,evolved over time,history,memories require time to,reconsolidation,sleep and consolidation,systems consolidation,th e idea that},
  number = {8}
}

@article{sreenivasan_desposito_2019,
  title = {The What, Where and How of Delay Activity},
  author = {Sreenivasan, Kartik K. and D'Esposito, Mark},
  year = {2019},
  month = may,
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/s41583-019-0176-7},
  abstract = {Working memory is characterized by neural activity that persists during the retention interval of delay tasks. Despite the ubiquity of this delay activity across tasks, species and experimental techniques, our understanding of this phenomenon remains incomplete. Although initially there was a narrow focus on sustained activation in a small number of brain regions, methodological and analytical advances have allowed researchers to uncover previously unobserved forms of delay activity various parts of the brain. In light of these new findings, this Review reconsiders what delay activity is, where in the brain it is found, what roles it serves and how it may be generated.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RGL2Z3DA\\Sreenivasan and D’Esposito - 2019 - The what, where and how of delay activity.pdf},
  journal = {Nature Reviews Neuroscience},
  language = {en}
}

@article{sridharan_menon_2008,
  title = {A Critical Role for the Right Fronto-Insular Cortex in Switching between Central-Executive and Default-Mode Networks},
  author = {Sridharan, Devarajan and Levitin, Daniel J and Menon, Vinod},
  year = {2008},
  volume = {105},
  pages = {12569--12574},
  issn = {0027-8424},
  doi = {10.1073/pnas.0800005105},
  abstract = {Cognitively demanding tasks that evoke activation in the brain's central-executive network (CEN) have been consistently shown to evoke decreased activation (deactivation) in the default-mode network (DMN). The neural mechanisms underlying this switch between activation and deactivation of large-scale brain networks remain completely unknown. Here, we use functional magnetic resonance imaging (fMRI) to investigate the mechanisms underly- ing switching of brain networks in three different experiments.We first examined this switching process in an auditory event seg- mentation task. We observed significant activation of the CEN and deactivation of the DMN, along with activation of a third network comprising the right fronto-insular cortex (rFIC) and anterior cin- gulate cortex (ACC), when participants perceived salient auditory event boundaries. Using chronometric techniques and Granger causality analysis, we show that the rFIC-ACC network, and the rFIC, in particular, plays a critical and causal role in switching between the CEN and the DMN. We replicated this causal connec- tivity pattern in two additional experiments: (i) a visual attention ``oddball'' task and (ii) a task-free resting state. These results indicate that the rFIC is likely to play a major role in switching between distinct brain networks across task paradigms and stim- ulus modalities. Our findings have important implications for a unified view of network mechanisms underlying both exogenous and endogenous cognitive control.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AUYSEE24\\Sridharan, Levitin, Menon - 2008 - A critical role for the right fronto-insular cortex in switching between central-executive and defaul.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  number = {34},
  pmid = {18723676}
}

@article{stachenfeld_gershman_2017,
  title = {The Hippocampus as a Predictive Map},
  author = {Stachenfeld, Kimberly L. and Botvinick, Matthew M. and Gershman, Samuel J},
  year = {2017},
  volume = {20},
  pages = {1643--1653},
  issn = {15461726},
  doi = {10.1038/nn.4650},
  abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein-protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-{$\alpha$}-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD {$\leq$} 2.0 \textbackslash AA for the interface backbone atoms) increased from 21\% with default Glide SP settings to 58\% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63\% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40\% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6YGKSRYI\\Stachenfeld, Botvinick, Gershman - 2017 - The hippocampus as a predictive map.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\C7XBXN6T\\Stachenfeld et al. - 2017 - The hippocampus as a predictive map.pdf},
  journal = {Nature Neuroscience},
  number = {11},
  pmid = {25246403}
}

@article{stanimirovic_petkovic_2019,
  title = {Improved {{GNN Models}} for {{Constant Matrix Inversion}}},
  author = {Stanimirovi{\'c}, Predrag S. and Petkovi{\'c}, Marko D.},
  year = {2019},
  month = mar,
  issn = {1370-4621, 1573-773X},
  doi = {10.1007/s11063-019-10025-9},
  abstract = {It was shown that the multiplication of the left hand side of the classical Zhang neural network design rule by an appropriate positive definite matrix generates a new neural design with improved convergence rate. Our intention is to apply similar principle on the standard gradient neural network (GNN) model. To that goal, we discover that some of proposed models can be considered as the multiplication of the right hand side of the GNN model by a symmetric positive-semidefinite matrix. As a final result, we propose appropriate general pattern to define various improvements of the standard GNN design for online real-time matrix inversion in time invariant case. The leading idea in generating improved models is initiated after a combination of two GNN patterns. Improved GNN (IGNN) design shows global exponential convergence with an improved convergence rate with respect to the convergence rate of the original GNN pattern. The acceleration in the convergence rate is defined by the smallest eigenvalue of appropriate positive semidefinite matrices. IGNN models are not only generalizations of original GNN models but they comprise so far defined improvements of the standard GNN design.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\68XU6EN4\\Stanimirović and Petković - 2019 - Improved GNN Models for Constant Matrix Inversion.pdf},
  journal = {Neural Processing Letters},
  language = {en}
}

@article{staresina_fell_2016,
  title = {Hippocampal Pattern Completion Is Linked to Gamma Power Increases and Alpha Power Decreases during Recollection},
  author = {Staresina, Bernhard P and Michelmann, Sebastian and Bonnefond, Mathilde and Jensen, Ole and Axmacher, Nikolai and Fell, Juergen},
  year = {2016},
  volume = {5},
  pages = {1--18},
  issn = {2050084X},
  doi = {10.7554/eLife.17397.001},
  abstract = {\{\textbackslash textless\}p\{\textbackslash textgreater\}How do we retrieve vivid memories upon encountering a simple cue? Computational models suggest that this feat is accomplished by pattern completion processes involving the hippocampus. However, empirical evidence for hippocampal pattern completion and its underlying mechanisms has remained elusive. Here, we recorded direct intracranial EEG as human participants performed an associative memory task. For each study (encoding) and test (retrieval) event, we derived time-frequency resolved representational patterns in the hippocampus and compared the extent of pattern reinstatement for different mnemonic outcomes. Results show that successful associative recognition (AR) yields enhanced event-specific reinstatement of encoding patterns compared to non-associative item recognition (IR). Moreover, we found that gamma power (50\textendash 90 Hz) increases \textendash{} in conjunction with alpha power (8\textendash 12 Hz) decreases not only distinguish AR from IR, but also correlate with the level of hippocampal reinstatement. These results link single-shot hippocampal pattern completion to episodic recollection and reveal how oscillatory dynamics in the gamma and alpha bands orchestrate these mnemonic processes.\{\textbackslash textless\}/p\{\textbackslash textgreater\}},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HCBQNCBT\\Staresina et al. - 2016 - Hippocampal pattern completion is linked to gamma power increases and alpha power decreases during recollectio.pdf},
  journal = {eLife},
  number = {AUGUST},
  pmid = {27508355}
}

@article{staudigl_doeller_2018,
  title = {Hexadirectional {{Modulation}} of {{High}}-{{Frequency Electrophysiological Activity}} in the {{Human Anterior Medial Temporal Lobe Maps Visual Space Highlights}} d {{Hexadirectional}} Modulation of Human High-Frequency Electrophysiological Activity d {{Grid}}-like Mapping of Vi},
  author = {Staudigl, Tobias and Leszczynski, Marcin and Jacobs, Joshua and Sheth, Sameer A and Schroeder, Charles E and Jensen, Ole and Doeller, Christian F},
  year = {2018},
  volume = {28},
  issn = {09609822},
  doi = {10.1016/j.cub.2018.09.035},
  abstract = {Staudigl et al. show grid-like modulation of human high-frequency activity in non-invasive magnetoencephalographic and intracranial EEG recordings. The results indicate that the human entorhinal cortex codes visual space in a grid-like manner, supporting the view that grid coding generalizes beyond environmental mapping during locomotion.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CZBETFHM\\Staudigl et al. - 2018 - Hexadirectional Modulation of High-Frequency Electrophysiological Activity in the Human Anterior Medial Tempora.pdf},
  journal = {Current Biology},
  keywords = {entorhinal cortex,eye movements,grid coding,intracranial electroencephalography,magnetoencephalography,navigation,visual space}
}

@article{steiger_bunzeck_2019,
  title = {Working Memory Performance in the Elderly Relates to Theta-Alpha Oscillations and Is Predicted by Parahippocampal and Striatal Integrity},
  author = {Steiger, Tineke K. and Herweg, Nora A. and Menz, Mareike M. and Bunzeck, Nico},
  year = {2019},
  month = dec,
  volume = {9},
  issn = {2045-2322},
  doi = {10.1038/s41598-018-36793-3},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BSS6JKE8\\Steiger et al. - 2019 - Working memory performance in the elderly relates .pdf},
  journal = {Scientific Reports},
  language = {en},
  number = {1}
}

@article{steinbeck_studer_2015,
  title = {Optogenetics Enables Functional Analysis of Human Embryonic Stem Cell\textendash Derived Grafts in a {{Parkinson}}'s Disease Model},
  author = {Steinbeck, Julius A and Choi, Se Joon and Mrejeru, Ana and Ganat, Yosif and Deisseroth, Karl and Sulzer, David and Mosharov, Eugene V and Studer, Lorenz},
  year = {2015},
  month = mar,
  volume = {33},
  pages = {204--209},
  issn = {1087-0156, 1546-1696},
  doi = {10.1038/nbt.3124},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SB6TI9F7\\Steinbeck et al. - 2015 - Optogenetics enables functional analysis of human .pdf},
  journal = {Nature Biotechnology},
  language = {en},
  number = {2}
}

@article{steinberg_janak_2013,
  title = {A Causal Link between Prediction Errors, Dopamine Neurons and Learning},
  author = {Steinberg, Elizabeth E and Keiflin, Ronald and Boivin, Josiah R and Witten, Ilana B and Deisseroth, Karl and Janak, Patricia H},
  year = {2013},
  volume = {16},
  pages = {966--973},
  issn = {1546-1726},
  doi = {10.1038/nn.3413},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\W7NIZTRC\\Steinberg et al. - 2013 - A causal link between prediction errors, dopamine neurons and learning.pdf},
  journal = {Nature Neuroscience},
  number = {7},
  pmid = {23708143}
}

@article{stemmler_herz_2015,
  title = {Decoding the {{Population Activity}} of {{Grid Cells}} for {{Spatial Localization}} and {{Goal}}-{{Directed Navigation}}},
  author = {Stemmler, Martin and Mathis, Alexander and Herz, Andreas V M},
  year = {2015},
  pages = {21204},
  doi = {10.1101/021204},
  abstract = {Mammalian grid cells fire whenever an animal crosses the points of an imaginary, hexagonal grid tessellating the environment. Here, we show how animals can localize themselves and navigate by reading-out a simple population vector of grid cell activity across multiple scales, even though this activity is intrinsically stochastic. This theory of dead reckoning explains why grid cells are organized into modules with equal lattice scale and orientation. Computing the homing vector is least error-prone when the ratio of successive grid scales is around 3/2. Silencing intermediate-scale modules should cause systematic errors in navigation, while knocking out the module at the smallest scale will only affect navigational precision. Read-out neurons should behave like goal-vector cells subject to nonlinear gain fields.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WLH9NZJD\\Stemmler, Mathis, Herz - 2015 - Decoding the Population Activity of Grid Cells for Spatial Localization and Goal-Directed Navigation.pdf},
  journal = {bioRxiv},
  pmid = {1000181167}
}

@article{stensola_moser_2012,
  title = {The Entorhinal Grid Map Is Discretized},
  author = {Stensola, Hanne and Stensola, Tor and Solstad, Trygve and Fr{\O}land, Kristian and Moser, May Britt and Moser, Edvard I.},
  year = {2012},
  volume = {492},
  pages = {72--78},
  issn = {00280836},
  doi = {10.1038/nature11649},
  abstract = {The medial entorhinal cortex (MEC) is part of the brain's circuit for dynamic representation of self-location. The metric of this representation is provided by grid cells, cells with spatial firing fields that tile environments in a periodic hexagonal pattern. Limited anatomical sampling has obscured whether the grid system operates as a unified system or a conglomerate of independent modules. Here we show with recordings from up to 186 grid cells in individual rats that grid cells cluster into a small number of layer-spanning anatomically overlapping modules with distinct scale, orientation, asymmetry and theta-frequency modulation. These modules can respond independently to changes in the geometry of the environment. The discrete topography of the grid-map, and the apparent autonomy of the modules, differ from the graded topography of maps for continuous variables in several sensory systems, raising the possibility that the modularity of the grid map is a product of local self-organizing network dynamics.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8BXVAPZ2\\Stensola et al. - 2012 - The entorhinal grid map is discretized.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\RBRMB9FA\\Stensola et al. - 2012 - The entorhinal grid map is discretized(2).pdf},
  journal = {Nature},
  number = {7427},
  pmid = {23222610}
}

@article{stensola_moser_2015,
  title = {Shearing-Induced Asymmetry in Entorhinal Grid Cells},
  author = {Stensola, Tor and Stensola, Hanne and Moser, May-Britt and Moser, Edvard I.},
  year = {2015},
  volume = {518},
  pages = {207--212},
  issn = {0028-0836},
  doi = {10.1038/nature14151},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5PRWQYTE\\Stensola et al. - 2015 - Shearing-induced asymmetry in entorhinal grid cells.pdf},
  journal = {Nature},
  number = {7538}
}

@article{stephan_heinzle_2017,
  title = {Laminar {{fMRI}} and Computational Theories of Brain Function},
  author = {Stephan, K E and Petzschner, F H and Kasper, L and Bayer, J and Wellstein, K V and Stefanics, G and Pruessmann, K P and Heinzle, J},
  year = {2017},
  doi = {10.1016/j.neuroimage.2017.11.001},
  abstract = {A B S T R A C T Recently developed methods for functional MRI at the resolution of cortical layers (laminar fMRI) offer a novel window into neurophysiological mechanisms of cortical activity. Beyond physiology, laminar fMRI also offers an unprecedented opportunity to test influential theories of brain function. Specifically, hierarchical Bayesian the-ories of brain function, such as predictive coding, assign specific computational roles to different cortical layers. Combined with computational models, laminar fMRI offers a unique opportunity to test these proposals non-invasively in humans. This review provides a brief overview of predictive coding and related hierarchical Bayesian theories, sum-marises their predictions with regard to layered cortical computations, examines how these predictions could be tested by laminar fMRI, and considers methodological challenges. We conclude by discussing the potential of laminar fMRI for clinically useful computational assays of layer-specific information processing.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KI7ZQXU2\\Stephan et al. - 2017 - Laminar fMRI and computational theories of brain function.pdf},
  keywords = {Computational psychiatry,Computational psychosomatics,Cortical layers,Effective connectivity,Neuromodeling,Predictive coding}
}

@book{stephan_stephan_2015,
  title = {Dynamic {{Causal Models}} for {{fMRI}}},
  author = {Stephan, K.E.},
  year = {2015},
  publisher = {{Elsevier Inc.}},
  doi = {10.1016/B978-0-12-397025-1.00339-0},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5BLZ8K53\\Flandin, Friston - 2015 - Topological Inference.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\DCQLWXPN\\Gitelman - 2015 - Convolution Models for FMRI.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\F9CZ2FQN\\Stephan - 2015 - Dynamic Causal Models for fMRI.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\URAKS48L\\Rosa - 2015 - Posterior Probability Maps.pdf},
  isbn = {978-0-12-397025-1},
  keywords = {Bayesian inference,Bayesian model selection,Effective connectivity,Evidence,Generative model,Synaptic plasticity},
  number = {3}
}

@article{stern_hasselmo_2001,
  title = {Medial Temporal and Prefrontal Contributions to Working Memory Tasks with Novel and Familiar Stimuli},
  author = {Stern, Chantal E. and Sherman, Seth J. and Kirchhoff, Brenda A. and Hasselmo, Michael E.},
  year = {2001},
  volume = {11},
  pages = {337--346},
  issn = {1050-9631, 1098-1063},
  doi = {10.1002/hipo.1048},
  abstract = {Lesions of parahippocampal structures impair performance of delayed matching tasks in nonhuman primates, suggesting a role for these structures in the maintenance of items in working memory and short-term stimulus matching. However, most human functional imaging studies have not shown medial temporal activation during working memory tasks and have primarily focused on functional magnetic resonance imaging (fMRI) signal intensity changes in the prefrontal and posterior parietal cortex. The goal of this study was to test the hypothesis that the difference between the human and nonhuman primate data results from the use of highly familiar stimuli in human working memory studies and trial-unique stimuli in nonhuman primate studies. We used fMRI to examine prefrontal and temporal lobe activation during performance of a working memory (two-back) task, using blocks of novel and highly familiar complex pictures. Performance of the working memory task with novel complex pictures resulted in greater signal change within medial temporal lobe structures than performance of the task with familiar complex pictures. In contrast, the working memory task with highly familiar stimuli resulted in greater prefrontal activation. These results are consistent without hypothesis that the medial temporal lobe is recruited for the shortterm maintenance of information that has no prior representation in the brain, whereas the prefrontal cortex is important for monitoring familiar stimuli that have a high degree of interference. A second set of tasks examined stimulus matching. Subjects performed a target-matching task, during which they identified a single target presented in blocks of novel or familiar stimuli. The results provide evidence of hippocampal and parahippocampal recruitment in the target-matching task with familiar stimuli. These results are consistent with prior animal studies and suggest that prefrontal regions may be important for the monitoring and matching of familiar stimuli which have a high potential for interference, whereas medial temporal regions may become proportionally more important for matching and maintenance of novel stimuli. Hippocampus 2001;11: 337\textendash 346. \textcopyright{} 2001 Wiley-Liss, Inc.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\52DPNJGI\\Stern et al. - 2001 - Medial temporal and prefrontal contributions to wo.pdf},
  journal = {Hippocampus},
  language = {en},
  number = {4}
}

@article{stetter_lang_2020,
  title = {Learning Intuitive Physics and One-Shot Imitation Using State-Action-Prediction Self-Organizing Maps},
  author = {Stetter, Martin and Lang, Elmar W.},
  year = {2020},
  month = jul,
  abstract = {Human learning and intelligence work differently from the supervised pattern recognition approach adopted in most deep learning architectures. Humans seem to learn rich representations by exploration and imitation, build causal models of the world, and use both to flexibly solve new tasks. We suggest a simple but effective unsupervised model which develops such characteristics. The agent learns to represent the dynamical physical properties of its environment by intrinsically motivated exploration, and performs inference on this representation to reach goals. For this, a set of self-organizing maps which represent state-action pairs is combined with a causal model for sequence prediction. The proposed system is evaluated in the cartpole environment. After an initial phase of playful exploration, the agent can execute kinematic simulations of the environment's future, and use those for action planning. We demonstrate its performance on a set of several related, but different one-shot imitation tasks, which the agent flexibly solves in an active inference style.},
  archivePrefix = {arXiv},
  eprint = {2007.01647},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KNZ74MRS\\stetter_lang_2020.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\YSDN5DRY\\2007.html},
  journal = {arXiv:2007.01647 [cs]},
  keywords = {Computer Science - Artificial Intelligence},
  primaryClass = {cs}
}

@article{stevenson_stevenson_2018,
  title = {Communicated by {{Satish Iyengar Omitted Variable Bias}} in {{GLMs}} of {{Neural Spiking Activity}}},
  author = {Stevenson, Ian H},
  year = {2018},
  doi = {10.1162/neco_a_01138},
  abstract = {Generalized linear models (GLMs) have a wide range of applications in systems neuroscience describing the encoding of stimulus and behav-ioral variables, as well as the dynamics of single neurons. However, in any given experiment, many variables that have an impact on neural activity are not observed or not modeled. Here we demonstrate, in both theory and practice, how these omitted variables can result in biased parameter estimates for the effects that are included. In three case studies , we estimate tuning functions for common experiments in motor cortex , hippocampus, and visual cortex. We find that including traditionally omitted variables changes estimates of the original parameters and that modulation originally attributed to one variable is reduced after new variables are included. In GLMs describing single-neuron dynamics, we then demonstrate how postspike history effects can also be biased by omitted variables. Here we find that omitted variable bias can lead to mistaken conclusions about the stability of single-neuron firing. Omitted variable bias can appear in any model with confounders-where omitted variables modulate neural activity and the effects of the omitted variables covary with the included effects. Understanding how and to what extent omitted variable bias affects parameter estimates is likely to be important for interpreting the parameters and predictions of many neural encoding models.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LVRYL8JX\\Stevenson - 2018 - Communicated by Satish Iyengar Omitted Variable Bias in GLMs of Neural Spiking Activity.pdf}
}

@article{stewart_eliasmith_2010,
  title = {Symbolic {{Reasoning}} in {{Spiking Neurons}}: {{A Model}} of the {{Cortex}}/{{Basal Ganglia}}/{{Thalamus Loop}}},
  author = {Stewart, Terrence C and Choo, Xuan and Eliasmith, Chris},
  year = {2010},
  pages = {1100--1105},
  doi = {10.1.1.353.644},
  abstract = {We present a model of symbol manipulation implemented using spiking neurons and closely tied to the anatomy of the cortex, basal ganglia, and thalamus. The model is a generalpurpose neural controller which plays a role analogous to a production system. Information stored in cortex is used by the basal ganglia as the basis for selecting between a set of inferences. When an inference rule is selected, it commands the thalamus to modify and transmit information between areas of the cortex. The system supports special-case and general-purpose inferences, including the ability to remember complex statements and answer questions about them. The resulting model suggests modifications to the standard structure of production system rules, and offers a neurological explanation for the 50 millisecond cognitive cycle time.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FCLMVN34\\Stewart, Choo, Eliasmith - 2010 - Symbolic Reasoning in Spiking Neurons A Model of the CortexBasal GangliaThalamus Loop.pdf},
  journal = {Annuel Meeting of the Cognitive Science Society},
  keywords = {cognitive architectures,decision making,neural engineering,neural production system}
}

@article{stewart_eliasmith_2011,
  title = {Neural Representations of Compositional Structures: Representing and Manipulating Vector Spaces with Spiking Neurons},
  author = {Stewart, Terrence C and Bekolay, Trevor and Eliasmith, Chris},
  year = {2011},
  volume = {23},
  pages = {145--153},
  doi = {10.1080/09540091.2011.571761},
  abstract = {This paper re-examines the question of localist vs. distributed neural representations using a biologically realistic framework based on the central notion of neurons having a preferred direction vector. A preferred direction vector captures the general observation that neurons fire most vigorously when the stimulus lies in a particular direction in a represented vector space. This framework has been successful in capturing a wide variety of detailed neural data, although here we focus on cognitive representation. In particular, we describe methods for constructing spiking networks that can represent and manipulate structured, symbol-like representations. In the context of such networks, neuron activities can seem both localist and distributed, depending on the space of inputs being considered. This analysis suggests that claims of a set of neurons being localist or distributed cannot be made sense of without specifying the particular stimulus set used to examine the neurons. 1. Neural representation Simple scalar values of behaviourally relevant variables (such as head tilt) can be understood as being encoded in the brain as shown in Figure 1 (Eliasmith and Anderson 2003). This pattern is found in both visual and motor areas, including head orientation detection and eye position control. Each line is the tuning curve for a different neuron, showing how its firing rate changes as the value being represented (x) changes. We can characterise this phenomenon by noting that the neurons fall into two groups, sometimes referred to as on neurons and off neurons. The on neurons 'prefer' (i.e. they fire more quickly for) positive values of x (tilting the head forward; looking to the right) and the off neurons prefer negative values (tilting backward; looking left). We can capture this effect mathematically by noting that the current flowing into on-neurons is proportional to x, and for off-neurons, it is proportional to -x. Indeed, a close match to empirical data is found if we assume that the total current J flowing into each neuron is J = {$\alpha$}px + J b , where x is the scalar value to be encoded, p is the neuron's preferred value (1 for on neurons},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CETDIAPH\\Stewart, Bekolay, Eliasmith - 2011 - Neural representations of compositional structures representing and manipulating vector spaces with.pdf},
  journal = {Connection Science},
  keywords = {distributed representation,localist representation,neural engineering framework,neural representation,preferred direction vectors,vector symbolic architectures},
  number = {2}
}

@inproceedings{stewart_eliasmith_2013,
  title = {Parsing {{Sequentially Presented Commands}} in a {{Large}}-{{Scale Biologically Realistic Brain Model}}},
  booktitle = {35th {{Annual Conference}} of the {{Cognitive Science Society}}},
  author = {Stewart, Terrence C and Eliasmith, Chris},
  year = {2013},
  pages = {3460--3467},
  abstract = {We present a neural mechanism for interpreting and executing visually presented commands. These are simple verb-noun commands (such as WRITE THREE) and can also include conditionals ([if] SEE SEVEN, [then] WRITE THREE). We apply this to a simplified version of our large-scale functional brain model "Spaun", where input is a 28x28 pixel visual stimulus, with a different pattern for each word. Output controls a simulated arm, giving hand-written answers. Cortical areas for categorizing, storing, and interpreting information are controlled by the basal ganglia (action selection) and thalamus (routing). The final model has approximately 100,000 LIF spiking neurons. We show that the model is extremely robust to neural damage (40 percent of neurons can be destroyed before performance drops significantly). Performance also drops for visual display times less than 250ms. Importantly, the system also scales to large vocabularies (approximately 100,000 nouns and verbs) without requiring an exponentially large number of neurons.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4TLEBHGE\\Stewart, Eliasmith - 2013 - Parsing Sequentially Presented Commands in a Large-Scale Biologically Realistic Brain Model.pdf},
  keywords = {cognitive architecture,cognitive control,neural engineering,only has a,parsing,parsing visual commands,spiking neurons,to a model that,to provide new instructions}
}

@article{stiso_bassett_2018,
  title = {Spatial {{Embedding Imposes Constraints}} on {{Neuronal Network Architectures Network Topology}} versus {{Geometry}} in {{Neural Systems}}},
  author = {Stiso, Jennifer and Bassett, Danielle S},
  year = {2018},
  volume = {22},
  pages = {1127--1142},
  doi = {10.1016/j.tics.2018.09.007},
  abstract = {Recent progress towards understanding circuit function has capitalized on tools from network science to parsimoniously describe the spatiotemporal architecture of neural systems. Such tools often address systems topology divorced from its physical instantiation. Nevertheless, for embedded systems such as the brain, physical laws directly constrain the processes of network growth, development, and function. We review here the rules imposed by the space and volume of the brain on the development of neuronal networks, and show that these rules give rise to a specific set of complex topologies. These rules also affect the repertoire of neural dynamics that can emerge from the system, and thereby inform our understanding of network dysfunction in disease. We close by discussing new tools and models to delineate the effects of spatial embedding. In contemporary neuroscience, increasing volumes of data are being used to answer the question of how heterogeneous and distributed interactions between neural units might give rise to complex behaviors. Such interactions form characteristic patterns across multiple spatial scales, spanning molecules and cells to brain regions and lobes [1]. An intuitive language in which to describe such interactions is network science, which elegantly represents interconnected systems as sets of nodes (see Glossary) linked by edges. Nodes often represent proteins, neurons, subcortical nuclei, or large cortical areas, and edges often represent either (i) structural links in the form of chemical bonds, synapses, or white matter tracts, or (ii) functional links in the form of statistical relations between nodal activity time series. Generally, the resultant network architecture can be fruitfully studied using tools from graph theory to obtain mechanistic insights pertinent to cognition [2], above and beyond those provided by studies of regional activation [3] (Box 1). In particular, several fundamental questions in neuroscience are quintessentially network questions concerning the physical relationships between functional units. How does the physical structure of a circuit affect its function? How does coordinated activity at small spatial scales give rise to emergent phenomena at large spatial scales? How might alterations in neurodevelopmental processes lead to circuit malfunction in psychiatric disorders? How might pathology progressively spread through cortical and subcortical tissue, giving rise to the well-known clinical presentations of neurological disease? These questions collectively highlight the fact that the brain-and its multiple networks of interacting units-is physically embedded into a fixed 3D enclosure. The natural consequences of this embedding include diverse physical drivers of early connection formation and physical constraints on the resultant adult network architecture. Understanding the constitution and basal dynamics of the system therefore requires not only approaches to quantify and predict network topology but also tools, theories, and methods to quantify and predict network geometry and its role in both enabling and constraining system function. Highlights The physical embedding of neural systems imposes constraints on the possible patterns of connections and the repertoire of functional motifs. Prominent competing rules guiding the formation of brain networks include the minimization of wiring cost, and maximizing network efficiency and diversity. These rules lead to high local clustering with sparse long-distance connections. Recent work suggests that intrinsic functional connectivity varies along dimensions that are tightly linked to the spatial embedding of the brain and to the topological properties that arise in the presence of spatial constraints. Similarly, these properties show widespread changes in various diseases. There is a rich and growing repertoire of statistics, null models, and generative models to aid researchers in testing focused hypotheses about the role of physical embedding in neural systems.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IGJLHVZ7\\Stiso, Bassett - 2018 - Spatial Embedding Imposes Constraints on Neuronal Network Architectures Network Topology versus Geometry in Neur.pdf},
  journal = {Trends in Cognitive Sciences},
  keywords = {dynamics,network,neuroscience,spatial embedding},
  number = {12}
}

@techreport{stocco_rosenbloom_2019,
  title = {A {{Common Architecture}} for {{Human}} and {{Artificial Cognition Explains Brain Activity Across Domains}}},
  author = {Stocco, Andrea and {Steine-Hanson}, Zoe and Koh, Natalie and Laird, John E. and Lebiere, Christian J. and Rosenbloom, Paul},
  year = {2019},
  month = jul,
  institution = {{Neuroscience}},
  doi = {10.1101/703777},
  abstract = {The Common Model of Cognition (CMC) is a consensus architecture for human and human-like artificial cognition. We hypothesized that, because of its generality, the CMC could be a candidate model of the large-scale functional architecture of the human brain. To this end, we analyzed neuroimaging from N=200 participants across seven tasks that cover the broad range of cognitive domains. The CMC framework was translated into a model of neural connectivity between brain regions homologous to CMC components. After the model was implemented and fitted using Dynamic Causal Modeling, its performance was compared against four alternative large-scale brain architectures that had been previously proposed in the field of neuroscience. The results show that the CMC outperforms the other four architectures within and across all domains. These findings suggest that a common, functional computational blueprint for human-like intelligence also captures the neural architecture that underpins human cognition.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SDQV2YGT\\Stocco et al. - 2019 - A Common Architecture for Human and Artificial Cog.pdf},
  language = {en},
  type = {Preprint}
}

@article{stoianov_pezzulo_2018,
  title = {Model-Based Spatial Navigation in the Hippocampus-Ventral Striatum Circuit: A Computational Analysis.},
  author = {Stoianov, I and Pennartz, C and Lansink, C and Pezzulo, G},
  year = {2018},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1006316},
  abstract = {While the neurobiology of simple and habitual choices is relatively well known, our current understanding of goal-directed choices and planning in the brain is still limited. Theoretical work suggests that goal-directed computations can be productively associated to model-based (reinforcement learning) computations, yet a detailed mapping between computational processes and neuronal circuits remains to be fully established. Here we report a computational analysis that aligns Bayesian nonparametrics and model-based reinforcement learning (MB-RL) to the functioning of the hippocampus (HC) and the ventral striatum (vStr)-a neuronal circuit that increasingly recognized to be an appropriate model system to understand goal-directed (spatial) decisions and planning mechanisms in the brain. We test the MB-RL agent in a contextual conditioning task that depends on intact hippocampus and ventral striatal (shell) function and show that it solves the task while showing key behavioral and neuronal signatures of the HC-vStr circuit. Our simulations also explore the benefits of biological forms of look-ahead prediction (forward sweeps) during both learning and control. This article thus contributes to fill the gap between our current understanding of computational algorithms and biological realizations of (model-based) reinforcement learning. Author summary Computational reinforcement learning theories have contributed to advance our understanding of how the brain implements decisions-and especially simple and habitual choices. However, our current understanding of the neural and computational principles of complex and flexible (goal-directed) choices is comparatively less advanced. Here we design and test a novel (model-based) reinforcement learning model, and align its learning and control mechanisms to the functioning of the neural circuit formed by the hippo-campus and the ventral striatum in rodents-which is key to goal-directed spatial cognition. In a series of simulations, we show that our model-based reinforcement learning agent replicates multi-level constraints (behavioral, neural, systems) emerged from rodent cue-and context-conditioning studies, thus contributing to establish a map between computational and neuronal mechanisms of goal-directed spatial cognition. PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi. Citation: Stoianov IP, Pennartz CMA, Lansink CS, Pezzulo G (2018) Model-based spatial navigation in the hippocampus-ventral striatum circuit: A computational analysis. PLoS Comput Biol 14(9): e1006316. https://doi.org/10. Data Availability Statement: Custom software implementing the computational model described in the study is fully available (in a self-maintained repository) at https://github.com/stoianov/MBRL.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3L42VTYD\\Peev Stoianov et al. - 2018 - Model-based spatial navigation in the hippocampus-ventral striatum circuit A computational analysis.pdf},
  journal = {Plos Computational Biology}
}

@techreport{stoianov_pezzulo_2020,
  title = {The Hippocampal Formation as a Hierarchical Generative Model Supporting Generative Replay and Continual Learning},
  author = {Stoianov, Ivilin and Maisto, Domenico and Pezzulo, Giovanni},
  year = {2020},
  month = jan,
  institution = {{Neuroscience}},
  doi = {10.1101/2020.01.16.908889},
  abstract = {We advance a novel computational theory of the hippocampal formation as a hierarchical generative model that organizes sequential experiences, such as rodent trajectories during spatial navigation, into coherent spatiotemporal contexts. We propose that to make this possible, the hippocampal generative model is endowed with strong inductive biases to pattern-separate individual items of experience (at the first hierarchical layer), organize them into sequences (at the second layer) and then cluster them into maps (at the third layer). This theory entails a novel characterization of hippocampal reactivations as generative replay: the offline resampling of fictive sequences from the generative model, for the sake of continual learning of multiple sequential experiences. Our experiments show that the hierarchical model using generative replay is able to learn and retain efficiently multiple spatial navigation trajectories, organizing them into separate spatial maps. Furthermore, it reproduces flexible aspects of hippocampal dynamics that have been challenging to explain within existing frameworks. This theory reconciles multiple roles of the hippocampal formation in mapbased navigation, episodic memory and imagination.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2F34UAFC\\Stoianov et al. - 2020 - The hippocampal formation as a hierarchical genera.pdf},
  language = {en},
  type = {Preprint}
}

@article{stokes_miller_2017,
  title = {Dynamic {{Coding}} for {{Flexible Cognitive Control}}},
  author = {Stokes, Mark G and Buschman, Timothy J and Miller, Earl K},
  year = {2017},
  pages = {221--241},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\462KH668\\Stokes, Buschman, Miller - 2017 - Dynamic Coding for Flexible Cognitive Control.pdf}
}

@article{stokes_stokes_2015,
  title = {`{{Activity}}-Silent' Working Memory in Prefrontal Cortex: A Dynamic Coding Framework},
  shorttitle = {`{{Activity}}-Silent' Working Memory in Prefrontal Cortex},
  author = {Stokes, Mark G.},
  year = {2015},
  month = jul,
  volume = {19},
  pages = {394--405},
  issn = {13646613},
  doi = {10.1016/j.tics.2015.05.004},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7HH9KINL\\Stokes - 2015 - ‘Activity-silent’ working memory in prefrontal cor.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {7}
}

@article{storrs_kriegeskorte_2019,
  title = {Deep {{Learning}} for {{Cognitive Neuroscience}}},
  author = {Storrs, Katherine R. and Kriegeskorte, Nikolaus},
  year = {2019},
  month = mar,
  abstract = {Neural network models can now recognise images, understand text, translate languages, and play many human games at human or superhuman levels. These systems are highly abstracted, but are inspired by biological brains and use only biologically plausible computations. In the coming years, neural networks are likely to become less reliant on learning from massive labelled datasets, and more robust and generalisable in their task performance. From their successes and failures, we can learn about the computational requirements of the different tasks at which brains excel. Deep learning also provides the tools for testing cognitive theories. In order to test a theory, we need to realise the proposed information-processing system at scale, so as to be able to assess its feasibility and emergent behaviours. Deep learning allows us to scale up from principles and circuit models to end-to-end trainable models capable of performing complex tasks. There are many levels at which cognitive neuroscientists can use deep learning in their work, from inspiring theories to serving as full computational models. Ongoing advances in deep learning bring us closer to understanding how cognition and perception may be implemented in the brain -- the grand challenge at the core of cognitive neuroscience.},
  archivePrefix = {arXiv},
  eprint = {1903.01458},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2D65YZDG\\Storrs and Kriegeskorte - 2019 - Deep Learning for Cognitive Neuroscience.pdf},
  journal = {arXiv:1903.01458 [cs, q-bio]},
  language = {en},
  primaryClass = {cs, q-bio}
}

@article{straka_hoffmann_2020,
  title = {{{PreCNet}}: {{Next Frame Video Prediction Based}} on {{Predictive Coding}}},
  shorttitle = {{{PreCNet}}},
  author = {Straka, Zdenek and Svoboda, Tomas and Hoffmann, Matej},
  year = {2020},
  month = apr,
  abstract = {Predictive coding, currently a highly influential theory in neuroscience, has not been widely adopted in machine learning yet. In this work, we transform the seminal model of Rao and Ballard (1999) into a modern deep learning framework while remaining maximally faithful to the original schema. The resulting network we propose (PreCNet) is tested on a widely used next frame video prediction benchmark, which consists of images from an urban environment recorded from a car-mounted camera. On this benchmark (training: 41k images from KITTI dataset; testing: Caltech Pedestrian dataset), we achieve to our knowledge the best performance to date when measured with the Structural Similarity Index (SSIM). On two other common measures, MSE and PSNR, the model ranked third and fourth, respectively. Performance was further improved when a larger training set (2M images from BDD100k), pointing to the limitations of the KITTI training set. This work demonstrates that an architecture carefully based in a neuroscience model, without being explicitly tailored to the task at hand, can exhibit unprecedented performance.},
  archivePrefix = {arXiv},
  eprint = {2004.14878},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CT7B4AXR\\straka_hoffmann_2020.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\N3YUUNIN\\2004.html},
  journal = {arXiv:2004.14878 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  primaryClass = {cs}
}

@article{suchow_alvarez_2011,
  title = {Report {{Motion Silences Awareness}} of {{Visual Change}}},
  author = {Suchow, Jordan W and Alvarez, George A},
  year = {2011},
  volume = {21},
  pages = {140--143},
  doi = {10.1016/j.cub.2010.12.019},
  abstract = {Loud bangs, bright flashes, and intense shocks capture attention, but other changes\textemdash even those of similar magni-tude\textemdash can go unnoticed. Demonstrations of change blind-ness have shown that observers fail to detect substantial alterations to a scene when distracted by an irrelevant flash, or when the alterations happen gradually [1\textendash 5]. Here, we show that objects changing in hue, luminance, size, or shape appear to stop changing when they move. This motion-induced failure to detect change, silencing, persists even though the observer attends to the objects, knows that they are changing, and can make veridical judgments about their current state. Silencing demonstrates the tight coupling of motion and object appearance. Results},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GXHK88DT\\Suchow, Alvarez - 2011 - Report Motion Silences Awareness of Visual Change.pdf},
  journal = {Current Biology}
}

@article{sugase-miyamoto_richmond_2008,
  title = {Short-{{Term Memory Trace}} in {{Rapidly Adapting Synapses}} of {{Inferior Temporal Cortex}}},
  author = {{Sugase-Miyamoto}, Yasuko and Liu, Zheng and Wiener, Matthew C. and Optican, Lance M. and Richmond, Barry J.},
  editor = {Friston, Karl J.},
  year = {2008},
  month = may,
  volume = {4},
  pages = {e1000073},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1000073},
  abstract = {Visual short-term memory tasks depend upon both the inferior temporal cortex (ITC) and the prefrontal cortex (PFC). Activity in some neurons persists after the first (sample) stimulus is shown. This delay-period activity has been proposed as an important mechanism for working memory. In ITC neurons, intervening (nonmatching) stimuli wipe out the delay-period activity; hence, the role of ITC in memory must depend upon a different mechanism. Here, we look for a possible mechanism by contrasting memory effects in two architectonically different parts of ITC: area TE and the perirhinal cortex. We found that a large proportion (80\%) of stimulus-selective neurons in area TE of macaque ITCs exhibit a memory effect during the stimulus interval. During a sequential delayed matching-to-sample task (DMS), the noise in the neuronal response to the test image was correlated with the noise in the neuronal response to the sample image. Neurons in perirhinal cortex did not show this correlation. These results led us to hypothesize that area TE contributes to short-term memory by acting as a matched filter. When the sample image appears, each TE neuron captures a static copy of its inputs by rapidly adjusting its synaptic weights to match the strength of their individual inputs. Input signals from subsequent images are multiplied by those synaptic weights, thereby computing a measure of the correlation between the past and present inputs. The total activity in area TE is sufficient to quantify the similarity between the two images. This matched filter theory provides an explanation of what is remembered, where the trace is stored, and how comparison is done across time, all without requiring delay period activity. Simulations of a matched filter model match the experimental results, suggesting that area TE neurons store a synaptic memory trace during short-term visual memory.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\K7A68TK2\\Sugase-Miyamoto et al. - 2008 - Short-Term Memory Trace in Rapidly Adapting Synaps.pdf},
  journal = {PLoS Computational Biology},
  language = {en},
  number = {5}
}

@article{sullivan_sullivan_1997,
  title = {System {{Analogies}}},
  author = {Sullivan, Charles},
  year = {1997},
  pages = {1--6},
  abstract = {There are simple and straightforward analogies between electrical, thermal, and fluid systems that we have been using as we study thermal and fluid systems. They are detailed in the center column of the table at the end of this handout. The analogies between current, heat flow, and fluid flow are intuitive and can be directly applied; KCL or the like works for all of them. Likewise, the analogies between voltage, temperature and pressure are intuitive and useful. Usually the quantity of interest is the pressure, voltage, or temperature difference across some element (although absolute pressure and temperature are well defined quantities, unlike absolute voltage, which is not defined except if some arbitrary reference point, such as the earth, is used). And KVL or something similar works for all three of these across variables (v, T, and p). However, mechanical, chemical, and resource systems don't fit so neatly into this scheme. Chemical and resource systems don't really fit at all. Although the faculty involved in this course have discussed a few possible analogies for chemical and resource systems, none help much or make much sense, and none are in common use. Analogies between mechanical systems and electrical and fluid systems, however, do work well and are in common use. The complication is that there are two ways to make the analogy, both of which work, and both of which have particular advantages and disadvantages. Mechanical Analogy I: Intuitive},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QSIW468M\\Sullivan - 1997 - System Analogies.pdf}
}

@article{sulpizio_galati_2016,
  title = {Role of the Human Retrosplenial Cortex/Parieto-Occipital Sulcus in Perspective Priming},
  author = {Sulpizio, Valentina and Committeri, Giorgia and Lambrey, Simon and Berthoz, Alain and Galati, Gaspare},
  year = {2016},
  volume = {125},
  pages = {108--119},
  issn = {10959572},
  doi = {10.1016/j.neuroimage.2015.10.040},
  abstract = {The ability to imagine the world from a different viewpoint is a fundamental competence for spatial reorientation and for imagining what another individual sees in the environment. Here, we investigated the neural bases of such an ability using functional magnetic resonance imaging. Healthy participants detected target displacements across consecutive views of a familiar virtual room, either from the perspective of an avatar (primed condition) or in the absence of such a prime (unprimed condition). In the primed condition, the perspective at test always corresponded to the avatar's perspective, while in the unprimed condition it was randomly chosen as 0, 45 or 135 deg of viewpoint rotation. We observed a behavioral advantage in performing a perspective transformation during the primed condition as compared to an equivalent amount of unprimed perspective change. Although many cortical regions (dorsal parietal, parieto-temporo-occipital junction, precuneus and retrosplenial cortex/parieto-occipital sulcus or RSC/POS) were involved in encoding and retrieving target location from different perspectives and were modulated by the amount of viewpoint rotation, the RSC/POS was the only area showing decreased activity in the primed as compared to the unprimed condition, suggesting that this region anticipates the upcoming perspective change. The retrosplenial cortex/parieto-occipital sulcus appears to play a special role in the allocentric coding of heading directions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FB8UZHSJ\\Sulpizio et al. - 2016 - Role of the human retrosplenial cortexparieto-occipital sulcus in perspective priming.pdf},
  journal = {NeuroImage},
  keywords = {Functional magnetic resonance (fMRI),Perspective priming,Retrosplenial cortex/parieto-occipital sulcus (RSC,Spatial memory,Viewpoint change,Virtual reality},
  pmid = {26484830}
}

@article{suma_suma_2017,
  title = {Biologically {{Plausible Cortical Hierarchical}}-{{Classifier Circuit Extensions}} in {{Spiking Neurons}}},
  author = {Suma, Peter},
  year = {2017},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KTLDLMEC\\Suma - 2017 - by.pdf}
}

@article{summerfield_sheahan_2019,
  title = {Structure Learning and the Posterior Parietal Cortex},
  author = {Summerfield, Christopher and Luyckx, Fabrice and Sheahan, Hannah},
  year = {2019},
  month = oct,
  pages = {101717},
  issn = {03010082},
  doi = {10.1016/j.pneurobio.2019.101717},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FYCKLJTG\\Summerfield et al. - 2019 - Structure learning and the posterior parietal cort.pdf},
  journal = {Progress in Neurobiology},
  language = {en}
}

@article{sun_orchard_2020,
  title = {A {{Predictive}}-{{Coding Network That Is Both Discriminative}} and {{Generative}}},
  author = {Sun, Wei and Orchard, Jeff},
  year = {2020},
  month = aug,
  pages = {1--27},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/neco_a_01311},
  abstract = {Predictive coding (PC) networks are a biologically interesting class of neural networks. Their layered hierarchy mimics the reciprocal connectivity pattern observed in the mammalian cortex, and they can be trained using local learning rules that approximate backpropagation (Bogacz, 2017). However, despite having feedback connections that enable information to flow down the network hierarchy, discriminative PC networks are not typically generative. Clamping the output class and running the network to equilibrium yields an input sample that usually does not resemble the training input. This letter studies this phenomenon and proposes a simple solution that promotes the generation of input samples that resemble the training inputs. Simple decay, a technique already in wide use in neural networks, pushes the PC network toward a unique minimum two-norm solution, and that unique solution provably (for linear networks) matches the training inputs. The method also vastly improves the samples generated for nonlinear networks, as we demonstrate on MNIST.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UJQ5A9YY\\Sun and Orchard - 2020 - A Predictive-Coding Network That Is Both Discrimin.pdf},
  journal = {Neural Computation},
  language = {en}
}

@article{sun_sun_,
  title = {Decay {{Makes Supervised Predictive Coding Generative}}},
  author = {Sun, Wei},
  pages = {121},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\T8VKE6JK\\Sun - Decay Makes Supervised Predictive Coding Generativ.pdf},
  language = {en}
}

@article{sun_tonegawa_2019,
  title = {{{CA1}} Pyramidal Cells Organize an Episode by Segmented and Ordered Events},
  author = {Sun, Chen and Yang, Wannan and Martin, Jared and Tonegawa, Susumu},
  year = {2019},
  month = mar,
  doi = {10.1101/565689},
  abstract = {A prevailing view is that the brain represents episodic experience as the continuous moment to moment changes in the experience. Whether the brain also represents the same experience as a sequence of discretely segmented events, is unknown. Here, we report a hippocampal CA1 ``chunking code'', tracking an episode as its discrete event subdivisions (``chunks'') and the sequential relationships between them. The chunking code is unaffected by unpredicted variations within the events, reflecting the code's flexible nature by being organized around events as abstract units. The chunking code changes accordingly when relationships between events are disrupted or modified. The discrete chunking code and continuous spatial code are represented in the same cells, but in an orthogonal manner, and can be independently perturbed. Optogenetic inactivation of MEC inputs to CA1 disrupts the chunking but not spatial code. The chunking code may be fundamental for representing an episode, alongside codes tracking continuous changes.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SXMBTB68\\Sun et al. - 2019 - CA1 pyramidal cells organize an episode by segment.pdf},
  journal = {bioRxiv},
  language = {en}
}

@article{sussillo_abbott_2009,
  title = {Generating {{Coherent Patterns}} of {{Activity}} from {{Chaotic Neural Networks}}},
  author = {Sussillo, David and Abbott, L.F.},
  year = {2009},
  month = aug,
  volume = {63},
  pages = {544--557},
  issn = {08966273},
  doi = {10.1016/j.neuron.2009.07.018},
  abstract = {Neural circuits display complex activity patterns both spontaneously and when responding to a stimulus or generating a motor output. How are these two forms of activity related? We develop a procedure called FORCE learning for modifying synaptic strengths either external to or within a model neural network to change chaotic spontaneous activity into a wide variety of desired activity patterns. FORCE learning works even though the networks we train are spontaneously chaotic and we leave feedback loops intact and unclamped during learning. Using this approach, we construct networks that produce a wide variety of complex output patterns, input-output transformations that require memory, multiple outputs that can be switched by control inputs, and motor patterns matching human motion capture data. Our results reproduce data on premovement activity in motor and premotor cortex, and suggest that synaptic plasticity may be a more rapid and powerful modulator of network activity than generally appreciated.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3HYBDLLD\\Sussillo and Abbott - 2009 - Generating Coherent Patterns of Activity from Chao.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\7KB493R2\\Sussillo and Abbott - 2009 - Generating Coherent Patterns of Activity from Chao.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\9ISQ3LD9\\Sussillo and Abbott - 2009 - Generating Coherent Patterns of Activity from Chao.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\TFIW56KR\\Sussillo and Abbott - 2009 - Generating Coherent Patterns of Activity from Chao.pdf},
  journal = {Neuron},
  language = {en},
  number = {4}
}

@article{sutton_barto_1998,
  title = {Introduction},
  author = {Sutton, Richard S and Barto, Andrew G},
  year = {1998},
  issn = {\textbackslash textlessnull\textbackslash textgreater},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CYZXKNXC\\Sutton, Barto - 1998 - Introduction.pdf},
  journal = {Reinforcement Learning}
}

@book{sutton_barto_2012,
  title = {Reinforcement Learning},
  author = {Sutton, Richard S and Barto, Andrew G},
  year = {2012},
  edition = {2nd Editio},
  publisher = {{MIT Press}},
  doi = {10.1109/MED.2013.6608833},
  abstract = {Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives when interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability. The book is divided into three parts. Part I defines the reinforcement learning problem in terms of Markov decision processes. Part II provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. Part III presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HNK3DGY6\\Sutton, Barto - 2012 - Reinforcement learning.pdf},
  isbn = {0-262-19398-1}
}

@book{sutton_barto_2018,
  title = {Reinforcement {{Learning}}},
  author = {Sutton, Richard S and Barto, Andrew G},
  year = {2018},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HQGKVVNW\\Sutton, Barto - 2018 - Reinforcement Learning.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\V6SE5RAI\\Richard S. Sutton and Andrew G. Barto - 2018 - Reinforcement Learning, Second Edition An Introduction.pdf},
  isbn = {978-0-262-03924-6},
  keywords = {Reinforcement Learning}
}

@article{sutton_sutton_1991,
  title = {Dyna, an Integrated Architecture for Learning, Planning, and Reacting},
  author = {Sutton, Richard S.},
  year = {1991},
  month = jul,
  volume = {2},
  pages = {160--163},
  issn = {01635719},
  doi = {10.1145/122344.122377},
  abstract = {Dyna is an AI architecture that integrates learning, planning, and reactive execution. Learning methods are used in Dyna both for compiling planning results and for updating a model of the effects of the agent's actions on the world. Planning is incremental and can use the probabilistic and ofttimes incorrect world models generated by learning processes. Execution is fully reactive in the sense that no planning intervenes between perception and action. Dyna relies on machine learning methods for learning from examples--these are among the basic building blocks making up the architecture--yet is not tied to any particular method. This paper briefly introduces Dyna and discusses its strengths and weaknesses with respect to other architectures.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FHIJC8J8\\Sutton - 1991 - Dyna, an integrated architecture for learning, pla.pdf},
  journal = {ACM SIGART Bulletin},
  language = {en},
  number = {4}
}

@article{sweeney-reed_richardson-klavehn_2014,
  title = {Corticothalamic Phase Synchrony and Cross-Frequency Coupling Predict Human Memory Formation.},
  author = {{Sweeney-Reed}, Catherine M and Zaehle, Tino and Voges, Juergen and Schmitt, Friedhelm C and Buentjen, Lars and Kopitzki, Klaus and Esslinger, Christine and Hinrichs, Hermann and Heinze, Hans-Jochen and Knight, Robert T and {Richardson-Klavehn}, Alan},
  year = {2014},
  volume = {3},
  pages = {e05352},
  issn = {2050-084X},
  doi = {10.7554/eLife.05352},
  abstract = {The anterior thalamic nucleus (ATN) is thought to play an important role in a brain network involving the hippocampus and neocortex, which enables human memories to be formed. However, its small size and location deep within the brain have impeded direct investigation in humans with non-invasive techniques. Here we provide direct evidence for a functional role for the ATN in memory formation from rare simultaneous human intrathalamic and scalp electroencephalogram (EEG) recordings from eight volunteering patients receiving intrathalamic electrodes implanted for the treatment of epilepsy, demonstrating real-time communication between neocortex and ATN during successful memory encoding. Neocortical-ATN theta oscillatory phase synchrony of local field potentials and neocortical-theta-to-ATN-gamma cross-frequency coupling during presentation of complex photographic scenes predicted later memory for the scenes, demonstrating a key role for the ATN in human memory encoding.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PQYIWLDW\\Sweeney-Reed et al. - 2014 - Corticothalamic phase synchrony and cross-frequency coupling predict human memory formation.pdf},
  journal = {eLife},
  pmid = {25535839}
}

@article{swets_birdsall_1961,
  title = {Decision {{Processes}} in {{Perception}}},
  author = {a. Swets, J and Tanner, W P and Birdsall, T G},
  year = {1961},
  volume = {68},
  pages = {301--340},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3U7KZU49\\Swets, Tanner, Birdsall - 1961 - Decision Processes in Perception.pdf},
  journal = {Psychological Review},
  number = {5}
}

@article{swets_swets_1961,
  title = {Is {{There}} a {{Sensory Threshold}}?: {{When}} the Effects of the Observer's Response Criterion Are Isolated, a Sensory Limitation Is Not Evident},
  author = {a. Swets, J},
  year = {1961},
  volume = {134},
  pages = {168--177},
  issn = {0036-8075},
  doi = {10.1126/science.134.3473.168},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YYPQGKQJ\\Swets - 1961 - Is There a Sensory Threshold When the effects of the observer's response criterion are isolated, a sensory limitation is.pdf},
  journal = {Science},
  number = {3473}
}

@article{szczepanski_knight_2014,
  title = {Dynamic {{Changes}} in {{Phase}}-{{Amplitude Coupling Facilitate Spatial Attention Control}} in {{Fronto}}-{{Parietal Cortex}}.},
  author = {Szczepanski, Sara M and Crone, Nathan E and a Kuperman, Rachel and Auguste, Kurtis I and Parvizi, Josef and Knight, Robert T},
  year = {2014},
  month = aug,
  volume = {12},
  pages = {e1001936},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.1001936},
  abstract = {Attention is a core cognitive mechanism that allows the brain to allocate limited resources depending on current task demands. A number of frontal and posterior parietal cortical areas, referred to collectively as the fronto-parietal attentional control network, are engaged during attentional allocation in both humans and non-human primates. Numerous studies have examined this network in the human brain using various neuroimaging and scalp electrophysiological techniques. However, little is known about how these frontal and parietal areas interact dynamically to produce behavior on a fine temporal (sub-second) and spatial (sub-centimeter) scale. We addressed how human fronto-parietal regions control visuospatial attention on a fine spatiotemporal scale by recording electrocorticography (ECoG) signals measured directly from subdural electrode arrays that were implanted in patients undergoing intracranial monitoring for localization of epileptic foci. Subjects (n = 8) performed a spatial-cuing task, in which they allocated visuospatial attention to either the right or left visual field and detected the appearance of a target. We found increases in high gamma (HG) power (70-250 Hz) time-locked to trial onset that remained elevated throughout the attentional allocation period over frontal, parietal, and visual areas. These HG power increases were modulated by the phase of the ongoing delta/theta (2-5 Hz) oscillation during attentional allocation. Critically, we found that the strength of this delta/theta phase-HG amplitude coupling predicted reaction times to detected targets on a trial-by-trial basis. These results highlight the role of delta/theta phase-HG amplitude coupling as a mechanism for sub-second facilitation and coordination within human fronto-parietal cortex that is guided by momentary attentional demands.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\N36Y69AJ\\Szczepanski et al. - 2014 - Dynamic Changes in Phase-Amplitude Coupling Facilitate Spatial Attention Control in Fronto-Parietal Cortex.pdf},
  journal = {PLoS biology},
  number = {8},
  pmid = {25157678}
}

@article{taherkhani_mcginnity_2020,
  title = {A Review of Learning in Biologically Plausible Spiking Neural Networks},
  author = {Taherkhani, Aboozar and Belatreche, Ammar and Li, Yuhua and Cosma, Georgina and Maguire, Liam P. and McGinnity, T.M.},
  year = {2020},
  month = feb,
  volume = {122},
  pages = {253--272},
  issn = {08936080},
  doi = {10.1016/j.neunet.2019.09.036},
  abstract = {Artificial neural networks have been used as a powerful processing tool in various areas such as pattern recognition, control, robotics, and bioinformatics. Their wide applicability has encouraged researchers to improve artificial neural networks by investigating the biological brain. Neurological research has significantly progressed in recent years and continues to reveal new characteristics of biological neurons. New technologies can now capture temporal changes in the internal activity of the brain in more detail and help clarify the relationship between brain activity and the perception of a given stimulus. This new knowledge has led to a new type of artificial neural network, the Spiking Neural Network (SNN), that draws more faithfully on biological properties to provide higher processing abilities. A review of recent developments in learning of spiking neurons is presented in this paper. First the biological background of SNN learning algorithms is reviewed. The important elements of a learning algorithm such as the neuron model, synaptic plasticity, information encoding and SNN topologies are then presented. Then, a critical review of the state-of-the-art learning algorithms for SNNs using single and multiple spikes is presented. Additionally, deep spiking neural networks are reviewed, and challenges and opportunities in the SNN field are discussed.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\46BBMG2J\\Taherkhani et al. - 2020 - A review of learning in biologically plausible spi.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\H2D2R9XD\\Taherkhani et al. - 2020 - A review of learning in biologically plausible spi.pdf},
  journal = {Neural Networks},
  language = {en}
}

@article{tait_goodfellow_2018,
  title = {Control of Clustered Action Potential Firing in a Mathematical Model of Entorhinal Cortex Stellate Cells},
  author = {Tait, Luke and Wedgwood, Kyle and {Tsaneva-Atanasova}, Krasimira and Brown, Jon T. and Goodfellow, Marc},
  year = {2018},
  issn = {00225193},
  doi = {10.1016/j.jtbi.2018.04.013},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8F4HWI32\\Tait et al. - 2018 - Control of clustered action potential firing in a mathematical model of entorhinal cortex stellate cells.pdf},
  journal = {Journal of Theoretical Biology},
  keywords = {bifurcation analysis,bursting,Dementia,neuron model,subthreshold oscillations}
}

@article{takahashi_larkum_2020,
  title = {Active Dendritic Currents Gate Descending Cortical Outputs in Perception},
  author = {Takahashi, Naoya and Ebner, Christian and {Sigl-Gl{\"o}ckner}, Johanna and Moberg, Sara and Nierwetberg, Svenja and Larkum, Matthew E.},
  year = {2020},
  month = aug,
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-020-0677-8},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LJNHSVVG\\Takahashi et al. - 2020 - Active dendritic currents gate descending cortical.pdf},
  journal = {Nature Neuroscience},
  language = {en}
}

@article{takahashi_larkum_2020a,
  title = {Active Dendritic Currents Gate Descending Cortical Outputs in Perception},
  author = {Takahashi, Naoya and Ebner, Christian and {Sigl-Gl{\"o}ckner}, Johanna and Moberg, Sara and Nierwetberg, Svenja and Larkum, Matthew E.},
  year = {2020},
  month = aug,
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-020-0677-8},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YFMUEXHW\\Takahashi et al. - 2020 - Active dendritic currents gate descending cortical.pdf},
  journal = {Nature Neuroscience},
  language = {en}
}

@article{takeda_miyashita_2018,
  title = {Dynamic Laminar Rerouting of Inter-Areal Mnemonic Signal by Cognitive Operations in Primate Temporal Cortex},
  author = {Takeda, Masaki and Hirabayashi, Toshiyuki and Adachi, Yusuke and Miyashita, Yasushi},
  year = {2018},
  doi = {10.1038/s41467-018-07007-1},
  abstract = {Execution of cognitive functions is orchestrated by a brain-wide network comprising multiple regions. However, it remains elusive whether the cortical laminar pattern of inter-areal interactions exhibits dynamic routings, depending on cognitive operations. We address this issue by simultaneously recording neuronal activities from area 36 and area TE of the temporal cortex while monkeys performed a visual cued-recall task. We identify dynamic laminar routing of the inter-areal interaction: during visual processing of a presented cue, spiking activities of area 36 neurons are preferentially coherent with local field potentials at the supragranular layer of area TE, while the signal from the same neurons switches to target the infragranular layer of area TE during memory retrieval. This layer-dependent signal represents the to-be-recalled object, and has an impact on the local processing at the supragranular layer in both cognitive operations. Thus, cortical layers form a key structural basis for dynamic switching of cognitive operations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PQ7FUWWI\\Takeda et al. - Unknown - Dynamic laminar rerouting of inter-areal mnemonic signal by cognitive operations in primate temporal cortex.pdf}
}

@article{tampuu_vicente_2019,
  title = {Efficient Neural Decoding of Self-Location with a Deep Recurrent Network},
  author = {Tampuu, Ardi and Matiisen, Tambet and {\'O}lafsd{\'o}ttir, H. Freyja and Barry, Caswell and Vicente, Raul},
  editor = {Battaglia, Francesco P.},
  year = {2019},
  month = feb,
  volume = {15},
  pages = {e1006822},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1006822},
  abstract = {Place cells in the mammalian hippocampus signal self-location with sparse spatially stable firing fields. Based on observation of place cell activity it is possible to accurately decode an animal's location. The precision of this decoding sets a lower bound for the amount of information that the hippocampal population conveys about the location of the animal. In this work we use a novel recurrent neural network (RNN) decoder to infer the location of freely moving rats from single unit hippocampal recordings. RNNs are biologically plausible models of neural circuits that learn to incorporate relevant temporal context without the need to make complicated assumptions about the use of prior information to predict the current state. When decoding animal position from spike counts in 1D and 2D-environments, we show that the RNN consistently outperforms a standard Bayesian approach with either flat priors or with memory. In addition, we also conducted a set of sensitivity analysis on the RNN decoder to determine which neurons and sections of firing fields were the most influential. We found that the application of RNNs to neural data allowed flexible integration of temporal context, yielding improved accuracy relative to the more commonly used Bayesian approaches and opens new avenues for exploration of the neural code. Published: February 15, 2019 Copyright: \textcopyright{} 2019 Tampuu et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\W9YZBLFE\\Tampuu et al. - 2019 - Efficient neural decoding of self-location with a .pdf},
  journal = {PLOS Computational Biology},
  language = {en},
  number = {2}
}

@article{tamura_gordon_2017,
  title = {Hippocampal-Prefrontal Theta-Gamma Coupling during Performance of a Spatial Working Memory Task},
  author = {Tamura, Makoto and Spellman, Timothy J and Rosen, Andrew M and Gogos, Joseph A and Gordon, Joshua A},
  year = {2017},
  doi = {10.1038/s41467-017-02108-9},
  abstract = {Cross-frequency coupling supports the organization of brain rhythms and is present during a range of cognitive functions. However, little is known about whether and how long-range cross-frequency coupling across distant brain regions subserves working memory. Here we report that theta\textendash slow gamma coupling between the hippocampus and medial prefrontal cortex (mPFC) is augmented in a genetic mouse model of cognitive dysfunction. This increased cross-frequency coupling is observed specifically when the mice successfully perform a spatial working memory task. In wild-type mice, increasing task difficulty by introducing a long delay or by optogenetically interfering with encoding, also increases theta\textendash gamma coupling during correct trials. Finally, epochs of high hippocampal theta\textendash prefrontal slow gamma coupling are associated with increased synchronization of neurons within the mPFC. These findings suggest that enhancement of theta\textendash slow gamma coupling reflects a compensatory mechanism to maintain spatial working memory perfor-mance in the setting of increased difficulty.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7HUEGSVL\\Tamura et al. - Unknown - Hippocampal-prefrontal theta-gamma coupling during performance of a spatial working memory task.pdf}
}

@article{tanaka_tanaka_1996,
  title = {Representation of Visual Features of Objects in the Inferotemporal Cortex},
  author = {Tanaka, Keiji},
  year = {1996},
  volume = {9},
  pages = {1459--1475},
  issn = {08936080},
  doi = {10.1016/S0893-6080(96)00045-7},
  abstract = {Cells in area TE of the inferotemporal cortex of the monkey brain selectively respond to various moderately complex object features, and those that respond to similar features cluster in a columnar region elongated vertical to the cortical surface. Columns representing related but different features partially overlap, and at least in some cases they comprise a continuous map of a piece of complex feature space. This continuous mapping is likely used for various computations, such as production of the image of the object at different viewing angles, illumination conditions, and articulation poses.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\F79EU6W8\\Tanaka - 1996 - Representation of visual features of objects in the inferotemporal cortex.pdf},
  journal = {Neural Networks},
  keywords = {area TE,extrastriate visual cortex,inferotemporal cortex,Macaque monkey,object recognition,object vision,optical imaging,population coding},
  number = {8},
  pmid = {12662545}
}

@article{tang_brecht_2014,
  title = {Pyramidal and {{Stellate Cell Specificity}} of {{Grid}} and {{Border Representations}} in {{Layer}} 2 of {{Medial Entorhinal Cortex}}},
  author = {Tang, Qiusong and Burgalossi, Andrea and Ebbesen, Christian Laut and Ray, Saikat and Naumann, Robert and Schmidt, Helene and Spicher, Dominik and Brecht, Michael},
  year = {2014},
  volume = {84},
  pages = {1191--1197},
  issn = {08966273},
  doi = {10.1016/j.neuron.2014.11.009},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\784HWHZ3\\Tang et al. - 2014 - Pyramidal and Stellate Cell Specificity of Grid and Border Representations in Layer 2 of Medial Entorhinal Corte(3).pdf},
  journal = {Neuron},
  number = {6}
}

@article{tang_jadhav_2018,
  title = {Conducting the {{Neural Symphony}} of {{Memory Replay}}},
  author = {Tang, Wenbo and Jadhav, Shantanu P},
  year = {2018},
  volume = {100},
  pages = {1016--1019},
  doi = {10.1016/j.neuron.2018.11.037},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7DWZQWD2\\Tang, Jadhav - 2018 - Conducting the Neural Symphony of Memory Replay.pdf},
  journal = {Neuron}
}

@techreport{tarder-stoll_aly_2019,
  title = {Dynamic Internal States Shape Memory Retrieval},
  author = {{Tarder-Stoll}, Hannah and Jayakumar, Manasi and {Dimsdale-Zucker}, Halle R. and Gunseli, Eren and Aly, Mariam},
  year = {2019},
  month = jul,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/kudj3},
  abstract = {Why do we sometimes easily retrieve memories, but other times appear to forget them? We often look to our external environment for retrieval cues, but another way to optimize memory retrieval is to be in a mental state, or mode, that prioritizes access to our internal representation of the world. Such a `retrieval mode' was proposed by Endel Tulving (1983), who considered it a neurocognitive state in which one keeps the goal of memory retrieval in mind. Building on Tulving's proposal, we review converging evidence from multiple lines of research that emphasize the importance of internal states in the instantiation of retrieval modes that optimize successful remembering. We identify three key factors that contribute to a retrieval mode by modulating either the likelihood or the content of retrieval: (1) an intention to remember or forget (either in the present or the future), (2) attentional selection of goal-relevant memories and suppression of distractors, and (3) fluctuating levels of acetylcholine in the hippocampus. We discuss empirical evidence that these internal states individually influence memory retrieval and propose how they may interact synergistically. Characterizing these dynamic internal factors may be a key to unlocking our understanding of the organization and accessibility of our memories.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6R5EYQKZ\\Tarder-Stoll et al. - 2019 - Dynamic internal states shape memory retrieval.pdf},
  language = {en},
  type = {Preprint}
}

@article{tarvainen_valpola_2017,
  title = {Mean Teachers Are Better Role Models: {{Weight}}-Averaged Consistency Targets Improve Semi-Supervised Deep Learning Results},
  author = {Tarvainen, Antti and Valpola, Harri},
  year = {2017},
  abstract = {The recently proposed Temporal Ensembling has achieved state-of-the-art results in several semi-supervised learning benchmarks. It maintains an exponential moving average of label predictions on each training example, and penalizes predictions that are inconsistent with this target. However, because the targets change only once per epoch, Temporal Ensembling becomes unwieldy when learning large datasets. To overcome this problem, we propose Mean Teacher, a method that averages model weights instead of label predictions. As an additional benefit, Mean Teacher improves test accuracy and enables training with fewer labels than Temporal Ensembling. Without changing the network architecture, Mean Teacher achieves an error rate of 4.35\% on SVHN with 250 labels, outperforming Temporal Ensembling trained with 1000 labels. We also show that a good network architecture is crucial to performance. Combining Mean Teacher and Residual Networks, we improve the state of the art on CIFAR-10 with 4000 labels from 10.55\% to 6.28\%, and on ImageNet 2012 with 10\% of the labels from 35.24\% to 9.11\%.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3VEHVV3N\\Tarvainen, Valpola - 2017 - Mean teachers are better role models Weight-averaged consistency targets improve semi-supervised deep learni.pdf},
  number = {Nips}
}

@article{taube_taube_2007,
  title = {The Head Direction Signal: Origins and Sensory-Motor Integration.},
  author = {Taube, Jeffrey S},
  year = {2007},
  month = jan,
  volume = {30},
  pages = {181--207},
  issn = {0147-006X},
  doi = {10.1146/annurev.neuro.29.051605.112854},
  abstract = {Navigation first requires accurate perception of one's spatial orientation within the environment, which consists of knowledge about location and directional heading. Cells within several limbic system areas of the mammalian brain discharge allocentrically as a function of the animal's directional heading, independent of the animal's location and ongoing behavior. These cells are referred to as head direction (HD) cells and are believed to encode the animal's perceived directional heading with respect to its environment. Although HD cells are found in several areas, the principal circuit for generating this signal originates in the dorsal tegmental nucleus and projects serially, with some reciprocal connections, to the lateral mammillary nucleus \textendash\{\textbackslash textgreater\} anterodorsal thalamus \textendash\{\textbackslash textgreater\} PoS, and terminates in the entorhinal cortex. HD cells receive multimodal information about landmarks and self-generated movements. Vestibular information appears critical for generating the directional signal, but motor/proprioceptive and landmark information are important for updating it.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IJ5HIYQN\\Taube - 2007 - The head direction signal origins and sensory-motor integration.pdf},
  journal = {Annual review of neuroscience},
  keywords = {Animals,Brain,Brain: anatomy {\&} histology,Brain: anatomy \& histology,Brain: physiology,Head Movements,Head Movements: physiology,Humans,Labyrinth,Labyrinth: physiology,Locomotion,Locomotion: physiology,Neural Pathways,Neural Pathways: anatomy {\&} histology,Neural Pathways: anatomy \& histology,Neural Pathways: physiology,Neurons,Neurons: physiology,Orientation,Orientation: physiology,Psychomotor Performance,Psychomotor Performance: physiology,Space Perception,Space Perception: physiology,Vestibule},
  pmid = {17341158}
}

@article{tchumatchenko_wolf_2011,
  title = {Spike Correlations - What Can They Tell about Synchrony?},
  author = {Tchumatchenko, Tatjana and Geisel, Theo and Volgushev, Maxim and Wolf, Fred},
  year = {2011},
  month = jan,
  volume = {5},
  pages = {68},
  issn = {1662-453X},
  doi = {10.3389/fnins.2011.00068},
  abstract = {Sensory and cognitive processing relies on the concerted activity of large populations of neurons. The advent of modern experimental techniques like two-photon population calcium imaging makes it possible to monitor the spiking activity of multiple neurons as they are participating in specific cognitive tasks. The development of appropriate theoretical tools to quantify and interpret the spiking activity of multiple neurons, however, is still in its infancy. One of the simplest and widely used measures of correlated activity is the pairwise correlation coefficient. While spike correlation coefficients are easy to compute using the available numerical toolboxes, it has remained largely an open question whether they are indeed a reliable measure of synchrony. Surprisingly, despite the intense use of correlation coefficients in the design of synthetic spike trains, the construction of population models and the assessment of the synchrony level in live neuronal networks very little was known about their computational properties. We showed that many features of pairwise spike correlations can be studied analytically in a tractable threshold model. Importantly, we demonstrated that under some circumstances the correlation coefficients can vanish, even though input and also pairwise spike cross correlations are present. This finding suggests that the most popular and frequently used measures can, by design, fail to capture the neuronal synchrony.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3HF9XS3T\\Tchumatchenko et al. - 2011 - Spike correlations - what can they tell about synchrony.pdf},
  journal = {Frontiers in neuroscience},
  keywords = {at the g{ö}ttingen,at the göttingen,correlation coefficient,count correlations,graduate school for neurosciences,phd thesis in 2010,spike correlations,synchrony,tatjana tchumatchenko defended her},
  number = {May},
  pmid = {21617732}
}

@article{teles-griloruivo_mellor_2017,
  title = {Coordinated {{Acetylcholine Release}} in {{Prefrontal Cortex}} and {{Hippocampus Is Associated}} with {{Arousal}} and {{Reward}} on {{Distinct Timescales}}},
  author = {{Teles-Grilo Ruivo}, Leonor M and Baker, Keeley L and Conway, Michael W and Kinsley, Peter J and Gilmour, Gary and Phillips, Keith G and Isaac, John T R and Lowry, John P and Mellor, Jack R},
  year = {2017},
  volume = {18},
  pages = {905--917},
  issn = {22111247},
  doi = {10.1016/j.celrep.2016.12.085},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VM8G6MIZ\\Teles-Grilo Ruivo et al. - 2017 - Coordinated Acetylcholine Release in Prefrontal Cortex and Hippocampus Is Associated with Arousal and.pdf},
  journal = {Cell Reports},
  number = {4}
}

@article{tenison_anderson_2016,
  title = {Phases of Learning: {{How}} Skill Acquisition Impacts Cognitive Processing},
  author = {Tenison, Caitlin and Fincham, Jon M and Anderson, John R},
  year = {2016},
  volume = {87},
  pages = {1--28},
  doi = {10.1016/j.cogpsych.2016.03.001},
  abstract = {a b s t r a c t This fMRI study examines the changes in participants' information processing as they repeatedly solve the same mathematical prob-lem. We show that the majority of practice-related speedup is pro-duced by discrete changes in cognitive processing. Because the points at which these changes take place vary from problem to problem, and the underlying information processing steps vary in duration, the existence of such discrete changes can be hard to detect. Using two converging approaches, we establish the exis-tence of three learning phases. When solving a problem in one of these learning phases, participants can go through three cognitive stages: Encoding, Solving, and Responding. Each cognitive stage is associated with a unique brain signature. Using a bottom-up approach combining multi-voxel pattern analysis and hidden semi-Markov modeling, we identify the duration of that stage on any particular trial from participants brain activation patterns. For our top-down approach we developed an ACT-R model of these cognitive stages and simulated how they change over the course of learning. The Solving stage of the first learning phase is long and involves a sequence of arithmetic computations. Participants tran-sition to the second learning phase when they can retrieve the answer, thereby drastically reducing the duration of the Solving stage. With continued practice, participants then transition to the third learning phase when they recognize the problem as a single unit and produce the answer as an automatic response. The dura-tion of this third learning phase is dominated by the Responding stage.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3GDVEQX9\\Tenison, Fincham, Anderson - 2016 - Phases of learning How skill acquisition impacts cognitive processing.pdf},
  journal = {Cognitive Psychology},
  keywords = {Cognitive modeling,fmri,Skill acquisition}
}

@article{terada_fujisawa_2017,
  title = {Temporal and {{Rate Coding}} for {{Discrete Event Sequences}} in the {{Hippocampus Article Temporal}} and {{Rate Coding}} for {{Discrete Event Sequences}} in the {{Hippocampus}}},
  author = {Terada, Satoshi and Sakurai, Yoshio and Nakahara, Hiroyuki and Fujisawa, Shigeyoshi},
  year = {2017},
  pages = {1--15},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2017.05.024},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QVC2FXTY\\Terada et al. - 2017 - Temporal and Rate Coding for Discrete Event Sequences in the Hippocampus Article Temporal and Rate Coding for Dis.pdf},
  journal = {Neuron}
}

@article{terbraak_terbraak_2006,
  title = {A {{Markov Chain Monte Carlo}} Version of the Genetic Algorithm {{Differential Evolution}}: {{Easy Bayesian}} Computing for Real Parameter Spaces},
  author = {Ter Braak, Cajo J F},
  year = {2006},
  volume = {16},
  pages = {239--249},
  issn = {09603174},
  doi = {10.1007/s11222-006-8769-1},
  abstract = {Differential Evolution (DE) is a simple genetic al- gorithm for numerical optimization in real parameter spaces. In a statistical context one would not just want the optimum but also its uncertainty. The uncertainty distribution can be obtained by a Bayesian analysis (after specifying prior and likelihood) using Markov Chain Monte Carlo (MCMC) sim- ulation. This paper integrates the essential ideas of DE and MCMC, resulting in Differential Evolution Markov Chain (DE-MC). DE-MC is a population MCMC algorithm, in which multiple chains are run in parallel. DE-MC solves an important problem inMCMC,namely that of choosing an appropriate scale and orientation for the jumping distribu- tion. In DE-MC the jumps are simply a fixed multiple of the differences of two random parameter vectors that are cur- rently in the population. The selection process of DE-MC works via the usual Metropolis ratio which defines the prob- ability with which a proposal is accepted. In tests with known uncertainty distributions, the efficiency of DE-MC with re- spect to random walk Metropolis with optimal multivariate Normal jumps ranged from 68\% for small population sizes to 100\% for large population sizes and even to 500\% for the 97.5\% point of a variable from a 50-dimensional Student distribution. Two Bayesian examples illustrate the potential of DE-MC in practice. DE-MC is shown to facilitate mul- tidimensional updates in a multi-chain ``Metropolis-within- Gibbs'' sampling approach. The advantage of DE-MC over conventionalMCMCare simplicity, speed of calculation and convergence, even for nearly collinear parameters and mul- timodal densities.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JUGM94DK\\Ter Braak - 2006 - A Markov Chain Monte Carlo version of the genetic algorithm Differential Evolution Easy Bayesian computing for real p.pdf},
  journal = {Statistics and Computing},
  keywords = {Block updating,Evolutionary Monte Carlo,Metropolis algorithm,Population Markov Chain Monte Carlo,Simulated Annealing,Simulated Tempering,Theophylline Kinetics},
  number = {3}
}

@article{teufel_fletcher_2020,
  ids = {teufel.fletcher.2020},
  title = {Forms of Prediction in the Nervous System},
  author = {Teufel, Christoph and Fletcher, Paul C.},
  year = {2020},
  month = mar,
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/s41583-020-0275-5},
  abstract = {The idea that predictions shape how we perceive and comprehend the world has become increasingly influential in the field of systems neuroscience. It also forms an important framework for understanding neuropsychiatric disorders, which are proposed to be the result of disturbances in the mechanisms through which prior information influences perception and belief, leading to the production of suboptimal models of the world. There is a widespread tendency to conceptualize the influence of predictions exclusively in terms of `top-down' processes, whereby predictions generated in higher-level areas exert their influence on lower-level areas within an information processing hierarchy. However, this excludes from consideration the predictive information embedded in the `bottom-up' stream of information processing. We describe evidence for the importance of this distinction and argue that it is critical for the development of the predictive processing framework and, ultimately, for an understanding of the perturbations that drive the emergence of neuropsychiatric symptoms and experiences.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MPI9CQAC\\Teufel and Fletcher - 2020 - Forms of prediction in the nervous system.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\XLPXNCP5\\Teufel and Fletcher - 2020 - Forms of prediction in the nervous system.pdf},
  journal = {Nature Reviews Neuroscience},
  language = {en}
}

@article{thesen_halgren_2012,
  title = {Sequential Then Interactive Processing of Letters and Words in the Left Fusiform Gyrus},
  author = {Thesen, Thomas and McDonald, Carrie R. and Carlson, Chad and Doyle, Werner and Cash, Syd and Sherfey, Jason and Felsovalyi, Olga and Girard, Holly and Barr, William and Devinsky, Orrin and Kuzniecky, Ruben and Halgren, Eric},
  year = {2012},
  month = jan,
  volume = {3},
  issn = {2041-1723},
  doi = {10.1038/ncomms2220},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WCDTUJK7\\Thesen et al. - 2012 - Sequential then interactive processing of letters .pdf},
  journal = {Nature Communications},
  language = {en},
  number = {1}
}

@article{theunissen_elie_2013,
  title = {Population Code, Noise Correlations, and Memory.},
  author = {Theunissen, Fr{\'e}d{\'e}ric E and Elie, Julie E},
  year = {2013},
  month = apr,
  volume = {78},
  pages = {209--210},
  issn = {1097-4199},
  doi = {10.1016/j.neuron.2013.04.012},
  abstract = {Changes in the correlated activity in the population code can increase neural discrimination by facilitating noise suppression. In this issue, Jeanne et al. (2013) observe learning-dependent changes in high-level avian auditory cortical neurons after a song discrimination task.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\98X8X89J\\Theunissen, Elie - 2013 - Population code, noise correlations, and memory.pdf},
  journal = {Neuron},
  number = {2},
  pmid = {23622058}
}

@article{theves_doeller_2019,
  title = {The {{Hippocampus Encodes Distances}} in {{Multidimensional Feature Space}}},
  author = {Theves, Stephanie and Fernandez, Guill{\'e}n and Doeller, Christian F.},
  year = {2019},
  month = apr,
  volume = {29},
  pages = {1226-1231.e3},
  issn = {09609822},
  doi = {10.1016/j.cub.2019.02.035},
  abstract = {The hippocampal formation encodes maps of the physical environment [1\textendash 5]. A key question in neuroscience is whether its spatial coding principles also provide a universal metric for the organization of non-spatial information. Initial evidence comes from studies revealing directional modulation of fMRI responses in humans [6, 7] during navigation through abstract spaces and the involvement of place and grid cells in encoding of non-spatial feature dimensions [8]. However, a critical feature of a map-like representation is information about distances between locations, which has yet only been demonstrated for physical space [4, 9]. Here, we probe whether the hippocampus similarly encodes distances between points in an abstract space spanned by continuous stimulus-feature dimensions that were relevant to the acquisition of a novel concept. We find that, after learning, two-dimensional distances between individual positions in the abstract space were represented in the hippocampal multivoxel pattern as well as in the univariate hippocampal signal as indexed by fMRI adaptation. These results support the notion that the hippocampus computes domain-general, multidimensional cognitive maps along continuous dimensions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DV8MFVCP\\Theves et al. - 2019 - The Hippocampus Encodes Distances in Multidimensio.pdf},
  journal = {Current Biology},
  language = {en},
  number = {7}
}

@article{thomasyeo_buckner_2011,
  title = {The Organization of the Human Cerebral Cortex Estimated by Intrinsic Functional Connectivity},
  author = {Thomas Yeo, B. T. and Krienen, Fenna M. and Sepulcre, Jorge and Sabuncu, Mert R. and Lashkari, Danial and Hollinshead, Marisa and Roffman, Joshua L. and Smoller, Jordan W. and Z{\"o}llei, Lilla and Polimeni, Jonathan R. and Fischl, Bruce and Liu, Hesheng and Buckner, Randy L.},
  year = {2011},
  month = sep,
  volume = {106},
  pages = {1125--1165},
  issn = {0022-3077, 1522-1598},
  doi = {10.1152/jn.00338.2011},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7WFUPPVM\\Thomas Yeo et al. - 2011 - The organization of the human cerebral cortex esti.pdf},
  journal = {Journal of Neurophysiology},
  language = {en},
  number = {3}
}

@article{thorn_graybiel_2010,
  title = {Differential {{Dynamics}} of {{Activity Changes}} in {{Dorsolateral}} and {{Dorsomedial Striatal Loops}} during {{Learning}}},
  author = {Thorn, Catherine A. and Atallah, Hisham and Howe, Mark and Graybiel, Ann M.},
  year = {2010},
  month = jun,
  volume = {66},
  pages = {781--795},
  issn = {08966273},
  doi = {10.1016/j.neuron.2010.04.036},
  abstract = {The basal ganglia are implicated in a remarkable range of functions influencing emotion and cognition as well as motor behavior. Current models of basal ganglia function hypothesize that parallel limbic, associative and motor cortico-basal ganglia loops contribute to this diverse set of functions, but little is yet known about how these loops operate and how their activities evolve during learning. To address these issues, we recorded simultaneously in sensorimotor and associative regions of the striatum as rats learned different versions of a conditional T-maze task. We found highly contrasting patterns of activity in these regions during task performance and found that these different patterns of structured activity developed concurrently, but with sharply different dynamics. Based on the region-specific dynamics of these patterns across learning, we suggest a working model whereby dorsomedial associative loops can modulate the access of dorsolateral sensorimotor loops to the control of action.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FA8A2WQP\\Thorn et al. - 2010 - Differential Dynamics of Activity Changes in Dorso.pdf},
  journal = {Neuron},
  language = {en},
  number = {5}
}

@article{tian_wu_2020,
  title = {Excitation-{{Inhibition Balanced Neural Networks}} for {{Fast Signal Detection}}},
  author = {Tian, Gengshuo and Li, Shangyang and Huang, Tiejun and Wu, Si},
  year = {2020},
  month = sep,
  volume = {14},
  pages = {79},
  issn = {1662-5188},
  doi = {10.3389/fncom.2020.00079},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TEGA7D45\\Tian et al. - 2020 - Excitation-Inhibition Balanced Neural Networks for.pdf},
  journal = {Frontiers in Computational Neuroscience},
  language = {en}
}

@article{tiganj_howard_2015,
  title = {A {{Simple}} Biophysically Plausible Model for Long Time Constants in Single Neurons},
  author = {Tiganj, Zoran and Hasselmo, Michael E and Howard, Marc W},
  year = {2015},
  volume = {25},
  pages = {27--37},
  issn = {10981063},
  doi = {10.1002/hipo.22347},
  abstract = {Recent work in computational neuroscience and cognitive psychology suggests that a set of cells that decay exponentially could be used to support memory for the time at which events took place. Analytically and through simulations on a biophysical model of an individual neuron, we demonstrate that exponentially decaying firing with a range of time constants up to minutes could be implemented using a simple combination of well-known neural mechanisms. In particular, we consider firing supported by calcium-controlled cation current. When the amount of calcium leaving the cell during an interspike interval is larger than the calcium influx during a spike, the overall decay in calcium concentration can be exponential, resulting in exponential decay of the firing rate. The time constant of the decay can be several orders of magnitude larger than the time constant of calcium clearance, and it could be controlled externally via a variety of biologically plausible ways. The ability to flexibly and rapidly control time constants could enable working memory of temporal history to be generalized to other variables in computing spatial and ordinal representations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\K984YHLR\\Tiganj, Hasselmo, Howard - 2014 - A Simple biophysically plausible model for long time constants in single neurons.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\NQ7C3JIL\\Tiganj, Hasselmo, Howard - 2015 - A Simple biophysically plausible model for long time constants in single neurons.pdf},
  journal = {Hippocampus},
  keywords = {Calcium-sensitive nonselective cation current,Cholinergic modulation,Exponentially decaying firing,Persistent firing,working-memory},
  number = {1},
  pmid = {25113022}
}

@inproceedings{tiganj_w.howard_2018,
  title = {Constructing Neural-Level Models of Behavior in Working Memory Tasks},
  booktitle = {2018 {{Conference}} on {{Cognitive Computational Neuroscience}}},
  author = {Tiganj, Zoran and Cruzado, Nathanael and W. Howard, Marc},
  year = {2018},
  publisher = {{Cognitive Computational Neuroscience}},
  address = {{Philadelphia, Pennsylvania, USA}},
  doi = {10.32470/CCN.2018.1199-0},
  abstract = {Constrained by results from classic behavioral experiments we provide a neural-level cognitive architecture for navigating memory and decision making space as a cognitive map. We propose a canonical microcircuit that can be used as a building block for working memory, decision making and cognitive control. The controller controls gates to route the flow of information between the working memory and the evidence accumulator and sets parameters of the circuits. We show that this type of cognitive architecture can account for results in behavioral experiments such as judgment of recency and delayedmatch-to-sample. In addition, the neural dynamics generated by the cognitive architecture provides a good match with neurophysiological data from rodents and monkeys.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QWCGVU37\\Tiganj et al. - 2018 - Constructing neural-level models of behavior in wo.pdf},
  language = {en}
}

@article{tingley_buzsaki_2018,
  title = {Transformation of a {{Spatial Map}} across the {{Hippocampal}}-{{Lateral Septal Circuit}}},
  author = {Tingley, David and Buzs{\'a}ki, Gy{\"o}rgy},
  year = {2018},
  volume = {98},
  pages = {1229--1242.e5},
  issn = {10974199},
  doi = {10.1016/j.neuron.2018.04.028},
  abstract = {The hippocampus constructs a map of the environment. How this ``cognitive map'' is utilized by other brain regions to guide behavior remains unexplored. To examine how neuronal firing patterns in the hippocampus are transmitted and transformed, we recorded neurons in its principal subcortical target, the lateral septum (LS). We observed that LS neurons carry reliable spatial information in the phase of action potentials, relative to hippocampal theta oscillations, while the firing rates of LS neurons remained uninformative. Furthermore, this spatial phase code had an anatomical microstructure within the LS and was bound to the hippocampal spatial code by synchronous gamma frequency cell assemblies. Using a data-driven model, we show that rate-independent spatial tuning arises through the dynamic weighting of CA1 and CA3 cell assemblies. Our findings demonstrate that transformation of the hippocampal spatial map depends on higher-order theta-dependent neuronal sequences. Video Abstract: [Figure presented] How abstract representations are translated into action is unknown. Tingley and Buzs\'aki describe how the hippocampal cognitive map is ``read out'' by a target region. The transformation relies on population coordination referenced to theta oscillations rather than the tuning of individual neurons.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\664S97ND\\Unknown - Unknown - Transformation of a Spatial Map across the Hippocampal-Lateral Septal Circuit.pdf},
  journal = {Neuron},
  keywords = {cell assemblies,dynamic weighting,hippocampus,information transfer,lateral septum,phase coding,rate coding,theta sequences,transformation},
  number = {6},
  pmid = {29779942}
}

@article{tingley_buzsaki_2019,
  title = {Routing of {{Hippocampal Ripples}} to {{Subcortical Structures}} via the {{Lateral Septum}}},
  author = {Tingley, David and Buzs{\'a}ki, Gy{\"o}rgy},
  year = {2019},
  month = nov,
  pages = {S0896627319308852},
  issn = {08966273},
  doi = {10.1016/j.neuron.2019.10.012},
  abstract = {The mnemonic functions of hippocampal sharp wave ripples (SPW-Rs) have been studied extensively. Because hippocampal outputs affect not only cortical but also subcortical targets, we examined the impact of SPW-Rs on the firing patterns of lateral septal (LS) neurons in behaving rats. A large fraction of SPW-Rs were temporally locked to high-frequency oscillations (HFOs) (120\textendash 180 Hz) in LS, with strongest coupling during non-rapid eye movement (NREM) sleep, followed by waking immobility. However, coherence and spike-local field potential (LFP) coupling between the two structures were low, suggesting that HFOs are generated locally within the LS GABAergic population. This hypothesis was supported by optogenetic induction of HFOs in LS. Spiking of LS neurons was largely independent of the sequential order of spiking in SPW-Rs but instead correlated with the magnitude of excitatory synchrony of the hippocampal output. Thus, LS is strongly activated by SPW-Rs and may convey hippocampal population events to its hypothalamic and brainstem targets.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MAK4JTW7\\Tingley and Buzsáki - 2019 - Routing of Hippocampal Ripples to Subcortical Stru.pdf},
  journal = {Neuron},
  language = {en}
}

@article{tingley_nitz_2018,
  title = {Multiplexed Oscillations and Phase-Rate Coding in the Basal Forebrain},
  author = {Tingley, David and Alexander, Andrew A and Quinn, Laleh K and Chiba, Andrea A and Nitz, Douglas A},
  year = {2018},
  volume = {In Press},
  issn = {2375-2548},
  doi = {10.1126/sciadv.aar3230},
  abstract = {Complex behaviors demand temporal coordination among functionally distinct brain regions. The basal forebrain's afferent and efferent structure suggests a capacity for mediating this coordination at a large scale. During perform\- ance of a spatial orientation task, synaptic activity in this region was dominated by four amplitude\-independent oscillations temporally organized by the phase of the slowest, a theta\-frequency rhythm. Oscillation amplitudes were also organized by task epoch and positively correlated to the task\-related modulation of individual neuron firing rates. For many neurons, spiking was temporally organized through phase precession against theta band field potential oscillations. Theta phase precession advanced in parallel to task progression, rather than absolute spatial location or time. Together, the findings reveal a process by which associative brain regions can integrate independent oscillatory inputs and transform them into sequence\-specific, rate\-coded outputs that are adaptive to the pace with which organisms interact with their environment.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Q84T8TZZ\\Tingley et al. - 2018 - Multiplexed oscillations and phase-rate coding in the basal forebrain.pdf},
  journal = {Science Advances}
}

@article{titley_hansel_2017,
  title = {Perspective {{Toward}} a {{Neurocentric View}} of {{Learning}}},
  author = {Titley, Heather K and Brunel, Nicolas and Hansel, Christian},
  year = {2017},
  volume = {95},
  pages = {19--32},
  doi = {10.1016/j.neuron.2017.05.021},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FXY2QPBA\\Titley, Brunel, Hansel - 2017 - Perspective Toward a Neurocentric View of Learning.pdf},
  journal = {Neuron},
  keywords = {cerebellum,ensemble,hippocampus,intrinsic,memory engram,neocortex,plasticity,Purkinje cell,pyramidal cell,synaptic}
}

@article{tocker_derdikman_2015,
  title = {Grid Cells Correlation Structure Suggests Organized Feedforward Projections into Superficial Layers of the Medial Entorhinal Cortex},
  author = {Tocker, Gilad and Barak, Omri and Derdikman, Dori},
  year = {2015},
  volume = {25},
  pages = {1599--1613},
  issn = {10981063},
  doi = {10.1002/hipo.22481},
  abstract = {Navigation requires integration of external and internal inputs to form a representation of location. Part of this integration is considered to be carried out by the grid cells network in the medial entorhinal cortex (MEC). However, the structure of this neural network is unknown. To shed light on this structure, we measured noise correlations between 508 pairs of simultaneous previously recorded grid cells. We differentiated between pure grid and conjunctive cells (pure grid in Layers II, III, and VI vs. conjunctive in Layers III and V-only Layer III was bi-modal), and devised a new method to classify cell pairs as belonging/not-belonging to the same module. We found that pairs from the same module show significantly more correlations than pairs from different modules. The correlations between pure grid cells decreased in strength as their relative spatial phase increased. However, correlations were mostly at 0 time-lag, suggesting that the source of correlations was not only synaptic, but rather resulted mostly from common input. Given our measured correlations, the two functional groups of grid cells (pure vs. conjunctive), and the known disorganized recurrent connections within Layer II, we propose the following model: conjunctive cells in deep layers form an attractor network whose activity is governed by velocity-controlled signals. A second manifold in Layer II receives organized feedforward projections from the deep layers, giving rise to pure grid cells. Numerical simulations indicate that organized projections induce such correlations as we measure in superficial layers. Our results provide new evidence for the functional anatomy of the entorhinal circuit-suggesting that strong phase-organized feedforward projections support grid fields in the superficial layers. \{\textcopyright\} 2015 Wiley Periodicals, Inc.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\I5Z2UHKF\\Tocker, Barak, Derdikman - 2015 - Grid cells correlation structure suggests organized feedforward projections into superficial layers of.pdf},
  journal = {Hippocampus},
  keywords = {Attractor network models,Conjunctive cells,Grid cell modules,Phase-related correlations,Theta phase-locking},
  number = {12},
  pmid = {26105192}
}

@article{tolman_tolman_1948,
  title = {Cognitive Maps in Rats and Men.},
  author = {Tolman, Edward C.},
  year = {1948},
  volume = {55},
  pages = {189--208},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/h0061626},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AE628W7U\\Tolman - 1948 - Cognitive maps in rats and men..pdf;C\:\\Users\\wchapman\\Zotero\\storage\\RM6ADFYR\\Tolman - 1948 - Cognitive maps in rats and men..pdf},
  journal = {Psychological Review},
  language = {en},
  number = {4}
}

@article{tompary_turk-browne_2018,
  title = {Attending to {{What}} and {{Where}}: {{Background Connectivity Integrates Categorical}} and {{Spatial Attention}}},
  author = {Tompary, Alexa and {Al-Aidroos}, Naseem and {Turk-Browne}, Nicholas B.},
  year = {2018},
  month = sep,
  volume = {30},
  pages = {1281--1297},
  issn = {0898-929X},
  doi = {10.1162/jocn_a_01284},
  abstract = {Top\textendash down attention prioritizes the processing of goal- relevant information throughout visual cortex based on where that information is found in space and what it looks like. Whereas attentional goals often have both spatial and featural compo- nents, most research on the neural basis of attention has exam- ined these components separately. Here we investigated how these attentional components are integrated by examining the attentional modulation of functional connectivity between visual areas with different selectivity. Specifically, we used fMRI to measure temporal correlations between spatially selective regions of early visual cortex and category-selective regions in ventral temporal cortex while participants performed a task that benefitted from both spatial and categorical attention. We found that categorical attention modulated the connectivity of category-selective areas, but only with retinotopic areas that coded for the spatially attended location. Similarly, spatial atten- tion modulated the connectivity of retinotopic areas only with the areas coding for the attended category. This pattern of results suggests that attentional modulation of connectivity is driven both by spatial selection and featural biases. Combined with exploratory analyses of frontoparietal areas that track these changes in connectivity among visual areas, this study begins to shed light on how different components of attention are inte- grated in support of more complex behavioral goals.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5CKZWP9W\\Tompary, Al-Aidroos, Turk-Browne - 2018 - Attending to What and Where Background Connectivity Integrates Categorical and Spatial Attenti.pdf},
  journal = {Journal of Cognitive Neuroscience},
  number = {9}
}

@article{torres-berrio_lopez-canul_2019,
  title = {The Ventral Hippocampus Is Required for Behavioral Flexibility but Not for Allocentric/Egocentric Learning},
  author = {{Torres-Berr{\'i}o}, Ang{\'e}lica and {Vargas-L{\'o}pez}, Viviana and {L{\'o}pez-Canul}, Martha},
  year = {2019},
  month = mar,
  volume = {146},
  pages = {40--50},
  issn = {03619230},
  doi = {10.1016/j.brainresbull.2018.12.011},
  abstract = {Behavioral flexibility is a complex cognitive function that allows for the rapid adaptation to a changing environment. This ability is modulated by the proper function of the prefrontal cortex (PFC), which receives important projections from the ventral hippocampus (vHPC). In this context, the vHPC might play a very important role in behavioral flexibility. Here, we infused the voltage-gated sodium channel blocker tetrodotoxin (TTX) to bilaterally inactivate the vHPC in adult rats and assessed behavioral flexibility in a spatial setting, using the allocentric-egocentric strategy switching task in the cross-shaped maze. We demonstrate that bilateral inactivation of the vHPC impaired the ability to switch from allocentric to egocentric (Experiment 1), and from egocentric to allocentric (Experiment 2) spatial strategies, as noted by the increased number of trials to reach the learning criterion and of entries into incorrect arms. These results resembled the effects of PFC inactivation by TTX on behavioral flexibility (Experiment 3). Furthermore, TTX infusion in the vHPC did not affect allocentric or egocentric learning per se but the ability to switch between either spatial strategy. Remarkably, inactivation of the vHPC decreased the latency to select an arm during the transition from an allocentric to an egocentric strategy, suggesting that the vHPC might mediate impulsive choices during the acquisition of a novel task. Our results highlight an important role of the vHPC in mediating behavioral flexibility by, most likely, modulating proper PFC function.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UZNYV4AL\\Torres-Berrío et al. - 2019 - The ventral hippocampus is required for behavioral.pdf},
  journal = {Brain Research Bulletin},
  language = {en}
}

@article{tort_eichenbaum_2009,
  title = {Theta-Gamma Coupling Increases during the Learning of Item-Context Associations},
  author = {Tort, A B L and Komorowski, R W and Manns, J R and Kopell, N J and Eichenbaum, H},
  year = {2009},
  volume = {106},
  pages = {20942--20947},
  issn = {0027-8424},
  doi = {10.1073/pnas.0911331106},
  abstract = {Phase-amplitude cross-frequency coupling (CFC) between theta (4-12 Hz) and gamma (30-100 Hz) oscillations occurs frequently in the hippocampus. However, it still remains unclear whether theta-gamma coupling has any functional significance. To address this issue, we studied CFC in local field potential oscillations recorded from the CA3 region of the dorsal hippocampus of rats as they learned to associate items with their spatial context. During the course of learning, the amplitude of the low gamma subband (30-60 Hz) became more strongly modulated by theta phase in CA3, and higher levels of theta-gamma modulation were maintained throughout overtraining sessions. Furthermore, the strength of theta-gamma coupling was directly correlated with the increase in performance accuracy during learning sessions. These findings suggest a role for hippocampal theta-gamma coupling in memory recall.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\J248KUD8\\Tort et al. - 2009 - Theta-gamma coupling increases during the learning of item-context associations.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  number = {49},
  pmid = {19934062}
}

@article{toyoizumi_gerstner_2005,
  title = {Generalized {{Bienenstock}}-{{Cooper}}-{{Munro}} Rule for Spiking Neurons That Maximizes Information Transmission},
  author = {Toyoizumi, Taro and Pfister, J.-P. and Aihara, Kazuyuki and Gerstner, Wulfram},
  year = {2005},
  volume = {102},
  pages = {5239--5244},
  issn = {0027-8424},
  doi = {10.1073/pnas.0500495102},
  abstract = {Maximization of information transmission by a spiking-neuron model predicts changes of synaptic connections that depend on timing of pre- and postsynaptic spikes and on the postsynaptic membrane potential. Under the assumption of Poisson firing statistics, the synaptic update rule exhibits all of the features of the Bienenstock-Cooper-Munro rule, in particular, regimes of synaptic potentiation and depression separated by a sliding threshold. Moreover, the learning rule is also applicable to the more realistic case of neuron models with refractoriness, and is sensitive to correlations between input spikes, even in the absence of presynaptic rate modulation. The learning rule is found by maximizing the mutual information between presynaptic and postsynaptic spike trains under the constraint that the postsynaptic firing rate stays close to some target firing rate. An interpretation of the synaptic update rule in terms of homeostatic synaptic processes and spike-timing-dependent plasticity is discussed.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RQ9GT24W\\Toyoizumi et al. - 2005 - Generalized Bienenstock-Cooper-Munro rule for spiking neurons that maximizes information transmission.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  keywords = {Bienenstock-Cooper-Munro,long-term depression,long-term potentiation,LTD,LTP,postsynaptic potential \\S,PSP},
  number = {14},
  pmid = {15795376}
}

@article{traub_whittington_2005,
  title = {Single-Column Thalamocortical Network Model Exhibiting Gamma Oscillations, Sleep Spindles, and Epileptogenic Bursts.},
  author = {Traub, Roger D. and Contreras, Diego and Cunningham, Mark O. and Murray, H. and LeBeau, Fiona E. N. and Roopun, Anita K. and Bibbig, Andrea E. J. and Wilent, William B. and Higley, Michael J. and Whittington, Miles A.},
  year = {2005},
  volume = {93},
  pages = {2194--2232},
  doi = {10.1152/jn.00983.2004},
  abstract = {To better understand population phenomena in thalamocortical neuronal ensembles, we have constructed a preliminary network model with 3,560 multicompartment neurons (containing soma, branching dendrites, and a portion of axon). Types of neurons included superficial pyramids (with regular spiking [RS] and fast rhythmic bursting [FRB] firing behaviors); RS spiny stellates; fast spiking (FS) interneurons, with basket-type and axoaxonic types of connectivity, and located in superficial and deep cortical layers; low threshold spiking (LTS) interneurons, which contacted principal cell dendrites; deep pyramids, which could have RS or intrinsic bursting (IB) firing behaviors, and endowed either with nontufted apical dendrites or with long tufted apical dendrites; thalamocortical relay (TCR) cells; and nucleus reticularis (nRT) cells. To the extent possible, both electrophysiology and synaptic connectivity were based on published data, although many arbitrary choices were necessary. In addition to synaptic connectivity (by AMPA/kainate, NMDA, and GABA(A) receptors), we also included electrical coupling between dendrites of interneurons, nRT cells, and TCR cells, and--in various combinations--electrical coupling between the proximal axons of certain cortical principal neurons. Our network model replicates several observed population phenomena, including 1) persistent gamma oscillations; 2) thalamocortical sleep spindles; 3) series of synchronized population bursts, resembling electrographic seizures; 4) isolated double population bursts with superimposed very fast oscillations ({$>$}100 Hz, "VFO"); 5) spike-wave, polyspike-wave, and fast runs (about 10 Hz). We show that epileptiform bursts, including double and multiple bursts, containing VFO occur in rat auditory cortex in vitro, in the presence of kainate, when both GABA(A) and GABA(B) receptors are blocked. Electrical coupling between axons appears necessary (as reported previously) for persistent gamma and additionally plays a role in the detailed shaping of epileptogenic events. The degree of recurrent synaptic excitation between spiny stellate cells, and their tendency to fire throughout multiple bursts, also appears critical in shaping epileptogenic events.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\965WQJM2\\traub_et_al_2005_single-column_thalamocortical_network_model_exhibiting_gamma_oscillations,.pdf},
  journal = {Journal of neurophysiology},
  number = {4}
}

@article{treisman_treisman_1980,
  title = {A {{Feature}}-{{Integration Theory}} of {{Attention}}},
  author = {Treisman, Anne M},
  year = {1980},
  volume = {12},
  pages = {97--136},
  abstract = {A new hypothesis about the role of focused attention is proposed. The feature-integration theory of attention suggests that attention must be directed serially to each stimulus in a display whenever conjunctions of more than one separable feature are needed to characterize or distinguish the possible objects presented. A number of predictions were tested in a variety of paradigms includ-ing visual search, texture segregation, identification and localization, and using both separable dimensions (shape and color) and local elements or parts of figures (lines, curves, etc. in letters) as the features to be integrated into complex wholes. The results were in general consistent with the hypothesis. They offer a new set of criteria for distinguishing separable from integral features and a new rationale for predicting which tasks will show attention limits and which will not. When we open our eyes on a familiar scene, we form an immediate impression of recognizable objects, organized coherently in a spatial framework. Analysis of our experience into more elementary sensations is difficult, and appears subjectively to require an unusual type of per-ceptual activity. In contrast, the physiological evidence suggests that the visual scene is analyzed at an early stage by specialized populations of receptors that respond selectively to such properties as orientation, color, spatial frequency, or movement, and map these properties in different areas of the brain (Zeki, 1976). The controversy between analytic and synthetic theories of perception goes back many years: the As-sociationists asserted that the experience of complex wholes is built by combining more elementary sensations, while the Gestalt psychologists claimed that the whole precedes its parts, that we initially register unitary objects and relationships, and only later, if necessary, analyze these ob-jects into their component parts or properties. This view is still active now},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UNRCSWFT\\Treisman - 1980 - A Feature-Integration Theory of Attention.pdf},
  journal = {Cognitive Psychology}
}

@article{treisman_treisman_1996,
  title = {The Binding Problem {{Abbreviations FIT}} Feature Integration Theory {{IC}} Illusory Conjunction {{IT}} Inferior Temporal Cortex {{PET}} Positron Emission Tomography},
  author = {Treisman, Anne},
  year = {1996},
  volume = {6},
  pages = {171--78},
  issn = {0959-4388},
  abstract = {Perceptual representations depend on distributed neural codes for relaying the parts and properties of objects. Some mechanism is needed to 'bind' the information relating to each object and to distinguish it from others. Possible candidates include cells tuned to conjunctions of features, spatial attention, and synchronized firing across separate but interconnected areas of the brain. Deficits in neurological patients suggest a role for the parietal cortex in the binding process. Several current models combine these ideas.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9EDEK6IX\\Treisman - 1996 - The binding problem Abbreviations FIT feature integration theory IC illusory conjunction IT inferior temporal cortex P.pdf},
  journal = {Current Opinion in Neurobiology}
}

@article{treisman_treisman_1998,
  title = {Feature Binding, Attention and Object Perception},
  author = {Treisman, Anne},
  year = {1998},
  month = aug,
  volume = {353},
  pages = {1295--1306},
  issn = {09628436},
  doi = {10.1098/rstb.1998.0284},
  abstract = {The seemingly e\textexclamdown ortless ability to perceive meaningful objects in an integrated scene actually depends on complex visual processes. The `binding problem' concerns the way in which we select and integrate the separate features of objects in the correct combinations. Experiments suggest that attention plays a central role in solving this problem. Some neurological patients show a dramatic breakdown in the ability to see several objects; their de\textcent cits suggest a role for the parietal cortex in the binding process. However, indirect measures of priming and interference suggest that more information may be implicitly available than we can consciously access.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CXEKYME2\\Treisman - 1998 - Feature binding, attention and object perception.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\JWFRNLUB\\Treisman - 1998 - Feature binding, attention and object perception.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\KPI2W6SW\\Treisman - Unknown - Feature binding, attention and object perception.pdf},
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  keywords = {attention,Attention,binding,Binding,features,Features,object perception,Object perception,parietal lobes,Parietal lobes,search,Search},
  number = {1373},
  pmid = {9770223}
}

@article{tripp_eliasmith_2016,
  title = {Function Approximation in Inhibitory Networks},
  author = {Tripp, Bryan and Eliasmith, Chris},
  year = {2016},
  volume = {77},
  pages = {95--106},
  issn = {08936080},
  doi = {10.1016/j.neunet.2016.01.010},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\I97CH9CY\\Tripp, Eliasmith - 2016 - Function approximation in inhibitory networks.pdf},
  journal = {Neural Networks}
}

@article{trongnetrpunya_ding_2015,
  title = {Assessing {{Granger Causality}} in {{Electrophysiological Data}}: {{Removing}} the {{Adverse Effects}} of {{Common Signals}} via {{Bipolar Derivations}}.},
  author = {Trongnetrpunya, Amy and Nandi, Bijurika and Kang, Daesung and Kocsis, Bernat and Schroeder, Charles E and Ding, Mingzhou},
  year = {2015},
  volume = {9},
  pages = {189},
  issn = {1662-5137},
  doi = {10.3389/fnsys.2015.00189},
  abstract = {Multielectrode voltage data are usually recorded against a common reference. Such data are frequently used without further treatment to assess patterns of functional connectivity between neuronal populations and between brain areas. It is important to note from the outset that such an approach is valid only when the reference electrode is nearly electrically silent. In practice, however, the reference electrode is generally not electrically silent, thereby adding a common signal to the recorded data. Volume conduction further complicates the problem. In this study we demonstrate the adverse effects of common signals on the estimation of Granger causality, which is a statistical measure used to infer synaptic transmission and information flow in neural circuits from multielectrode data. We further test the hypothesis that the problem can be overcome by utilizing bipolar derivations where the difference between two nearby electrodes is taken and treated as a representation of local neural activity. Simulated data generated by a neuronal network model where the connectivity pattern is known were considered first. This was followed by analyzing data from three experimental preparations where a priori predictions regarding the patterns of causal interactions can be made: (1) laminar recordings from the hippocampus of an anesthetized rat during theta rhythm, (2) laminar recordings from V4 of an awake-behaving macaque monkey during alpha rhythm, and (3) ECoG recordings from electrode arrays implanted in the middle temporal lobe and prefrontal cortex of an epilepsy patient during fixation. For both simulation and experimental analysis the results show that bipolar derivations yield the expected connectivity patterns whereas the untreated data (referred to as unipolar signals) do not. In addition, current source density signals, where applicable, yield results that are close to the expected connectivity patterns, whereas the commonly practiced average re-reference method leads to erroneous results.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ARQNKG3Y\\Trongnetrpunya et al. - 2015 - Assessing Granger Causality in Electrophysiological Data Removing the Adverse Effects of Common Signals v.pdf},
  journal = {Frontiers in systems neuroscience},
  keywords = {bipolar signals,ECoG,Granger casuality,Hippocampus,unipolar signals,V4},
  number = {January},
  pmid = {26834583}
}

@article{trouche_dupret_2016,
  title = {Recoding a Cocaine-Place Memory Engram to a Neutral Engram in the Hippocampus},
  author = {Trouche, St{\'e}phanie and Perestenko, Pavel V and {van de Ven}, Gido M and Bratley, Claire T and McNamara, Colin G and {Campo-Urriza}, Natalia and Black, S Lucas and Reijmers, Leon G and Dupret, David},
  year = {2016},
  month = apr,
  volume = {19},
  pages = {564--567},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn.4250},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KTPCY725\\Trouche et al. - 2016 - Recoding a cocaine-place memory engram to a neutra.pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {4}
}

@article{trouche_dupret_2019,
  title = {A {{Hippocampus}}-{{Accumbens Tripartite Neuronal Motif Guides Appetitive Memory}} in {{Space}}},
  author = {Trouche, St{\'e}phanie and Koren, Vadim and Doig, Natalie M. and Ellender, Tommas J. and {El-Gaby}, Mohamady and {Lopes-dos-Santos}, V{\'i}tor and Reeve, Hayley M. and Perestenko, Pavel V. and Garas, Farid N. and Magill, Peter J. and Sharott, Andrew and Dupret, David},
  year = {2019},
  month = mar,
  volume = {176},
  pages = {1393-1406.e16},
  issn = {00928674},
  doi = {10.1016/j.cell.2018.12.037},
  abstract = {Retrieving and acting on memories of food-predicting environments are fundamental processes for animal survival. Hippocampal pyramidal cells (PYRs) of the mammalian brain provide mnemonic representations of space. Yet the substrates by which these hippocampal representations support memory-guided behavior remain unknown. Here, we uncover a direct connection from dorsal CA1 (dCA1) hippocampus to nucleus accumbens (NAc) that enables the behavioral manifestation of place-reward memories. By monitoring neuronal ensembles in mouse dCA1/NAc pathway, combined with celltype selective optogenetic manipulations of inputdefined postsynaptic neurons, we show that dCA1 PYRs drive NAc medium spiny neurons and orchestrate their spiking activity using feedforward inhibition mediated by dCA1-connected parvalbumin-expressing fast-spiking interneurons. This tripartite cross-circuit motif supports spatial appetitive memory and associated NAc assemblies, being independent of dorsal subiculum and dispensable for both spatial novelty detection and reward seeking. Our findings demonstrate that the dCA1/NAc pathway instantiates a limbic-motor interface for neuronal representations of space to promote effective appetitive behavior.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MGJUUYRW\\Trouche et al. - 2019 - A Hippocampus-Accumbens Tripartite Neuronal Motif .pdf},
  journal = {Cell},
  language = {en},
  number = {6}
}

@article{trousdale_josic_2013,
  title = {A Generative Spike Train Model with Time-Structured Higher Order Correlations.},
  author = {Trousdale, James and Hu, Yu and {Shea-Brown}, Eric and Josi{\'c}, Kre{\v s}imir},
  year = {2013},
  month = jan,
  volume = {7},
  pages = {84},
  issn = {1662-5188},
  doi = {10.3389/fncom.2013.00084},
  abstract = {Emerging technologies are revealing the spiking activity in ever larger neural ensembles. Frequently, this spiking is far from independent, with correlations in the spike times of different cells. Understanding how such correlations impact the dynamics and function of neural ensembles remains an important open problem. Here we describe a new, generative model for correlated spike trains that can exhibit many of the features observed in data. Extending prior work in mathematical finance, this generalized thinning and shift (GTaS) model creates marginally Poisson spike trains with diverse temporal correlation structures. We give several examples which highlight the model's flexibility and utility. For instance, we use it to examine how a neural network responds to highly structured patterns of inputs. We then show that the GTaS model is analytically tractable, and derive cumulant densities of all orders in terms of model parameters. The GTaS framework can therefore be an important tool in the experimental and theoretical exploration of neural dynamics.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JBAGALQZ\\Trousdale et al. - 2013 - A generative spike train model with time-structured higher order correlations.pdf},
  journal = {Frontiers in computational neuroscience},
  keywords = {correlations,cumulant,model,neuronal modeling,neuronal network,neuronal networks,point processes,spiking neurons},
  number = {July},
  pmid = {23908626}
}

@article{truccolo_brown_2005,
  title = {A {{Point Process Framework}} for {{Relating Neural Spiking Activity}} to {{Spiking History}}, {{Neural Ensemble}}, and {{Extrinsic Covariate Effects}}},
  author = {Truccolo, Wilson and Eden, Uri T. and Fellows, Matthew R. and Donoghue, John P. and Brown, Emery N.},
  year = {2005},
  month = feb,
  volume = {93},
  pages = {1074--1089},
  issn = {0022-3077, 1522-1598},
  doi = {10.1152/jn.00697.2004},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EHEIH78B\\Truccolo et al. - 2005 - A Point Process Framework for Relating Neural Spik.pdf},
  journal = {Journal of Neurophysiology},
  language = {en},
  number = {2}
}

@article{tsao_moser_2018,
  title = {Integrating Time from Experience in the Lateral Entorhinal Cortex},
  author = {Tsao, Albert and Sugar, J{\o}rgen and Lu, Li and Wang, Cheng and Knierim, James J and Moser, May-Britt and Moser, Edvard I.},
  year = {2018},
  issn = {0028-0836},
  doi = {10.1038/s41586-018-0459-6},
  abstract = {The encoding of time and its binding to events are crucial for episodic memory, but how these processes are carried out in hippocampal-entorhinal circuits is unclear. Here we show in freely foraging rats that temporal information is robustly encoded across time scales from seconds to hours within the overall population state of the lateral entorhinal cortex. Similarly pronounced encoding of time was not present in the medial entorhinal cortex or in hippocampal areas CA3-CA1. When animals' experiences were constrained by behavioural tasks to become similar across repeated trials, the encoding of temporal flow across trials was reduced, whereas the encoding of time relative to the start of trials was improved. The findings suggest that populations of lateral entorhinal cortex neurons represent time inherently through the encoding of experience. This representation of episodic time may be integrated with spatial inputs from the medial entorhinal cortex in the hippocampus, allowing the hippocampus to store a unified representation of what, where and when. The representation of time is a crucial component of episodic memory 1-3. Although a considerable body of work has now demonstrated that the hippocampus has an essential role in generating a representation of time 4-11 , our understanding of how the brain represents time for episodic memory (episodic time) is still in a nascent stage. The primary function of episodic time is to record the order of events within experience, which does not require a precise representation of metric time, differentiating it from interval and circadian timing 12-14. Rather than being able to keep precise metric time, the neural code for episodic time should have the following two fundamental properties: 1) the code should arise automatically without any behavioural training, to support one-shot formation of episodic memory, and 2) the code should be able to capture the different scales of time at which experience may occur. Recently, two types of representation of time have been observed in the hippocampus and medial entorhinal cortex (MEC): time cells, which fire at specific points in time as an animal performs a task 15-19 , and the decorrelation of place cell activity across hours to days 20-25. However, neither of these representations of time has been shown to fully support one-shot formation of episodic memories in combination with variable timescales. Furthermore, how either of these representations of time arises is unknown. Here, we investigated temporal coding outside the place-cell system, in the lateral entorhinal cortex (LEC). We focused on the LEC because (i) this area is a major source of cortical input to the hippocampus, (ii) previous work has shown that responses in the LEC to physical stimuli could be unstable across time 26,27 , and (iii) a clear underlying function has not yet been defined for the LEC. We found a representation of time in the LEC that exhibited both of the expected signatures of episodic time, and thus could support episodic memory. Temporal coding in individual LEC cells To explore temporal coding in the LEC, we recorded neural activity over more than an hour while rats ran in a box in which the colour of the walls alternated between black and white in a fixed pattern over 12 trials (BW12 experiment, Fig. 1a, Extended Data Fig. 1). An extended number of trials was used to increase the likelihood that animals defined multiple temporal contexts across the experiment, and an interleaved design was chosen to avoid confounding changes in wall colour with progression of time. Data were also recorded from the CA3 and MEC for comparison. Examining LEC responses by eye, we noticed that some cells exhibited clear ramping activity (Fig. 1a, b), raising the possibility that the passage of time can be tracked through the firing rates of individual LEC cells. Responses to specific environmental features such as walls and cue cards 26 were also observed, consistent with the established role of the LEC in encoding environmental context 28-30. We quantified the influence of wall colour and time on the activity of single cells using a generalized linear model (GLM) incorporating time, wall colour and position as variables for fitting the firing rates of individual neurons, which were binned temporally into blocks of 500 ms (Extended Data Fig. 2a-d). A considerable number of LEC cells were selective specifically for time (20.4\% of all recorded cells), whereas only 2.0\% of CA3 cells and 4.5\% of MEC cells were selective for time alone (number of cells significantly influenced by at least one variable for LEC: 186 out of 451, 41.2\%; CA3: 72 out of 148, 48.6\%; MEC: 49 out of 133, 36.8\%; Fig. 1c). The distributions of cell selectivity for the LEC, CA3 and MEC were consistent across individual animals (Fig. 1c). Because time was modelled as a linearly increasing function in the GLM, all identified time-selective cells exhibited some form of ramping activity. Both increasing and decreasing ramps across a range of time constants were observed (Extended Data Fig. 2c), as would be expected if they performed a Laplace transform of the recent past 31. Ramping cells were found in both deep and superficial layers, with no clear difference in the time constants (see Supplementary Information). Ramping responses, particularly across the entire recording session, were not due to recording instability (Extended Data Fig. 2e-g, see Methods). We found little evidence in the LEC for non-ramping time-specific activity similar to that of time cells (Extended Data Fig. 3). LEC population states encode temporal information We next focused on the overall population of LEC cells and asked whether its dynamics reflected time coding. We first visualized the overall population data from individual animals using linear discriminant analysis to determine the dimensions that optimally discriminate the},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FGA6BCAF\\tsao et al. - 2018 - Integrating time from experience in the lateral entorhinal cortex.pdf},
  journal = {Nature}
}

@article{tsuno_hasselmo_2015,
  title = {Rebound Spiking Properties of Mouse Medial Entorhinal Cortex Neurons in Vivo.},
  author = {Tsuno, Yusuke and Chapman, G William and Hasselmo, Michael E},
  year = {2015},
  volume = {42},
  pages = {2974--2984},
  issn = {1460-9568},
  doi = {10.1111/ejn.13097},
  abstract = {Medial entorhinal cortex is the gateway between cortex and hippocampus, and plays a critical role for spatial coding as represented by grid cell activity. In the medial entorhinal cortex, inhibitory circuits are robust, and the presence of h-current leads to rebound potentials and rebound spiking in in vitro experiments. It has been hypothesized that these properties, combined with local field potential oscillations, may contribute to grid cell formation. To examine the properties of in vivo rebound spikes, we performed whole cell patch clamp recordings in medial entorhinal cortex neurons in anesthetized mice. We injected hyperpolarizing inputs representing inhibitory synaptic inputs with sinusoidal oscillations and found that hyperpolarizing inputs injected at specific phases of oscillation had higher probability of inducing subsequent spikes at the peak of the oscillation in some neurons. Also, this effect was prominent in the cells with large sag potential which is a marker of h-current. In addition, larger and longer hyperpolarizing current square pulse stimulation resulted in a larger probability of eliciting rebound spikes. We did not observe a relationship between amplitude or duration of hyperpolarizing current pulse stimulation and the delay of rebound spikes. These results suggest that rebound spikes are observed in vivo and may play a role in generating grid cell activity in medial entorhinal cortex neurons. This article is protected by copyright. All rights reserved.},
  copyright = {All rights reserved},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2GXNL68R\\Tsuno, Chapman, Hasselmo - 2015 - Rebound spiking properties of mouse medial entorhinal cortex neurons in vivo.pdf},
  journal = {The European journal of neuroscience},
  keywords = {h-current,oscillation,patch clamp,rebound potential,sag},
  pmid = {26454151}
}

@article{turkheimer_leech_2019,
  title = {Conflicting Emergences. {{Weak}} vs. Strong Emergence for the Modelling of Brain Function},
  author = {Turkheimer, Federico E. and Hellyer, Peter and Kehagia, Angie A. and Expert, Paul and Lord, Louis-David and Vohryzek, Jakub and De Faria Dafflon, Jessica and Brammer, Mick and Leech, Robert},
  year = {2019},
  month = apr,
  volume = {99},
  pages = {3--10},
  issn = {01497634},
  doi = {10.1016/j.neubiorev.2019.01.023},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PKAN9IE5\\Turkheimer et al. - 2019 - Conflicting emergences. Weak vs. strong emergence .pdf},
  journal = {Neuroscience \& Biobehavioral Reviews},
  language = {en}
}

@article{turner_steyvers_2013,
  title = {A Method for Efficiently Sampling from Distributions with Correlated Dimensions.},
  author = {Turner, Brandon M. and Sederberg, Per B. and Brown, Scott D. and Steyvers, Mark},
  year = {2013},
  volume = {18},
  pages = {368--384},
  issn = {1939-1463},
  doi = {10.1037/a0032222},
  abstract = {Bayesian estimation has played a pivotal role in the understanding of individual differences. However, for many models in psychology, Bayesian estimation of model parameters can be difficult. One reason for this difficulty is that conventional sampling algorithms, such as Markov chain Monte Carlo (MCMC), can be inefficient and impractical when little is known about the target distribution\textendash particularly the target distribution's covariance structure. In this article, we highlight some reasons for this inefficiency and advocate the use of a population MCMC algorithm, called differential evolution Markov chain Monte Carlo (DE-MCMC), as a means of efficient proposal generation. We demonstrate in a simulation study that the performance of the DE-MCMC algorithm is unaffected by the correlation of the target distribution, whereas conventional MCMC performs substantially worse as the correlation increases. We then show that the DE-MCMC algorithm can be used to efficiently fit a hierarchical version of the linear ballistic accumulator model to response time data, which has proven to be a difficult task when conventional MCMC is used.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YZAGIWED\\Turner et al. - 2013 - A method for efficiently sampling from distributions with correlated dimensions.pdf},
  journal = {Psychological Methods},
  keywords = {ballistic accumulator model,differential evolution,hierarchical bayesian estimation,involved in a behavior,linear,mathematical models often posit,mechanisms designed to,mimic the underlying processes,of interest,optimal transition kernel,response time},
  number = {3},
  pmid = {23646991}
}

@article{turner_steyvers_2015,
  title = {Why More Is Better: {{Simultaneous}} Modeling of {{EEG}}, {{fMRI}}, and Behavioral Data},
  author = {Turner, Brandon M and Rodriguez, Christian A and Norcia, Tony M and Mcclure, Samuel M and Steyvers, Mark},
  year = {2015},
  volume = {128},
  pages = {96--115},
  doi = {10.1016/j.neuroimage.2015.12.030},
  abstract = {a b s t r a c t The need to test a growing number of theories in cognitive science has led to increased interest in inferential methods that integrate multiple data modalities. In this manuscript, we show how a method for integrating three data modalities within a single framework provides (1) more detailed descriptions of cognitive processes and (2) more accurate predictions of unobserved data than less integrative methods. Specifically, we show how combining either EEG and fMRI with a behavioral model can perform substantially better than a behavioral-data-only model in both generative and predictive modeling analyses. We then show how a trivariate model \textendash{} a model including EEG, fMRI, and behavioral data \textendash{} outperforms bivariate models in both generative and predictive modeling analyses. Together, these results suggest that within an appropriate modeling framework, more data can be used to better constrain cognitive theory, and to generate more accurate predictions for behav-ioral and neural data.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\E2QDRA3U\\Turner et al. - 2015 - Why more is better Simultaneous modeling of EEG, fMRI, and behavioral data.pdf},
  journal = {NeuroImage},
  keywords = {Bayesian modeling,eeg,fmri,Joint modeling framework,Linear Ballistic Accumulator model}
}

@article{turner_vanmaanen_2017,
  title = {Approaches to Analysis in Model-Based Cognitive Neuroscience},
  author = {Turner, Brandon M. and Forstmann, Birte U. and Love, Bradley C. and Palmeri, Thomas J. and Van Maanen, Leendert},
  year = {2017},
  volume = {76},
  pages = {65--79},
  issn = {10960880},
  doi = {10.1016/j.jmp.2016.01.001},
  abstract = {Our understanding of cognition has been advanced by two traditionally non-overlapping and non-interacting groups. Mathematical psychologists rely on behavioral data to evaluate formal models of cognition, whereas cognitive neuroscientists rely on statistical models to understand patterns of neural activity, often without any attempt to make a connection to the mechanism supporting the computation. Both approaches suffer from critical limitations as a direct result of their focus on data at one level of analysis (cf. Marr, 1982), and these limitations have inspired researchers to attempt to combine both neural and behavioral measures in a cross-level integrative fashion. The importance of solving this problem has spawned several entirely new theoretical and statistical frameworks developed by both mathematical psychologists and cognitive neuroscientists. However, with each new approach comes a particular set of limitations and benefits. In this article, we survey and characterize several approaches for linking brain and behavioral data. We organize these approaches on the basis of particular cognitive modeling goals: (1) using the neural data to constrain a behavioral model, (2) using the behavioral model to predict neural data, and (3) fitting both neural and behavioral data simultaneously. Within each goal, we highlight a few particularly successful approaches for accomplishing that goal, and discuss some applications. Finally, we provide a conceptual guide to choosing among various analytic approaches in performing model-based cognitive neuroscience.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\49TZPDMK\\Turner et al. - 2017 - Approaches to analysis in model-based cognitive neuroscience.pdf},
  journal = {Journal of Mathematical Psychology},
  keywords = {analysis,Linking,Model-based cognitive neuroscience}
}

@article{tversky_kahneman_1974,
  title = {Judgment under Uncertainty: Heuristics and Biases. {{Biases}} in Judgments Reveal Some Heuristics of Thinking under Uncertainty},
  author = {Tversky, Amos and Kahneman, Daniel},
  year = {1974},
  volume = {185},
  pages = {1124--1131},
  issn = {00368075 (ISSN)},
  doi = {Cited By (since 1996) 3914\\nExport Date 30 November 2011},
  abstract = {Biases in judgment reveal some heuristics of thinking about uncertainty. Three heuristics are discussed. (Author/RH)},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UV22T8N8\\Tversky, Kahneman - 1974 - Judgment under uncertainty heuristics and biases. Biases in judgments reveal some heuristics of thinking unde.pdf},
  journal = {Science},
  keywords = {Bias,Cognitive Processes,Decision Making,Decision Making Skills,Heuristics,Probability,Problem Solving},
  pmid = {17835457}
}

@article{tye_tye_2018,
  title = {Review {{Neural Circuit Motifs}} in {{Valence Processing}}},
  author = {Tye, Kay M},
  year = {2018},
  volume = {100},
  pages = {436--452},
  doi = {10.1016/j.neuron.2018.10.001},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KREQISAB\\Tye - 2018 - Review Neural Circuit Motifs in Valence Processing.pdf},
  journal = {Neuron},
  keywords = {amygdala,BLA,circuits,Divergent Paths,emotion,lateral hypothalamus,motivation,neural,Opposing Components,valence}
}

@article{udeigwe_ermentrout_2017,
  title = {Emergent {{Dynamical Properties}} of the {{BCM Learning Rule}}},
  author = {Udeigwe, Lawrence C and Munro, Paul W and Ermentrout, G. Bard},
  year = {2017},
  volume = {7},
  issn = {21908567},
  doi = {10.1186/s13408-017-0044-6},
  abstract = {The Bienenstock-Cooper-Munro (BCM) learning rule provides a simple setup for synaptic modification that combines a Hebbian product rule with a homeostatic mechanism that keeps the weights bounded. The homeostatic part of the learning rule depends on the time average of the post-synaptic activity and provides a sliding threshold that distinguishes between increasing or decreasing weights. There are, thus, two essential time scales in the BCM rule: a homeostatic time scale, and a synaptic modification time scale. When the dynamics of the stimulus is rapid enough, it is possible to reduce the BCM rule to a simple averaged set of differential equations. In previous analyses of this model, the time scale of the sliding threshold is usually faster than that of the synaptic modification. In this paper, we study the dynamical properties of these averaged equations when the homeostatic time scale is close to the synaptic modification time scale. We show that instabilities arise leading to oscillations and in some cases chaos and other complex dynamics. We consider three cases: one neuron with two weights and two stimuli, one neuron with two weights and three stimuli, and finally a weakly interacting network of neurons.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CQZLE8AY\\Udeigwe et al. - 2017 - Emergent Dynamical Properties of the BCM Learning Rule.pdf},
  journal = {Journal of Mathematical Neuroscience},
  keywords = {BCM,Chaos,Learning rule,Oscillation},
  number = {1},
  pmid = {28220467}
}

@article{ullman_ullman_2019,
  title = {Using Neuroscience to Develop Artificial Intelligence},
  author = {Ullman, Shimon},
  year = {2019},
  month = feb,
  volume = {363},
  pages = {692--693},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aau6595},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8QABGH6J\\Ullman - 2019 - Using neuroscience to develop artificial intellige.pdf},
  journal = {Science},
  language = {en},
  number = {6428}
}

@article{ulloa_bullock_2003,
  title = {A Neural Network Simulating Human Reach-Grasp Coordination by Continuous Updating of Vector Positioning Commands.},
  author = {Ulloa, Antonio and Bullock, Daniel},
  year = {2003},
  month = oct,
  volume = {16},
  pages = {1141--1160},
  issn = {0893-6080},
  doi = {10.1016/S0893-6080(03)00079-0},
  abstract = {We developed a neural network model to simulate temporal coordination of human reaching and grasping under variable initial grip apertures and perturbations of object size and object location/orientation. The proposed model computes reach-grasp trajectories by continuously updating vector positioning commands. The model hypotheses are (1) hand/wrist transport, grip aperture, and hand orientation control modules are coupled by a gating signal that fosters synchronous completion of the three sub-goals. (2) Coupling from transport and orientation velocities to aperture control causes maximum grip apertures that scale with these velocities and exceed object size. (3) Part of the aperture trajectory is attributable to an aperture-reducing passive biomechanical effect that is stronger for larger apertures. (4) Discrepancies between internal representations of targets partially inhibit the gating signal, leading to movement time increases that compensate for perturbations. Simulations of the model replicate key features of human reach-grasp kinematics observed under three experimental protocols. Our results indicate that no precomputation of component movement times is necessary for online temporal coordination of the components of reaching and grasping.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\29FQK7BZ\\Ulloa, Bullock - 2003 - A neural network simulating human reach-grasp coordination by continuous updating of vector positioning commands.pdf},
  journal = {Neural networks : the official journal of the International Neural Network Society},
  keywords = {Arm,Arm: physiology,Hand,Hand Strength,Hand Strength: physiology,Hand: physiology,Humans,Models,Neural Networks (Computer),Psychomotor Performance,Psychomotor Performance: physiology,Theoretical},
  number = {8},
  pmid = {13678619}
}

@article{uncapher_wagner_2011,
  title = {Dissociable {{Effects}} of {{Top}}-{{Down}} and {{Bottom}}-{{Up Attention}} during {{Episodic Encoding}}},
  author = {Uncapher, Melina R and Hutchinson, J Benjamin and Wagner, Anthony D},
  year = {2011},
  volume = {31},
  pages = {12613--12628},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.0152-11.2011},
  abstract = {It is well established that the formation of memories for life's experiences-episodic memory-is influenced by how we attend to those experiences, yet the neural mechanisms by which attention shapes episodic encoding are still unclear. We investigated how top-down and bottom-up attention contribute to memory encoding of visual objects in humans by manipulating both types of attention during fMRI of episodic memory formation. We show that dorsal parietal cortex-specifically, intraparietal sulcus (IPS)-was engaged during top-down attention and was also recruited during the successful formation of episodic memories. By contrast, bottom-up attention engaged ventral parietal cortex-specifically, temporoparietal junction (TPJ)-and was also more active during encoding failure. Functional connectivity analyses revealed further dissociations in how top-down and bottom-up attention influenced encoding: while both IPS and TPJ influenced activity in perceptual cortices thought to represent the information being encoded (fusiform/lateral occipital cortex), they each exerted opposite effects on memory encoding. Specifically, during a preparatory period preceding stimulus presentation, a stronger drive from IPS was associated with a higher likelihood that the subsequently attended stimulus would be encoded. By contrast, during stimulus processing, stronger connectivity with TPJ was associated with a lower likelihood the stimulus would be successfully encoded. These findings suggest that during encoding of visual objects into episodic memory, top-down and bottom-up attention can have opposite influences on perceptual areas that subserve visual object representation, suggesting that one manner in which attention modulates memory is by altering the perceptual processing of to-be-encoded stimuli.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SU9ET985\\Uncapher, Hutchinson, Wagner - 2011 - BehavioralSystemsCognitive Dissociable Effects of Top-Down and Bottom-Up Attention during Episodic.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\XWDM4YZZ\\Uncapher, Hutchinson, Wagner - 2011 - BehavioralSystemsCognitive Dissociable Effects of Top-Down and Bottom-Up Attention during Episodic.pdf},
  journal = {Journal of Neuroscience},
  number = {35},
  pmid = {21880922}
}

@article{unger_badre_2016,
  title = {Working Memory Gating Mechanisms Explain Developmental Change in Rule-Guided Behavior},
  author = {Unger, Kerstin and Ackerman, Laura and Chatham, Christopher H. and Amso, Dima and Badre, David},
  year = {2016},
  volume = {155},
  pages = {8--22},
  issn = {18737838},
  doi = {10.1016/j.cognition.2016.05.020},
  abstract = {Cognitive control requires choosing contextual information to update into working memory (input gating), maintaining it there (maintenance) stable against distraction, and then choosing which subset of maintained information to use in guiding action (output gating). Recent work has raised the possibility that the development of rule-guided behavior, in the transition from childhood to adolescence, is linked specifically to changes in the gating components of working memory (Amso, Haas, McShane, \& Badre, 2014). Given the importance of effective rule-guided behavior for decision making in this developmental transition, we used hierarchical rule tasks to probe the precise developmental dynamics of working memory gating. This mechanistic precision informs ongoing efforts to train cognitive control and working memory operations across typical and atypical development. The results of Experiment 1 verified that the development of rule-guided behavior is uniquely linked to increasing hierarchical complexity but not to increasing maintenance demands across 1st, 2nd, and 3rd order rule tasks. Experiment 2 then investigated whether this developmental trajectory in rule-guided behavior is best explained by change in input gating or output gating. Further, as input versus output gating also tend to correlate with a more proactive versus reactive control strategy in these tasks, we assessed developmental change in the degree to which these two processes were deployed efficiently given the task. Experiment 2 shows that the developmental change observed in Experiment 1 and in Amso et al. (2014) is likely a result of increased efficacy of output gating processes, as well as greater strategic efficiency in that adolescents opt for this costly process less often than children.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\INSCY3NR\\Unger et al. - 2016 - Working memory gating mechanisms explain developmental change in rule-guided behavior.pdf},
  journal = {Cognition},
  keywords = {Cognitive control,Computational model,Development,Input and output gating,working-memory}
}

@article{urakubo_kuroda_2008,
  title = {Requirement of an Allosteric Kinetics of {{NMDA}} Receptors for Spike Timing-Dependent Plasticity.},
  author = {Urakubo, Hidetoshi and Honda, Minoru and Froemke, Robert C and Kuroda, Shinya},
  year = {2008},
  volume = {28},
  pages = {3310--3323},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.0303-08.2008},
  abstract = {Spike timing-dependent synaptic plasticity (STDP) plays an important role in neural development and information processing in the brain; however, the mechanism by which spike timing information is encoded into STDP remains unclear. Here, we show that a novel allosteric kinetics of NMDA receptors (NMDARs) is required for STDP. We developed a detailed biophysical model of STDP and found that the model required spike timing-dependent distinct suppression of NMDARs by Ca(2+)-calmodulin. This led us to predict an allosteric kinetics of NMDARs: a slow and rapid suppression of NMDARs by Ca(2+)-calmodulin with prespiking \textendash\{\textbackslash textgreater\} postspiking and postspiking \textendash\{\textbackslash textgreater\} prespiking, respectively. We found that the allosteric kinetics, but not the conventional kinetics, is consistent with specific features of amplitudes and peak time of NMDAR-mediated EPSPs in experiments. We found that the allosteric kinetics of NMDARs was also valid for synaptic plasticity induced by more complex spike trains in layer II/III of visual cortex. We extracted an essential synaptic learning rule by reduction of the allosteric STDP model and found that spike timing-dependent bidirectional role of postspiking in synaptic modification, which depends on the allosteric kinetics, is the essential principle in STDP. Thus, we propose a simple hypothesis of the allosteric kinetics of NMDARs that can coherently explain critical features of spike timing-dependent NMDAR-mediated EPSPs and synaptic plasticity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3MM3LDM5\\Urakubo et al. - 2008 - Requirement of an allosteric kinetics of NMDA receptors for spike timing-dependent plasticity.pdf},
  journal = {The Journal of Neuroscience},
  keywords = {kinetic simulation,ltd,ltp,nmda receptor,spike timing-dependent plasticity,systems neurobiology},
  number = {13},
  pmid = {18367598}
}

@article{usher_mcclelland_2001,
  title = {The Time Course of Perceptual Choice: {{The}} Leaky, Competing Accumulator Model.},
  author = {Usher, Marius and McClelland, James L},
  year = {2001},
  volume = {108},
  pages = {550--592},
  issn = {1939-1471},
  doi = {10.1037/0033-295X.108.3.550},
  abstract = {The time course of perceptual choice is discussed in a model of gradual, leaky, stochastic, and competitive information accumulation in nonlinear decision units. Special cases of the model match a classical diffusion process, but leakage and competition work together to address several challenges to existing diffusion, random walk, and accumulator models. The model accounts for data from choice tasks using both time-controlled (e.g., response signal) and standard reaction time paradigms and its adequacy compares favorably with other approaches. A new paradigm that controls the time of arrival of information supporting different choice alternatives provides further support. The model captures choice behavior regardless of the number of alternatives, accounting for the log-linear relation between reaction time and number of alternatives (Hick's law) and explains a complex pattern of visual and contextual priming in visual word identification.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7R9BP26K\\Usher, McClelland - 2001 - The time course of perceptual choice The leaky, competing accumulator model(2).pdf},
  journal = {Psychological Review},
  number = {3},
  pmid = {11488378}
}

@article{valadez-godinez_santiago-montero_2020,
  title = {On the Accuracy and Computational Cost of Spiking Neuron Implementation},
  author = {{Valadez-God{\'i}nez}, Sergio and Sossa, Humberto and {Santiago-Montero}, Ra{\'u}l},
  year = {2020},
  month = feb,
  volume = {122},
  pages = {196--217},
  issn = {08936080},
  doi = {10.1016/j.neunet.2019.09.026},
  abstract = {Since more than a decade ago, three statements about spiking neuron (SN) implementations have been widely accepted: 1) Hodgkin and Huxley (HH) model is computationally prohibitive, 2) Izhikevich (IZH) artificial neuron is as efficient as Leaky Integrate-and-Fire (LIF) model, and 3) IZH model is more efficient than HH model (Izhikevich, 2004). As suggested by Hodgkin and Huxley (1952), their model operates in two modes: by using the {$\alpha$}'s and {$\beta$}'s rate functions directly (HH model) and by storing them into tables (HHT model) for computational cost reduction. Recently, it has been stated that: 1) HHT model (HH using tables) is not prohibitive, 2) IZH model is not efficient, and 3) both HHT and IZH models are comparable in computational cost (Skocik \& Long, 2014). That controversy shows that there is no consensus concerning SN simulation capacities. Hence, in this work, we introduce a refined approach, based on the multiobjective optimization theory, describing the SN simulation capacities and ultimately choosing optimal simulation parameters. We have used normalized metrics to define the capacity levels of accuracy, computational cost, and efficiency. Normalized metrics allowed comparisons between SNs at the same level or scale. We conducted tests for balanced, lower, and upper boundary conditions under a regular spiking mode with constant and random current stimuli. We found optimal simulation parameters leading to a balance between computational cost and accuracy. Importantly, and, in general, we found that 1) HH model (without using tables) is the most accurate, computationally inexpensive, and efficient, 2) IZH model is the most expensive and inefficient, 3) both LIF and HHT models are the most inaccurate, 4) HHT model is more expensive and inaccurate than HH model due to {$\alpha$}'s and {$\beta$}'s table discretization, and 5) HHT model is not comparable in computational cost to IZH model. These results refute the theory formulated over a decade ago (Izhikevich, 2004) and go more in-depth in the statements formulated by Skocik and Long (2014). Our statements imply that the number of dimensions or FLOPS in the SNs are theoretical but not practical indicators of the true computational cost. The metric we propose for the computational cost is more precise than FLOPS and was found to be invariant to computer architecture. Moreover, we found that the firing frequency used in previous works is a necessary but an insufficient metric to evaluate the simulation accuracy. We also show that our results are consistent with the theory of numerical methods and the theory of SN discontinuity. Discontinuous SNs, such LIF and IZH models, introduce a considerable error every time a spike is generated. In addition, compared to the constant input current, the random input current increases the computational cost and inaccuracy. Besides, we found that the search for optimal simulation parameters is problem-specific. That is important because most of the previous works have intended to find a general and unique optimal simulation. Here, we show that this solution could not exist because it is a multiobjective optimization problem that depends on several factors. This work sets up a renewed thesis concerning the SN simulation that is useful to several related research areas, including the emergent Deep Spiking Neural Networks.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7PZJD838\\Valadez-Godínez et al. - 2020 - On the accuracy and computational cost of spiking .pdf;C\:\\Users\\wchapman\\Zotero\\storage\\UTI5VTUU\\Valadez-Godínez et al. - 2020 - On the accuracy and computational cost of spiking .pdf},
  journal = {Neural Networks},
  language = {en}
}

@article{valderrama_levanquyen_2012,
  title = {Identifying an Increased Risk of Epileptic Seizures Using a Multi-Feature {{EEG}}\textendash{{ECG}} Classification},
  author = {Valderrama, M and Alvarado, C and Nikolopoulos, S and Martinerie, J and Adam, C and Navarro, V and Le Van Quyen, M},
  year = {2012},
  month = may,
  volume = {7},
  pages = {237--244},
  issn = {17468094},
  doi = {10.1016/j.bspc.2011.05.005},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RII3TTA2\\Valderrama et al. - 2012 - Identifying an increased risk of epileptic seizures using a multi-feature EEG–ECG classification.pdf},
  journal = {Biomedical Signal Processing and Control},
  number = {3}
}

@article{valdes-sosa_gutkin_2018,
  title = {Generalized {{Cross}}-{{Frequency Decomposition}}: {{A Method}} for the {{Extraction}} of {{Neuronal Components Coupled}} at {{Different Frequencies}}},
  author = {{Valdes-Sosa}, Pedro Antonio and Nolte, Guido and Wijk, Bernadette Van and Nikulin, Vadim V and Volk, Denis and Dubinin, Igor and Myasnikova, Alexandra and Gutkin, Boris},
  year = {2018},
  volume = {12},
  doi = {10.3389/fninf.2018.00072},
  abstract = {Perceptual, motor and cognitive processes are based on rich interactions between remote regions in the human brain. Such interactions can be carried out through phase synchronization of oscillatory signals. Neuronal synchronization has been primarily studied within the same frequency range, e.g., within alpha or beta frequency bands. Yet, recent research shows that neuronal populations can also demonstrate phase synchronization between different frequency ranges. An extraction of such cross-frequency interactions in EEG/MEG recordings remains, however, methodologically challenging. Here we present a new method for the robust extraction of cross-frequency phase-to-phase synchronized components. Generalized Cross-Frequency Decomposition (GCFD) reconstructs the time courses of synchronized neuronal components, their spatial filters and patterns. Our method extends the previous state of the art, Cross-Frequency Decomposition (CFD), to the whole range of frequencies: it works for any f 1 and f 2 whenever f 1 : f 2 is a rational number. GCFD gives a compact description of non-linearly interacting neuronal sources on the basis of their cross-frequency phase coupling. We successfully validated the new method in simulations and tested it with real EEG recordings including resting state data and steady state visually evoked potentials (SSVEP).},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2IWQ9ZCI\\Valdes-Sosa et al. - 2018 - Generalized Cross-Frequency Decomposition A Method for the Extraction of Neuronal Components Coupled at Diff.pdf},
  journal = {Frontiers in Neuroinformatics | www.frontiersin.org},
  keywords = {brain oscillations,cross-frequency coupling,EEG \& MEG,phase-to-phase coupling,source localization}
}

@article{vales_smith_2015,
  title = {Words, Shape, Visual Search and Visual Working Memory in 3-Year-Old Children},
  author = {Vales, Catarina and Smith, Linda B.},
  year = {2015},
  volume = {18},
  pages = {65--79},
  issn = {14677687},
  doi = {10.1111/desc.12179},
  abstract = {Do words cue children's visual attention, and if so, what are the relevant mechanisms? Across four experiments, 3-year-old children (N = 163) were tested in visual search tasks in which targets were cued with only a visual preview versus a visual preview and a spoken name. The experiments were designed to determine whether labels facilitated search times and to examine one route through which labels could have their effect: By influencing the visual working memory representation of the target. The targets and distractors were pictures of instances of basic-level known categories and the labels were the common name for the target category. We predicted that the label would enhance the visual working memory representation of the target object, guiding attention to objects that better matched the target representation. Experiments 1 and 2 used conjunctive search tasks, and Experiment 3 varied shape discriminability between targets and distractors. Experiment 4 compared the effects of labels to repeated presentations of the visual target, which should also influence the working memory representation of the target. The overall pattern fits contemporary theories of how the contents of visual working memory interact with visual search and attention, and shows that even in very young children heard words affect the processing of visual information. Introduction},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L9IH73CY\\Vales, Smith - 2015 - Words, shape, visual search and visual working memory in 3-year-old children.pdf},
  journal = {Developmental Science},
  number = {1},
  pmid = {24720802}
}

@article{valpola_valpola_2015,
  title = {From {{Neural PCA}} to {{Deep Unsupervised Learning}}},
  author = {Valpola, Harri},
  year = {2015},
  abstract = {A network supporting deep unsupervised learning is presented. The network is an autoencoder with lateral shortcut connections from the encoder to decoder at each level of the hierarchy. The lateral shortcut connections allow the higher levels of the hierarchy to focus on abstract invariant features. While standard autoencoders are analogous to latent variable models with a single layer of stochastic variables, the proposed network is analogous to hierarchical latent variables models. Learning combines denoising autoencoder and denoising sources separation frameworks. Each layer of the network contributes to the cost function a term which measures the distance of the representations produced by the encoder and the decoder. Since training signals originate from all levels of the network, all layers can learn efficiently even in deep networks. The speedup offered by cost terms from higher levels of the hierarchy and the ability to learn invariant features are demonstrated in experiments.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZPGI86ZK\\Valpola - 2015 - From Neural PCA to Deep Unsupervised Learning.pdf}
}

@article{vandekerckhove_tuerlinckx_2007,
  title = {Fitting the Ratcliff Diffusion Model to Experimental Data},
  author = {Vandekerckhove, Joachim and Tuerlinckx, Francis},
  year = {2007},
  issn = {1069-9384},
  doi = {10.3758/BF03193087},
  abstract = {Many experiments in psychology yield both reaction time and accuracy data. However, no off-the-shelf methods yet exist for the statistical analysis of such data. One particularly successful model has been the diffusion process, but using it is difficult in practice because of numerical, statistical, and software problems. We present a general method for performing diffusion model analyses on experimental data. By implementing design matrices, a wide range of across-condition restrictions can be imposed on model parameters, in a flexible way. It becomes possible to fit models with parameters regressed onto predictors. Moreover, data analytical tools are discussed that can be used to handle various types o f outliersand contaminants. We briefly present an easy-to-use software tool that helps perform diffusion model analyses.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TI7DCYQJ\\Vandekerckhove, Tuerlinckx - 2007 - Fitting the ratcliff diffusion model to experimental data.pdf},
  journal = {Psychonomic Bulletin \& Review},
  pmid = {18229471}
}

@article{vandenoord_vinyals_2019,
  title = {Representation {{Learning}} with {{Contrastive Predictive Coding}}},
  author = {Van Den Oord, Aaron and Li, Yazhe and Vinyals, Oriol},
  year = {2019},
  abstract = {While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CW6QPYTQ\\OordLiVinyals19.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\QFBNNNZG\\1807.03748.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\R6UE5CFB\\1807.html},
  journal = {arXiv}
}

@article{vandermaaten_hinton_2008,
  title = {Visualizing {{Data}} Using T-{{SNE}}},
  author = {Van Der Maaten, Laurens and Hinton, Geoffrey},
  year = {2008},
  volume = {9},
  pages = {2579--2605},
  abstract = {We present a new technique called " t-SNE " that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images of objects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large data sets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to influence the way in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of data sets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualiza-tions produced by t-SNE are significantly better than those produced by the other techniques on almost all of the data sets.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FERJ29T7\\Van Der Maaten, Hinton - 2008 - Visualizing Data using t-SNE.pdf},
  journal = {Journal of Machine Learning Research},
  keywords = {dimensionality reduction,embedding algorithms,manifold learning,multidimensional scaling,visualization}
}

@article{vanderplas_vanderplas_2014,
  title = {Frequentism and {{Bayesianism}}: {{A Python}}-Driven {{Primer}}},
  author = {Vanderplas, Jake},
  year = {2014},
  abstract = {\textemdash This paper presents a brief, semi-technical comparison of the es-sential features of the frequentist and Bayesian approaches to statistical infer-ence, with several illustrative examples implemented in Python. The differences between frequentism and Bayesianism fundamentally stem from differing defini-tions of probability, a philosophical divide which leads to distinct approaches to the solution of statistical problems as well as contrasting ways of asking and answering questions about unknown parameters. After an example-driven discussion of these differences, we briefly compare several leading Python sta-tistical packages which implement frequentist inference using classical methods and Bayesian inference using Markov Chain Monte Carlo.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\92SRKKS2\\Vanderplas - 2014 - Frequentism and Bayesianism A Python-driven Primer.pdf},
  journal = {PROC. OF THE 13th PYTHON IN SCIENCE CONF}
}

@article{vanede_nobre_2018,
  title = {Neural {{Oscillations}}: {{Sustained Rhythms}} or {{Transient Burst}}- {{Events}}?},
  author = {Van Ede, Freek and Quinn, Andrew J and Woolrich, Mark W and Nobre, Anna C},
  year = {2018},
  doi = {10.1016/j.tins.2018.04.004},
  abstract = {Frequency-specific patterns of neural activity are increasingly interpreted as transient bursts of isolated events rather than as rhythmically sustained oscilla-tions. This has potentially far-reaching implications for theories of how such oscillations originate and how they shape neural com-putations. As this debate unfolds, we explore alternative interpreta-tions and ask how best to distin-guish between them. The recasting of neural oscillations as burst-events is gaining momentum, and is already inspiring the quantification of novel neural parameters such as burst-rate. The 'bursting' interpretation comes with far-reaching implications, but of course its significance hinges on it being an accurate reflection of the physiological measurements in each particular case. This Forum article aims not to argue for, or against, bursts, but instead aims to help to guide this incipient debate onto productive tracks. To do so, we clarify what burst versus sustained oscillation-based interpretations of frequency-spe-cific neural activity precisely entail, and we explore methodological approaches that may be well suited for arbitrating between these interpretations. In the pro-cess, we illustrate how the two scenarios can be easily confused when it comes to realistic (noise-containing) neural data, and we raise the possibility of a novel 'hybrid' scenario.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\V9ZKFCC9\\Van Ede et al. - 2018 - Neural Oscillations Sustained Rhythms or Transient Burst- Events.pdf},
  keywords = {beta oscillations,eeg,frequency analysis,local field potential,magnetoencephalography,signal interpretation}
}

@article{vanede_nobre_2019,
  title = {Concurrent Visual and Motor Selection during Visual Working Memory Guided Action},
  author = {{van Ede}, Freek and Chekroud, Sammi R. and Stokes, Mark G. and Nobre, Anna C.},
  year = {2019},
  month = mar,
  volume = {22},
  pages = {477--483},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-018-0335-6},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3VF6M7LW\\van Ede et al. - 2019 - Concurrent visual and motor selection during visua.pdf},
  journal = {Nature Neuroscience},
  language = {en},
  number = {3}
}

@article{vanede_vanede_2018,
  title = {Mnemonic and Attentional Roles for States of Attenuated Alpha Oscillations in Perceptual Working Memory: A Review},
  shorttitle = {Mnemonic and Attentional Roles for States of Attenuated Alpha Oscillations in Perceptual Working Memory},
  author = {{van Ede}, Freek},
  year = {2018},
  month = oct,
  volume = {48},
  pages = {2509--2515},
  issn = {0953816X},
  doi = {10.1111/ejn.13759},
  abstract = {Alpha oscillations are often reported to be amplified during working memory (WM) retention, serving to disengage sensory areas to protect internal representations from external interference. At the same time, contemporary views of WM postulate that sensory areas may often also be recruited for retention. I here review recent evidence that during such `perceptual' WM, alpha oscillations in mnemonically relevant sensory areas are not amplified but attenuated instead. I will argue that such attenuated alpha states serve a mnemonic role and, further, that larger attenuation may support item-specific attentional prioritisation within perceptual WM. In critically evaluating this role, I also consider (and argue against) four alternatives to a strictly mnemonic account of the available data that may also prove useful to consider in future research. Finally, I highlight key implications of these data for the study of WM and for our understanding of the functional roles of states of attenuated alpha oscillations in cognition.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DIDBAMUV\\van Ede - 2018 - Mnemonic and attentional roles for states of atten.pdf},
  journal = {European Journal of Neuroscience},
  language = {en},
  number = {7}
}

@article{vangerven_vangerven_2017,
  title = {A Primer on Encoding Models in Sensory Neuroscience},
  author = {{van Gerven}, Marcel A.J.},
  year = {2017},
  volume = {76},
  pages = {172--183},
  issn = {10960880},
  doi = {10.1016/j.jmp.2016.06.009},
  abstract = {A principal goal in sensory neuroscience is to understand how properties of our environment are reflected in neural activity patterns. Recent advances in computational modeling provide increasingly accurate predictions of how neural populations across the brain respond to complex naturalistic stimuli. The employed computational models, referred to as encoding models, explicitly transform complex stimuli into observed neural responses. This rapidly developing field is becoming increasingly important in sensory neuroscience as it provides detailed insights into the functional organization of neural representations. The present work starts by discussing the theoretical underpinnings of encoding models. Next, various applications of encoding models are reviewed. Finally, potential research directions that may shape future work in this area of research are described.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\A8VGI69M\\van Gerven - 2017 - A primer on encoding models in sensory neuroscience.pdf},
  journal = {Journal of Mathematical Psychology},
  keywords = {Decoding,Encoding,Population receptive field,Sensory neuroscience}
}

@article{vangerven_vangerven_2017a,
  title = {Computational {{Foundations}} of {{Natural Intelligence}}},
  author = {{van Gerven}, Marcel},
  year = {2017},
  volume = {11},
  issn = {1662-5188},
  doi = {10.3389/fncom.2017.00112},
  abstract = {New developments in AI and neuroscience are revitalizing the quest to understanding natural intelligence, offering insight about how to equip machines with human-like capabilities. This paper reviews some of the computational principles relevant for understanding natural intelligence and, ultimately, achieving strong AI. After reviewing basic principles, a variety of computational modeling approaches is discussed. Subsequently, I concentrate on the use of artificial neural networks as a framework for modeling cognitive processes. This paper ends by outlining some of the challenges that remain to fulfill the promise of machines that show human-like intelligence.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\C8FLL3Q6\\Van Gerven - Unknown - Computational Foundations of Natural Intelligence.pdf},
  journal = {Frontiers in Computational Neuroscience}
}

@article{vankerkoerle_roelfsema_2014,
  title = {Alpha and Gamma Oscillations Characterize Feedback and Feedforward Processing in Monkey Visual Cortex},
  author = {{van Kerkoerle}, Timo and Self, Matthew W and Dagnino, Bruno and {Gariel-Mathis}, Marie-Alice and Poort, Jasper and {van der Togt}, Chris and Roelfsema, Pieter R},
  year = {2014},
  volume = {111},
  pages = {14332--14341},
  issn = {0027-8424},
  doi = {10.1073/pnas.1402773111},
  abstract = {Cognitive functions rely on the coordinated activity of neurons in many brain regions, but the interactions between cortical areas are not yet well understood. Here we investigated whether low-frequency (\$\textbackslash alpha\$) and high-frequency (\$\textbackslash gamma\$) oscillations characterize different directions of information flow in monkey visual cortex. We recorded from all layers of the primary visual cortex (V1) and found that \$\textbackslash gamma\$-waves are initiated in input layer 4 and propagate to the deep and superficial layers of cortex, whereas \$\textbackslash alpha\$-waves propagate in the opposite direction. Simultaneous recordings from V1 and downstream area V4 confirmed that \$\textbackslash gamma\$- and \$\textbackslash alpha\$-waves propagate in the feedforward and feedback direction, respectively. Microstimulation in V1 elicited \$\textbackslash gamma\$-oscillations in V4, whereas microstimulation in V4 elicited \$\textbackslash alpha\$-oscillations in V1, thus providing causal evidence for the opposite propagation of these rhythms. Furthermore, blocking NMDA receptors, thought to be involved in feedback processing, suppressed \$\textbackslash alpha\$ while boosting \$\textbackslash gamma\$. These results provide new insights into the relation between brain rhythms and cognition.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ACJRKMG8\\van Kerkoerle et al. - 2014 - Alpha and gamma oscillations characterize feedback and feedforward processing in monkey visual cortex.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  number = {40},
  pmid = {25205811}
}

@article{vankov_bowers_2019,
  title = {Training Neural Networks to Encode Symbols Enables Combinatorial Generalization},
  author = {Vankov, Ivan I and Bowers, Jeffrey S},
  year = {2019},
  pages = {10},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VVSKRQM8\\Vankov and Bowers - Training neural networks to encode symbols enables.pdf},
  language = {en}
}

@article{vann_maguire_2009,
  title = {What Does the Retrosplenial Cortex Do?},
  author = {Vann, Seralynne D. and Aggleton, John P. and Maguire, Eleanor A.},
  year = {2009},
  month = nov,
  volume = {10},
  pages = {792--802},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn2733},
  abstract = {The past decade has seen a transformation in research on the retrosplenial cortex (RSC). This cortical area has emerged as a key member of a core network of brain regions that underpins a range of cognitive functions, including episodic memory, navigation, imagination and planning for the future. It is now also evident that the RSC is consistently compromised in the most common neurological disorders that impair memory. Here we review advances on multiple fronts, most notably in neuroanatomy, animal studies and neuroimaging, that have highlighted the importance of the RSC for cognition, and consider why specifying its precise functions remains problematic.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\R3HB7YX8\\Vann et al. - 2009 - What does the retrosplenial cortex do.pdf},
  journal = {Nature Reviews Neuroscience},
  language = {en},
  number = {11}
}

@book{vann_nelson_2015,
  title = {The Mammillary Bodies and Memory: More than a Hippocampal Relay},
  author = {Vann, Seralynne D and Nelson, Andrew J D},
  year = {2015},
  edition = {First},
  volume = {219},
  publisher = {{Elsevier B.V.}},
  doi = {10.1016/bs.pbr.2015.03.006},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LDEL5JWM\\Vann, Nelson - 2015 - The mammillary bodies and memory more than a hippocampal relay.pdf},
  keywords = {anterograde amnesia,Anterograde amnesia,fornix,Fornix,mammillothalamic tract,Mammillothalamic tract,medial diencephalon,Medial diencephalon,papez circuit,Papez circuit}
}

@article{vanravenzwaaij_brown_2017,
  title = {A Confirmatory Approach for Integrating Neural and Behavioral Data into a Single Model},
  author = {{van Ravenzwaaij}, Don and Provost, Alexander and Brown, Scott D.},
  year = {2017},
  volume = {76},
  pages = {131--141},
  issn = {10960880},
  doi = {10.1016/j.jmp.2016.04.005},
  abstract = {Recent decades have witnessed amazing advances in both mathematical models of cognition and in the field of cognitive neuroscience. These developments were initially independent of one another, but recently the fields have started to become interested in joining forces. The resulting joint modeling of behavioral and neural data can be difficult, but has proved fruitful. We briefly review different approaches used in decision-making research for linking behavioral and neural data, and also provide an example. Our example provides a tight link between behavioral data and evoked scalp potentials measured during mental rotation. The example model illustrates a powerful hypothesis-driven way of linking such data sets. We demonstrate the use of such a model, provide a model comparison against interesting alternatives, and discuss the conclusions that follow from applying such a joint model.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9SB23RQV\\van Ravenzwaaij, Provost, Brown - 2017 - A confirmatory approach for integrating neural and behavioral data into a single model.pdf},
  journal = {Journal of Mathematical Psychology},
  keywords = {Cognitive neuroscience,ERP,Joint modeling,Response time data}
}

@article{vanravenzwaaij_wagenmakers_2012,
  title = {Optimal Decision Making in Neural Inhibition Models.},
  author = {{van Ravenzwaaij}, Don and {van der Maas}, Han L. J. and Wagenmakers, Eric-Jan},
  year = {2012},
  volume = {119},
  pages = {201--215},
  issn = {1939-1471},
  doi = {10.1037/a0026275},
  abstract = {In their influential Psychological Review article, Bogacz, Brown, Moehlis, Holmes, and Cohen (2006) discussed optimal decision making as accomplished by the drift diffusion model (DDM). The authors showed that neural inhibition models, such as the leaky competing accumulator model (LCA) and the feedforward inhibition model (FFI), can mimic the DDM and accomplish optimal decision making. Here we show that these conclusions depend on how the models handle negative activation values and (for the LCA) across-trial variability in response conservativeness. Negative neural activations are undesirable for both neurophysiological and mathematical reasons. However, when negative activations are truncated to 0, the equivalence to the DDM is lost. Simulations show that this concern has practical ramifications: the DDM generally outperforms truncated versions of the LCA and the FFI, and the parameter estimates from the neural models can no longer be mapped onto those of the DDM in a simple fashion. We show that for both models, truncation may be avoided by assuming a baseline activity for each accumulator. This solution allows the LCA to approximate the DDM and the FFI to be identical to the DDM.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JMV2SKFA\\van Ravenzwaaij, van der Maas, Wagenmakers - 2012 - Optimal decision making in neural inhibition models.pdf},
  journal = {Psychological Review},
  keywords = {drift diffusion model,feedforward inhibition model,leaky competing accumulator model,model equivalence,phase planes},
  number = {1},
  pmid = {22103672}
}

@article{vanrullen_vanrullen_2018,
  title = {Attention {{Cycles}}},
  author = {VanRullen, Rufin},
  year = {2018},
  volume = {99},
  pages = {632--634},
  issn = {10974199},
  doi = {10.1016/j.neuron.2018.08.006},
  abstract = {Current evidence challenges the traditional view of attention as a continuously active spotlight, suggesting instead a rhythmic operation at around 4\textendash 8 Hz. New intracranial recordings in monkeys and humans, including two papers in this issue of Neuron, by Helfrich et al. (2018) and Fiebelkorn et al. (2018), now validate this alternative notion and characterize its oscillatory neural bases. Current evidence challenges the traditional view of attention as a continuously active spotlight, suggesting instead a rhythmic operation at around 4\textendash 8 Hz. New intracranial recordings in monkeys and humans, including two papers in this issue of Neuron, by Helfrich et al. (2018) and Fiebelkorn et al. (2018), now validate this alternative notion and characterize its oscillatory neural bases.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\J3DWA36C\\VanRullen - 2018 - Attention Cycles.pdf},
  journal = {Neuron},
  number = {4}
}

@article{vanschouwenburg_gazzaley_2017,
  title = {Spatial {{Attention}} and the {{Effects}} of {{Frontoparietal Alpha Band Stimulation}}},
  author = {{van Schouwenburg}, Martine R and Zanto, Theodore P and Gazzaley, Adam},
  year = {2017},
  volume = {10},
  pages = {1--11},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2016.00658},
  abstract = {A frontoparietal network has long been implicated in top-down control of attention. Recent studies have suggested that this network might communicate through coherence in the alpha band. Here we aimed to test the effect of coherent alpha (8\textendash 12 Hz) stimulation on the frontoparietal network. To this end, we recorded behavioral performance and electroencephalography (EEG) data while participants were engaged in a spatial attention task. Furthermore, participants received transcranial alternating current stimulation (tACS) over the right frontal and parietal cortex, which oscillated coherently in-phase within the alpha band. Compared to a group of participants that received sham stimulation, we found that coherent frontoparietal alpha band stimulation altered a behavioral spatial attention bias. Neurally, the groups showed hemispheric-specific differences in alpha coherence between the frontal and parietal-occipital cortex. These results provide preliminary evidence that alpha coherence in the frontoparietal network might play a role in top-down control of spatial attention.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RUCLKYR7\\van Schouwenburg, Zanto, Gazzaley - 2017 - Spatial Attention and the Effects of Frontoparietal Alpha Band Stimulation.pdf},
  journal = {Frontiers in Human Neuroscience},
  keywords = {alpha oscillations,coherence,connectivity,trans,transcranial alternating current stimulation,visual},
  number = {January},
  pmid = {28174529}
}

@article{vanson_putman_2018,
  title = {Frontal {{EEG}} Theta/Beta Ratio during Mind Wandering Episodes},
  author = {{van Son}, Dana and De Blasio, Frances M. and Fogarty, Jack S. and Angelidis, Angelos and Barry, Robert J. and Putman, Peter},
  year = {2018},
  volume = {140},
  pages = {19--27},
  issn = {0301-0511},
  doi = {10.1016/J.BIOPSYCHO.2018.11.003},
  abstract = {BACKGROUND In resting-state EEG, the ratio between frontal power in the slow theta frequency band and the fast beta frequency band (the theta/beta ratio, TBR) has previously been negatively related to attentional control. Also, increased theta and reduced beta power were observed during mind wandering (MW) compared to episodes of focused attention. Thus, increased resting-state frontal TBR could be related to MW, suggesting that previously observed relationships between TBR and attentional control could reflect MW episodes increasing the average resting state TBR in people with low attentional control. GOALS To replicate and extend the previous theta and beta MW effects for frontal TBR recordings and test if MW related changes in frontal TBR are related to attentional control. METHOD Twenty-six healthy participants performed a 40-minute breath-counting task, after a baseline EEG recording, while EEG was measured and participants indicated MW episodes with button presses. RESULTS Frontal TBR was significantly higher during MW episodes than during on-task periods. However, no relation between frontal TBR and attentional control was found. CONCLUSIONS This confirms that frontal TBR varies with MW, which is thought to reflect, among other things, a state of reduced top-down attentional control over thoughts. 194 words},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EFKTFBA3\\van Son et al. - 2018 - Frontal EEG thetabeta ratio during mind wandering episodes.pdf},
  journal = {Biological Psychology},
  keywords = {Attentional control,beta ratio,eeg theta,EEG theta/beta ratio,Mind wandering},
  number = {November 2018}
}

@article{vanveen_suzuki_1997,
  title = {Localization of {{Brain Electrical Activity}} via {{Linearly Constrained Minimum Variance Spatial Filtering}}},
  author = {Van Veen, Barry D and Van Drongelen, Wim and Yuchtman, Moshe and Suzuki, Akifumi},
  year = {1997},
  volume = {44},
  abstract = {\textemdash{} A spatial filtering method for localizing sources of brain electrical activity from surface recordings is described and analyzed. The spatial filters are implemented as a weighted sum of the data recorded at different sites. The weights are chosen to minimize the filter output power subject to a linear constraint. The linear constraint forces the filter to pass brain electrical activity from a specified location, while the power minimization attenuates activity originating at other locations. The estimated output power as a function of location is normalized by the estimated noise power as a function of location to obtain a neural activity index map. Locations of source activity correspond to maxima in the neural activity index map. The method does not require any prior assumptions about the number of active sources of their geometry because it exploits the spatial covariance of the source electrical activity. This paper presents a development and analysis of the method and explores its sensitivity to deviations between actual and assumed data models. The effect on the algorithm of covariance matrix estimation, correlation between sources, and choice of reference is discussed. Simulated and measured data is used to illustrate the efficacy of the approach.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WIN6KGVC\\Van Veen et al. - 1997 - Localization of Brain Electrical Activity via Linearly Constrained Minimum Variance Spatial Filtering.pdf},
  journal = {IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING},
  keywords = {EEG localization,Index Terms— Dipole localization,linearly constrained minimum variance filter,MEG localization,reference electrode,spatial filtering},
  number = {9}
}

@article{vanvliet_kujala_2018,
  title = {Analysis of {{Functional Connectivity}} and {{Oscillatory Power Using DICS}}: {{From Raw MEG Data}} to {{Group}}-{{Level Statistics}} in {{Python}}},
  shorttitle = {Analysis of {{Functional Connectivity}} and {{Oscillatory Power Using DICS}}},
  author = {{van Vliet}, Marijn and Liljestr{\"o}m, Mia and Aro, Susanna and Salmelin, Riitta and Kujala, Jan},
  year = {2018},
  month = sep,
  volume = {12},
  pages = {586},
  issn = {1662-453X},
  doi = {10.3389/fnins.2018.00586},
  abstract = {Communication between brain regions is thought to be facilitated by the synchronization of oscillatory activity. Hence, large-scale functional networks within the brain may be estimated by measuring synchronicity between regions. Neurophysiological recordings, such as magnetoencephalography (MEG) and electroencephalography (EEG), provide a direct measure of oscillatory neural activity with millisecond temporal resolution. In this paper, we describe a full data analysis pipeline for functional connectivity analysis based on dynamic imaging of coherent sources (DICS) of MEG data. DICS is a beamforming technique in the frequency-domain that enables the study of the cortical sources of oscillatory activity and synchronization between brain regions. All the analysis steps, starting from the raw MEG data up to publication-ready group-level statistics and visualization, are discussed in depth, including methodological considerations, rules of thumb and tradeoffs. We start by computing cross-spectral density (CSD) matrices using a wavelet approach in several frequency bands (alpha, theta, beta, gamma). We then provide a way to create comparable source spaces across subjects and discuss the cortical mapping of spectral power. For connectivity analysis, we present a canonical computation of coherence that facilitates a stable estimation of all-to-all connectivity. Finally, we use group-level statistics to limit the network to cortical regions for which significant differences between experimental conditions are detected and produce vertex- and parcel-level visualizations of the different brain networks. Code examples using the MNE-Python package are provided at each step, guiding the reader through a complete analysis of the freely available openfMRI ds000117 ``familiar vs. unfamiliar vs. scrambled faces'' dataset. The goal is to educate both novice and experienced data analysts with the ``tricks of the trade'' necessary to successfully perform this type of analysis on their own data.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9WGN79D8\\van Vliet et al. - 2018 - Analysis of Functional Connectivity and Oscillator.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\G2QWPZLL\\van Vliet et al. - 2018 - Analysis of Functional Connectivity and Oscillator.pdf},
  journal = {Frontiers in Neuroscience},
  language = {en}
}

@article{vanvugt_roelfsema_2020,
  title = {The {{Contribution}} of {{AMPA}} and {{NMDA Receptors}} to {{Persistent Firing}} in the {{Dorsolateral Prefrontal Cortex}} in {{Working Memory}}},
  author = {{van Vugt}, Bram and {van Kerkoerle}, Timo and Vartak, Devavrat and Roelfsema, Pieter R.},
  year = {2020},
  month = mar,
  volume = {40},
  pages = {2458--2470},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.2121-19.2020},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TZ9W9MNB\\van Vugt et al. - 2020 - The Contribution of AMPA and NMDA Receptors to Per.pdf},
  journal = {The Journal of Neuroscience},
  language = {en},
  number = {12}
}

@article{vanwijk_daffertshofer_2012,
  title = {Neural Synchrony within the Motor System: What Have We Learned so Far?},
  author = {{van Wijk}, Bernadette C M and Beek, Peter J and Daffertshofer, Andreas},
  year = {2012},
  month = jan,
  volume = {6},
  pages = {252},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2012.00252},
  abstract = {Synchronization of neural activity is considered essential for information processing in the nervous system. Both local and inter-regional synchronization are omnipresent in different frequency regimes and relate to a variety of behavioral and cognitive functions. Over the years, many studies have sought to elucidate the question how alpha/mu, beta, and gamma synchronization contribute to motor control. Here, we review these studies with the purpose to delineate what they have added to our understanding of the neural control of movement. We highlight important findings regarding oscillations in primary motor cortex, synchronization between cortex and spinal cord, synchronization between cortical regions, as well as abnormal synchronization patterns in a selection of motor dysfunctions. The interpretation of synchronization patterns benefits from combining results of invasive and non-invasive recordings, different data analysis tools, and modeling work. Importantly, although synchronization is deemed to play a vital role, it is not the only mechanism for neural communication. Spike timing and rate coding act together during motor control and should therefore both be accounted for when interpreting movement-related activity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VL5SQS9L\\van Wijk, Beek, Daffertshofer - 2012 - Neural synchrony within the motor system what have we learned so far.pdf},
  journal = {Frontiers in human neuroscience},
  keywords = {corticospinal coherence,information,information processing,motor control,motor cortex,movement,movement disorders,neural synchronization,oscillations},
  number = {September},
  pmid = {22969718}
}

@article{vasilaki_gerstner_2009,
  ids = {vasilaki\_gerstner\_2009a},
  title = {Spike-{{Based Reinforcement Learning}} in {{Continuous State}} and {{Action Space}}: {{When Policy Gradient Methods Fail}}},
  shorttitle = {Spike-{{Based Reinforcement Learning}} in {{Continuous State}} and {{Action Space}}},
  author = {Vasilaki, Eleni and Fr{\'e}maux, Nicolas and Urbanczik, Robert and Senn, Walter and Gerstner, Wulfram},
  editor = {Friston, Karl J.},
  year = {2009},
  month = dec,
  volume = {5},
  pages = {e1000586},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1000586},
  abstract = {Changes of synaptic connections between neurons are thought to be the physiological basis of learning. These changes can be gated by neuromodulators that encode the presence of reward. We study a family of reward-modulated synaptic learning rules for spiking neurons on a learning task in continuous space inspired by the Morris Water maze. The synaptic update rule modifies the release probability of synaptic transmission and depends on the timing of presynaptic spike arrival, postsynaptic action potentials, as well as the membrane potential of the postsynaptic neuron. The family of learning rules includes an optimal rule derived from policy gradient methods as well as reward modulated Hebbian learning. The synaptic update rule is implemented in a population of spiking neurons using a network architecture that combines feedforward input with lateral connections. Actions are represented by a population of hypothetical action cells with strong mexican-hat connectivity and are read out at theta frequency. We show that in this architecture, a standard policy gradient rule fails to solve the Morris watermaze task, whereas a variant with a Hebbian bias can learn the task within 20 trials, consistent with experiments. This result does not depend on implementation details such as the size of the neuronal populations. Our theoretical approach shows how learning new behaviors can be linked to reward-modulated plasticity at the level of single synapses and makes predictions about the voltage and spike-timing dependence of synaptic plasticity and the influence of neuromodulators such as dopamine. It is an important step towards connecting formal theories of reinforcement learning with neuronal and synaptic properties.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5S6UQBE8\\Vasilaki et al. - 2009 - Spike-Based Reinforcement Learning in Continuous S.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\B2P5FKTY\\Vasilaki et al. - 2009 - Spike-Based Reinforcement Learning in Continuous S.pdf},
  journal = {PLoS Computational Biology},
  language = {en},
  number = {12}
}

@article{vasilkoski_versace_2011,
  title = {Review of Stability Properties of Neural Plasticity Rules for Implementation on Memristive Neuromorphic Hardware},
  author = {Vasilkoski, Zlatko and Ames, Heather and Chandler, Ben and Gorchetchnikov, Anatoli and Leveille, Jasmin and Livitz, Gennady and Mingolla, Ennio and Versace, Massimiliano},
  year = {2011},
  month = jul,
  pages = {2563--2569},
  doi = {10.1109/IJCNN.2011.6033553},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QA8TJKZE\\Vasilkoski et al. - 2011 - Review of stability properties of neural plasticity rules for implementation on memristive neuromorphic hardw.pdf},
  journal = {The 2011 International Joint Conference on Neural Networks}
}

@article{vass_epstein_2013,
  title = {Abstract Representations of Location and Facing Direction in the Human Brain.},
  author = {Vass, Lindsay K and a Epstein, Russell},
  year = {2013},
  month = apr,
  volume = {33},
  pages = {6133--6142},
  issn = {1529-2401},
  doi = {10.1523/JNEUROSCI.3873-12.2013},
  abstract = {Humans, like other mobile organisms, rely on spatial representations to guide navigation from place to place. Although previous work has identified neural systems involved in wayfinding, the specific spatial codes supported by these systems are not well understood. We use functional magnetic resonance imaging to identify regions within the human medial temporal and medial parietal lobes that encode two fundamental spatial quantities-location and facing direction-in a manner that abstracts away from sensory inputs. University students were scanned while viewing photographs taken at several familiar campus locations. Multivoxel pattern analyses indicated that the left presubiculum, retrosplenial complex, and parietal-occipital sulcus coded location identity even across non-overlapping views, whereas the right presubiculum coded facing direction even across noncontiguous locations. The location and direction codes supported by these regions may be critical to our ability to navigate within the extended environment and to understand its large-scale spatial structure.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LGCN49JZ\\Vass, Epstein - 2013 - Abstract representations of location and facing direction in the human brain.pdf},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  keywords = {Brain,Brain Mapping,Brain: blood supply,Brain: physiology,Computer-Assisted,Female,Humans,Image Processing,Magnetic Resonance Imaging,Male,Neuropsychological Tests,Orientation,Orientation: physiology,Oxygen,Photic Stimulation,Reaction Time,Space Perception,Space Perception: physiology},
  number = {14},
  pmid = {23554494}
}

@article{vaswani_polosukhin_2017,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
  year = {2017},
  issn = {1469-8714},
  doi = {10.1017/S0952523813000308},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\K5CF2E5S\\Vaswani et al. - Unknown - Attention Is All You Need.pdf},
  pmid = {24016424}
}

@article{vato_panzeri_2014,
  title = {A Bidirectional Brain-Machine Interface Algorithm That Approximates Arbitrary Force-Fields},
  author = {Vato, Alessandro and Szymanski, Francois D and Semprini, Marianna and a. {Mussa-Ivaldi}, Ferdinando and Panzeri, Stefano},
  year = {2014},
  volume = {9},
  issn = {19326203},
  doi = {10.1371/journal.pone.0091677},
  abstract = {We examine bidirectional brain-machine interfaces that control external devices in a closed loop by decoding motor cortical activity to command the device and by encoding the state of the device by delivering electrical stimuli to sensory areas. Although it is possible to design this artificial sensory-motor interaction while maintaining two independent channels of communication, here we propose a rule that closes the loop between flows of sensory and motor information in a way that approximates a desired dynamical policy expressed as a field of forces acting upon the controlled external device. We previously developed a first implementation of this approach based on linear decoding of neural activity recorded from the motor cortex into a set of forces (a force field) applied to a point mass, and on encoding of position of the point mass into patterns of electrical stimuli delivered to somatosensory areas. However, this previous algorithm had the limitation that it only worked in situations when the position-to-force map to be implemented is invertible. Here we overcome this limitation by developing a new non-linear form of the bidirectional interface that can approximate a virtually unlimited family of continuous fields. The new algorithm bases both the encoding of position information and the decoding of motor cortical activity on an explicit map between spike trains and the state space of the device computed with Multi-Dimensional-Scaling. We present a detailed computational analysis of the performance of the interface and a validation of its robustness by using synthetic neural responses in a simulated sensory-motor loop.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ED8S4WSE\\Vato et al. - 2014 - A bidirectional brain-machine interface algorithm that approximates arbitrary force-fields.pdf},
  journal = {PLoS ONE},
  number = {3},
  pmid = {24626393}
}

@article{vendetti_bunge_2017,
  title = {Eye {{Movements Reveal Optimal Strategies}} for {{Analogical Reasoning}}},
  author = {Vendetti, Michael S and Starr, Ariel and Johnson, Elizabeth L and Modavi, Kiana and Bunge, Silvia A},
  year = {2017},
  volume = {8},
  pages = {2--10},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2017.00932},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NZDVN9WP\\Vendetti et al. - 2017 - Eye Movements Reveal Optimal Strategies for Analogical Reasoning.pdf},
  journal = {Frontiers in Psychology},
  keywords = {analogy,eye movements,individual differences,problem solving strategies},
  number = {June}
}

@article{verduzco-flores_oreilly_2015,
  title = {How the Credit Assignment Problems in Motor Control Could Be Solved after the Cerebellum Predicts Increases in Error},
  author = {{Verduzco-Flores}, Sergio O. and O'Reilly, Randall C},
  year = {2015},
  volume = {9},
  issn = {1662-5188},
  doi = {10.3389/fncom.2015.00039},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BT3ISCYQ\\Verduzco-Flores, O'Reilly - 2015 - How the credit assignment problems in motor control could be solved after the cerebellum predicts inc.pdf},
  journal = {Frontiers in Computational Neuroscience},
  number = {January}
}

@article{verfaellie_keane_2019,
  title = {Self-Related Processing and Future Thinking: {{Distinct}} Contributions of Ventromedial Prefrontal Cortex and the Medial Temporal Lobes},
  shorttitle = {Self-Related Processing and Future Thinking},
  author = {Verfaellie, Mieke and Wank, Aubrey A. and Reid, Allison G. and Race, Elizabeth and Keane, Margaret M.},
  year = {2019},
  month = jun,
  volume = {115},
  pages = {159--171},
  issn = {00109452},
  doi = {10.1016/j.cortex.2019.01.028},
  abstract = {Episodic future thinking depends on a core network of regions that involves, in addition to the medial temporal lobes (MTL), the ventromedial prefrontal cortex (vmPFC). Neuroimaging studies suggest that vmPFC is particularly involved when future thinking requires consideration of self-relevant information, but lesion evidence for a special role of vmPFC in constructing selfrelevant scenarios is limited. To clarify the involvement of vmPFC in future thinking, eight patients with vmPFC lesions were asked to imagine future events pertaining to the self or to another person, and their performance was contrasted with that of eight patients with MTL lesions. Patients with vmPFC lesions were no more detailed in their description of future events pertaining to the self than of events pertaining to another person. In contrast, like controls, patients with MTL lesions showed a self-benefit, despite impoverished performance overall. These findings accord with evidence from neuroimaging studies and elucidate the distinct contributions of vmPFC and MTL to future thinking.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TQGPEYCI\\Verfaellie et al. - 2019 - Self-related processing and future thinking Disti.pdf},
  journal = {Cortex},
  language = {en}
}

@article{versace_gorchetchnikov_2008,
  title = {{{KInNeSS}}: A Modular Framework for Computational Neuroscience.},
  author = {Versace, Massimiliano and Ames, Heather and L{\'e}veill{\'e}, Jasmin and Fortenberry, Bret and Gorchetchnikov, Anatoli},
  year = {2008},
  month = jan,
  volume = {6},
  pages = {291--309},
  issn = {1559-0089},
  doi = {10.1007/s12021-008-9021-2},
  abstract = {Making use of very detailed neurophysiological, anatomical, and behavioral data to build biologically-realistic computational models of animal behavior is often a difficult task. Until recently, many software packages have tried to resolve this mismatched granularity with different approaches. This paper presents KInNeSS, the KDE Integrated NeuroSimulation Software environment, as an alternative solution to bridge the gap between data and model behavior. This open source neural simulation software package provides an expandable framework incorporating features such as ease of use, scalability, an XML based schema, and multiple levels of granularity within a modern object oriented programming design. KInNeSS is best suited to simulate networks of hundreds to thousands of branched multi-compartmental neurons with biophysical properties such as membrane potential, voltage-gated and ligand-gated channels, the presence of gap junctions or ionic diffusion, neuromodulation channel gating, the mechanism for habituative or depressive synapses, axonal delays, and synaptic plasticity. KInNeSS outputs include compartment membrane voltage, spikes, local-field potentials, and current source densities, as well as visualization of the behavior of a simulated agent. An explanation of the modeling philosophy and plug-in development is also presented. Further development of KInNeSS is ongoing with the ultimate goal of creating a modular framework that will help researchers across different disciplines to effectively collaborate using a modern neural simulation platform.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\RW5ZU785\\Versace et al. - 2008 - KInNeSS a modular framework for computational neuroscience.pdf},
  journal = {Neuroinformatics},
  keywords = {Algorithms,Animals,Central Nervous System,Central Nervous System: physiology,Computational Biology,Computational Biology: methods,Computer Simulation,Interdisciplinary Communication,Ion Channels,Ion Channels: physiology,Neurons,Neurons: physiology,Neurophysiology,Neurophysiology: methods,Neurosciences,Neurosciences: methods,Programming Languages,Software,Synaptic Potentials,Synaptic Potentials: physiology},
  number = {4},
  pmid = {18695948}
}

@phdthesis{versace_versace_2007,
  title = {Laminar {{Circuits}} for {{Synchronous Thalamocortical Information Processing}} and {{Attentive Stable Learning}} by {{Spiking Neurons}}},
  author = {Versace, Massimiliano},
  year = {2007},
  abstract = {How do our brains transform the "blooming buzzing confusion" of daily experience into a coherent sense of self? How do cells at multiple processing stages, none of which has a global view of brain dynamics or behavioral outcomes, trigger learning at multiple synaptic sites to achieve useful behaviorally important goals in a continually changing world? How does synaptic plasticity occur at a remarkably rapid rate, as anyone who has gone to an exciting movie is readily aware, yet also protect useful memories from catastrophic forgetting? A neural model clarifies mechanisms that subserve fast stable learning by explaining and quantitatively simulating data about single cell biophysics and neurophysiology, laminar neuroanatomy, aggregate cell recordings, large-scale oscillations, and spike-timing dependent plasticity. Attentive matching between bottom- up sensory signals and top-down learned expectations plays a key role in the model: A good enough match generates synchronous attentive resonance and learning, whereas a mismatch causes reset and search for a new recognition category. Many authors havedescribed synchronous oscillations within and across brain regions as one way in which behaviorally significant brain states are organized. Aggregate and single-cell recordings from multiple thalamic and cortical levels of mammals have shown high- and low- frequency rhythmic synchronous activity correlated with perceptual and cognitive tasks. Large-scale neuronal population models have been proposed to model oscillatory dynamics. However, these models do not show how brain spikes, oscillations, and resonant states can subserve fast learning. The present Synchronous Matching Adaptive Resonance Theory (SMART) model uses spiking phase relationships with spike-timing dependent plasticity to restrict learning to matched feature patterns. The SMART model further develops ART predictions that top-down expectations regulate matching and thereby help to focus attention, synchronize and gain-modulate attended feature representations, and trigger new learning},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UTRRCXQU\\Versace - 2007 - Laminar Circuits for Synchronous Thalamocortical Information Processing and Attentive Stable Learning by Spiking Neuron.pdf},
  school = {Boston University},
  type = {{{PhD Thesis}}}
}

@article{vertes_leranth_2007,
  title = {Nucleus Reuniens of the Midline Thalamus: {{Link}} between the Medial Prefrontal Cortex and the Hippocampus},
  author = {Vertes, Robert P and Hoover, Walter B and {Szigeti-Buck}, Klara and Leranth, Csaba},
  year = {2007},
  volume = {71},
  pages = {601--609},
  issn = {03619230},
  doi = {10.1016/j.brainresbull.2006.12.002},
  abstract = {The medial prefrontal cortex and the hippocampus serve well recognized roles in memory processing. The hippocampus projects densely to, and exerts strong excitatory actions on, the medial prefrontal cortex. Interestingly, the medial prefrontal cortex, in rats and other species, has no direct return projections to the hippocampus, and few projections to parahippocampal structures including the entorhinal cortex. It is well established that the nucleus reuniens of the midline thalamus is the major source of thalamic afferents to the hippocampus. Since the medial prefrontal cortex also distributes to nucleus reuniens, we examined medial prefrontal connections with populations of nucleus reuniens neurons projecting to hippocampus. We used a combined anterograde and retrograde tracing procedure at the light and electron microscopic levels. Specifically, we made Phaseolus vulgaris-leuccoagglutinin (PHA-L) injections into the medial prefrontal cortex and Fluorogold injections into the hippocampus (CA1/subiculum) and examined termination patterns of anterogradely PHA-L labeled fibers on retrogradely FG labeled cells of nucleus reuniens. At the light microscopic level, we showed that fibers from the medial prefrontal cortex form multiple putative synaptic contacts with dendrites of hippocampally projecting neurons throughout the extent of nucleus reuniens. At ultrastructural level, we showed that medial prefrontal cortical fibers form asymmetric contacts predominantly with dendritic shafts of hippocampally projecting reuniens cells. These findings indicate that nucleus reuniens represents a critical link between the medial prefrontal cortex and the hippocampus. We discuss the possibility that nucleus reuniens gates the flow of information between the medial prefrontal cortex and hippocampus dependent upon attentive/arousal states of the organism. \textcopyright{} 2007 Elsevier Inc. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\548W7U9W\\Vertes et al. - 2007 - NUCLEUS REUNIENS OF THE MIDLINE THALAMUS LINK BETWEEN THE MEDIAL PREFRONTAL CORTEX AND THE HIPPOCAMPUS HHS Public.pdf},
  journal = {Brain Research Bulletin},
  keywords = {Entorhinal cortex,Mediodorsal nucleus,Prelimbic cortex,Rat,working-memory},
  number = {6},
  pmid = {17292803}
}

@book{vertes_vertes_2006,
  title = {Interactions among the Medial Prefrontal Cortex, Hippocampus and Midline Thalamus in Emotional and Cognitive Processing in the Rat},
  author = {Vertes, Robert P},
  year = {2006},
  volume = {142},
  doi = {10.1016/j.neuroscience.2006.06.027},
  abstract = {The medial prefrontal cortex (mPFC) participates in several higher order functions including selective attention, visceromotor control, decision making and goal-directed behaviors. We discuss the role of the infralimbic cortex (IL) in visceromotor control and the prelimbic cortex (PL) in cognition and their interactions in goal-directed behaviors in the rat. The PL strongly interconnects with a relatively small group of structures that, like PL, subserve cognition, and together have been designated the 'PL circuit.' These structures primarily include the hippocampus, insular cortex, nucleus accumbens, basolateral nucleus of the amygdala, the mediodorsal and reuniens nuclei of the thalamus and the ventral tegmental area of the midbrain. Lesions of each of these structures, like those of PL, produce deficits in delayed response tasks and memory. The PL (and ventral anterior cingulate cortex) (AC) of rats is ideally positioned to integrate current and past information, including its affective qualities, and act on it through its projections to the ventral striatum/ventral pallidum. We further discuss the role of nucleus reuniens of thalamus as a major interface between the mPFC and the hippocampus, and as a prominent source of afferent limbic information to the mPFC and hippocampus. We suggest that the IL of rats is functionally homologous to the orbitomedial cortex of primates and the prelimbic (and ventral AC) cortex to the lateral/dorsolateral cortex of primates, and that the IL/PL complex of rats exerts significant control over emotional and cognitive aspects of goal-directed behavior. \textcopyright{} 2006 IBRO.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IUBEY3M7\\Vertes - 2006 - INTERACTIONS AMONG THE MEDIAL PREFRONTAL CORTEX, HIPPOCAMPUS AND MIDLINE THALAMUS IN EMOTIONAL AND COGNITIVE PROCESSING.pdf},
  isbn = {0306-4522},
  keywords = {hippocampus,infralimbic cortex,memory,nucleus reuniens,prelimbic cortex,working-memory},
  pmid = {16887277}
}

@book{vertes_vertes_2015,
  title = {Major Diencephalic Inputs to the Hippocampus: Supramammillary Nucleus and Nucleus Reuniens. {{Circuitry}} and Function},
  author = {Vertes, Robert P},
  year = {2015},
  edition = {First},
  volume = {219},
  publisher = {{Elsevier B.V.}},
  doi = {10.1016/bs.pbr.2015.03.008},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7G86LS5W\\Vertes - 2015 - Major diencephalic inputs to the hippocampus supramammillary nucleus and nucleus reuniens. Circuitry and function.pdf},
  keywords = {Entorhinal cortex,Fear memory,Long-term potentiation,Medial septum,Rhomboid nucleus,Theta rhythm,Trajectory-dependent neurons,working-memory}
}

@article{villagrasa_hamker_2018,
  title = {On the Role of Cortex-Basal Ganglia Interactions for Category Learning: {{A}} Neuro-Computational Approach},
  author = {Villagrasa, Francesc and Baladron, Javier and Vitay, Julien and Schroll, Henning and Antzoulatos, Evan G and Miller, Earl K and Hamker, Fred H},
  year = {2018},
  doi = {10.1523/JNEUROSCI.0874-18.2018},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\I7JZPRYW\\Villagrasa et al. - 2018 - On the role of cortex-basal ganglia interactions for category learning A neuro-computational approach.pdf}
}

@article{vinck_pennartz_2011,
  title = {An Improved Index of Phase-Synchronization for Electrophysiological Data in the Presence of Volume-Conduction, Noise and Sample-Size Bias},
  author = {Vinck, Martin and Oostenveld, Robert and Van Wingerden, Marijn and Battaglia, Franscesco and Pennartz, Cyriel M A},
  year = {2011},
  volume = {55},
  pages = {1548--1565},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2011.01.055},
  abstract = {Phase-synchronization is a manifestation of interaction between neuronal groups measurable from LFP, EEG or MEG signals, however, volume conduction can cause the coherence and the phase locking value to spuriously increase. It has been shown that the imaginary component of the coherency (ImC) cannot be spuriously increased by volume-conduction of independent sources. Recently, it was proposed that the phase lag index (PLI), which estimates to what extent the phase leads and lags between signals from two sensors are nonequiprobable, improves on the ImC. Compared to ImC, PLI has the advantage of being less influenced by phase delays. However, sensitivity to volume-conduction and noise, and capacity to detect changes in phase-synchronization, is hindered by the discontinuity of the PLI, as small perturbations turn phase lags into leads and vice versa. To solve this problem, we introduce a related index, namely the weighted phase lag index (WPLI). Differently from PLI, in WPLI the contribution of the observed phase leads and lags is weighted by the magnitude of the imaginary component of the cross-spectrum. We demonstrate two advantages of the WPLI over the PLI, in terms of reduced sensitivity to additional, uncorrelated noise sources and increased statistical power to detect changes in phase-synchronization. Another factor that can affect phase-synchronization indices is sample-size bias. We show that, when directly estimated, both PLI and the magnitude of the ImC have typically positively biased estimators. To solve this problem, we develop an unbiased estimator of the squared PLI, and a debiased estimator of the squared WPLI. ?? 2011 Elsevier Inc.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BC24AP7S\\Vinck et al. - 2011 - An improved index of phase-synchronization for electrophysiological data in the presence of volume-conduction, noi.pdf},
  journal = {NeuroImage},
  keywords = {Coherence,Imaginary,Oscillation,Phase relationship,Synchronization},
  number = {4},
  pmid = {21276857}
}

@article{vinck_pennartz_2015,
  title = {Cell-{{Type}} and {{State}}-{{Dependent Synchronization}} among {{Rodent Somatosensory}}, {{Visual}}, {{Perirhinal Cortex}}, and {{Hippocampus CA1}}.},
  author = {Vinck, Martin and Bos, Jeroen J and {Van Mourik-Donga}, Laura A and Oplaat, Krista T and Klein, Gerbrand A and Jackson, Jadin C and Gentet, Luc J and Pennartz, Cyriel M A},
  year = {2015},
  volume = {9},
  pages = {187},
  issn = {1662-5137},
  doi = {10.3389/fnsys.2015.00187},
  abstract = {Beta and gamma rhythms have been hypothesized to be involved in global and local coordination of neuronal activity, respectively. Here, we investigated how cells in rodent area S1BF are entrained by rhythmic fluctuations at various frequencies within the local area and in connected areas, and how this depends on behavioral state and cell type. We performed simultaneous extracellular field and unit recordings in four connected areas of the freely moving rat (S1BF, V1M, perirhinal cortex, CA1). S1BF spiking activity was strongly entrained by both beta and gamma S1BF oscillations, which were associated with deactivations and activations, respectively. We identified multiple classes of fast spiking and excitatory cells in S1BF, which showed prominent differences in rhythmic entrainment and in the extent to which phase locking was modulated by behavioral state. Using an additional dataset acquired by whole-cell recordings in head-fixed mice, these cell classes could be compared with identified phenotypes showing gamma rhythmicity in their membrane potential. We next examined how S1BF cells were entrained by rhythmic fluctuations in connected brain areas. Gamma-synchronization was detected in all four areas, however we did not detect significant gamma coherence among these areas. Instead, we only found long-range coherence in the theta-beta range among these areas. In contrast to local S1BF synchronization, we found long-range S1BF-spike to CA1-LFP synchronization to be homogeneous across inhibitory and excitatory cell types. These findings suggest distinct, cell-type contributions of low and high-frequency synchronization to intra- and inter-areal neuronal interactions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AJPTJHR5\\Vinck et al. - 2015 - Cell-Type and State-Dependent Synchronization among Rodent Somatosensory, Visual, Perirhinal Cortex, and Hippocamp.pdf},
  journal = {Frontiers in systems neuroscience},
  keywords = {cell-type and state-dependent,doi,fnsys,ginal research,interneurons,long-,oscillations,published,synchronization},
  number = {January},
  pmid = {26834582}
}

@article{vinck_perrenoud_2019,
  title = {Layers of {{Rhythms}} \textemdash{} from {{Cortical Anatomy}} to {{Dynamics}}},
  author = {Vinck, Martin and Perrenoud, Quentin},
  year = {2019},
  month = feb,
  volume = {101},
  pages = {358--360},
  issn = {08966273},
  doi = {10.1016/j.neuron.2019.01.028},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9TJ6PNGE\\Vinck and Perrenoud - 2019 - Layers of Rhythms — from Cortical Anatomy to Dynam.pdf},
  journal = {Neuron},
  language = {en},
  number = {3}
}

@article{vinokurov_oreilly_2012,
  title = {Unsurpervised {{Learning}} in {{Hybrid Cognitive Architectures}}},
  author = {Vinokurov, Yury and Lebiere, Christian and Wyatte, Dean and Herd, Seth and O'Reilly, Randall C},
  year = {2012},
  pages = {36--41},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8MQHGRHD\\Vinokurov et al. - 2012 - Unsurpervised Learning in Hybrid Cognitive Architectures.pdf},
  number = {January}
}

@article{viola_debener_2009,
  title = {Semi-Automatic Identification of Independent Components Representing {{EEG}} Artifact.},
  author = {Viola, Filipa Campos and Thorne, Jeremy and Edmonds, Barrie and Schneider, Till and Eichele, Tom and Debener, Stefan},
  year = {2009},
  month = may,
  volume = {120},
  pages = {868--877},
  issn = {1872-8952},
  doi = {10.1016/j.clinph.2009.01.015},
  abstract = {OBJECTIVE: Independent component analysis (ICA) can disentangle multi-channel electroencephalogram (EEG) signals into a number of artifacts and brain-related signals. However, the identification and interpretation of independent components is time-consuming and involves subjective decision making. We developed and evaluated a semi-automatic tool designed for clustering independent components from different subjects and/or EEG recordings. METHODS: CORRMAP is an open-source EEGLAB plug-in, based on the correlation of ICA inverse weights, and finds independent components that are similar to a user-defined template. Component similarity is measured using a correlation procedure that selects components that pass a threshold. The threshold can be either user-defined or determined automatically. CORRMAP clustering performance was evaluated by comparing it with the performance of 11 users from different laboratories familiar with ICA. RESULTS: For eye-related artifacts, a very high degree of overlap between users (phi\{\textbackslash textgreater\}0.80), and between users and CORRMAP (phi\{\textbackslash textgreater\}0.80) was observed. Lower degrees of association were found for heartbeat artifact components, between users (phi\{\textbackslash textless\}0.70), and between users and CORRMAP (phi\{\textbackslash textless\}0.65). CONCLUSIONS: These results demonstrate that CORRMAP provides an efficient, convenient and objective way of clustering independent components. SIGNIFICANCE: CORRMAP helps to efficiently use ICA for the removal EEG artifacts.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FZR3MU3Z\\Viola et al. - 2009 - Semi-automatic identification of independent components representing EEG artifact.pdf},
  journal = {Clinical neurophysiology : official journal of the International Federation of Clinical Neurophysiology},
  keywords = {Algorithms,Artificial Intelligence,Automated: methods,Brain,Brain Mapping,Brain Mapping: methods,Brain: physiology,Computer Simulation,Computer-Assisted,Electroencephalography,Electroencephalography: methods,Evoked Potentials,Evoked Potentials: physiology,Eye Movements,Eye Movements: physiology,Heart Rate,Heart Rate: physiology,Humans,Pattern Recognition,Signal Processing,Software,Software Validation},
  number = {5},
  pmid = {19345611}
}

@article{virgiliog._falcon_2020,
  title = {Spiking {{Neural Networks}} Applied to the Classification of Motor Tasks in {{EEG}} Signals},
  author = {Virgilio G., Carlos D. and Sossa A., Juan H. and Antelis, Javier M. and Falc{\'o}n, Luis E.},
  year = {2020},
  month = feb,
  volume = {122},
  pages = {130--143},
  issn = {08936080},
  doi = {10.1016/j.neunet.2019.09.037},
  abstract = {Motivated by the recent progress of Spiking Neural Network (SNN) models in pattern recognition, we report on the development and evaluation of brain signal classifiers based on SNNs. The work shows the capabilities of this type of Spiking Neurons in the recognition of motor imagery tasks from EEG signals and compares their performance with other traditional classifiers commonly used in this application. This work includes two stages: the first stage consists of comparing the performance of the SNN models against some traditional neural network models. The second stage, compares the SNN models performance in two input conditions: input features with constant values and input features with temporal information. The EEG signals employed in this work represent five motor imagery tasks: i.e. rest, left hand, right hand, foot and tongue movements. These EEG signals were obtained from a public database provided by the Technological University of Graz (Brunner et al., 2008). The feature extraction stage was performed by applying two algorithms: power spectral density and wavelet decomposition. Likewise, this work uses raw EEG signals for the second stage of the problem solution. All of the models were evaluated in the classification between two motor imagery tasks. This work demonstrates that with a smaller number of Spiking neurons, simple problems can be solved. Better results are obtained by using patterns with temporal information, thereby exploiting the capabilities of the SNNs.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AB78EYTF\\Virgilio G. et al. - 2020 - Spiking Neural Networks applied to the classificat.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\D5GIIIIK\\Virgilio G. et al. - 2020 - Spiking Neural Networks applied to the classificat.pdf},
  journal = {Neural Networks},
  language = {en}
}

@article{vo_kable_2014,
  title = {Dorsal Striatum Is Necessary for Stimulus-Value but Not Action-Value Learning in Humans},
  author = {Vo, Khoi and Rutledge, Robb B. and Chatterjee, Anjan and Kable, Joseph W.},
  year = {2014},
  month = dec,
  volume = {137},
  pages = {3129--3135},
  issn = {1460-2156, 0006-8950},
  doi = {10.1093/brain/awu277},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\24ZJ36K6\\Vo et al. - 2014 - Dorsal striatum is necessary for stimulus-value bu.pdf},
  journal = {Brain},
  language = {en},
  number = {12}
}

@article{voelker_eliasmith_2018,
  title = {Communicated by {{Gordon Pipa Improving Spiking Dynamical Networks}}: {{Accurate Delays}}, {{Higher}}-{{Order Synapses}}, and {{Time Cells}}},
  author = {Voelker, Aaron R and Eliasmith, Chris},
  year = {2018},
  doi = {10.1162/NECO_a_01046},
  abstract = {Researchers building spiking neural networks face the challenge of improving the biological plausibility of their model networks while maintaining the ability to quantitatively characterize network behavior. In this work, we extend the theory behind the neural engineering framework (NEF), a method of building spiking dynamical networks, to permit the use of a broad class of synapse models while maintaining prescribed dynamics up to a given order. This theory improves our understanding of how low-level synaptic properties alter the accuracy of high-level computations in spiking dynamical networks. For completeness, we provide characterizations for both continuous-time (i.e., analog) and discrete-time (i.e., digital) simulations. We demonstrate the utility of these extensions by mapping an optimal delay line onto various spiking dynamical networks using higher-order models of the synapse. We show that these networks nonlinearly encode rolling windows of input history, using a scale invariant representation, with accuracy depending on the frequency content of the input signal. Finally, we reveal that these methods provide a novel explanation of time cell responses during a delay task, which have been observed throughout hippocampus, striatum, and cortex.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IE5ZELGR\\Voelker, Eliasmith - 2018 - Communicated by Gordon Pipa Improving Spiking Dynamical Networks Accurate Delays, Higher-Order Synapses, and.pdf}
}

@article{vogels_abbott_2005,
  title = {Signal {{Propagation}} and {{Logic Gating}} in {{Networks}} of {{Integrate}}-and-{{Fire Neurons}}},
  author = {Vogels, Tim P and Abbott, L F},
  year = {2005},
  volume = {25},
  pages = {10786--10795},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.3508-05.2005},
  abstract = {Transmission of signals within the brain is essential for cognitive function, but it is not clear how neural circuits support reliable and accurate signal propagation over a sufficiently large dynamic range. Two modes of propagation have been studied: synfire chains, in which synchronous activity travels through feedforward layers of a neuronal network, and the propagation of fluctuations in firing rate across these layers. In both cases, a sufficient amount of noise, which was added to previous models from an external source, had to be included to support stable propagation. Sparse, randomly connected networks of spiking model neurons can generate chaotic patterns of activity. We investigate whether this activity, which is a more realistic noise source, is sufficient to allow for signal transmission. We find that, for rate-coded signals but not for synfire chains, such networks support robust and accurate signal reproduction through up to six layers if appropriate adjustments are made in synaptic strengths. We investigate the factors affecting transmission and show that multiple signals can propagate simultaneously along different pathways. Using this feature, we show how different types of logic gates can arise within the architecture of the random network through the strengthening of specific synapses.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3CCALXYF\\Vogels, Abbott - 2005 - Signal Propagation and Logic Gating in Networks of Integrate-and-Fire Neurons.pdf},
  journal = {The Journal of Neuroscience},
  keywords = {integrate-and-fire neurons,logic gates,network models,propagation,rate coding,sensory processing,synfire chains},
  number = {46},
  pmid = {16291952}
}

@article{voigts_moore_2013,
  title = {The {{flexDrive}}: An Ultra-Light Implant for Optical Control and Highly Parallel Chronic Recording of Neuronal Ensembles in Freely Moving Mice.},
  author = {Voigts, Jakob and Siegle, Joshua H and Pritchett, Dominique L and Moore, Christopher I},
  year = {2013},
  month = jan,
  volume = {7},
  pages = {8},
  issn = {1662-5137},
  doi = {10.3389/fnsys.2013.00008},
  abstract = {Electrophysiological recordings from ensembles of neurons in behaving mice are a central tool in the study of neural circuits. Despite the widespread use of chronic electrophysiology, the precise positioning of recording electrodes required for high-quality recordings remains a challenge, especially in behaving mice. The complexity of available drive mechanisms, combined with restrictions on implant weight tolerated by mice, limits current methods to recordings from no more than 4-8 electrodes in a single target area. We developed a highly miniaturized yet simple drive design that can be used to independently position 16 electrodes with up to 64 channels in a package that weighs \{{$\sim\rbrace$}2 g. This advance over current designs is achieved by a novel spring-based drive mechanism that reduces implant weight and complexity. The device is easy to build and accommodates arbitrary spatial arrangements of electrodes. Multiple optical fibers can be integrated into the recording array and independently manipulated in depth. Thus, our novel design enables precise optogenetic control and highly parallel chronic recordings of identified single neurons throughout neural circuits in mice.\vphantom\}},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\8TSGUNEU\\Voigts et al. - 2013 - The flexDrive an ultra-light implant for optical control and highly parallel chronic recording of neuronal ensemb.pdf},
  journal = {Frontiers in systems neuroscience},
  keywords = {electrode array,electrophysiology,free behavior,microdrive,multi-site,op,optogenetics},
  number = {May},
  pmid = {23717267}
}

@article{voloh_womelsdorf_2016,
  title = {A {{Role}} of {{Phase}}-{{Resetting}} in {{Coordinating Large Scale Neural Networks During Attention}} and {{Goal}}-{{Directed Behavior}}.},
  author = {Voloh, Benjamin and Womelsdorf, Thilo},
  year = {2016},
  volume = {10},
  pages = {18},
  issn = {1662-5137},
  doi = {10.3389/fnsys.2016.00018},
  abstract = {Short periods of oscillatory activation are ubiquitous signatures of neural circuits. A broad range of studies documents not only their circuit origins, but also a fundamental role for oscillatory activity in coordinating information transfer during goal directed behavior. Recent studies suggest that resetting the phase of ongoing oscillatory activity to endogenous or exogenous cues facilitates coordinated information transfer within circuits and between distributed brain areas. Here, we review evidence that pinpoints phase resetting as a critical marker of dynamic state changes of functional networks. Phase resets: (1) set a "neural context" in terms of narrow band frequencies that uniquely characterizes the activated circuits; (2) impose coherent low frequency phases to which high frequency activations can synchronize, identifiable as cross-frequency correlations across large anatomical distances; (3) are critical for neural coding models that depend on phase, increasing the informational content of neural representations; and (4) likely originate from the dynamics of canonical E-I circuits that are anatomically ubiquitous. These multiple signatures of phase resets are directly linked to enhanced information transfer and behavioral success. We survey how phase resets re-organize oscillations in diverse task contexts, including sensory perception, attentional stimulus selection, cross-modal integration, Pavlovian conditioning, and spatial navigation. The evidence we consider suggests that phase-resets can drive changes in neural excitability, ensemble organization, functional networks, and ultimately, overt behavior.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\AY3YFZYD\\Voloh, Womelsdorf - 2016 - A Role of Phase-Resetting in Coordinating Large Scale Neural Networks During Attention and Goal-Directed Beha.pdf},
  journal = {Frontiers in systems neuroscience},
  keywords = {alpha,coding,cross frequency couplin,cross frequency coupling,inter-areal coordination,oscillations,phase reset,theta},
  number = {March},
  pmid = {27013986}
}

@article{volpegiovanni_volpegiovanni_2017,
  title = {{{BRAPH}}: {{A Graph Theory Software}} for the {{Analysis}} of {{Brain Connectivity}}},
  author = {Volpe, Giovanni, Mite Mijalkov},
  year = {2017},
  pages = {1--23},
  issn = {1932-6203},
  doi = {http://dx.doi.org/10.1101/106625},
  abstract = {The brain is a large-scale complex network whose workings rely on the interaction between its various regions. In the past few years, the organization of the human brain network has been studied extensively using concepts from graph theory, where the brain is represented as a set of nodes connected by edges. This representation of the brain as a connectome can be used to assess important measures that reflect its topological architecture. We have developed a freeware MatLab-based software (BRAPH \textendash{} BRain Analysis using graPH theory) for connectivity analysis of brain networks derived from structural magnetic resonance imaging (MRI), functional MRI (fMRI), positron emission tomography (PET) and electroencephalogram (EEG) data. BRAPH allows building connectivity matrices, calculating global and local network measures, performing non-parametric permutations for group comparisons, assessing the modules in the network, and comparing the results to random networks. By contrast to other toolboxes, it allows performing longitudinal comparisons of the same patients across different points in time. Furthermore, even though a user-friendly interface is provided, the architecture of the program is modular (object-oriented) so that it can be easily expanded and customized. To demonstrate the abilities of BRAPH, we performed structural and functional graph theory analyses in two separate studies. In the first study, using MRI data, we assessed the differences in global and nodal network topology in healthy controls, patients with amnestic mild cognitive impairment, and patients with Alzheimer's disease. In the second study, using resting-state fMRI data, we compared healthy controls and Parkinson's patients with mild cognitive impairment},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IJTMF9AK\\Mijalkov et al. - Unknown - BRAPH A graph theory software for the analysis of brain connectivity for the Alzheimer's Disease Neuroimagin.pdf},
  journal = {Plos one},
  keywords = {graph theory analysis,longitudinal analysis,network topology,object-oriented software},
  number = {February},
  pmid = {28763447}
}

@article{voytek_desposito_2015,
  title = {Oscillatory Dynamics Coordinating Human Frontal Networks in Support of Goal Maintenance},
  author = {Voytek, Bradley and Kayser, Andrew S and Badre, David and Fegen, David and Chang, Edward F and Crone, Nathan E and Parvizi, Josef and Knight, Robert T and D'Esposito, Mark},
  year = {2015},
  volume = {31},
  pages = {1--10},
  issn = {1097-6256},
  doi = {10.1038/nn.4071},
  abstract = {Humans have a capacity for hierarchical cognitive control: the ability to simultaneously control immediate actions while holding more abstract goals in mind. Neuropsychological and neuroimaging evidence suggests that hierarchical cognitive control emerges from a frontal architecture whereby prefrontal cortex coordinates neural activity in the motor cortices when abstract rules are needed to govern motor outcomes. Here we utilize the improved temporal resolution of human intracranial electrocorticography to investigate the mechanisms by which frontal cortical oscillatory networks communicate in support of hierarchical cognitive control. Responding according to progressively more abstract rules results in increased prefrontal local neuronal population activity (high gamma amplitude, 80-150 Hz) and greater frontal network theta phase encoding (4-8 Hz) which together predict trial-by-trial response times. Theta phase encoding couples with high gamma amplitude during interregional information encoding, suggesting that interregional phase encoding is a mechanism for the dynamic instantiation of complex cognitive functions by frontal cortical subnetworks. 2 Humans have the ability to control immediate actions while maintaining more abstract overarching goals 1-5 . The frontal lobes are crucial for goal-directed behavior 6,7 , including hierarchical control over action 8-10 , and neuroimaging demonstrates that neural activity is greater in prefrontal cortex (PFC), compared to primary motor (M1) and premotor (PMC) cortices, as rules governing behavior become more abstract 2-4 . This processing gradient may reflect a dynamic network architecture supporting hierarchical cognitive control whereby PFC interacts with M1/PMC during higher-order action selection 7,10-15 . This control process is predicated on the capacity for the PFC to concurrently process information at multiple timescales and levels of abstraction. However, this fundamental problem in cognitive neuroscience\textemdash how groups of brain regions coordinate information transfer in a noisy neuronal environment to maintain multiple},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6ZW5AD93\\Voytek et al. - 2015 - Oscillatory dynamics coordinating human frontal networks in support of goal maintenance(3).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\7LNARF6E\\Voytek et al. - 2015 - Oscillatory dynamics coordinating human frontal networks in support of goal maintenance(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\J7TXG4JQ\\Voytek et al. - 2015 - Oscillatory dynamics coordinating human frontal networks in support of goal maintenance.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\QZUDUZEA\\Voytek et al. - 2015 - Oscillatory dynamics coordinating human frontal networks in support of goal maintenance(3).pdf},
  journal = {Nature Neuroscience},
  number = {July},
  pmid = {26214371}
}

@article{waegeman_schrauwen_2013,
  title = {{{MACOP}} Modular Architecture with Control Primitives.},
  author = {Waegeman, Tim and Hermans, Michiel and Schrauwen, Benjamin},
  year = {2013},
  month = jan,
  volume = {7},
  pages = {99},
  issn = {1662-5188},
  doi = {10.3389/fncom.2013.00099},
  abstract = {Walking, catching a ball and reaching are all tasks in which humans and animals exhibit advanced motor skills. Findings in biological research concerning motor control suggest a modular control hierarchy which combines movement/motor primitives into complex and natural movements. Engineers inspire their research on these findings in the quest for adaptive and skillful control for robots. In this work we propose a modular architecture with control primitives (MACOP) which uses a set of controllers, where each controller becomes specialized in a subregion of its joint and task-space. Instead of having a single controller being used in this subregion [such as MOSAIC (modular selection and identification for control) on which MACOP is inspired], MACOP relates more to the idea of continuously mixing a limited set of primitive controllers. By enforcing a set of desired properties on the mixing mechanism, a mixture of primitives emerges unsupervised which successfully solves the control task. We evaluate MACOP on a numerical model of a robot arm by training it to generate desired trajectories. We investigate how the tracking performance is affected by the number of controllers in MACOP and examine how the individual controllers and their generated control primitives contribute to solving the task. Furthermore, we show how MACOP compensates for the dynamic effects caused by a fixed control rate and the inertia of the robot.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YRAI7EQQ\\Waegeman, Hermans, Schrauwen - 2013 - MACOP modular architecture with control primitives.pdf},
  journal = {Frontiers in computational neuroscience},
  keywords = {echo state networks,mosaic,motor control,motor pr,motor primitives,movement primitives,reservoir computing,robot control},
  number = {July},
  pmid = {23888140}
}

@article{wagner_luo_2019,
  title = {Neocortex\textendash{{Cerebellum Circuits}} for {{Cognitive Processing}}},
  author = {Wagner, Mark J. and Luo, Liqun},
  year = {2019},
  month = nov,
  pages = {S0166223619302036},
  issn = {01662236},
  doi = {10.1016/j.tins.2019.11.002},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MBDN6YM2\\Wagner and Luo - 2019 - Neocortex–Cerebellum Circuits for Cognitive Proces.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\TQM32FAK\\Wagner and Luo - 2019 - Neocortex–Cerebellum Circuits for Cognitive Proces.pdf},
  journal = {Trends in Neurosciences},
  language = {en}
}

@article{waldhauser_hanslmayr_2012,
  title = {Alpha/{{Beta Oscillations Indicate Inhibition}} of {{Interfering Visual Memories}}},
  author = {Waldhauser, G T and Johansson, M and Hanslmayr, S},
  year = {2012},
  volume = {32},
  pages = {1953--1961},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.4201-11.2012},
  abstract = {Selective retrieval of a specific target memory often leads to the forgetting of related but irrelevant memories. Current cognitive theory states that such retrieval-induced forgetting arises due to inhibition of competing memory traces. To date, however, direct neural evidence for this claim has not been forthcoming. Studies on selective attention suggest that cortical inhibition is mediated by increased brain oscillatory activity in the alpha/beta frequency band. The present study, testing 18 human subjects, investigated whether these mechanisms can be generalized to selective memory retrieval in which competing memories interfere with the retrieval of a target memory. Our experiment was designed so that each cue used to search memory was associated with a target memory and a competitor memory stored in separate brain hemispheres. Retrieval-induced forgetting was observed in a condition in which the competitor memory interfered with target retrieval. Increased oscillatory alpha/beta power was observed over the hemisphere housing the sensory representation of the competitor memory trace and predicted the amount of retrieval-induced forgetting in the subsequent memory test. These results provide the first direct evidence for inhibition of competing memories during episodic memory retrieval and suggest that competitive retrieval is governed by inhibitory mechanisms similar to those employed in selective attention.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L7HIPPSY\\Waldhauser, Johansson, Hanslmayr - 2012 - AlphaBeta Oscillations Indicate Inhibition of Interfering Visual Memories.pdf},
  journal = {Journal of Neuroscience},
  number = {6},
  pmid = {22323708}
}

@article{walker_newhall_2018,
  title = {Inferring Information Flow in Spike-Train Data Sets Using a Trial-Shuffle Method},
  author = {Walker, Benjamin L. and Newhall, Katherine A.},
  editor = {Brown, Kevin Scott},
  year = {2018},
  month = nov,
  volume = {13},
  pages = {e0206977},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0206977},
  abstract = {Understanding information processing in the brain requires the ability to determine the functional connectivity between the different regions of the brain. We present a method using transfer entropy to extract this flow of information between brain regions from spike-train data commonly obtained in neurological experiments. Transfer entropy is a statistical measure based in information theory that attempts to quantify the information flow from one process to another, and has been applied to find connectivity in simulated spike-train data. Due to statistical error in the estimator, inferring functional connectivity requires a method for determining significance in the transfer entropy values. We discuss the issues with numerical estimation of transfer entropy and resulting challenges in determining significance before presenting the trial-shuffle method as a viable option. The trial-shuffle method, for spiketrain data that is split into multiple trials, determines significant transfer entropy values independently for each individual pair of neurons by comparing to a created baseline distribution using a rigorous statistical test. This is in contrast to either globally comparing all neuron transfer entropy values or comparing pairwise values to a single baseline value. In establishing the viability of this method by comparison to several alternative approaches in the literature, we find evidence that preserving the inter-spike-interval timing is important. We then use the trial-shuffle method to investigate information flow within a model network as we vary model parameters. This includes investigating the global flow of information within a connectivity network divided into two well-connected subnetworks, going beyond local transfer of information between pairs of neurons.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PPN6QZCS\\Walker and Newhall - 2018 - Inferring information flow in spike-train data set.pdf},
  journal = {PLOS ONE},
  language = {en},
  number = {11}
}

@article{wallis_miller_2001,
  title = {Single Neurons in Prefrontal Cortex Encode Abstract Rules.},
  author = {Wallis, J D and Anderson, K C and Miller, Earl K},
  year = {2001},
  volume = {411},
  pages = {953--956},
  issn = {0028-0836},
  doi = {10.1038/35082081},
  abstract = {The ability to abstract principles or rules from direct experience allows behaviour to extend beyond specific circumstances to general situations. For example, we learn the 'rules' for restaurant dining from specific experiences and can then apply them in new restaurants. The use of such rules is thought to depend on the prefrontal cortex (PFC) because its damage often results in difficulty in following rules. Here we explore its neural basis by recording from single neurons in the PFC of monkeys trained to use two abstract rules. They were required to indicate whether two successively presented pictures were the same or different depending on which rule was currently in effect. The monkeys performed this task with new pictures, thus showing that they had learned two general principles that could be applied to stimuli that they had not yet experienced. The most prevalent neuronal activity observed in the PFC reflected the coding of these abstract rules.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\W75FFMR3\\Wallis, Anderson, Miller - 2001 - Single neurons in prefrontal cortex encode abstract rules.pdf},
  journal = {Nature},
  number = {6840},
  pmid = {11418860}
}

@article{wallis_miller_2003,
  title = {Neuronal Activity in Primate Dorsolateral and Orbital Prefrontal Cortex during Performance of a Reward Preference Task},
  author = {Wallis, Jonathan D. and Miller, Earl K.},
  year = {2003},
  issn = {0953816X},
  doi = {10.1046/j.1460-9568.2003.02922.x},
  abstract = {An important function of the prefrontal cortex (PFC) is the control of goal-directed behaviour. This requires information as to whether actions were successful in obtaining desired outcomes such as rewards. While lesion studies implicate a particular PFC region, the orbitofrontal cortex (OFC), in reward processing, neurons encoding reward have been reported in both the OFC and the dorsolateral prefrontal cortex (DLPFC). To compare and contrast their roles, we recorded simultaneously from both areas while two rhesus monkeys (Macaca mulatta) performed a reward preference task. The monkeys had to choose between pictures associated with different amounts of a juice reward. Neuronal activity in both areas reflected the reward amount. However, neurons in the DLPFC encoded both the reward amount and the monkeys' forthcoming response, while neurons in the OFC more often encoded the reward amount alone. Further, reward selectivity arose more rapidly in the OFC than the DLPFC. These results are consistent with reward information entering the PFC via the OFC, where it is passed to the DLPFC and used to control behaviour.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KSEEVRKJ\\Wallis, Miller - 2003 - Neuronal activity in primate dorsolateral and orbital prefrontal cortex during performance of a reward preferenc.pdf},
  journal = {European Journal of Neuroscience},
  keywords = {Dorsolateral,Neurophysiology,Orbitofrontal,Prefrontal,Reward,Rhesus monkey},
  pmid = {14622240}
}

@article{wallis_wallis_2011,
  title = {Cross-Species Studies of Orbitofrontal Cortex and Value-Based Decision-Making},
  author = {Wallis, Jonathan D},
  year = {2011},
  volume = {15},
  doi = {10.1038/nn.2956},
  abstract = {In 1998, at the Forum of European Neuroscience in Berlin, there was a symposium entitled " The Mysterious Orbitofrontal Cortex " 1 . The feeling was that, in the frontal lobe, an area with a long history of frustrating researchers, the function of OFC was particularly baffling. Despite that pessimism, the intervening 13 years have seen nota-ble progress in our understanding. Much of this progress has been driven by two factors. First, there has been theoretical convergence: researchers from a variety of fields have found that OFC has a fun-damental role in value-based decision-making. Second, researchers have employed increasingly sophisticated behavioral methods drawn from economics and psychology to measure decision-making. This period has been satisfying, as researchers from disparate fields have formed links between their research and the mystery of OFC has looked increasingly solvable. However, it is perhaps time to assess how deeply this theoretical convergence extends. It is becoming clear that discrepancies exist between results from different methodologies. The goal of this review is to highlight these discrepancies and examine whether they can be explained by species differences in the function and anatomy of OFC. Psychologists distinguish between two conceptually distinct types of decision-making. Perceptual decision-making refers to the process by which a subject makes a judgment about sensory input 2 . The bag-gage screener examines an X-ray trying to decide whether the bag contains a gun or a hair dryer. On the other hand, value-based deci-sion-making resembles the folk definition of decision-making: for example, deciding whether to have bacon or cereal for breakfast 3 . Unlike perceptual decision-making, value-based decision-making is inherently subjective. You could make a best guess as to what I will choose based on your past experience of my choices (I usually choose bacon) and your knowledge of my current goals (I recently went on a diet), but without knowing my precise internal state, this remains a guess. It is this process of valuing alternatives to determine the best choice that is thought to be a core OFC function. Early studies of the effects of frontal lobe damage in humans emphasized the importance of OFC and the adjacent medial fron-tal cortex for everyday decision-making 4 . Laboratory tests sought to mimic this process with gambling tasks in which money could be won or lost probabilistically 5 . The flavor was certainly of value-based decision-making, even though the terminology had yet to be agreed on. Later studies explicitly tested individuals with OFC damage on perceptual and value-based decision-making tasks and found impairments only on the latter 6 . Furthermore, if damage was restricted to dorsolateral prefrontal areas, decision-making usually (although not always 7) remained intact 6,8,9 . Neuroimaging studies are consistent with these findings; value-based decision-making typically activates orbital and medial frontal regions rather than dorsolateral frontal areas 10\textendash 20 . Studies in monkeys have also shown that OFC damage impairs various aspects of value-based decision-making, including the ability to assign 21 and update 22 stimulus values. Early neurophysiological studies revealed that OFC neurons encode a subject's relative prefer-ences between different rewards 23 and that reward information is encoded more quickly in OFC than in dorsolateral prefrontal cortex 24 and anterior cingulate cortex 25 . Later studies, employing sophisti-cated methods from economics, showed that OFC neuronal activ-ity matched the animal's subjective valuation of the reward 26 . OFC neurons in both rats and monkeys also encode a wide range of other variables that are necessary for decision-making, including positive and negative expected outcomes 27\textendash 29 , hypothetical and actual out-comes 30 , the amount of time 31,32 and effort 33 necessary to acquire an outcome, confidence in the decision 34 , and the probability that one's choice will be fruitful 33 . In summary, an impressive body of evidence from an array of meth-ods has implicated OFC in value-based decision-making. Although it is not surprising that the field has tended to emphasize the remarkable consistency in the findings 3,35\textendash 37 , discrepancies do exist. However, before discussing them, we will first review the anatomy of OFC across species.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Q98ZC96K\\Wallis - 2011 - Cross-species studies of orbitofrontal cortex and value-based decision-making.pdf},
  journal = {Nature Neuroscience},
  number = {1}
}

@article{wallis_wallis_2018,
  title = {Decoding {{Cognitive Processes}} from {{Neural Ensembles}}},
  author = {Wallis, Joni D.},
  year = {2018},
  month = dec,
  volume = {22},
  pages = {1091--1102},
  issn = {13646613},
  doi = {10.1016/j.tics.2018.09.002},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9DELZXCQ\\Wallis - 2018 - Decoding Cognitive Processes from Neural Ensembles.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {12}
}

@article{walsh_oconnell_2020,
  ids = {walsh.oconnell.2020a},
  title = {Evaluating the Neurophysiological Evidence for Predictive Processing as a Model of Perception},
  author = {Walsh, Kevin S. and McGovern, David P. and Clark, Andy and O'Connell, Redmond G.},
  year = {2020},
  month = mar,
  pages = {nyas.14321},
  issn = {0077-8923, 1749-6632},
  doi = {10.1111/nyas.14321},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EPIR8YAG\\Walsh et al. - 2020 - Evaluating the neurophysiological evidence for pre.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\PPEHIEAC\\Walsh et al. - 2020 - Evaluating the neurophysiological evidence for pre.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\YYW2WBBN\\walsh.oconnell..pdf;C\:\\Users\\wchapman\\Zotero\\storage\\PNJLYI5Z\\nyas.html},
  journal = {Annals of the New York Academy of Sciences},
  language = {en}
}

@article{wang_botvinick_2018,
  title = {Prefrontal Cortex as a Meta-Reinforcement Learning System},
  author = {Wang, Jane X. and {Kurth-Nelson}, Zeb and Kumaran, Dharshan and Tirumala, Dhruva and Soyer, Hubert and Leibo, Joel Z. and Hassabis, Demis and Botvinick, Matthew},
  year = {2018},
  volume = {21},
  pages = {860--868},
  issn = {15461726},
  doi = {10.1038/s41593-018-0147-8},
  abstract = {Over the past 20 years, neuroscience research on reward-based learning has converged on a canonical model, under which the neurotransmitter dopamine `stamps in' associations between situations, actions and rewards by modulating the strength of synaptic connections between neurons. However, a growing number of recent findings have placed this standard model under strain. We now draw on recent advances in artificial intelligence to introduce a new theory of reward-based learning. Here, the dopamine system trains another part of the brain, the prefrontal cortex, to operate as its own free-standing learning system. This new perspective accommodates the findings that motivated the standard model, but also deals gracefully with a wider range of observations, providing a fresh foundation for future research.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GVNQK8GT\\Wang et al. - 2018 - Prefrontal cortex as a meta-reinforcement learning.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\UKDXNHIM\\s41593-018-0147-8.pdf},
  journal = {Nature Neuroscience},
  number = {6},
  pmid = {29760527}
}

@article{wang_ding_2016,
  title = {Top-{{Down Control}} of {{Visual Alpha Oscillations}}: {{Sources}} of {{Control Signals}} and {{Their Mechanisms}} of {{Action}}},
  author = {Wang, Chao and Rajagovindan, Rajasimhan and Han, Sahng-Min and Ding, Mingzhou},
  year = {2016},
  volume = {10},
  pages = {1--14},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2016.00015},
  abstract = {Alpha oscillations (8\textendash 12 Hz) are thought to inversely correlate with cortical excitability. Goal-oriented modulation of alpha has been studied extensively. In visual spatial attention, alpha over the region of visual cortex corresponding to the attended location decreases, signifying increased excitability to facilitate the processing of impending stimuli. In contrast, in retention of verbal working memory, alpha over visual cortex increases, signifying decreased excitability to gate out stimulus input to protect the information held online from sensory interference. According to the prevailing model, this goal-oriented biasing of sensory cortex is effected by top-down control signals from frontal and parietal cortices. The present study tests and substantiates this hypothesis by (a) identifying the signals that mediate the top-down biasing influence, (b) examining whether the cortical areas issuing these signals are task-specific or task-independent, and (c) establishing the possible mechanism of the biasing action. High-density human EEG data were recorded in two experimental paradigms: a trial-by-trial cued visual spatial attention task and a modified Sternberg working memory task. Applying Granger causality to both sensor-level and source-level data we report the following findings. In covert visual spatial attention, the regions exerting top-down control over visual activity are lateralized to the right hemisphere, with the dipoles located at the right frontal eye field (FEF) and the right inferior frontal gyrus (IFG) being the main sources of top-down influences. During retention of verbal working memory, the regions exerting top-down control over visual activity are lateralized to the left hemisphere, with the dipoles located at the left middle frontal gyrus (MFG) being the main source of top-down influences. In both experiments, top-down influences are mediated by alpha oscillations, and the biasing effect is likely achieved via an inhibition-disinhibition mechanism.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZE5KV6RN\\Wang et al. - 2016 - Top-Down Control of Visual Alpha Oscillations Sources of Control Signals and Their Mechanisms of Action.pdf},
  journal = {Frontiers in Human Neuroscience},
  keywords = {alpha,eeg,granger causality,top-down control,visual spatial attention,working-memory},
  number = {January},
  pmid = {26834601}
}

@article{wang_jensen_2018,
  title = {Gamma {{Oscillatory Activity Related}} to {{Language Prediction}}},
  author = {Wang, Lin and Hagoort, Peter and Jensen, Ole},
  year = {2018},
  volume = {30},
  pages = {1075--1085},
  issn = {0898-929X},
  doi = {10.1162/jocn_a_01275},
  abstract = {Using magnetoencephalography, the current study examined gamma activity associated with language prediction. Participants read high- and low-constraining sentences in which the final word of the sentence was either expected or unexpected. Although no consistent gamma power difference induced by the sentence-final words was found between the expected and unexpected conditions, the correlation of gamma power during the prediction and activation intervals of the sentence-final words was larger when the presented words matched with the prediction compared with when the prediction was violated or when no prediction was available. This suggests that gamma magnitude relates to the match between predicted and perceived words. Moreover, the expected words induced activity with a slower gamma frequency compared with that induced by unexpected words. Overall, the current study establishes that prediction is related to gamma power correlations and a slowing of the gamma frequency.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PR9SXIYI\\Wang, Hagoort, Jensen - 2018 - Gamma Oscillatory Activity Related to Language Prediction.pdf},
  journal = {Journal of Cognitive Neuroscience},
  number = {8},
  pmid = {29708821}
}

@article{wang_kass_2014,
  title = {An {{Empirical Model}} for {{Reliable Spiking Activity}}},
  author = {Wang, W and Tripathy, Shreejoy and Padmanabhan, K and Urban, Nn and Kass, Re},
  year = {2014},
  volume = {1872},
  pages = {1840--1872},
  issn = {1530888X},
  doi = {10.1162/NECO},
  abstract = {Understanding a neuron's transfer function, which relates a neuron's inputs to its outputs, is essential for understanding the computational role of single neurons. Recently, statistical models, based on point processes and using generalized linear model (GLM) technology, have been widely applied to predict dynamic neuronal transfer functions. However, the standard version of these models fails to capture important features of neural activity, such as responses to stimuli that elicit highly reliable trial-to-trial spiking. Here, we consider a generalization of the usual GLM that incorporates nonlinearity by modeling reliable and nonreliable spikes as being generated by distinct stimulus features. We develop},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TFKR88MM\\Wang et al. - 2014 - An Empirical Model for Reliable Spiking Activity.pdf},
  journal = {Neural computation},
  pmid = {25602775}
}

@article{wang_knierim_2018,
  title = {Egocentric Coding of External Items in the Lateral Entorhinal Cortex},
  author = {Wang, Cheng and Chen, Xiaojing and Lee, Heekyung and Deshmukh, Sachin S and Yoganarasimha, D and Savelli, Francesco and Knierim, James J},
  year = {2018},
  month = nov,
  volume = {362},
  pages = {945--949},
  issn = {0036-8075},
  doi = {10.1126/science.aau4940},
  abstract = {Episodic memory, the conscious recollection of past events, is typically experienced from a first-person (egocentric) perspective. The hippocampus plays an essential role in episodic memory and spatial cognition. Although the allocentric nature of hippocampal spatial coding is well understood, little is known about whether the hippocampus receives egocentric information about external items. We recorded in rats the activity of single neurons from the lateral entorhinal cortex (LEC) and medial entorhinal cortex (MEC), the two major inputs to the hippocampus. Many LEC neurons showed tuning for egocentric bearing of external items, whereas MEC cells tended to represent allocentric bearing. These results demonstrate a fundamental dissociation between the reference frames of LEC and MEC neural representations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7PXVILN7\\Wang et al. - Unknown - Egocentric coding of external items in the lateral entorhinal cortex.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\RADYR5Q6\\Wang et al. - 2018 - Egocentric coding of external items in the lateral entorhinal cortex.pdf},
  journal = {Science},
  number = {6417}
}

@article{wang_knierim_2020,
  title = {Egocentric and Allocentric Representations of Space in the Rodent Brain},
  author = {Wang, Cheng and Chen, Xiaojing and Knierim, James J},
  year = {2020},
  month = feb,
  volume = {60},
  pages = {12--20},
  issn = {09594388},
  doi = {10.1016/j.conb.2019.11.005},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BS89JV6P\\Wang et al. - 2020 - Egocentric and allocentric representations of spac.pdf},
  journal = {Current Opinion in Neurobiology},
  language = {en}
}

@article{wang_tao_2016,
  title = {Graded, {{Dynamically Routable Information Processing}} with {{Synfire}}-{{Gated Synfire Chains}}},
  author = {Wang, Zhuo and Sornborger, Andrew T. and Tao, Louis},
  editor = {Graham, Lyle J.},
  year = {2016},
  month = jun,
  volume = {12},
  pages = {e1004979},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1004979},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\37L6U5GN\\Wang et al. - 2016 - Graded, Dynamically Routable Information Processin.PDF},
  journal = {PLOS Computational Biology},
  language = {en},
  number = {6}
}

@article{wang_ting_2017,
  title = {A Light- and Calcium-Gated Transcription Factor for Imaging and Manipulating Activated Neurons},
  author = {Wang, Wenjing and Wildes, Craig P and Pattarabanjird, Tanyaporn and Sanchez, Mateo I and Glober, Gordon F and Matthews, Gillian A and Tye, Kay M and Ting, Alice Y},
  year = {2017},
  month = jun,
  volume = {35},
  pages = {864--871},
  issn = {1087-0156, 1546-1696},
  doi = {10.1038/nbt.3909},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\H9UQER49\\Wang et al. - 2017 - A light- and calcium-gated transcription factor fo.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\MX38H5TQ\\Wang et al. - 2017 - A light- and calcium-gated transcription factor fo.pdf},
  journal = {Nature Biotechnology},
  language = {en},
  number = {9}
}

@article{wang_yu_2018,
  title = {{{PredRNN}}++: {{Towards A Resolution}} of the {{Deep}}-in-{{Time Dilemma}} in {{Spatiotemporal Predictive Learning}}},
  shorttitle = {{{PredRNN}}++},
  author = {Wang, Yunbo and Gao, Zhifeng and Long, Mingsheng and Wang, Jianmin and Yu, Philip S.},
  year = {2018},
  month = apr,
  abstract = {We present PredRNN++, a recurrent network for spatiotemporal predictive learning. In pursuit of a great modeling capability for short-term video dynamics, we make our network deeper in time by leveraging a new recurrent structure named Causal LSTM with cascaded dual memories. To alleviate the gradient propagation difficulties in deep predictive models, we propose a Gradient Highway Unit, which provides alternative quick routes for the gradient flows from outputs back to long-range previous inputs. The gradient highway units work seamlessly with the causal LSTMs, enabling our model to capture the short-term and the long-term video dependencies adaptively. Our model achieves state-of-the-art prediction results on both synthetic and real video datasets, showing its power in modeling entangled motions.},
  archivePrefix = {arXiv},
  eprint = {1804.06300},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VAZMXIGJ\\Wang et al. - 2018 - PredRNN++ Towards A Resolution of the Deep-in-Tim.pdf},
  journal = {arXiv:1804.06300 [cs, stat]},
  language = {en},
  primaryClass = {cs, stat}
}

@article{wang_zhao_2016,
  title = {Auto-Encoder Based Dimensionality Reduction},
  author = {Wang, Yasi and Yao, Hongxun and Zhao, Sicheng},
  year = {2016},
  month = apr,
  volume = {184},
  pages = {232--242},
  issn = {18728286},
  doi = {10.1016/j.neucom.2015.08.104},
  abstract = {Auto-encoder-a tricky three-layered neural network, known as auto-association before, constructs the "building block" of deep learning, which has been demonstrated to achieve good performance in various domains. In this paper, we try to investigate the dimensionality reduction ability of auto-encoder, and see if it has some kind of good property that might accumulate when being stacked and thus contribute to the success of deep learning.Based on the above idea, this paper starts from auto-encoder and focuses on its ability to reduce the dimensionality, trying to understand the difference between auto-encoder and state-of-the-art dimensionality reduction methods. Experiments are conducted both on the synthesized data for an intuitive understanding of the method, mainly on two and three-dimensional spaces for better visualization, and on some real datasets, including MNIST and Olivetti face datasets. The results show that auto-encoder can indeed learn something different from other methods. Besides, we preliminarily investigate the influence of the number of hidden layer nodes on the performance of auto-encoder and its possible relation with the intrinsic dimensionality of input data.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NX9NMDWY\\Wang, Yao, Zhao - 2016 - Auto-encoder based dimensionality reduction.pdf},
  journal = {Neurocomputing},
  keywords = {Auto-encoder,Dimensionality reduction,Dimensionality-accuracy,Intrinsic dimensionality,Visualization},
  pmid = {11463758}
}

@article{warden_miller_2010,
  title = {Task-{{Dependent Changes}} in {{Short}}-{{Term Memory}} in the {{Prefrontal Cortex}}},
  author = {Warden, Melissa R and Miller, Earl K},
  year = {2010},
  volume = {30},
  pages = {15801--15810},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1569-10.2010},
  abstract = {The prefrontal cortex (PFC) is important for flexible, context-dependent behavioral control. It also plays a critical role in short-term memory maintenance. Though many studies have investigated these functions independently, it is unclear how these two very different processes are realized by a single brain area. To address this, we trained two monkeys on two variants of an object sequence memory task. These tasks had the same memory requirements but differed in how information was read out and used. For the ``recognition'' task, the monkeys had to remember two sequentially presented objects and then release a bar when a matching sequence was recognized. For the ``recall'' task, the monkeys had to remember the same sequence of objects but were instead required to recall the sequence and reproduce it with saccadic eye movements when presented with an array of objects. After training, we recorded the activity of PFC neurons during task performance. We recorded 222 neurons during the recognition task, 177 neurons during the recall task, and 248 neurons during the switching task (interleaved blocks of recognition and recall). Task context had a profound influence on neural selectivity for objects. During the recall task, the first object was encoded more strongly than the second object, while during the recognition task, the second object was encoded more strongly. In addition, most of the neurons encoded both the task and the objects, evidence for a single population responsible for these two critical prefrontal functions.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LAZRCRRD\\Warden, Miller - 2010 - Task-Dependent Changes in Short-Term Memory in the Prefrontal Cortex.pdf},
  journal = {The Journal of Neuroscience},
  number = {47},
  pmid = {21106819}
}

@article{wasmuht_stokes_2018,
  title = {Intrinsic Neuronal Dynamics Predict Distinct Functional Roles during Working Memory},
  author = {Wasmuht, Dante Francisco and Spaak, Eelke and Buschman, Timothy J and Miller, Earl K and Stokes, Mark G},
  year = {2018},
  pages = {233171},
  issn = {2041-1723},
  doi = {10.1101/233171},
  abstract = {Working memory (WM) is characterized by the ability to maintain stable representations over time; however, neural activity associated with WM maintenance can be highly dynamic. We explore whether complex population coding dynamics during WM relate to the intrinsic temporal properties of single neurons in lateral prefrontal cortex (lPFC), the frontal eye fields (FEF) and lateral intraparietal cortex (LIP) of two monkeys (Macaca mulatta). We found that cells with short timescales carried memory information relatively early during memory encoding in lPFC; whereas long timescale cells played a greater role later during processing, dominating coding in the delay period. We also observed a link between functional connectivity at rest and intrinsic timescale in FEF and LIP. Our results indicate that individual differences in the temporal processing capacity predicts complex neuronal dynamics during WM; ranging from rapid dynamic encoding of stimuli to slower, but stable, maintenance of mnemonic information.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\T7QV6EZW\\Wasmuht et al. - Unknown - Intrinsic neuronal dynamics predict distinct functional roles during working memory.pdf},
  journal = {Nature Communications}
}

@book{wasserman_wasserman_2004,
  title = {All of {{Statistics}}},
  author = {Wasserman, Larry},
  year = {2004},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VHE2IXF3\\Wasserman - 2004 - All of Statistics.pdf},
  isbn = {0-387-21736-3}
}

@article{wassum_maidment_2008,
  title = {Silicon Wafer-Based Platinum Microelectrode Array Biosensor for near Real-Time Measurement of Glutamate in Vivo},
  author = {Wassum, Kate M and Tolosa, Vanessa M and Wang, Jianjun and Walker, Eric and Monbouquette, Harold G and Maidment, Nigel T},
  year = {2008},
  volume = {8},
  pages = {5023--5036},
  issn = {14248220},
  doi = {10.3390/s8085023},
  abstract = {Using Micro-Electro-Mechanical-Systems (MEMS) technologies, we have developed silicon wafer-based platinum microelectrode arrays (MEAs) modified with glutamate oxidase (GluOx) for electroenzymatic detection of glutamate in vivo. These MEAs were designed to have optimal spatial resolution for in vivo recordings. Selective detection of glutamate in the presence of the electroactive interferents, dopamine and ascorbic acid, was attained by deposition of polypyrrole and Nafion. The sensors responded to glutamate with a limit of detection under 1muM and a sub-1-second response time in solution. In addition to extensive in vitro characterization, the utility of these MEA glutamate biosensors was also established in vivo. In the anesthetized rat, these MEA glutamate biosensors were used for detection of cortically-evoked glutamate release in the ventral striatum. The MEA biosensors also were applied to the detection of stress-induced glutamate release in the dorsal striatum of the freely-moving rat.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BPCHGTQR\\Wassum et al. - 2008 - Silicon wafer-based platinum microelectrode array biosensor for near real-time measurement of glutamate in vivo.pdf},
  journal = {Sensors},
  keywords = {Central nervous system,Constant potential amperometry,Glutamate biosensor,Nafion,Polypyrrole},
  number = {8},
  pmid = {19543440}
}

@article{watabe-uchida_uchida_2012,
  title = {Whole-{{Brain Mapping}} of {{Direct Inputs}} to {{Midbrain Dopamine Neurons}}},
  author = {{Watabe-Uchida}, Mitsuko and Zhu, Lisa and Ogawa, Sachie K. and Vamanrao, Archana and Uchida, Naoshige},
  year = {2012},
  volume = {74},
  pages = {858--873},
  issn = {08966273},
  doi = {10.1016/j.neuron.2012.03.017},
  abstract = {Recent studies indicate that dopamine neurons in the ventral tegmental area (VTA) and substantia nigra pars compacta (SNc) convey distinct signals. To explore this difference, we comprehensively identified each area@s monosynaptic inputs using the rabies virus. We show that dopamine neurons in both areas integrate inputs from a more diverse collection of areas than previously thought, including autonomic, motor, and somatosensory areas. SNc and VTA dopamine neurons receive contrasting excitatory inputs: the former from the somatosensory/motor cortex and subthalamic nucleus, which may explain their short-latency responses to salient events; and the latter from the lateral hypothalamus, which may explain their involvement in value coding. We demonstrate that neurons in the striatum that project directly to dopamine neurons form patches in both the dorsal and ventral striatum, whereas those projecting to GABAergic neurons are distributed in the matrix compartment. Neuron-type-specific connectivity lays a foundation for studying how dopamine neurons compute outputs.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Q4989773\\Watabe-Uchida et al. - 2012 - Whole-Brain Mapping of Direct Inputs to Midbrain Dopamine Neurons.pdf},
  journal = {Neuron},
  number = {5},
  pmid = {22681690}
}

@article{watters_zoran_2017,
  title = {Visual {{Interaction Networks}}},
  author = {Watters, Nicholas and Tacchetti, Andrea and Weber, Theophane and Pascanu, Razvan and Battaglia, Peter and Zoran, Daniel},
  year = {2017},
  abstract = {From just a glance, humans can make rich predictions about the future state of a wide range of physical systems. On the other hand, modern approaches from engineering, robotics, and graphics are often restricted to narrow domains and require direct measurements of the underlying states. We introduce the Visual Interaction Network, a general-purpose model for learning the dynamics of a physical system from raw visual observations. Our model consists of a perceptual front-end based on convolutional neural networks and a dynamics predictor based on interaction networks. Through joint training, the perceptual front-end learns to parse a dynamic visual scene into a set of factored latent object representations. The dynamics predictor learns to roll these states forward in time by computing their interactions and dynamics, producing a predicted physical trajectory of arbitrary length. We found that from just six input video frames the Visual Interaction Network can generate accurate future trajectories of hundreds of time steps on a wide range of physical systems. Our model can also be applied to scenes with invisible objects, inferring their future states from their effects on the visible objects, and can implicitly infer the unknown mass of objects. Our results demonstrate that the perceptual module and the object-based dynamics predictor module can induce factored latent representations that support accurate dynamical predictions. This work opens new opportunities for model-based decision-making and planning from raw sensory observations in complex physical environments.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L23XVG8A\\Watters et al. - 2017 - Visual Interaction Networks.pdf}
}

@article{wayne_lillicrap_2018,
  title = {Unsupervised {{Predictive Memory}} in a {{Goal}}-{{Directed Agent}}},
  author = {Wayne, Greg and Hung, Chia-Chun and Amos, David and Mirza, Mehdi and Ahuja, Arun and {Grabska-Barwinska}, Agnieszka and Rae, Jack and Mirowski, Piotr and Leibo, Joel Z and Santoro, Adam and Gemici, Mevlana and Reynolds, Malcolm and Harley, Tim and Abramson, Josh and Mohamed, Shakir and Rezende, Danilo and Saxton, David and Cain, Adam and Hillier, Chloe and Silver, David and Kavukcuoglu, Koray and Botvinick, Matt and Hassabis, Demis and Lillicrap, Timothy},
  year = {2018},
  abstract = {Animals execute goal-directed behaviours despite the limited range and scope of their sensors. To cope, they explore environments and store memories maintaining estimates of important information that is not presently available. Recently, progress has been made with artificial intelligence (AI) agents that learn to perform tasks from sensory input, even at a human level, by merging reinforcement learning (RL) algorithms with deep neural networks, and the excitement surrounding these results has led to the pursuit of related ideas as explanations of non-human animal learning. However, we demonstrate that contemporary RL algorithms struggle to solve simple tasks when enough information is concealed from the sensors of the agent, a property called "partial observability". An obvious requirement for handling partially observed tasks is access to extensive memory, but we show memory is not enough; it is critical that the right information be stored in the right format. We develop a model, the Memory, RL, and Inference Network (MERLIN), in which memory formation is guided by a process of predictive modeling. MERLIN facilitates the solution of tasks in 3D virtual reality environments for which partial observability is severe and memories must be maintained over long durations. Our model demonstrates a single learning agent architecture that can solve canonical behavioural tasks in psychology and neurobiology without strong simplifying assumptions about the dimensionality of sensory input or the duration of experiences.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4SH466HF\\Wayne et al. - 2018 - Unsupervised Predictive Memory in a Goal-Directed Agent(2).pdf}
}

@article{webb_cohen_2020,
  title = {Learning {{Representations}} That {{Support Extrapolation}}},
  author = {Webb, Taylor W. and Dulberg, Zachary and Frankland, Steven M. and Petrov, Alexander A. and O'Reilly, Randall C. and Cohen, Jonathan D.},
  year = {2020},
  month = jul,
  abstract = {Extrapolation -- the ability to make inferences that go beyond the scope of one's experiences -- is a hallmark of human intelligence. By contrast, the generalization exhibited by contemporary neural network algorithms is largely limited to interpolation between data points in their training corpora. In this paper, we consider the challenge of learning representations that support extrapolation. We introduce a novel visual analogy benchmark that allows the graded evaluation of extrapolation as a function of distance from the convex domain defined by the training data. We also introduce a simple technique, context normalization, that encourages representations that emphasize the relations between objects. We find that this technique enables a significant improvement in the ability to extrapolate, considerably outperforming a number of competitive techniques.},
  archivePrefix = {arXiv},
  eprint = {2007.05059},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Y6R8ZE8A\\webb_cohen_2020.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\VE6NYNFK\\2007.html},
  journal = {arXiv:2007.05059 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  primaryClass = {cs}
}

@article{weber_fairhall_2019,
  title = {Coding {{Principles}} in {{Adaptation}}},
  author = {Weber, Alison I. and Krishnamurthy, Kamesh and Fairhall, Adrienne L.},
  year = {2019},
  month = sep,
  volume = {5},
  pages = {427--449},
  issn = {2374-4642, 2374-4650},
  doi = {10.1146/annurev-vision-091718-014818},
  abstract = {Adaptation is a common principle that recurs throughout the nervous system at all stages of processing. This principle manifests in a variety of phenomena, from spike frequency adaptation, to apparent changes in receptive fields with changes in stimulus statistics, to enhanced responses to unexpected stimuli. The ubiquity of adaptation leads naturally to the question: What purpose do these different types of adaptation serve? A diverse set of theories, often highly overlapping, has been proposed to explain the functional role of adaptive phenomena. In this review, we discuss several of these theoretical frameworks, highlighting relationships among them and clarifying distinctions. We summarize observations of the varied manifestations of adaptation, particularly as they relate to these theoretical frameworks, focusing throughout on the visual system and making connections to other sensory systems.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZESYD5M9\\Weber et al. - 2019 - Coding Principles in Adaptation.pdf},
  journal = {Annual Review of Vision Science},
  language = {en},
  number = {1}
}

@book{weber_pillow_2017,
  title = {Capturing the Dynamical Repertoire of Single Neurons with Generalized Linear Models},
  author = {Weber, Alison I and Pillow, Jonathan W},
  year = {2017},
  volume = {29},
  doi = {10.1162/NECO_a_01021},
  abstract = {A key problem in computational neuroscience is to find simple, tractable models that are nevertheless flexible enough to capture the response properties of real neurons. Here we examine the capabilities of recurrent point process models known as Poisson generalized linear models (GLMs). These models are defined by a set of linear filters, a point nonlinearity, and conditionally Poisson spiking. They have desirable statistical properties for fitting and have been widely used to analyze spike trains from electrophysiological recordings. However, the dynamical repertoire of GLMs has not been systematically compared to that of real neurons. Here we show that GLMs can reproduce a comprehensive suite of canonical neural response behaviors, including tonic and phasic spiking, bursting, spike rate adaptation, type I and type II excitation, and two forms of bistability. GLMs can also capture stimulus-dependent changes in spike timing precision and reliability that mimic those observed in real neurons, and can exhibit varying degrees of stochasticity, from virtually deterministic responses to greater-than-Poisson variability. These results show that Poisson GLMs can exhibit a wide range of dynamic spiking behaviors found in real neurons, making them well suited for qualitative dynamical as well as quantitative statistical studies of single-neuron and population response properties.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\TPNXUG7A\\Weber, Pillow - 2017 - Capturing the Dynamical Repertoire of Single Neurons with Generalized Linear Models.pdf},
  isbn = {0899-7667},
  pmid = {25602775}
}

@article{weber_wermter_2007,
  title = {A Self-Organizing Map of Sigma-Pi Units},
  author = {Weber, Cornelius and Wermter, Stefan},
  year = {2007},
  month = aug,
  volume = {70},
  pages = {2552--2560},
  issn = {09252312},
  doi = {10.1016/j.neucom.2006.05.014},
  abstract = {By frame of reference transformations, an input variable in one coordinate system is transformed into an output variable in a different coordinate system depending on another input variable. If the variables are represented as neural population codes, then a sigma-pi network is a natural way of coding this transformation. By multiplying two inputs it detects coactivations of input units, and by summing over the multiplied inputs, one output unit can respond invariantly to different combinations of coactivated input units. Here, we present a sigma-pi network and a learning algorithm by which the output representation self-organizes to form a topographic map. This network solves the frame of reference transformation problem by unsupervised learning. \textcopyright{} 2006 Elsevier B.V. All rights reserved.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SKCURY7V\\Weber, Wermter, Lang - 2007 - A self-organizing map of sigma-pi units.pdf},
  journal = {Neurocomputing},
  keywords = {Frame of reference transformations,Invariances,Population coding},
  number = {13-15}
}

@article{welday_blair_2011,
  title = {Cosine Directional Tuning of Theta Cell Burst Frequencies: Evidence for Spatial Coding by Oscillatory Interference.},
  author = {Welday, Adam C and Shlifer, I Gary and Bloom, Matthew L and Zhang, Kechen and Blair, Hugh T},
  year = {2011},
  month = nov,
  volume = {31},
  pages = {16157--16176},
  issn = {1529-2401},
  doi = {10.1523/JNEUROSCI.0712-11.2011},
  abstract = {The rodent septohippocampal system contains "theta cells," which burst rhythmically at 4-12 Hz, but the functional significance of this rhythm remains poorly understood (Buzs\{\'a\}ki, 2006). Theta rhythm commonly modulates the spike trains of spatially tuned neurons such as place (O'Keefe and Dostrovsky, 1971), head direction (Tsanov et al., 2011a), grid (Hafting et al., 2005), and border cells (Savelli et al., 2008; Solstad et al., 2008). An "oscillatory interference" theory has hypothesized that some of these spatially tuned neurons may derive their positional firing from phase interference among theta oscillations with frequencies that are modulated by the speed and direction of translational movements (Burgess et al., 2005, 2007). This theory is supported by studies reporting modulation of theta frequency by movement speed (Rivas et al., 1996; Geisler et al., 2007; Jeewajee et al., 2008a), but modulation of theta frequency by movement direction has never been observed. Here we recorded theta cells from hippocampus, medial septum, and anterior thalamus of freely behaving rats. Theta cell burst frequencies varied as the cosine of the rat's movement direction, and this directional tuning was influenced by landmark cues, in agreement with predictions of the oscillatory interference theory. Computer simulations and mathematical analysis demonstrated how a postsynaptic neuron can detect location-dependent synchrony among inputs from such theta cells, and thereby mimic the spatial tuning properties of place, grid, or border cells. These results suggest that theta cells may serve a high-level computational function by encoding a basis set of oscillatory signals that interfere with one another to synthesize spatial memory representations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YG8V6NRH\\Welday et al. - 2011 - Cosine directional tuning of theta cell burst frequencies evidence for spatial coding by oscillatory interference.pdf},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  keywords = {Animals,Biophysics,Brain,Brain: cytology,Brain: physiology,Computer Simulation,Cues,Exploratory Behavior,Long-Evans,Male,Models,Movement,Movement: physiology,Neurological,Neurons,Neurons: physiology,Orientation,Rats,Space Perception,Space Perception: physiology,Theta Rhythm,Theta Rhythm: physiology,Video Recording,Video Recording: methods},
  number = {45},
  pmid = {22072668}
}

@article{wells_lever_2013,
  title = {Novelty and Anxiolytic Drugs Dissociate Two Components of Hippocampal Theta in Behaving Rats.},
  author = {Wells, Christine E and Amos, Doran P and Jeewajee, Ali and Douchamps, Vincent and Rodgers, John and O'Keefe, John and Burgess, Neil and Lever, Colin},
  year = {2013},
  month = may,
  volume = {33},
  pages = {8650--8667},
  issn = {1529-2401},
  doi = {10.1523/JNEUROSCI.5040-12.2013},
  abstract = {Hippocampal processing is strongly implicated in both spatial cognition and anxiety and is temporally organized by the theta rhythm. However, there has been little attempt to understand how each type of processing relates to the other in behaving animals, despite their common substrate. In freely moving rats, there is a broadly linear relationship between hippocampal theta frequency and running speed over the normal range of speeds used during foraging. A recent model predicts that spatial-translation-related and arousal/anxiety-related mechanisms of hippocampal theta generation underlie dissociable aspects of the theta frequency-running speed relationship (the slope and intercept, respectively). Here we provide the first confirmatory evidence: environmental novelty decreases slope, whereas anxiolytic drugs reduce intercept. Variation in slope predicted changes in spatial representation by CA1 place cells and novelty-responsive behavior. Variation in intercept predicted anxiety-like behavior. Our findings isolate and doubly dissociate two components of theta generation that operate in parallel in behaving animals and link them to anxiolytic drug action, novelty, and the metric for self-motion.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\W7FMV9VY\\Wells et al. - 2013 - Novelty and anxiolytic drugs dissociate two components of hippocampal theta in behaving rats.pdf},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  keywords = {Animal,Animals,Anxiety,anxiolytic,Body Temperature,Body Temperature: drug effects,Disease Models,Dose-Response Relationship,Drug,Electroencephalography,Evoked Potentials,Evoked Potentials: drug effects,Exploratory Behavior,Exploratory Behavior: drug effects,Exploratory Behavior: physiology,Hippocampus,Hippocampus: drug effects,Hippocampus: physiology,Male,Rats,Space Perception,Space Perception: drug effects,Space Perception: physiology,Theta Rhythm,Theta Rhythm: drug effects,Theta Rhythm: physiology,Time Factors},
  number = {20},
  pmid = {23678110}
}

@article{wen_ding_2013,
  title = {Multivariate {{Granger}} Causality: An Estimation Framework Based on Factorization of the Spectral Density Matrix},
  author = {Wen, Xiaotong and Rangarajan, Govindan and Ding, Mingzhou},
  year = {2013},
  volume = {371},
  pages = {20110610--20110610},
  issn = {1364-503X},
  doi = {10.1098/rsta.2011.0610},
  abstract = {Granger causality is increasingly being applied to multi-electrode neurophysiological and functional imaging data to characterize directional interactions between neurons and brain regions. For a multivariate dataset, one might be interested in different subsets of the recorded neurons or brain regions. According to the current estimation framework, for each subset, one conducts a separate autoregressive model fitting process, introducing the potential for unwanted variability and uncertainty. In this paper, we propose a multivariate framework for estimating Granger causality. It is based on spectral density matrix factorization and offers the advantage that the estimation of such a matrix needs to be done only once for the entire multivariate dataset. For any subset of recorded data, Granger causality can be calculated through factorizing the appropriate submatrix of the overall spectral density matrix.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VSZURZXP\\Wen, Rangarajan, Ding - 2013 - Multivariate Granger causality an estimation framework based on factorization of the spectral density mat.pdf},
  journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  keywords = {biomedical engineering,factorization,Granger causality,multivariate,spectral density matrix,statistics Keywords,Subject Areas},
  number = {1997},
  pmid = {23858479}
}

@book{werlen_jones_2015,
  title = {Modulating the Map: Dopaminergic Tuning of Hippocampal Spatial Coding and Interactions},
  author = {Werlen, Emilie and Jones, Matthew W},
  year = {2015},
  edition = {First},
  volume = {219},
  publisher = {{Elsevier B.V.}},
  doi = {10.1016/bs.pbr.2015.03.002},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\N93FFCYH\\Werlen, Jones - 2015 - Modulating the map dopaminergic tuning of hippocampal spatial coding and interactions.pdf},
  keywords = {dopamine,Dopamine,happily,hippocampus,Hippocampus,it is mid-july,learning and memory,Learning and memory,prefrontal cortex,Prefrontal cortex,rome,sore,the air is hot,theta coherence,Theta coherence}
}

@article{white_mathur_2018,
  title = {Anterior {{Cingulate Cortex Input}} to the {{Claustrum Is Required}} for {{Top}}-{{Down Action Control}}},
  author = {White, Michael G and Panicker, Matthew and Mu, Chaoqi and Carter, Ashley M and Roberts, Bradley M and Dharmasri, Poorna A and Mathur, Brian N},
  year = {2018},
  volume = {22},
  pages = {84--95},
  issn = {22111247},
  doi = {10.1016/j.celrep.2017.12.023},
  abstract = {Cognitive abilities, such as volitional attention, operate under top-down, executive frontal cortical control of hierarchically lower structures. The circuit mechanisms underlying this process are unresolved. The claustrum possesses interconnectivity with many cortical areas and, thus, is hypothesized to orchestrate the cortical mantle for top-down control. Whether the claustrum receives top-down input and how this input may be processed by the claustrum have yet to be formally tested, however. We reveal that a rich anterior cingulate cortex (ACC) input to the claustrum encodes a preparatory top-down information signal on a five-choice response assay that is necessary for optimal task performance. We further show that ACC input monosynaptically targets claustrum inhibitory interneurons and spiny glutamatergic projection neurons, the latter of which amplify ACC input in a manner that is powerfully constrained by claustrum inhibitory microcircuitry. These results demonstrate ACC input to the claustrum is critical for top-down control guiding action. White et al. show that anterior cingulate cortex (ACC) input to the claustrum encodes a top-down preparatory signal on a 5-choice response assay that is critical for task performance. Claustrum microcircuitry amplifies top-down ACC input in a frequency-dependent manner for eventual propagation to the cortex for cognitive control of action.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5QB75CRU\\White et al. - 2018 - Anterior Cingulate Cortex Input to the Claustrum Is Required for Top-Down Action Control.pdf},
  journal = {Cell Reports},
  keywords = {attention,bottom-up,fiber photometry,microcircuit,motor cortices,optogenetics,sensory cortices},
  number = {1},
  pmid = {29298436}
}

@article{whitlock_moser_2012,
  title = {Functional Split between Parietal and Entorhinal Cortices in the Rat.},
  author = {Whitlock, Jonathan R and Pfuhl, Gerit and Dagslott, Nenitha and Moser, May-Britt and Moser, Edvard I},
  year = {2012},
  month = feb,
  volume = {73},
  pages = {789--802},
  issn = {1097-4199},
  doi = {10.1016/j.neuron.2011.12.028},
  abstract = {Posterior parietal cortex (PPC) and medial entorhinal cortex (MEC) are important elements of the neural circuit for space, but whether representations in these areas are controlled by the same factors is unknown. We recorded single units simultaneously in PPC and MEC of freely foraging rats and found that a subset of PPC cells are tuned to specific modes of movement irrespective of the animals' location or heading, whereas grid cells in MEC expressed static spatial maps. The behavioral correlates of PPC cells switched completely when the same animals ran in a spatially structured maze or when they ran similar stereotypic sequences in an open arena. Representations in PPC were similar in identical mazes in different rooms where grid cells completely realigned their firing fields. The data suggest that representations in PPC are determined by the organization of actions while cells in MEC are driven by spatial inputs.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FY9JMQRE\\Whitlock et al. - 2012 - Functional split between parietal and entorhinal cortices in the rat.pdf},
  journal = {Neuron},
  keywords = {Animals,Brain Mapping,Cluster Analysis,Electrodes,Entorhinal Cortex,Entorhinal Cortex: cytology,Entorhinal Cortex: physiology,Fourier Analysis,Implanted,Long-Evans,Male,Movement,Movement: physiology,Neural Pathways,Neural Pathways: physiology,Neurons,Neurons: physiology,Parietal Lobe,Parietal Lobe: cytology,Parietal Lobe: physiology,Rats,Spatial Behavior,Spatial Behavior: physiology},
  number = {4},
  pmid = {22365551}
}

@article{whitlock_whitlock_2017,
  title = {Posterior Parietal Cortex},
  author = {Whitlock, Jonathan R.},
  year = {2017},
  month = jul,
  volume = {27},
  pages = {R691-R695},
  issn = {09609822},
  doi = {10.1016/j.cub.2017.06.007},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JN7XVWRR\\Whitlock - 2017 - Posterior parietal cortex.pdf},
  journal = {Current Biology},
  language = {en},
  number = {14}
}

@article{whittaker_whittaker_1963,
  title = {Synaptic {{Transmission}}},
  author = {Whittaker, V P},
  year = {1963},
  volume = {2},
  pages = {203},
  doi = {10.1088/1478-3975/4/1/001},
  abstract = {Chemical inhibition and stimulation of central nervous system},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HV9TH2LW\\Whittaker - 1963 - Synaptic Transmission.pdf},
  journal = {California Medicine},
  number = {2}
}

@techreport{whittington_behrens_2019,
  title = {The {{Tolman}}-{{Eichenbaum Machine}}: {{Unifying}} Space and Relational Memory through Generalisation in the Hippocampal Formation},
  shorttitle = {The {{Tolman}}-{{Eichenbaum Machine}}},
  author = {Whittington, James CR and Muller, Tim H and Mark, Shirley and Barry, Caswell and Burgess, Neil and Behrens, Timothy EJ},
  year = {2019},
  month = sep,
  institution = {{Neuroscience}},
  doi = {10.1101/770495},
  abstract = {The hippocampal-entorhinal system is important for spatial and relational memory tasks. We formally link these domains; provide a mechanistic understanding of the hippocampal role in generalisation; and offer unifying principles underlying many entorhinal and hippocampal cell-types. We propose medial entorhinal cells form a basis describing structural knowledge, and hippocampal cells link this basis with sensory representations. Adopting these principles, we introduce the Tolman-Eichenbaum machine (TEM). After learning, TEM entorhinal cells include grid, band, border and object-vector cells. Hippocampal cells include place and landmark cells, remapping between environments. Crucially, TEM also predicts empirically recorded representations in complex non-spatial tasks. TEM predicts hippocampal remapping is not random as previously believed. Rather structural knowledge is preserved across environments. We confirm this in simultaneously recorded place and grid cells.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VDMMSAGN\\Whittington et al. - 2019 - The Tolman-Eichenbaum Machine Unifying space and .pdf},
  language = {en},
  type = {Preprint}
}

@article{whittington_bogacz_2017,
  ids = {whittington\_bogacz\_2017a},
  title = {An {{Approximation}} of the {{Error Backpropagation Algorithm}} in a {{Predictive Coding Network}} with {{Local Hebbian Synaptic Plasticity}}},
  author = {Whittington, James C. R. and Bogacz, Rafal},
  year = {2017},
  month = may,
  volume = {29},
  pages = {1229--1262},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/NECO_a_00949},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FCFU36MV\\Whittington and Bogacz - 2017 - An Approximation of the Error Backpropagation Algo.pdf},
  journal = {Neural Computation},
  language = {en},
  number = {5}
}

@article{whittington_bogacz_2019,
  title = {Theories of {{Error Back}}-{{Propagation}} in the {{Brain}}},
  author = {Whittington, James C.R. and Bogacz, Rafal},
  year = {2019},
  month = mar,
  volume = {23},
  pages = {235--250},
  issn = {13646613},
  doi = {10.1016/j.tics.2018.12.005},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GUIMH2GY\\Whittington and Bogacz - 2019 - Theories of Error Back-Propagation in the Brain.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {3}
}

@article{wianda_ross_2019,
  title = {The Roles of Alpha Oscillation in Working Memory Retention},
  author = {Wianda, Elvis and Ross, Bernhard},
  year = {2019},
  month = apr,
  volume = {9},
  pages = {e01263},
  issn = {2162-3279, 2162-3279},
  doi = {10.1002/brb3.1263},
  abstract = {Introduction: Brain processes of working memory involve oscillatory activities at multiple frequencies in local and long-range neural networks. The current study addressed the specific roles of alpha oscillations during memory encoding and retention, supporting the hypothesis that multiple functional mechanisms of alpha oscillations exist in parallel. Method: We recorded magnetoencephalography (MEG) in 25 healthy young adults, who performed a variant of a Sternberg working memory task. A sequential list of five consonant letters was visually presented and was followed after a 2.0 s retention interval by a probe of a pair of two letters from the study list. Participants responded whether the probe pair was in same or reversed order in the list. Result: Reaction time (RT) was shortest for the first letters in the list, increased with increasing serial position, and shorter for the last position. RT was substantially longer for the probe in reversed order. Time-frequency analysis of the MEG revealed event-related desynchronization (ERD) of alpha oscillations during the encoding interval and an alpha power increase (ERS) during memory retention. Alpha ERD during encoding occurred at 10 Hz and ERS during retention at 12 Hz, suggesting different alpha mechanisms. Analysis of alpha coherence and alpha-gamma cross-spectral coupling, applied to MEG beamformer source activity, revealed connectivity across brain areas. Additionally, alpha-gamma coupling identified centers of local computation. The connectivity between occipital and frontotemporal areas was correlated with alpha ERS during memory retention. Cross-frequency coupling between alpha phase and gamma amplitude depicted a hierarchy of information flow from frontal to temporal and occipital brain areas. Conclusion: Alpha decrease during encoding indicates an active state of visual processing, while subsequent ERS indicates inhibition of further visual input for protecting the memory, and phasic timing of temporal and occipital gamma oscillations is related to a long-range working memory networks.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\J5AEY6A2\\Wianda and Ross - 2019 - The roles of alpha oscillation in working memory r.pdf},
  journal = {Brain and Behavior},
  language = {en},
  number = {4}
}

@article{wiecki_frank_2013,
  title = {A Computational Model of Inhibitory Control in Frontal Cortex and Basal Ganglia.},
  author = {Wiecki, Thomas V and Frank, Michael J},
  year = {2013},
  volume = {120},
  pages = {329--355},
  issn = {1939-1471},
  doi = {10.1037/a0031542},
  abstract = {Planning and executing volitional actions in the face of conflicting habitual responses is a critical aspect of human behavior. At the core of the interplay between these 2 control systems lies an override mechanism that can suppress the habitual action selection process and allow executive control to take over. Here, we construct a neural circuit model informed by behavioral and electrophysiological data collected on various response inhibition paradigms. This model extends a well-established model of action selection in the basal ganglia by including a frontal executive control network that integrates information about sensory input and task rules to facilitate well-informed decision making via the oculomotor system. Our simulations of the anti-saccade, Simon, and saccade-override tasks ensue in conflict between a prepotent and controlled response that causes the network to pause action selection via projections to the subthalamic nucleus. Our model reproduces key behavioral and electrophysiological patterns and their sensitivity to lesions and pharmacological manipulations. Finally, we show how this network can be extended to include the inferior frontal cortex to simulate key qualitative patterns of global response inhibition demands as required in the stop-signal task.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HT4AXT7M\\Wiecki, Frank - 2013 - A computational model of inhibitory control in frontal cortex and basal ganglia.pdf},
  journal = {Psychol Rev},
  keywords = {Animals,basal ganglia,Basal Ganglia/*physiology,before you act,before you react,before you spend,before your criticize,cognitive control,Computer Simulation,Decision Making/physiology,doi,dx,earn,Electrophysiological Phenomena,Executive Function/*physiology,http,Humans,listen,neural network model,Neurological,Neuropsychological Tests,Neurotransmitter Agents/physiology,org,prefrontal cortex,Prefrontal Cortex/*physiology,Reaction Time/physiology,response inhibition,Saccades/physiology,supp,supplemental materials,think,Time Factors},
  number = {2},
  pmid = {23586447}
}

@article{wiecki_frank_2013a,
  title = {{{HDDM}}: {{Hierarchical Bayesian}} Estimation of the {{Drift}}-{{Diffusion Model}} in {{Python}}},
  author = {Wiecki, Thomas V and Sofer, Imri and Frank, Michael J},
  year = {2013},
  volume = {7},
  issn = {1662-5196},
  doi = {10.3389/fninf.2013.00014},
  abstract = {The diffusion model is a commonly used tool to infer latent psychological processes underlying decision-making, and to link them to neural mechanisms based on response times. Although efficient open source software has been made available to quantitatively fit the model to data, current estimation methods require an abundance of response time measurements to recover meaningful parameters, and only provide point estimates of each parameter. In contrast, hierarchical Bayesian parameter estimation methods are useful for enhancing statistical power, allowing for simultaneous estimation of individual subject parameters and the group distribution that they are drawn from, while also providing measures of uncertainty in these parameters in the posterior distribution. Here, we present a novel Python-based toolbox called HDDM (hierarchical drift diffusion model), which allows fast and flexible estimation of the the drift-diffusion model and the related linear ballistic accumulator model. HDDM requires fewer data per subject/condition than non-hierarchical methods, allows for full Bayesian data analysis, and can handle outliers in the data. Finally, HDDM supports the estimation of how trial-by-trial measurements (e.g., fMRI) influence decision-making parameters. This paper will first describe the theoretical background of the drift diffusion model and Bayesian inference. We then illustrate usage of the toolbox on a real-world data set from our lab. Finally, parameter recovery studies show that HDDM beats alternative fitting methods like the {$\chi$}(2)-quantile method as well as maximum likelihood estimation. The software and documentation can be downloaded at: http://ski.clps.brown.edu/hddm\_docs/},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2RZXH9S3\\Wiecki, Sofer, Frank - 2013 - HDDM Hierarchical Bayesian estimation of the Drift-Diffusion Model in Python.pdf},
  journal = {Frontiers in Neuroinformatics},
  keywords = {Bayesian modeling,decision-making,drift diffusion model,Python,software},
  pmid = {23935581}
}

@article{wijeakumar_curtu_2017,
  title = {Model-Based Functional Neuroimaging Using Dynamic Neural Fields: {{An}} Integrative Cognitive Neuroscience Approach},
  author = {Wijeakumar, Sobanawartiny and Ambrose, Joseph P. and Spencer, John P. and Curtu, Rodica},
  year = {2017},
  volume = {76},
  pages = {212--235},
  issn = {10960880},
  doi = {10.1016/j.jmp.2016.11.002},
  abstract = {A fundamental challenge in cognitive neuroscience is to develop theoretical frameworks that effectively span the gap between brain and behavior, between neuroscience and psychology. Here, we attempt to bridge this divide by formalizing an integrative cognitive neuroscience approach using dynamic field theory (DFT). We begin by providing an overview of how DFT seeks to understand the neural population dynamics that underlie cognitive processes through previous applications and comparisons to other modeling approaches. We then use previously published behavioral and neural data from a response selection Go/Nogo task as a case study for model simulations. Results from this study served as the `standard' for comparisons with a model-based fMRI approach using dynamic neural fields (DNF). The tutorial explains the rationale and hypotheses involved in the process of creating the DNF architecture and fitting model parameters. Two DNF models, with similar structure and parameter sets, are then compared. Both models effectively simulated reaction times from the task as we varied the number of stimulus\textendash response mappings and the proportion of Go trials. Next, we directly simulated hemodynamic predictions from the neural activation patterns from each model. These predictions were tested using general linear models (GLMs). Results showed that the DNF model that was created by tuning parameters to capture simultaneously trends in neural activation and behavioral data quantitatively outperformed a Standard GLM analysis of the same dataset. Further, by using the GLM results to assign functional roles to particular clusters in the brain, we illustrate how DNF models shed new light on the neural populations' dynamics within particular brain regions. Thus, the present study illustrates how an interactive cognitive neuroscience model can be used in practice to bridge the gap between brain and behavior.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FCSNTL7J\\Wijeakumar et al. - 2017 - Model-based functional neuroimaging using dynamic neural fields An integrative cognitive neuroscience approac.pdf},
  journal = {Journal of Mathematical Psychology},
  keywords = {Dynamic field theory modeling,Functional magnetic resonance imaging,Integrative cognitive neuroscience,Response selection}
}

@techreport{wijngaarden_ito_2019,
  title = {Representation of {{Distance}} and {{Direction}} of {{Nearby Boundaries}} in {{Retrosplenial Cortex}}},
  author = {van Wijngaarden, Joeri B.G. and Babl, Susanne S. and Ito, Hiroshi T.},
  year = {2019},
  month = oct,
  institution = {{Neuroscience}},
  doi = {10.1101/807453},
  abstract = {Abstract           Borders and edges are salient and behaviourally relevant features for navigating the environment. The brain forms dedicated neural representations of environmental boundaries, which are assumed to serve as a reference for spatial coding. Here we expand this border coding network to include the retrosplenial cortex (RSC) in which we identified neurons that increase their firing near all boundaries of an arena. RSC border cells specifically encode walls, but not objects, and maintain their tuning in the absence of direct sensory detection. Unlike border cells in the medial entorhinal cortex (MEC), RSC border cells are sensitive to the animal's direction to nearby walls located contralateral to the recorded hemisphere. Pharmacogenetic inactivation of MEC led to a disruption of RSC border coding, but not vice versa, indicating network directionality. Together these data shed light on how information about distance and direction of boundaries is generated in the brain for guiding navigation behaviour.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Y2KENXI4\\Wijngaarden et al. - 2019 - Representation of Distance and Direction of Nearby.pdf},
  language = {en},
  type = {Preprint}
}

@article{wikenheiser_redish_2015,
  title = {Hippocampal Theta Sequences Reflect Current Goals},
  author = {Wikenheiser, Andrew M and Redish, a David},
  year = {2015},
  volume = {18},
  doi = {10.1038/nn.3909},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4NV2HE3Y\\Wikenheiser, Redish - 2015 - Hippocampal theta sequences reflect current goals.pdf},
  journal = {Nature Neuroscience},
  number = {2}
}

@book{wikipedia_wikipedia_2010,
  title = {Functional Integration},
  author = {Wikipedia, From},
  year = {2010},
  publisher = {{Elsevier Inc.}},
  doi = {10.1016/B978-0-12-372560-8.50036-X},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WBNQZVUB\\Wikipedia - 2010 - Functional integration.pdf},
  isbn = {981-238-107-4}
}

@article{wilber_mcnaughton_2014,
  title = {Interaction of {{Egocentric}} and {{World}}-{{Centered Reference Frames}} in the {{Rat Posterior Parietal Cortex}}},
  author = {Wilber, A A and Clark, B J and Forster, T C and Tatsuno, M and McNaughton, B L},
  year = {2014},
  volume = {34},
  pages = {5431--5446},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.0511-14.2014},
  abstract = {Navigation requires coordination of egocentric and allocentric spatial reference frames and may involve vectorial computations relative to landmarks. Creation of a representation of target heading relative to landmarks could be accomplished from neurons that encode the conjunction of egocentric landmark bearings with allocentric head direction. Landmark vector representations could then be created by combining these cells with distance encoding cells. Landmark vector cells have been identified in rodent hippocampus. Given remembered vectors at goal locations, it would be possible to use such cells to compute trajectories to hidden goals. To look for the first stage in this process, we assessed parietal cortical neural activity as a function of egocentric cue light location and allocentric head direction in rats running a random sequence to light locations around a circular platform. We identified cells that exhibit the predicted egocentric-by-allocentric conjunctive characteristics and anticipate orienting toward the goal.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DM4M5CYT\\Wilber et al. - 2014 - Interaction of Egocentric and World-Centered Reference Frames in the Rat Posterior Parietal Cortex(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\J6KZNAYY\\Wilber et al. - 2014 - Interaction of Egocentric and World-Centered Reference Frames in the Rat Posterior Parietal Cortex(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\NLSLIUCM\\Wilber et al. - 2014 - Interaction of Egocentric and World-Centered Refer.pdf},
  journal = {Journal of Neuroscience},
  keywords = {allocentric,head direction,landmark navigation,posterior parietal cortex,spatial navigation,spatial orientation},
  number = {16},
  pmid = {24741034}
}

@article{wilber_mcnaughton_2017,
  title = {Laminar {{Organization}} of {{Encoding}} and {{Memory Reactivation}} in the {{Parietal Cortex}}},
  author = {Wilber, Aaron A. and Skelin, Ivan and Wu, Wei and McNaughton, Bruce L.},
  year = {2017},
  volume = {95},
  pages = {1406--1419.e5},
  issn = {10974199},
  doi = {10.1016/j.neuron.2017.08.033},
  abstract = {Egocentric neural coding has been observed in parietal cortex (PC), but its topographical and laminar organization is not well characterized. We used multi-site recording to look for evidence of local clustering and laminar consistency of linear and angular velocity encoding in multi-neuronal spiking activity (MUA) and in the high-frequency (300\textendash 900 Hz) component of the local field potential (HF-LFP), believed to reflect local spiking activity. Rats were trained to run many trials on a large circular platform, either to LED-cued goal locations or as a spatial sequence from memory. Tuning to specific self-motion states was observed and exhibited distinct cortical depth-invariant coding properties. These patterns of collective local and laminar activation during behavior were reactivated in compressed form during post-experience sleep and temporally coupled to cortical delta waves and hippocampal sharp-wave ripples. Thus, PC neuron motion encoding is consistent across cortical laminae, and this consistency is maintained during memory reactivation. Wilber, Skelin, et al. use multi-site recordings to demonstrate tuning across large populations of cells organized into modules encoding specific movements in parietal cortex. Activity patterns were shown to reactivate during post-experience sleep and were temporally coupled to hippocampal reactivation.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7RWBYCEA\\Wilber et al. - 2017 - Laminar Organization of Encoding and Memory Reactivation in the Parietal Cortex.pdf},
  journal = {Neuron},
  keywords = {delta wave,high-frequency local field potential,hippocampus,memory reactivation,modular organization,movement decoding,multi-unit activity,parietal cortex,posterior parietal cortex,template matching},
  number = {6},
  pmid = {28910623}
}

@article{wilhelm_oberauer_2013,
  title = {What Is Working Memory Capacity, and How Can We Measure It?},
  author = {Wilhelm, Oliver and Hildebrandt, Andrea and Oberauer, Klaus},
  year = {2013},
  volume = {4},
  pages = {1--22},
  issn = {16641078},
  doi = {10.3389/fpsyg.2013.00433},
  abstract = {A latent variable study examined whether different classes of working-memory tasks measure the same general construct of working-memory capacity (WMC). Data from 270 subjects were used to examine the relationship between Binding, Updating, Recall-N-back, and Complex Span tasks, and the relations of WMC with secondary memory measures, indicators of cognitive control from two response-conflict paradigms (Simon task and Eriksen flanker task), and fluid intelligence. Confirmatory factor analyses support the concept of a general WMC factor. Results from structural-equation modeling show negligible relations of WMC with response-conflict resolution, and very strong relations of WMC with secondary memory and fluid intelligence. The findings support the hypothesis that individual differences in WMC reflect the ability to build, maintain and update arbitrary bindings.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FJHMB4VL\\Wilhelm, Hildebrandt, Oberauer - 2013 - What is working memory capacity, and how can we measure it.pdf},
  journal = {Frontiers in Psychology},
  keywords = {Binding,Cognitive control,Fluid intelligence,Secondary memory,working-memory},
  number = {JUL},
  pmid = {23898309}
}

@article{wilmes_clopath_2019,
  title = {Inhibitory Microcircuits for Top-down Plasticity of Sensory Representations},
  author = {Wilmes, Katharina Anna and Clopath, Claudia},
  year = {2019},
  month = dec,
  volume = {10},
  pages = {5055},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-12972-2},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4PIECG7U\\Wilmes and Clopath - 2019 - Inhibitory microcircuits for top-down plasticity o.pdf},
  journal = {Nature Communications},
  language = {en},
  number = {1}
}

@article{wilson_collins_2019,
  title = {Ten Simple Rules for the Computational Modeling of Behavioral Data},
  author = {Wilson, Robert C and Collins, Anne Ge},
  year = {2019},
  pages = {1--35},
  doi = {10.31234/OSF.IO/46MBN},
  abstract = {Computational modeling of behavioral data has revolutionized psychology and neuroscience. By fitting models to experimental data we can probe the algorithms underlying behavior, find neural correlates of computational variables and more precisely understand the effects of drugs, illness and interventions. But with great power comes great responsibility. In this note we give ten simple rules to ensure that computational modeling is used with care. What is the computational modeling of behavioral data? The goal of computational modeling in behavioral science is to use precise mathematical models to make better sense of behavioral data. The behavioral data most often come in the form of choices, but can also be reaction times, eye movements, or other easily observable behaviors. The models come in the form of mathematical equations that link the experimentally observable variables (e.g. stimuli, outcomes, past experiences) to behavior in the immediate future. In this sense, computational models instantiate different 'algorithmic hypotheses' about how behavior is generated. Exactly what it means to 'make sense' of behavioral data is, to some extent, a matter of taste that will vary according to the researcher's goals (Kording, Blohm, Schrater, \& Kay, 2018). In some cases, a simple model that can explain broad qualitative features of the 1},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6UBNSSFP\\Wilson, Collins - 2019 - Ten simple rules for the computational modeling of behavioral data.pdf}
}

@article{wilson_phillips_1983,
  title = {Spatial Frequency Tuning of Orientation Selective Units Estimated by Oblique Masking},
  author = {Wilson, Hugh R and Mcfarlane, David K and Phillips, Gregory C},
  year = {1983},
  volume = {23},
  pages = {873--882},
  issn = {00426989},
  doi = {10.1016/0042-6989(83)90055-X},
  abstract = {Threshold elevations were measured as a function of the spatial frequency of high contrast cosine masks using spatially localized test stimuli with a 1.0 octave bandwidth. The cosine masks were oriented at 14.5?? relative to the vertical test patterns in order to average out spatial phase effects. The experiment was repeated for each of 14 test frequencies spanning the range 0.25-22.0 c/deg in 0.5 octave steps. The resulting threshold elevation curves fell into a small number of distinct groups, suggesting the existence of discrete spatial frequency mechanisms in human central vision. The data are shown to be consistent with a model having just six distinct classes of spatial frequency mechanisms in the fovea. Spatial frequency bandwidths of these mechanisms ranged from 2.5 octaves at low frequencies to as narrow as 1.25 octaves at high spatial frequencies. These results require revision of the Wilson and Bergen (1979) [Vision Res. 19, 19-32] model for spatial vision. ?? 1983.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BCZ59BBM\\Wilson, Mcfarlane, Phillips - 1983 - Spatial frequency tuning of orientation selective units estimated by oblique masking.pdf},
  journal = {Vision Research},
  keywords = {Bandwidths,Masking,Nonlinearities,Orientation,Spatial frequency},
  number = {9},
  pmid = {6636547}
}

@article{wilson_sur_2012,
  title = {Division and Subtraction by Distinct Cortical Inhibitory Networks in Vivo.},
  author = {Wilson, Nathan R and a Runyan, Caroline and Wang, Forea L and Sur, Mriganka},
  year = {2012},
  month = aug,
  volume = {488},
  pages = {343--348},
  issn = {1476-4687},
  doi = {10.1038/nature11347},
  abstract = {Brain circuits process information through specialized neuronal subclasses interacting within a network. Revealing their interplay requires activating specific cells while monitoring others in a functioning circuit. Here we use a new platform for two-way light-based circuit interrogation in visual cortex in vivo to show the computational implications of modulating different subclasses of inhibitory neurons during sensory processing. We find that soma-targeting, parvalbumin-expressing (PV) neurons principally divide responses but preserve stimulus selectivity, whereas dendrite-targeting, somatostatin-expressing (SOM) neurons principally subtract from excitatory responses and sharpen selectivity. Visualized in vivo cell-attached recordings show that division by PV neurons alters response gain, whereas subtraction by SOM neurons shifts response levels. Finally, stimulating identified neurons while scanning many target cells reveals that single PV and SOM neurons functionally impact only specific subsets of neurons in their projection fields. These findings provide direct evidence that inhibitory neuronal subclasses have distinct and complementary roles in cortical computations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DV25BRPC\\Wilson et al. - 2012 - Division and subtraction by distinct cortical inhibitory networks in vivo.pdf},
  journal = {Nature},
  keywords = {Animals,Dendrites,Dendrites: metabolism,Electrophysiology,Interneurons,Interneurons: physiology,Mice,Models,Neural Inhibition,Neural Inhibition: physiology,Neural Pathways,Neural Pathways: physiology,Neurological,Neurons,Neurons: physiology,Parvalbumins,Parvalbumins: metabolism,Somatostatin,Somatostatin: metabolism,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology},
  number = {7411},
  pmid = {22878717}
}

@techreport{wilting_priesemann_2018,
  title = {Dynamic {{Adaptive Computation}}: {{Tuning}} Network States to Task Requirements},
  author = {Wilting, Jens and Dehning, Jonas and Neto, Joao Pinheiro and Rudelt, Lucas and Wibral, Michael and Zierenberg, Johannes and Priesemann, Viola},
  year = {2018},
  abstract = {Neural circuits are able to perform computations under very diverse conditions and requirements. The required computations impose clear constraints on their fine-tuning: a rapid and maximally informative response to stimuli in general requires decorrelated baseline neural activity. Such network dynamics is known as asynchronous-irregular. In contrast, spatio-temporal integration of information requires maintenance and transfer of stimulus information over extended time periods. This can be realized at criticality, a phase transition where correlations, sensitivity and integration time diverge. Being able to flexibly switch, or even combine the above properties in a task-dependent manner would present a clear functional advantage. We propose that cortex operates in a reverberating regime because it is particularly favorable for ready adaptation of computational properties to context and task. This reverberating regime enables cortical networks to interpolate between the asynchronous-irregular and the critical state by small changes in effective synaptic strength or excitation-inhibition ratio. These changes directly adapt computational properties, including sensitivity, amplification, integration time and correlation length within the local network. We review recent converging evidence that cortex in vivo operates in the reverberating regime, and that various cortical areas have adapted their integration times to processing requirements. In addition, we propose that neuromodulation enables a fine-tuning of the network, so that local circuits can either decorrelate or integrate, and quench or maintain their input depending on task. We argue that this task-dependent tuning, which we call "dynamic adaptive computation", presents a central organization principle of cortical networks and discuss first experimental evidence. Cortical networks are confronted with ever-changing conditions, whether these are imposed on them by a natural environment, or induced by the actions of the subjects themselves. For example, when a predator is lurking for a prey it should detect the smallest movement in the bushes anywhere in the visual field, but as soon as the prey is in full view and the predator moves to strike, visual attention should focus on the prey (Fig. 1A). Optimal adaptation for these changing tasks requires a precise and flexible adjustment of input amplification and other properties within the local, specialized circuits of primary visual cortex: strong amplification of small input while lurking, but quenching of any irrelevant input when chasing. These are changes from one task to another. However, even the processing within a single task may require the joint contributions of networks with diverse computational properties. For example, listening to spoken language involves the integration of phonemes at the timescale of milliseconds to words and whole sentences lasting for seconds. Such temporal integration might be realized by a hierarchy of temporal receptive fields, a prime example of adaption to different processing requirements of each brain area [1, 2, Fig. 1B]. Basic network properties like sensitivity, amplification, and integration timescale optimize different aspects of computation, and hence a generic input-output relation can be used to infer signatures of the computational properties, and changes thereof [3, 4]. Throughout this manuscript, we refer to computation capability in the following two, high-level senses. First, the integration timescale determines the capability to process sequential stimuli. If small inputs are quenched away rapidly, the network may quickly be ready to process the next input. In contrast, networks that maintain input for long timescales may be slow at responding to novel input, but instead they can integrate information and input over extended time periods [5, 6, 7, 8]. This is at the heart of reservoir computing in echo state networks or liquid state machines [9, 10, 11, 12, 13, 5]. Second, the detection of small stimuli relies on a sufficient amplification [14]. However, increased sensitivity to weak stimuli can lead to increased trial-to-trial variability [15].},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PHPNTPM2\\Wilting et al. - 2018 - Dynamic Adaptive Computation Tuning network states to task requirements.pdf}
}

@article{winter_taube_2015,
  title = {Passive {{Transport Disrupts Grid Signals}} in the {{Parahippocampal Cortex}}},
  author = {Winter, Shawn S and Mehlman, Max L and Clark, Benjamin J and Taube, Jeffrey S},
  year = {2015},
  issn = {09609822},
  doi = {10.1016/j.cub.2015.08.034},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UTTQCX25\\Winter et al. - 2015 - Passive Transport Disrupts Grid Signals in the Parahippocampal Cortex.pdf},
  journal = {Current Biology},
  number = {September}
}

@article{wiskott_sejnowski_2002,
  title = {Slow {{Feature Analysis}}: {{Unsupervised Learning}} of {{Invariances}}},
  author = {Wiskott, Laurenz and Sejnowski, Terrence J},
  year = {2002},
  volume = {14},
  pages = {715--770},
  issn = {0899-7667},
  doi = {10.1162/089976602317318938},
  abstract = {Invariant features of temporally varying signals are useful for analysis and classification. Slow feature analysis (SFA) is a new method for learning invariant or slowly varying features from a vectorial input signal. It is based on a nonlinear expansion of the input signal and application of principal component analysis to this expanded signal and its time derivative. It is guaranteed to find the optimal solution within a family of functions directly and can learn to extract a large number of decorrelated features, which are ordered by their degree of invariance. SFA can be applied hierarchically to process high-dimensional input signals and extract complex features. SFA is applied first to complex cell tuning properties based on simple cell output, including disparity and motion. Then more complicated input-output functions are learned by repeated application of SFA. Finally, a hierarchical network of SFA modules is presented as a simple model of the visual system. The same unstructured network can learn translation, size, rotation, contrast, or, to a lesser degree, illumination invariance for one-dimensional objects, depending on only the training stimulus. Surprisingly, only a few training objects suffice to achieve good generalization to new objects. The generated representation is suitable for object recognition. Performance degrades if the network is trained to learn multiple invariances simultaneously.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\YD4LAU94\\Wiskott, Sejnowski - 2002 - Slow Feature Analysis Unsupervised Learning of Invariances.pdf},
  journal = {Neural Computation},
  number = {4},
  pmid = {11936959}
}

@article{wittenberg_wang_2006,
  title = {Malleability of {{Spike}}-{{Timing}}-{{Dependent Plasticity}} at the {{CA3}}-{{CA1 Synapse}}},
  author = {Wittenberg, G. M. and Wang, S. S.- H.},
  year = {2006},
  month = jun,
  volume = {26},
  pages = {6610--6617},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.5388-05.2006},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4TCUADL6\\Wittenberg and Wang - 2006 - Malleability of Spike-Timing-Dependent Plasticity .pdf},
  journal = {Journal of Neuroscience},
  language = {en},
  number = {24}
}

@article{wixted_mickes_2014,
  title = {A Signal-Detection-Based Diagnostic-Feature-Detection Model of Eyewitness Identification.},
  author = {Wixted, John T and Mickes, Laura},
  year = {2014},
  volume = {121},
  pages = {262--276},
  issn = {1939-1471},
  doi = {10.1037/a0035940},
  abstract = {The theoretical understanding of eyewitness identifications made from a police lineup has long been guided by the distinction between absolute and relative decision strategies. In addition, the accuracy of identifications associated with different eyewitness memory procedures has long been evaluated using measures like the diagnosticity ratio (the correct identification rate divided by the false identification rate). Framed in terms of signal-detection theory, both the absolute/relative distinction and the diagnosticity ratio are mainly relevant to response bias while remaining silent about the key issue of diagnostic accuracy, or discriminability (i.e., the ability to tell the difference between innocent and guilty suspects in a lineup). Here, we propose a signal-detection-based model of eyewitness identification, one that encourages the use of (and helps to conceptualize) receiver operating characteristic (ROC) analysis to measure discriminability. Recent ROC analyses indicate that the simultaneous presentation of faces in a lineup yields higher discriminability than the presentation of faces in isolation, and we propose a diagnostic feature-detection hypothesis to account for that result. According to this hypothesis, the simultaneous presentation of faces allows the eyewitness to appreciate that certain facial features (viz., those that are shared by everyone in the lineup) are non-diagnostic of guilt. To the extent that those non-diagnostic features are discounted in favor of potentially more diagnostic features, the ability to discriminate innocent from guilty suspects will be enhanced.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\22J5F98A\\Wixted, Mickes - 2014 - A signal-detection-based diagnostic-feature-detection model of eyewitness identification.pdf},
  journal = {Psychological review},
  keywords = {confidence and accuracy,eyewitness memory,roc analysis,signal-detection theory},
  number = {2},
  pmid = {24730600}
}

@article{wolfe_kenner_2005,
  title = {Rare Items Often Missed in Visual Searches},
  author = {Wolfe, Jeremy M. and Horowitz, Todd S. and Kenner, Naomi M.},
  year = {2005},
  month = may,
  volume = {435},
  pages = {439--440},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/435439a},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4KTCKLP7\\Wolfe et al. - 2005 - Rare items often missed in visual searches.pdf},
  journal = {Nature},
  language = {en},
  number = {7041}
}

@article{wolff_stokes_2017,
  title = {Dynamic Hidden States Underlying Working-Memory-Guided Behavior},
  author = {Wolff, Michael J and Jochim, Janina and Aky{\"u}rek, Elkan G and Stokes, Mark G},
  year = {2017},
  volume = {20},
  doi = {10.1038/nn.4546},
  abstract = {nature neurOSCIenCe a r t I C l e S Working memory (WM) is a core cognitive function critical for flexible , intelligent behavior 1. Until recently, it was widely assumed that information is maintained in WM by maintaining specific activity states that represent the specific memoranda 2,3. However, accumulating evidence increasingly shows that successful maintenance in WM is not strictly dependent on an unbroken chain of corresponding delay activity 4 and that item-specific activity states could reflect other cog-nitive processes. For example, in monkey studies, persistent activity ramps up with expectation of the probe 5-8. Similarly, in humans, it has been shown that unattended WM content is not reflected in the neural signal, even when it is still clearly maintained 9-11. Evidence for WM in the absence of persistent delay activity suggests that WM can be maintained in activity-silent neural states 4. Recent theories acknowledge that brain activity is highly dynamic, even when the contents of working memory remain stable 12. Multiple neurophysiological mechanisms could underlie such dynamics 13-15. According to a dynamic coding model of WM 4 , behaviorally relevant sensory input drives a memory-item-specific neural response, which triggers an item-specific change in the functional state of the system. Depending on the precise neural mechanism, this functional state could be activity-silent (for example, short-term synaptic plasticity 14,16-19) and maintained throughout the memory delay to serve as the neural context for subsequent processing. Items in WM would be read out via the context-dependent response to a probe stimulus during recall 13,20. Crucially, this model predicts that dynamic hidden states are constructed when new information is encoded and dissolved as soon as it is forgotten. This model also predicts that dynamic hidden states should determine the quality of a representation maintained in WM. To probe hidden neural states, we developed a functional perturbation approach to 'ping' the brain. Analogously to the use of active sonar (or echolocation), the response to a well-characterized impulse stimulus can be used to infer the current state of the system 4,13. We recently validated this general approach using noninvasive electro-encephalography (EEG) in a proof-of-principle study 21. The presentation of a high-contrast neutral visual stimulus evoked neural activity that clearly discriminated the previously presented visual stimulus. Here we exploit this approach to track the functional dynamics of hidden states for WM. Across two experiments, we showed that the content of WM could be decoded from the impulse response during the maintenance interval, while forgotten information left effectively no trace. In Experiment 2, we demonstrated robust hidden-state representations for unattended content in WM, providing a plausible mechanism for maintenance that is independent of the activity associated with the focus of attention. Finally, we also found evidence that the quality of working memory varied with the decodability of these hidden states. RESULTS Experiment 1 In Experiment 1, 30 human participants performed a visual WM task while EEG was recorded. At the beginning of each trial (Fig. 1a), two memory items were presented, but a retrospective cue (retro-cue) presented during the delay instructed participants which item would actually be probed 22,23. The other item could be simply forgotten. The retro-cue in this design was essential to differentiate WM from basic stimulation history 24. During a subsequent memory delay, we then presented a high-contrast 'impulse' stimulus. Memory performance for the cued item was tested after the impulse by a centrally presented memory probe (Fig. 1b). Time-frequency decomposition of lateralized activity in posterior sensors (Fig. 1c) showed significant lateralization Recent theoretical models propose that working memory is mediated by rapid transitions in 'activity-silent' neural states (for example, short-term synaptic plasticity). According to the dynamic coding framework, such hidden state transitions flexibly configure memory networks for memory-guided behavior and dissolve them equally fast to allow forgetting. We developed a perturbation approach to measure mnemonic hidden states in an electroencephalogram. By 'pinging' the brain during maintenance, we show that memory-item-specific information is decodable from the impulse response, even in the absence of attention and lingering delay activity. Moreover, hidden memories are remarkably flexible: an instruction cue that directs people to forget one item is sufficient to wipe the corresponding trace from the hidden state. In contrast, temporarily unattended items remain robustly coded in the hidden state, decoupling attentional focus from cue-directed forgetting. Finally, the strength of hidden-state coding predicts the accuracy of working-memory-guided behavior, including memory precision.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\C3W8TQZM\\Wolff et al. - 2017 - Dynamic hidden states underlying working-memory-guided behavior.pdf},
  number = {6}
}

@article{wolff_vann_2018,
  title = {The {{Cognitive Thalamus}} as a Gateway to Mental Representations},
  author = {Wolff, Mathieu and Vann, Seralynne D},
  year = {2018},
  doi = {10.1523/JNEUROSCI.0479-18.2018},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PVENZ77E\\Wolff, Vann - 2018 - The Cognitive Thalamus as a gateway to mental representations.pdf},
  journal = {Cite as: J. Neurosci},
  keywords = {important}
}

@article{womelsdorf_everling_2010,
  title = {Selective {{Theta}}-{{Synchronization}} of {{Choice}}-{{Relevant Information Subserves Goal}}-{{Directed Behavior}}},
  author = {Womelsdorf, Thilo and Vinck, Martin and Leung, L Stan and Everling, Stefan},
  year = {2010},
  volume = {4},
  pages = {1--13},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2010.00210},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5TW4K6IJ\\Womelsdorf et al. - 2010 - Selective Theta-Synchronization of Choice-Relevant Information Subserves Goal-Directed Behavior.pdf},
  journal = {Frontiers in Human Neuroscience},
  keywords = {cognitive control,decision making,oscillation,reinforcement learning,theta synchronization},
  number = {November}
}

@article{wong_versace_2012,
  title = {{{CARTMAP}}: A Neural Network Method for Automated Feature Selection in Financial Time Series Forecasting},
  author = {Wong, Charles and Versace, Massimiliano},
  year = {2012},
  month = jan,
  volume = {21},
  pages = {969--977},
  issn = {0941-0643},
  doi = {10.1007/s00521-012-0830-8},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IWAVKVSF\\Wong, Versace - 2012 - CARTMAP a neural network method for automated feature selection in financial time series forecasting.pdf},
  journal = {Neural Computing and Applications},
  number = {5}
}

@article{wu_wu_2018,
  title = {Improved {{Expressivity Through Dendritic Neural Networks}}},
  author = {Wu, Xundong},
  year = {2018},
  abstract = {A typical biological neuron, such as a pyramidal neuron of the neocortex, receives thousands of afferent synaptic inputs on its dendrite tree and sends the efferent axonal output downstream. In typical artificial neural networks, dendrite trees are modeled as linear structures that funnel weighted synaptic inputs to the cell bodies. However, numerous experimental and theoretical studies have shown that dendritic arbors are far more than simple linear accumulators. That is, synaptic inputs can actively modulate their neighboring synaptic activities; therefore, the dendritic structures are highly nonlinear. In this study, we model such local nonlinearity of dendritic trees with our dendritic neural network (DENN) structure and apply this structure to typical machine learning tasks. Equipped with localized nonlinearities, DENNs can attain greater model expressivity than regular neural networks while maintaining efficient network inference. Such strength is evidenced by the increased fitting power when we train DENNs with supervised machine learning tasks. We also empirically show that the locality structure can improve the generalization performance of DENNs, as exemplified by DENNs outranking naive deep neural network architectures when tested on 121 classification tasks from the UCI machine learning repository.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SA4N2Q45\\Wu et al. - Unknown - Improved Expressivity Through Dendritic Neural Networks.pdf},
  number = {Nips}
}

@article{wu_yu_2019,
  title = {A {{Comprehensive Survey}} on {{Graph Neural Networks}}},
  author = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
  year = {2019},
  month = jan,
  abstract = {Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this survey, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art graph neural networks into four categories, namely recurrent graph neural networks, convolutional graph neural networks, graph autoencoders and spatial-temporal graph neural networks. We further discuss the applications of graph neural networks across various domains and summarize the open source codes and benchmarks of the existing algorithms on different learning tasks. Finally, we propose potential research directions in this rapidly growing field.},
  archivePrefix = {arXiv},
  eprint = {1901.00596},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6SEYMPAR\\Wu_et_al_2019_A_Comprehensive_Survey_on_Graph_Neural_Networks.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\A79PP8FP\\1901.html},
  journal = {arXiv:1901.00596 [cs, stat]},
  primaryClass = {cs, stat}
}

@article{wutz_miller_2018,
  title = {Different {{Levels}} of {{Category Abstraction}} by {{Different Dynamics}} in {{Different Prefrontal Areas}}},
  author = {Wutz, Andreas and Loonis, Roman and Roy, Jefferson E. and Donoghue, Jacob A. and Miller, Earl K},
  year = {2018},
  volume = {97},
  pages = {716--726.e8},
  issn = {08966273},
  doi = {10.1016/j.neuron.2018.01.009},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\D8UWBJ7X\\Wutz et al. - 2018 - Different Levels of Category Abstraction by Different Dynamics in Different Prefrontal Areas(2).pdf;C\:\\Users\\wchapman\\Zotero\\storage\\D8WTMZAN\\Wutz et al. - 2018 - Different Levels of Category Abstraction by Different Dynamics in Different Prefrontal Areas.pdf},
  journal = {Neuron},
  number = {3},
  pmid = {29395915}
}

@article{wutz_samaha_2018,
  title = {Frequency Modulation of Neural Oscillations According to Visual Task Demands.},
  author = {Wutz, Andreas and Melcher, David and Samaha, Jason},
  year = {2018},
  volume = {115},
  pages = {1346--1351},
  issn = {1091-6490},
  doi = {10.1073/pnas.1713318115},
  abstract = {Temporal integration in visual perception is thought to occur within cycles of occipital alpha-band (8-12 Hz) oscillations. Successive stimuli may be integrated when they fall within the same alpha cycle and segregated for different alpha cycles. Consequently, the speed of alpha oscillations correlates with the temporal resolution of perception, such that lower alpha frequencies provide longer time windows for perceptual integration and higher alpha frequencies correspond to faster sampling and segregation. Can the brain's rhythmic activity be dynamically controlled to adjust its processing speed according to different visual task demands? We recorded magnetoencephalography (MEG) while participants switched between task instructions for temporal integration and segregation, holding stimuli and task difficulty constant. We found that the peak frequency of alpha oscillations decreased when visual task demands required temporal integration compared with segregation. Alpha frequency was strategically modulated immediately before and during stimulus processing, suggesting a preparatory top-down source of modulation. Its neural generators were located in occipital and inferotemporal cortex. The frequency modulation was specific to alpha oscillations and did not occur in the delta (1-3 Hz), theta (3-7 Hz), beta (15-30 Hz), or gamma (30-50 Hz) frequency range. These results show that alpha frequency is under top-down control to increase or decrease the temporal resolution of visual perception.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\W8A3I4KN\\Wutz, Melcher, Samaha - Unknown - Frequency modulation of neural oscillations according to visual task demands.pdf},
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  number = {6},
  pmid = {29358390}
}

@article{wutz_weisz_2020,
  title = {Oscillatory {{Bursts}} in {{Parietal Cortex Reflect Dynamic Attention}} between {{Multiple Objects}} and {{Ensembles}}},
  author = {Wutz, Andreas and Zazio, Agnese and Weisz, Nathan},
  year = {2020},
  month = sep,
  volume = {40},
  pages = {6927--6937},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0231-20.2020},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2C4YLTT9\\Wutz et al. - 2020 - Oscillatory Bursts in Parietal Cortex Reflect Dyna.pdf},
  journal = {The Journal of Neuroscience},
  language = {en},
  number = {36}
}

@phdthesis{wyatte_wyatte_2010,
  title = {Recurrent Processing during Object Recognition},
  author = {Wyatte, Dean R},
  year = {2010},
  doi = {10.3389/fpsyg.2013.00124},
  abstract = {How does the brain learn to recognize objects visually, and perform this difficult feat robustly in the face of many sources of ambiguity and variability? We present a computational model based on the biology of the relevant visual pathways that learns to reliably recognize 100 different object categories in the face of naturally occurring variability in location, rotation, size, and lighting. The model exhibits robustness to highly ambiguous, partially occluded inputs. Both the unified, biologically plausible learning mechanism and the robustness to occlusion derive from the role that recurrent connectivity and recurrent processing mechanisms play in the model. Furthermore, this interaction of recurrent connectivity and learning predicts that high-level visual representations should be shaped by error signals from nearby, associated brain areas over the course of visual learning. Consistent with this prediction, we show how semantic knowledge about object categories changes the nature of their learned visual representations, as well as how this representational shift supports the mapping between perceptual and conceptual knowledge. Altogether, these findings support the potential importance of ongoing recurrent processing throughout the brain's visual system and suggest ways in which object recognition can be understood in terms of interactions within and between processes over time.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\Z5ZSF8P4\\Wyatte - 2010 - Recurrent processing during object recognition.pdf},
  keywords = {Computational model,Feedback,Object recognition,Recurrent processing,Winners-take-all mechanism},
  pmid = {23554596},
  type = {{{PhD Thesis}}}
}

@article{wyrick_mazzucato_2020,
  title = {State-Dependent Control of Cortical Processing Speed via Gain Modulation},
  author = {Wyrick, David and Mazzucato, Luca},
  year = {2020},
  month = apr,
  abstract = {To thrive in dynamic environments, animals can generate flexible behavior and rapidly adapt responses to a changing context and internal state. Examples of behavioral flexibility include faster stimulus responses when attentive and slower responses when distracted. Contextual modulations may occur early in the cortical hierarchy and may be implemented via afferent projections from top-down pathways or neuromodulation onto sensory cortex. However, the computational mechanisms mediating the effects of such projections are not known. Here, we investigate the effects of afferent projections on the information processing speed of cortical circuits. Using a biologically plausible model based on recurrent networks of excitatory and inhibitory neurons arranged in cluster, we classify the effects of cell-type specific perturbations on the circuit's stimulus-processing capability. We found that perturbations differentially controlled processing speed, leading to counterintuitive effects such as improved performance with increased input variance. Our theory explains the effects of all perturbations in terms of gain modulation, which controls the timescale of the circuit dynamics. We tested our model using large-scale electrophysiological recordings from the visual hierarchy in freely running mice, where a decrease in single-cell gain during locomotion explained the observed acceleration of visual processing speed. Our results establish a novel theory of cell-type specific perturbations linking connectivity, dynamics, and information processing via gain modulations.},
  archivePrefix = {arXiv},
  eprint = {2004.04190},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\CU2SR8Z5\\wyrick_mazzucato_2020.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\JQ639247\\2004.html},
  journal = {arXiv:2004.04190 [q-bio]},
  keywords = {Quantitative Biology - Neurons and Cognition},
  primaryClass = {q-bio}
}

@article{xiao_wu_2013,
  title = {Adaptive Neural Information Processing with Dynamical Electrical Synapses.},
  author = {Xiao, Lei and Zhang, Dan-Ke and Li, Yuan-Qing and Liang, Pei-Ji and Wu, Si},
  year = {2013},
  month = jan,
  volume = {7},
  pages = {36},
  issn = {1662-5188},
  doi = {10.3389/fncom.2013.00036},
  abstract = {The present study investigates a potential computational role of dynamical electrical synapses in neural information process. Compared with chemical synapses, electrical synapses are more efficient in modulating the concerted activity of neurons. Based on the experimental data, we propose a phenomenological model for short-term facilitation of electrical synapses. The model satisfactorily reproduces the phenomenon that the neuronal correlation increases although the neuronal firing rates attenuate during the luminance adaptation. We explore how the stimulus information is encoded in parallel by firing rates and correlated activity of neurons, and find that dynamical electrical synapses mediate a transition from the firing rate code to the correlation one during the luminance adaptation. The latter encodes the stimulus information by using the concerted, but lower neuronal firing rate, and hence is economically more efficient.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QDYARHIB\\Xiao et al. - 2013 - Adaptive neural information processing with dynamical electrical synapses.pdf},
  journal = {Frontiers in computational neuroscience},
  keywords = {dynamical encoding,electrical synapses,inform,information processing,short-term plasticity},
  number = {April},
  pmid = {23596413}
}

@article{xie_padoa-schioppa_2016,
  title = {Neuronal Remapping and Circuit Persistence in Economic Decisions},
  author = {Xie, Jue and {Padoa-Schioppa}, Camillo},
  year = {2016},
  pages = {1--9},
  issn = {1097-6256},
  doi = {10.1038/nn.4300},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\N7U2YUG7\\Xie, Padoa-Schioppa - 2016 - Neuronal remapping and circuit persistence in economic decisions.pdf},
  journal = {Nature Neuroscience},
  number = {May},
  pmid = {27159800}
}

@article{xie_seung_2003,
  title = {Equivalence of {{Backpropagation}} and {{Contrastive Hebbian Learning}} in a {{Layered Network}}},
  author = {Xie, Xiaohui and Seung, H. Sebastian},
  year = {2003},
  month = feb,
  volume = {15},
  pages = {441--454},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/089976603762552988},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LPPT69AX\\Xie and Seung - 2003 - Equivalence of Backpropagation and Contrastive Heb.pdf},
  journal = {Neural Computation},
  language = {en},
  number = {2}
}

@article{xiong_urtasun_2020,
  title = {{{LoCo}}: {{Local Contrastive Representation Learning}}},
  shorttitle = {{{LoCo}}},
  author = {Xiong, Yuwen and Ren, Mengye and Urtasun, Raquel},
  year = {2020},
  month = aug,
  abstract = {Deep neural nets typically perform end-to-end backpropagation to learn the weights, a procedure that creates synchronization constraints in the weight update step across layers and is not biologically plausible. Recent advances in unsupervised contrastive representation learning point to the question of whether a learning algorithm can also be made local, that is, the updates of lower layers do not directly depend on the computation of upper layers. While Greedy InfoMax separately learns each block with a local objective, we found that it consistently hurts readout accuracy in state-of-the-art unsupervised contrastive learning algorithms, possibly due to the greedy objective as well as gradient isolation. In this work, we discover that by overlapping local blocks stacking on top of each other, we effectively increase the decoder depth and allow upper blocks to implicitly send feedbacks to lower blocks. This simple design closes the performance gap between local learning and end-to-end contrastive learning algorithms for the first time. Aside from standard ImageNet experiments, we also show results on complex downstream tasks such as object detection and instance segmentation directly using readout features.},
  archivePrefix = {arXiv},
  eprint = {2008.01342},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5VB3M8KC\\xiong_urtasun_2020.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\FKT7GM9Z\\2008.html},
  journal = {arXiv:2008.01342 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{xu_bi_2017,
  title = {A Tri-Network Model of Human Semantic Processing},
  author = {Xu, Yangwen and He, Yong and Bi, Yanchao},
  year = {2017},
  month = sep,
  volume = {8},
  doi = {10.3389/fpsyg.2017.01538},
  abstract = {Humans process the meaning of the world via both verbal and nonverbal modalities. It has been established that widely distributed cortical regions are involved in semantic processing, yet the global wiring pattern of this brain system has not been considered in the current neurocognitive semantic models. We review evidence from the brain-network perspective, which shows that the semantic system is topologically segregated into three brain modules. Revisiting previous region-based evidence in light of these new network findings, we postulate that these three modules support multimodal experiential representation, language-supported representation, and semantic control. A tri-network neurocognitive model of semantic processing is proposed, which generates new hypotheses regarding the network basis of different types of semantic processes.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EPUT32MV\\Xu, He, Bi - 2017 - A Tri-network Model of Human Semantic Processing.pdf},
  pmid = {28955266}
}

@article{xu_wu_2019,
  title = {Unsupervised {{Discovery}} of {{Parts}}, {{Structure}}, and {{Dynamics}}},
  author = {Xu, Zhenjia and Liu, Zhijian and Sun, Chen and Murphy, Kevin and Freeman, William T. and Tenenbaum, Joshua B. and Wu, Jiajun},
  year = {2019},
  month = mar,
  abstract = {Humans easily recognize object parts and their hierarchical structure by watching how they move; they can then predict how each part moves in the future. In this paper, we propose a novel formulation that simultaneously learns a hierarchical, disentangled object representation and a dynamics model for object parts from unlabeled videos. Our Parts, Structure, and Dynamics (PSD) model learns to, first, recognize the object parts via a layered image representation; second, predict hierarchy via a structural descriptor that composes low-level concepts into a hierarchical structure; and third, model the system dynamics by predicting the future. Experiments on multiple real and synthetic datasets demonstrate that our PSD model works well on all three tasks: segmenting object parts, building their hierarchical structure, and capturing their motion distributions.},
  archivePrefix = {arXiv},
  eprint = {1903.05136},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ZGPHRI3H\\Xu et al. - 2019 - Unsupervised Discovery of Parts, Structure, and Dy.pdf},
  journal = {arXiv:1903.05136 [cs]},
  language = {en},
  primaryClass = {cs}
}

@book{xu_xu_2018,
  title = {The {{Posterior Parietal Cortex}} in {{Adaptive Visual Processing}}},
  author = {Xu, Yaoda},
  year = {2018},
  volume = {41},
  doi = {10.1016/j.tins.2018.07.012},
  abstract = {Although the primate posterior parietal cortex (PPC) has been largely associated with space, attention, and action-related processing, a growing number of studies have reported the direct representation of a diverse array of action-independent nonspatial visual information in the PPC during both perception and visual working memory. By describing the distinctions and the close interactions of visual representation with space, attention, and action-related processing in the PPC, here I propose that we may understand these diverse PPC functions together through the unique contribution of the PPC to adaptive visual processing and form a more integrated and structured view of the role of the PPC in vision, cognition, and action.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\MBDUX6JX\\Xu - 2018 - The Posterior Parietal Cortex in Adaptive Visual Processing.pdf},
  keywords = {cognition,vision,visual representation},
  pmid = {30115412}
}

@article{yamins_dicarlo_2016,
  title = {Using Goal-Driven Deep Learning Models to Understand Sensory Cortex},
  author = {Yamins, Daniel L.K. and DiCarlo, James J.},
  year = {2016},
  volume = {19},
  pages = {356--365},
  issn = {15461726},
  doi = {10.1038/nn.4244},
  abstract = {Fueled by innovation in the computer vision and artificial intelligence communities, recent developments in computational neuroscience have used goal-driven hierarchical convolutional neural networks (HCNNs) to make strides in modeling neural single-unit and population responses in higher visual cortical areas. In this Perspective, we review the recent progress in a broader modeling context and describe some of the key technical innovations that have supported it. We then outline how the goal-driven HCNN approach can be used to delve even more deeply into understanding the development and organization of sensory cortical processing.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7JCZ2QVF\\Yamins, DiCarlo - 2016 - Using goal-driven deep learning models to understand sensory cortex.pdf},
  journal = {Nature Neuroscience},
  number = {3},
  pmid = {26906502}
}

@article{yamins_yamins_2013,
  title = {Hierarchical {{Modular Optimization}} of {{Convolutional Networks Achieves Representations Similar}} to {{Macaque IT}} and {{Human Ventral Stream}}-Hierarchical-Modular- Optimization-of-Convolutional-Networks-Achieves-Representations- Similar-to-Macaque-It-and-Human-Vent},
  author = {Yamins, Citation and Hong, Ha and Cadieu, Charles and Dicarlo, James J and Yamins, Daniel},
  year = {2013},
  volume = {26},
  abstract = {Humans recognize visually-presented objects rapidly and accurately. To under-stand this ability, we seek to construct models of the ventral stream, the series of cortical areas thought to subserve object recognition. One tool to assess the qual-ity of a model of the ventral stream is the Representational Dissimilarity Matrix (RDM), which uses a set of visual stimuli and measures the distances produced in either the brain (i.e. fMRI voxel responses, neural firing rates) or in models (fea-tures). Previous work has shown that all known models of the ventral stream fail to capture the RDM pattern observed in either IT cortex, the highest ventral area, or in the human ventral stream. In this work, we construct models of the ventral stream using a novel optimization procedure for category-level object recognition problems, and produce RDMs resembling both macaque IT and human ventral stream. The model, while novel in the optimization procedure, further develops a long-standing functional hypothesis that the ventral visual stream is a hierarchi-cally arranged series of processing stages optimized for visual object recognition.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QC2W6BXA\\Yamins et al. - 2013 - Hierarchical Modular Optimization of Convolutional Networks Achieves Representations Similar to Macaque IT and Hu.pdf}
}

@article{yang_eschenko_2019,
  title = {Occurrence of {{Hippocampal Ripples}} Is {{Associated}} with {{Activity Suppression}} in the {{Mediodorsal Thalamic Nucleus}}},
  author = {Yang, Mingyu and Logothetis, Nikos K and Eschenko, Oxana},
  year = {2019},
  doi = {10.1523/JNEUROSCI.2107-18.2018},
  abstract = {Forming reliable memories requires coordinated activity within distributed brain networks. At present, neural mechanisms underlying systems-level consolidation of declarative memory beyond the hippocampal-prefrontal interactions remain largely unexplored. The mediodorsal thalamic nucleus (MD) is reciprocally connected with the medial prefrontal cortex (mPFC) and also receives inputs from parahippocampal regions. The MD may thus modulate functional connectivity between the hippocampus and the mPFC at different stages of information processing. Here, we characterized, in freely behaving Sprague Dawley male rats, the MD neural activity around hippocampal ripples, indicators of memory replay and hippocampal-cortical information transfer. Overall, the MD firing rate was transiently (0.76 0.06 s) decreased around ripples, with the MD activity suppression preceding the ripple onset for 0.41 0.04 s (range, 0.01-0.95 s). The degree of MD modulation correlated with ripple amplitude, differed across behavioral states, and also depended on the dynamics of hippocampal-cortical population activity. The MD suppression was the strongest and the most consistent during awake ripples. During non-rapid eye movement sleep, MD firing rate decreased around spindle-uncoupled ripples, but increased around spindle-coupled ripples. Our results suggest a competitive interaction between the thalamocortical and hippocampal-cortical networks supporting "on-line" and "off-line" information processing, respectively. We hypothesize that thalamic activity suppression during spindle-uncoupled ripples is favorable for memory replay, as it reduces interference from sensory relay. In turn, the thalamic input during hippocampal-cortical communication, as indicated by spindle/ripple coupling, may contribute to selectivity and reliability of information transfer. Both predictions need to be tested in future experiments.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5TG2RV7L\\Yang, Logothetis, Eschenko - 2019 - Occurrence of Hippocampal Ripples is Associated with Activity Suppression in the Mediodorsal Thalami.pdf},
  keywords = {cortical state,hippocampus,mediodorsal thalamus,memory consolidation,sharp-wave ripples,sleep}
}

@article{yartsev_ulanovsky_2013,
  title = {Representation of Three-Dimensional Space in the Hippocampus of Flying Bats.},
  author = {Yartsev, Michael M and Ulanovsky, Nachum},
  year = {2013},
  month = apr,
  volume = {340},
  pages = {367--372},
  issn = {1095-9203},
  doi = {10.1126/science.1235338},
  abstract = {Many animals, on air, water, or land, navigate in three-dimensional (3D) environments, yet it remains unclear how brain circuits encode the animal's 3D position. We recorded single neurons in freely flying bats, using a wireless neural-telemetry system, and studied how hippocampal place cells encode 3D volumetric space during flight. Individual place cells were active in confined 3D volumes, and in \{\textbackslash textgreater\}90\{\%\} of the neurons, all three axes were encoded with similar resolution. The 3D place fields from different neurons spanned different locations and collectively represented uniformly the available space in the room. Theta rhythmicity was absent in the firing patterns of 3D place cells. These results suggest that the bat hippocampus represents 3D volumetric space by a uniform and nearly isotropic rate code.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HXVMFJ2G\\Yartsev, Ulanovsky - 2013 - Representation of three-dimensional space in the hippocampus of flying bats.pdf},
  journal = {Science (New York, N.Y.)},
  keywords = {Animal,Animal: physiology,Animals,Chiroptera,Chiroptera: anatomy {\&} histology,Chiroptera: anatomy \& histology,Chiroptera: psychology,Flight,Hippocampus,Hippocampus: physiology,Male,Space Perception,Space Perception: physiology,Theta Rhythm},
  number = {6130},
  pmid = {23599496}
}

@article{yassa_bhattacharyya_2018,
  title = {Modeling {{Contextual Modulation}} of {{Memory Associations}} in the {{Hippocampus}}},
  author = {Yassa, Michael A and Mendelsohn, Avi and Aimone, James B and Pilly, Praveen K and Howard, Michael D and Bhattacharyya, Rajan},
  year = {2018},
  volume = {12},
  pages = {442},
  doi = {10.3389/fnhum.2018.00442},
  abstract = {We present a computational model of how memories can be contextually acquired and recalled in the hippocampus. Our adaptive contextual memory model comprises the lateral entorhinal cortex (LEC), the dentate gyrus (DG) and areas CA3 and CA1 in the hippocampus, and assumes external inputs about context that originate in the prefrontal cortex (PFC). Specifically, we propose that there is a top-down bias on the excitability of cells in the DG of the hippocampus that recruits a sub-population of cells to differentiate contexts, independent of experienced stimuli, expanding the "pattern separation" role typically attributed to the DG. It has been demonstrated in rats that if PFC is inactivated, both acquisition and recall of memory associations are impaired. However, PFC inactivation during acquisition of one set of memory associations surprisingly leads to subsequent facilitation of the acquisition of a conflicting set of memory associations in the same context under normal PFC operation. We provide here the first computational and algorithmic account of how the absence or presence of the top-down contextual biases on the excitability of DG cells during different learning phases of these experiments explains these data. Our model simulates PFC inactivation as the loss of inhibitory control on DG, which leads to full or partial activation of DG cells related to conflicting memory associations previously acquired in different contexts. This causes context-inappropriate memory traces to become active in the CA3 recurrent network and thereby the output CA1 area within the hippocampus. We show that these incongruous memory patterns proactively interfere with and slow the acquisition of new memory associations. Further, we demonstrate that pattern completion within CA3 in response to a partial cue for the recall of previously acquired memories is also impaired by PFC inactivation for the same reason. Pre-training the model with interfering memories in contexts different from those used in the experiments, simulating a lifetime of experiences, was crucial to reproduce the rat behavioral data. Finally, we made several testable predictions based on the model that suggest future experiments to deepen our understanding of brain-wide memory processes.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\XDCE8KZG\\Yassa et al. - 2018 - Modeling Contextual Modulation of Memory Associations in the Hippocampus.pdf},
  journal = {Frontiers in Human Neuroscience | www.frontiersin.org},
  keywords = {IMPORTANT}
}

@article{ye_xue_2016,
  title = {Neural {{Global Pattern Similarity Underlies True}} and {{False Memories}}},
  author = {Ye, Z and Zhu, Bi and Zhuang, Liping and Lu, Zhonglin and Chen, C and Xue, G},
  year = {2016},
  volume = {36},
  pages = {6792--6802},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.0425-16.2016},
  abstract = {The neural processes giving rise to human memory strength signals remain poorly understood. Inspired by formal computational models that posit a central role of global matching in memory strength, we tested a novel hypothesis that the strengths of both true and false memories arise from the global similarity of an item's neural activation pattern during retrieval to that of all the studied items during encoding (i.e., the encoding-retrieval neural global pattern similarity [ER-nGPS]). We revealed multiple ER-nGPS signals that carried distinct information and contributed differentially to true and false memories: Whereas the ER-nGPS in the parietal regions reflected semantic similarity and was scaled with the recognition strengths of both true and false memories, ER-nGPS in the visual cortex contrib-uted solely to true memory. Moreover, ER-nGPS differences between the parietal and visual cortices were correlated with frontal moni-toring processes. By combining computational and neuroimaging approaches, our results advance a mechanistic understanding of memory strength in recognition.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L8EJRY9C\\Ye et al. - 2016 - Neural Global Pattern Similarity Underlies True and False Memories.pdf},
  journal = {Journal of Neuroscience},
  keywords = {DRM,false memory,fmri,global matching models,neural global pattern similarity,recognition},
  number = {25},
  pmid = {27335409}
}

@article{yi_deng_2017,
  title = {Action Potential Initiation in a Two-Compartment Model of Pyramidal Neuron Mediated by Dendritic {{Ca2}}+ Spike},
  author = {Yi, Guosheng and Wang, Jiang and Wei, Xile and Deng, Bin},
  year = {2017},
  month = may,
  volume = {7},
  pages = {45684},
  issn = {2045-2322},
  doi = {10.1038/srep45684},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\ATV5FXJC\\Yi et al. - 2017 - Action potential initiation in a two-compartment m.pdf},
  journal = {Scientific Reports},
  language = {en},
  number = {1}
}

@article{yi_tang_2004,
  title = {Neural Networks Based Approach for Computing Eigenvectors and Eigenvalues of Symmetric Matrix},
  author = {Yi, Zhang and Fu, Yan and Tang, Hua Jin},
  year = {2004},
  month = apr,
  volume = {47},
  pages = {1155--1164},
  issn = {08981221},
  doi = {10.1016/S0898-1221(04)90110-1},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\W4MJCQDY\\Yi et al. - 2004 - Neural networks based approach for computing eigen.pdf},
  journal = {Computers \& Mathematics with Applications},
  language = {en},
  number = {8-9}
}

@article{yildirim_yildirim_2012,
  title = {Bayesian {{Inference}} : {{Gibbs Sampling}}},
  author = {Yildirim, Ilker},
  year = {2012},
  volume = {14627},
  pages = {1--6},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\4XJ94JHQ\\Yildirim - 2012 - Bayesian Inference Gibbs Sampling.pdf}
}

@article{yildiz_deneve_2016,
  title = {Predictive {{Ensemble Decoding}} of {{Acoustical Features Explains Context}}-{{Dependent Receptive Fields}}},
  author = {Yildiz, Izzet B. and Mesgarani, Nima and Deneve, Sophie},
  year = {2016},
  month = dec,
  volume = {36},
  pages = {12338--12350},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.4648-15.2016},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NUB9CTSX\\Yildiz et al. - 2016 - Predictive Ensemble Decoding of Acoustical Feature.pdf},
  journal = {The Journal of Neuroscience},
  language = {en},
  number = {49}
}

@article{yin_balleine_2005,
  title = {The Role of the Dorsomedial Striatum in Instrumental Conditioning: {{Striatum}} and Instrumental Conditioning},
  shorttitle = {The Role of the Dorsomedial Striatum in Instrumental Conditioning},
  author = {Yin, Henry H. and Ostlund, Sean B. and Knowlton, Barbara J. and Balleine, Bernard W.},
  year = {2005},
  month = jul,
  volume = {22},
  pages = {513--523},
  issn = {0953816X, 14609568},
  doi = {10.1111/j.1460-9568.2005.04218.x},
  abstract = {Considerable evidence suggests that, in instrumental conditioning, rats learn the relationship between actions and their specific consequences or outcomes. The present study examined the role of the dorsomedial striatum (DMS) in this type of learning after excitotoxic lesions and reversible, muscimol-induced inactivation. In three experiments, rats were first trained to press two levers for distinct outcomes, and then tested after training using a variety of behavioural assays that have been established to detect actionoutcome learning. In Experiment 1, pre-training lesions of the posterior DMS abolished the sensitivity of rats' instrumental performance to both outcome devaluation and contingency degradation when tested in extinction, whereas lesions of the anterior DMS had no effect. In Experiment 2, both pre-training and post-training lesions of the posterior DMS were equally effective in reducing the sensitivity of performance both to devaluation and degradation treatments. In Experiment 3, the infusion of muscimol into the posterior DMS selectively abolished sensitivity of performance to devaluation and contingency degradation without impairing the ability of rats to discriminate either the instrumental actions performed or the identity of the earned outcomes. Taken together, these results suggest that the posterior region of the DMS is a crucial neural substrate for the acquisition and expression of action\textendash outcome associations in instrumental conditioning.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\GH6XWD7S\\Yin et al. - 2005 - The role of the dorsomedial striatum in instrument.pdf},
  journal = {European Journal of Neuroscience},
  language = {en},
  number = {2}
}

@article{yin_nurmikko_2014,
  title = {Wireless {{Neurosensor}} for {{Full}}-{{Spectrum Electrophysiology Recordings}} during {{Free Behavior}}},
  author = {Yin, Ming and Borton, David A. and Komar, Jacob and Agha, Naubahar and Lu, Yao and Li, Hao and Laurens, Jean and Lang, Yiran and Li, Qin and Bull, Christopher and Larson, Lawrence and Rosler, David and Bezard, Erwan and Courtine, Gr{\'e}goire and Nurmikko, Arto V.},
  year = {2014},
  month = dec,
  issn = {08966273},
  doi = {10.1016/j.neuron.2014.11.010},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6PYSBQXP\\Yin et al. - 2014 - Wireless Neurosensor for Full-Spectrum Electrophysiology Recordings during Free Behavior.pdf},
  journal = {Neuron}
}

@article{yonelinas_wiltgen_2019,
  title = {A Contextual Binding Theory of Episodic Memory: Systems Consolidation Reconsidered},
  shorttitle = {A Contextual Binding Theory of Episodic Memory},
  author = {Yonelinas, Andrew P. and Ranganath, Charan and Ekstrom, Arne D. and Wiltgen, Brian J.},
  year = {2019},
  month = mar,
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/s41583-019-0150-4},
  abstract = {Episodic memory reflects the ability to recollect the temporal and spatial context of past experiences. Episodic memories depend on the hippocampus but have been proposed to undergo rapid forgetting unless consolidated during offline periods such as sleep to neocortical areas for long-term storage. Here, we propose an alternative to this standard systems consolidation theory (SSCT) \textemdash{} a contextual binding account \textemdash{} in which the hippocampus binds item-related and context-related information. We compare these accounts in light of behavioural, lesion, neuroimaging and sleep studies of episodic memory and contend that forgetting is largely due to contextual interference, episodic memory remains dependent on the hippocampus across time, contextual drift produces post-encoding activity and sleep benefits memory by reducing contextual interference.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\3X7UYE5V\\Yonelinas et al. - 2019 - A contextual binding theory of episodic memory sy.pdf},
  journal = {Nature Reviews Neuroscience},
  language = {en}
}

@article{yonk_margolis_2019,
  title = {Traces of {{Learning}} in {{Thalamocortical Circuits}}},
  author = {Yonk, Alex J. and Margolis, David J.},
  year = {2019},
  month = jul,
  volume = {103},
  pages = {175--176},
  issn = {08966273},
  doi = {10.1016/j.neuron.2019.06.020},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JE8L8GAI\\Yonk and Margolis - 2019 - Traces of Learning in Thalamocortical Circuits.pdf},
  journal = {Neuron},
  language = {en},
  number = {2}
}

@techreport{yoo_hayden_2019,
  title = {Multicentric Tracking of Multiple Agents by Anterior Cingulate Cortex during Pursuit and Evasion},
  author = {Yoo, Seng Bum Michael and Tu, Jiaxin Cindy and Hayden, Benjamin Yost},
  year = {2019},
  month = oct,
  institution = {{Neuroscience}},
  doi = {10.1101/796375},
  abstract = {SUMMARY           Successful pursuit and evasion require rapid and precise coordination of navigation with adaptive motor control. We hypothesized that the dorsal anterior cingulate cortex (dACC), which communicates bidirectionally with both the hippocampal complex and premotor/motor areas, would serve a mapping role in this process. We recorded responses of dACC ensembles in two macaques performing a joystick-controlled continuous pursuit/evasion task. We found that dACC multiplexes two sets of signals, (1) world-centric variables that together form a representation of the position and velocity of all relevant agents (self, prey, and predator) in the virtual world, and (2) avatar-centric variables, i.e. self-prey distance and angle. Both sets of variables are multiplexed within an overlapping set of neurons. Our results suggest that dACC may contribute to pursuit and evasion by computing and continuously updating a multicentric representation of the unfolding task state, and support the hypothesis that it plays a high-level abstract role in the control of behavior.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\93R4JYZU\\Yoo et al. - 2019 - Multicentric tracking of multiple agents by anteri.pdf},
  language = {en},
  type = {Preprint}
}

@article{yoo_hayden_2020,
  title = {The Neural Basis of Predictive Pursuit},
  author = {Yoo, Seng Bum Michael and Tu, Jiaxin Cindy and Piantadosi, Steven T. and Hayden, Benjamin Yost},
  year = {2020},
  month = jan,
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-019-0561-6},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\C6J8859G\\Yoo et al. - 2020 - The neural basis of predictive pursuit.pdf},
  journal = {Nature Neuroscience},
  language = {en}
}

@article{yttri_dudman_2016,
  title = {Opponent and Bidirectional Control of Movement Velocity in the Basal Ganglia},
  author = {Yttri, Eric A and Dudman, Joshua T},
  year = {2016},
  volume = {533},
  pages = {402--406},
  issn = {0028-0836},
  doi = {10.1038/nature17639},
  abstract = {For goal-directed behaviour it is critical that we can both select the appropriate action and learn to modify the underlying movements (for example, the pitch of a note or velocity of a reach) to improve outcomes. The basal ganglia are a critical nexus where circuits necessary for the production of behaviour, such as the neocortex and thalamus, are integrated with reward signalling to reinforce successful, purposive actions. The dorsal striatum, a major input structure of basal ganglia, is composed of two opponent pathways, direct and indirect, thought to select actions that elicit positive outcomes and suppress actions that do not, respectively. Activity-dependent plasticity modulated by reward is thought to be sufficient for selecting actions in the striatum. Although perturbations of basal ganglia function produce profound changes in movement, it remains unknown whether activity-dependent plasticity is sufficient to produce learned changes in movement kinematics, such as velocity. Here we use cell-type-specific stimulation in mice delivered in closed loop during movement to demonstrate that activity in either the direct or indirect pathway is sufficient to produce specific and sustained increases or decreases in velocity, without affecting action selection or motivation. These behavioural changes were a form of learning that accumulated over trials, persisted after the cessation of stimulation, and were abolished in the presence of dopamine antagonists. Our results reveal that the direct and indirect pathways can each bidirectionally control movement velocity, demonstrating unprecedented specificity and flexibility in the control of volition by the basal ganglia.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JBBWCFQN\\Yttri, Dudman - 2016 - Opponent and bidirectional control of movement velocity in the basal ganglia.pdf},
  journal = {Nature},
  number = {7603},
  pmid = {27135927}
}

@article{yu_bandettini_2019,
  title = {Layer-Specific Activation of Sensory Input and Predictive Feedback in the Human Primary Somatosensory Cortex},
  author = {Yu, Yinghua and Huber, Laurentius and Yang, Jiajia and Jangraw, David C. and Handwerker, Daniel A. and Molfese, Peter J. and Chen, Gang and Ejima, Yoshimichi and Wu, Jinglong and Bandettini, Peter A.},
  year = {2019},
  month = may,
  volume = {5},
  pages = {eaav9053},
  issn = {2375-2548},
  doi = {10.1126/sciadv.aav9053},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\9FENX6FC\\Yu et al. - 2019 - Layer-specific activation of sensory input and pre.pdf},
  journal = {Science Advances},
  language = {en},
  number = {5}
}

@article{yuan_franconeri_2016,
  title = {Are {{Categorical Spatial Relations Encoded}} by {{Shifting Visual Attention}} between {{Objects}}?},
  author = {Yuan, Lei and Uttal, David and Franconeri, Steven},
  year = {2016},
  doi = {10.1371/journal.pone.0163141},
  abstract = {Perceiving not just values, but relations between values, is critical to human cognition. We tested the predictions of a proposed mechanism for processing categorical spatial relations between two objects-the shift account of relation processing-which states that relations such as 'above' or 'below' are extracted by shifting visual attention upward or downward in space. If so, then shifts of attention should improve the representation of spatial relations, compared to a control condition of identity memory. Participants viewed a pair of briefly flashed objects and were then tested on either the relative spatial relation or identity of one of those objects. Using eye tracking to reveal participants' voluntary shifts of attention over time, we found that when initial fixation was on neither object, relational memory showed an absolute advantage for the object following an attention shift, while identity memory showed no advantage for either object. This result is consistent with the shift account of relation processing. When initial fixation began on one of the objects, identity memory strongly benefited this fixated object, while relational memory only showed a relative benefit for objects following an attention shift. This result is also consistent, although not as uniquely, with the shift account of relation processing. Taken together, we suggest that the attention shift account provides a mechanistic explanation for the overall results. This account can potentially serve as the common mechanism underlying both linguistic and perceptual representations of spatial relations.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\SKT34N33\\Yuan, Uttal, Franconeri - 2016 - Are Categorical Spatial Relations Encoded by Shifting Visual Attention between Objects.pdf}
}

@article{zador_zador_2019,
  title = {A Critique of Pure Learning and What Artificial Neural Networks Can Learn from Animal Brains},
  author = {Zador, Anthony M.},
  year = {2019},
  month = dec,
  volume = {10},
  pages = {3770},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-11786-6},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\92X3XDR5\\Zador - 2019 - A critique of pure learning and what artificial ne.pdf},
  journal = {Nature Communications},
  language = {en},
  number = {1}
}

@article{zaldivar_panzeri_2017,
  title = {Dopamine {{Is Signaled}} by {{Mid}}-Frequency {{Oscillations}} and {{Boosts Output Layers Visual Information}} in {{Visual Cortex}}},
  author = {Zaldivar, Daniel and Goense, Jozien and Lowe, Scott C and Logothetis, Nikos K and Correspondence, Stefano Panzeri and Panzeri, Stefano},
  year = {2017},
  doi = {10.1016/j.cub.2017.12.006},
  abstract = {Graphical Abstract Highlights d Mid-range frequency band reflects dopaminergic neuromodulation d Dopamine increases gamma band visual information d Heterogeneity of the visual information in neural activity across layers d Layer-and frequency-dependent increase of information elicited by dopamine In Brief Zaldivar et al. investigated how dopamine modulates oscillatory cortical activity. They found that endogenous oscillations in the mid-range [19\textendash 38 Hz] band capture dopamine changes and that dopamine enhances the visual information carried by the gamma [50\textendash 100 Hz] band in the output cortical layers. Zaldivar et al., 2018, Current Biology 28, 1\textendash 12 January 22, 2018 \textordfeminine{} 2017 Elsevier Ltd. SUMMARY Neural oscillations are ubiquitously observed in cortical activity, and are widely believed to be crucial for mediating transmission of information across the cortex. Yet, the neural phenomena contributing to each oscillation band, and their effect on information coding and transmission, are largely unknown. Here, we investigated whether individual frequency bands specifically reflect changes in the concentrations of dopamine, an important neuromodulator, and how dopamine affects oscillatory information process-ing. We recorded the local field potential (LFP) at different depths of primary visual cortex (V1) in anes-thetized monkeys (Macaca mulatta) during sponta-neous activity and during visual stimulation with Hollywood movie clips while pharmacologically mimicking dopaminergic neuromodulation by sys-temic injection of L-DOPA (a metabolic precursor of dopamine). We found that dopaminergic neuro-modulation had marked effects on both sponta-neous and movie-evoked neural activity. During spontaneous activity, dopaminergic neuromodula-tion increased the power of the LFP specifically in the [19\textendash 38 Hz] band, suggesting that the power of endogenous visual cortex oscillations in this band can be used as a robust marker of dopaminergic neuromodulation. Moreover, dopamine increased visual information encoding over all frequencies dur-ing movie stimulation. The information increase due to dopamine was prominent in the supragranular layers of cortex that project to higher cortical areas and in the gamma [50\textendash 100 Hz] band that has been previously implicated in mediating feedforward in-formation transfer. These results thus individuate new neural mechanisms by which dopamine may promote the readout of relevant sensory information by strengthening the transmission of information from primary to higher areas.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DDWMQACA\\Zaldivar et al. - 2017 - Dopamine Is Signaled by Mid-frequency Oscillations and Boosts Output Layers Visual Information in Visual Cortex.pdf},
  keywords = {correlations,cortical circuits,cortical layers,dopaminergic neuromodulation,information theory,LFPs,local field potentials,naturalistic vision,primary visual cortex,V1}
}

@article{zambaldi_battaglia_2018,
  title = {Relational {{Deep Reinforcement Learning}}},
  author = {Zambaldi, Vinicius and Raposo, David and Santoro, Adam and Bapst, Victor and Li, Yujia and Babuschkin, Igor and Tuyls, Karl and Reichert, David and Lillicrap, Timothy and Lockhart, Edward and Shanahan, Murray and Langston, Victoria and Pascanu, Razvan and Botvinick, Matthew and Vinyals, Oriol and Battaglia, Peter},
  year = {2018},
  issn = {15249050},
  doi = {10.1109/TITS.2017.2725912},
  abstract = {We introduce an approach for deep reinforcement learning (RL) that improves upon the efficiency, generalization capacity, and interpretability of conventional approaches through structured perception and relational reasoning. It uses self-attention to iteratively reason about the relations between entities in a scene and to guide a model-free policy. Our results show that in a novel navigation and planning task called Box-World, our agent finds interpretable solutions that improve upon baselines in terms of sample complexity, ability to generalize to more complex scenes than experienced during training, and overall performance. In the StarCraft II Learning Environment, our agent achieves state-of-the-art performance on six mini-games \textendash{} surpassing human grandmaster performance on four. By considering architectural inductive biases, our work opens new directions for overcoming important, but stubborn, challenges in deep RL.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\24CLKDWK\\Zambaldi et al. - Unknown - Relational Deep Reinforcement Learning.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\33LLAXCH\\Zambaldi et al. - Unknown - Relational Deep Reinforcement Learning(2).pdf}
}

@article{zambaldi_battaglia_2019,
  title = {{{DEEP REINFORCEMENT LEARNING WITH RELATIONAL INDUCTIVE BIASES}}},
  author = {Zambaldi, Vinicius and Raposo, David and Santoro, Adam and Bapst, Victor and Li, Yujia and Babuschkin, Igor and Tuyls, Karl and Reichert, David and Lillicrap, Timothy and Lockhart, Edward and Shanahan, Murray and Langston, Victoria and Pascanu, Razvan and Botvinick, Matthew and Vinyals, Oriol and Battaglia, Peter},
  year = {2019},
  pages = {18},
  abstract = {We introduce an approach for augmenting model-free deep reinforcement learning agents with a mechanism for relational reasoning over structured representations, which improves performance, learning efficiency, generalization, and interpretability. Our architecture encodes an image as a set of vectors, and applies an iterative message-passing procedure to discover and reason about relevant entities and relations in a scene. In six of seven StarCraft II Learning Environment mini-games, our agent achieved state-of-the-art performance, and surpassed human grandmasterlevel on four. In a novel navigation and planning task, our agent's performance and learning efficiency far exceeded non-relational baselines, it was able to generalize to more complex scenes than it had experienced during training. Moreover, when we examined its learned internal representations, they reflected important structure about the problem and the agent's intentions. The main contribution of this work is to introduce techniques for representing and reasoning about states in model-free deep reinforcement learning agents via relational inductive biases. Our experiments show this approach can offer advantages in efficiency, generalization, and interpretability, and can scale up to meet some of the most challenging test environments in modern artificial intelligence.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PV8ZNNSM\\Zambaldi et al. - 2019 - DEEP REINFORCEMENT LEARNING WITH RELATIONAL INDUCT.pdf},
  language = {en}
}

@article{zammit_muscat_2018,
  title = {Working Memory Alpha-Beta Band Oscillatory Signatures in Adolescents and Young Adults},
  author = {Zammit, Nowell and Falzon, Owen and Camilleri, Kenneth and Muscat, Richard},
  year = {2018},
  month = oct,
  volume = {48},
  pages = {2527--2536},
  issn = {0953816X},
  doi = {10.1111/ejn.13897},
  abstract = {The timing of neural activity is an intriguing way of exposing behaviorally relevant neural activity, as neural populations exploit transient windows of synchronized activations to exchange dynamic communications in the service of various cognitive operations. The link between neural synchrony and working memory (WM) has been supported at the theoretical and empirical level. However, findings have also shown that WM encoding is also related to significant alpha\textendash beta desynchronization. These findings have been primarily recorded during subsequent memory effect paradigms that compare correct with incorrect encoding trials. The dissociable contribution imparted by various processes to WM performance suggests that incorrect performance may not be directly translatable to unsuccessful encoding. Here, we address the relationship between alpha\textendash beta desynchronization and encoding through the use of an alternative paradigm design by contrasting frontal and parietal human scalp electroencephalography activity during the encoding interval of a delayed matching-to-sample task with that recorded during a control task. The additional use of non-verbal/semantic visual stimulation and recruitment of typically developing adolescent subjects has led us to the conclusion that encoding-relevant alpha\textendash beta decrements can be replicated via a non-verbal/semantic delayed matching-tosample task and these are also evident in typically developing adolescents, in addition to adults, as has been previously demonstrated. The identification of encoding-related alpha\textendash beta decrements in adolescent subjects performing such WM tasks may open new avenues to explore whether such a rhythmic signature may explain WM and electrophysiological deficits that emerge in various adolescent neuropsychiatric disorders such as attention deficit hyperactivity disorder.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\7Y8FZNUS\\Zammit et al. - 2018 - Working memory alpha-beta band oscillatory signatu.pdf},
  journal = {European Journal of Neuroscience},
  language = {en},
  number = {7}
}

@article{zanos_pack_2015,
  title = {A {{Sensorimotor Role}} for {{Traveling Waves}} in {{Primate Visual Cortex}}},
  author = {Zanos, Theodoros P and Mineault, Patrick J and Nasiotis, Konstantinos T and Guitton, Daniel and Pack, Christopher C},
  year = {2015},
  volume = {85},
  pages = {615--627},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2014.12.043},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\NNEQB7K7\\Zanos et al. - 2015 - A Sensorimotor Role for Traveling Waves in Primate Visual Cortex.pdf},
  journal = {Neuron},
  number = {3}
}

@article{zeidman_maguire_2016,
  title = {Anterior Hippocampus: The Anatomy of Perception, Imagination and Episodic Memory},
  shorttitle = {Anterior Hippocampus},
  author = {Zeidman, Peter and Maguire, Eleanor A.},
  year = {2016},
  month = mar,
  volume = {17},
  pages = {173--182},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn.2015.24},
  abstract = {The brain creates a model of the world around us. We can use this representation to perceive and comprehend what we see at any given moment, but also to vividly re-experience scenes from our past and imagine future (or even fanciful) scenarios. Recent work has shown that these cognitive functions \textemdash perception, imagination and recall of scenes and events \textemdash{} all engage the anterior hippocampus. In this Opinion article, we capitalize on new findings from functional neuroimaging to propose a model that links high-level cognitive functions to specific structures within the anterior hippocampus.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\JA68QSYL\\Zeidman and Maguire - 2016 - Anterior hippocampus the anatomy of perception, i.pdf},
  journal = {Nature Reviews Neuroscience},
  language = {en},
  number = {3}
}

@techreport{zeldenrust_deneve_2019,
  title = {Efficient and Robust Coding in Heterogeneous Recurrent Networks},
  author = {Zeldenrust, Fleur and Gutkin, Boris and Den{\'e}ve, Sophie},
  year = {2019},
  month = oct,
  institution = {{Neuroscience}},
  doi = {10.1101/804864},
  abstract = {Cortical networks show a large heterogeneity of neuronal properties. However, traditional coding models have focused on homogeneous populations of excitatory and inhibitory neurons. Here, we analytically derive a class of recurrent networks of spiking neurons that close to optimally track a continuously varying input online, based on two assumptions: 1) every spike is decoded linearly and 2) the network aims to reduce the mean-squared error between the input and the estimate. From this we derive a class of predictive coding networks, that unifies encoding and decoding and in which we can investigate the difference between homogeneous networks and heterogeneous networks, in which each neurons represents different features and has different spike-generating properties. We find that in this framework, `type 1' and `type 2' neurons arise naturally and networks consisting of a heterogeneous population of different neuron types are both more efficient and more robust against correlated noise. We make two experimental predictions: 1) we predict that integrators show strong correlations with other integrators and resonators are correlated with resonators, whereas the correlations are much weaker between neurons with different coding properties and 2) that `type 2' neurons are more coherent with the overall network activity than `type 1' neurons.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\P453JRDQ\\Zeldenrust et al. - 2019 - Efficient and robust coding in heterogeneous recur.pdf},
  language = {en},
  type = {Preprint}
}

@article{zelinsky_b_2013,
  title = {Modelling Eye Movements in a Categorical Search Task {{Modelling}} Eye Movements in a Categorical Search Task},
  author = {Zelinsky, Gregory J and Adeli, Hossein and Peng, Yifan and Samaras, Dimitris and B, Phil Trans R Soc},
  year = {2013},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\46LECGXZ\\Zelinsky et al. - 2013 - Modelling eye movements in a categorical search task Modelling eye movements in a categorical search task.pdf},
  keywords = {behaviour,cognition,computational biology},
  number = {September}
}

@article{zeman_dellasala_2015,
  title = {Lives without Imagery \textendash{} {{Congenital}} Aphantasia},
  author = {Zeman, Adam and Dewar, Michaela and Della Sala, Sergio},
  year = {2015},
  month = dec,
  volume = {73},
  pages = {378--380},
  issn = {00109452},
  doi = {10.1016/j.cortex.2015.05.019},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\EAZT2PW9\\Zeman et al. - 2015 - Lives without imagery – Congenital aphantasia.pdf},
  journal = {Cortex},
  language = {en}
}

@article{zenke_ganguli_2018,
  title = {{{SuperSpike}}: {{Supervised Learning}} in {{Multilayer Spiking Neural Networks}}},
  shorttitle = {{{SuperSpike}}},
  author = {Zenke, Friedemann and Ganguli, Surya},
  year = {2018},
  month = jun,
  volume = {30},
  pages = {1514--1541},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/neco_a_01086},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\K2YHVP3H\\Zenke and Ganguli - 2018 - SuperSpike Supervised Learning in Multilayer Spik.pdf},
  journal = {Neural Computation},
  language = {en},
  number = {6}
}

@article{zhang_jonas_2020,
  title = {Selective {{Routing}} of {{Spatial Information Flow}} from {{Input}} to {{Output}} in {{Hippocampal Granule Cells}}},
  author = {Zhang, Xiaomin and Schl{\"o}gl, Alois and Jonas, Peter},
  year = {2020},
  month = aug,
  pages = {S0896627320305237},
  issn = {08966273},
  doi = {10.1016/j.neuron.2020.07.006},
  abstract = {Dentate gyrus granule cells (GCs) connect the entorhinal cortex to the hippocampal CA3 region, but how they process spatial information remains enigmatic. To examine the role of GCs in spatial coding, we measured excitatory postsynaptic potentials (EPSPs) and action potentials (APs) in head-fixed mice running on a linear belt. Intracellular recording from morphologically identified GCs revealed that most cells were active, but activity level varied over a wide range. Whereas only \$5\% of GCs showed spatially tuned spiking, \$50\% received spatially tuned input. Thus, the GC population broadly encodes spatial information, but only a subset relays this information to the CA3 network. Fourier analysis indicated that GCs received conjunctive place-grid-like synaptic input, suggesting code conversion in single neurons. GC firing was correlated with dendritic complexity and intrinsic excitability, but not extrinsic excitatory input or dendritic cable properties. Thus, functional maturation may control input-output transformation and spatial code conversion.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FG3XP65T\\Zhang et al. - 2020 - Selective Routing of Spatial Information Flow from.pdf},
  journal = {Neuron},
  language = {en}
}

@article{zhang_manning_2018,
  title = {Graph {{Convolution}} over {{Pruned Dependency Trees Improves Relation Extraction}}},
  author = {Zhang, Yuhao and Qi, Peng and Manning, Christopher D.},
  year = {2018},
  issn = {0034-7744},
  abstract = {Dependency trees help relation extraction models capture long-range relations between words. However, existing dependency-based models either neglect crucial information (e.g., negation) by pruning the dependency trees too aggressively, or are computationally inefficient because it is difficult to parallelize over different tree structures. We propose an extension of graph convolutional networks that is tailored for relation extraction, which pools information over arbitrary dependency structures efficiently in parallel. To incorporate relevant information while maximally removing irrelevant content, we further apply a novel pruning strategy to the input trees by keeping words immediately around the shortest path between the two entities among which a relation might hold. The resulting model achieves state-of-the-art performance on the large-scale TACRED dataset, outperforming existing sequence and dependency-based neural models. We also show through detailed analysis that this model has complementary strengths to sequence models, and combining them further improves the state of the art.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\5MHS547S\\Zhang, Qi, Manning - 2018 - Graph Convolution over Pruned Dependency Trees Improves Relation Extraction.pdf},
  number = {2005},
  pmid = {11354973}
}

@article{zhang_millan_2015,
  title = {Discriminant Brain Connectivity Patterns of Performance Monitoring at Average and Single-Trial Levels},
  author = {Zhang, Huaijian and Chavarriaga, Ricardo and Mill{\'a}n, Jos{\'e} del R.},
  year = {2015},
  month = oct,
  volume = {120},
  pages = {64--74},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2015.07.012},
  abstract = {Electrophysiological and neuroimaging evidence suggest the existence of common mechanisms for monitoring erroneous events, independent of the source of errors. Previous works have described modulations of theta activity in the medial frontal cortex elicited by either self-generated errors or erroneous feedback. In turn, similar patterns have recently been reported to appear after the observation of external errors. We report cross-regional interactions after observation of errors at both average and single-trial levels. We recorded scalp electroencephalography (EEG) signals from 15 subjects while monitoring the movement of a cursor on a computer screen. Connectivity patterns, estimated using multivariate auto-regressive models, show increased error-related modulations of the information transfer in the theta and alpha bands between frontocentral and frontolateral areas. Conversely, a decrease of connectivity in the beta band is also observed. These network patterns are similar to those elicited by self-generated errors. However, since no motor response is required, they appear to be related to intrinsic mechanisms of error processing, instead of being linked to co-activation of motor areas. Noticeably, we demonstrate that cross-regional interaction patterns can be estimated on a trial-by-trial basis. These trialspecific patterns, consistent with the multi-trial analysis, convey discriminant information on whether a trial was elicited by observation of an erroneous action. Overall, our study supports the role of frequency-specific modulations in the medial frontal cortex in coordinating cross-regional activity during cognitive monitoring at a single-trial basis.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\S3EQAZS7\\Zhang et al. - 2015 - Discriminant brain connectivity patterns of perfor.pdf},
  journal = {NeuroImage},
  language = {en}
}

@article{zhang_nurmikko_2009,
  title = {Optical Detection of Brain Cell Activity Using Plasmonic Gold Nanoparticles},
  author = {Zhang, Jiayi and Atay, Tolga and Nurmikko, A V},
  year = {2009},
  pages = {1--6},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\DAW32DII\\Zhang, Atay, Nurmikko - 2009 - Optical detection of brain cell activity using plasmonic gold nanoparticles.pdf},
  journal = {Nano letters}
}

@article{zhang_sakagami_2016,
  title = {Functional Connectivity between Prefrontal Cortex and Striatum Estimated by Phase Locking Value},
  author = {Zhang, Yan and Pan, Xiaochuan and Wang, Rubin and Sakagami, Masamichi},
  year = {2016},
  volume = {10},
  pages = {245--254},
  issn = {18714099},
  doi = {10.1007/s11571-016-9376-2},
  abstract = {The interplay between the prefrontal cortex (PFC) and striatum has an important role in cognitive processes. To investigate interactive functions between the two areas in reward processing, we recorded local field potentials (LFPs) simultaneously from the two areas of two monkeys performing a reward prediction task (large reward vs small reward). The power of the LFPs was calculated in three frequency bands: the beta band (15-29 Hz), the low gamma band (30-49 Hz), and the high gamma band (50-100 Hz). We found that both the PFC and striatum encoded the reward information in the beta band. The reward information was also found in the high gamma band in the PFC, not in the striatum. We further calculated the phase-locking value (PLV) between two LFP signals to measure the phase synchrony between the PFC and striatum. It was found that significant differences occurred between PLVs in different task periods and in different frequency bands. The PLVs in small reward condition were significant higher than that in large reward condition in the beta band. In contrast, the PLVs in the high gamma band were stronger in large reward trials than in small trials. These results suggested that the functional connectivity between the PFC and striatum depended on the task periods and reward conditions. The beta synchrony between the PFC and striatum may regulate behavioral outputs of the monkeys in the small reward condition.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KQPFLQ2Z\\Zhang et al. - 2016 - Functional connectivity between prefrontal cortex and striatum estimated by phase locking value.pdf},
  journal = {Cognitive Neurodynamics},
  keywords = {Beta band,Gamma band,Phase-locking value,Prefrontal cortex,Striatum},
  number = {3},
  pmid = {27275380}
}

@article{zhang_sejnowski_1998,
  title = {Interpreting {{Neuronal Population Activity}} by {{Reconstruction}}: {{Unified Framework With Application}} to {{Hippocampal Place Cells}}},
  shorttitle = {Interpreting {{Neuronal Population Activity}} by {{Reconstruction}}},
  author = {Zhang, Kechen and Ginzburg, Iris and McNaughton, Bruce L. and Sejnowski, Terrence J.},
  year = {1998},
  month = feb,
  volume = {79},
  pages = {1017--1044},
  issn = {0022-3077, 1522-1598},
  doi = {10.1152/jn.1998.79.2.1017},
  abstract = {Zhang, Kechen, Iris Ginzburg, Bruce L. McNaughton, and Terrence J. Sejnowski. Interpreting neuronal population activity by reconstruction: unified framework with application to hippocampal place cells. J. Neurophysiol. 79: 1017\textendash 1044, 1998. Physical variables such as the orientation of a line in the visual field or the location of the body in space are coded as activity levels in populations of neurons. Reconstruction or decoding is an inverse problem in which the physical variables are estimated from observed neural activity. Reconstruction is useful first in quantifying how much information about the physical variables is present in the population and, second, in providing insight into how the brain might use distributed representations in solving related computational problems such as visual object recognition and spatial navigation. Two classes of reconstruction methods, namely, probabilistic or Bayesian methods and basis function methods, are discussed. They include important existing methods as special cases, such as population vector coding, optimal linear estimation, and template matching. As a representative example for the reconstruction problem, different methods were applied to multi-electrode spike train data from hippocampal place cells in freely moving rats. The reconstruction accuracy of the trajectories of the rats was compared for the different methods. Bayesian methods were especially accurate when a continuity constraint was enforced, and the best errors were within a factor of two of the information-theoretic limit on how accurate any reconstruction can be and were comparable with the intrinsic experimental errors in position tracking. In addition, the reconstruction analysis uncovered some interesting aspects of place cell activity, such as the tendency for erratic jumps of the reconstructed trajectory when the animal stopped running. In general, the theoretical values of the minimal achievable reconstruction errors quantify how accurately a physical variable is encoded in the neuronal population in the sense of mean square error, regardless of the method used for reading out the information. One related result is that the theoretical accuracy is independent of the width of the Gaussian tuning function only in two dimensions. Finally, all the reconstruction methods considered in this paper can be implemented by a unified neural network architecture, which the brain feasibly could use to solve related problems.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\HDLL9ZL7\\Zhang et al. - 1998 - Interpreting Neuronal Population Activity by Recon.pdf},
  journal = {Journal of Neurophysiology},
  language = {en},
  number = {2}
}

@article{zhang_zhao_2019,
  title = {Multi-{{Labeled Relation Extraction}} with {{Attentive Capsule Network}}},
  author = {Zhang, Xinsong and Li, Pengshuai and Jia, Weijia and Zhao, Hai},
  year = {2019},
  month = jul,
  volume = {33},
  pages = {7484--7491},
  issn = {2374-3468, 2159-5399},
  doi = {10.1609/aaai.v33i01.33017484},
  abstract = {To disclose overlapped multiple relations from a sentence still keeps challenging. Most current works in terms of neural models inconveniently assuming that each sentence is explicitly mapped to a relation label, cannot handle multiple relations properly as the overlapped features of the relations are either ignored or very difficult to identify. To tackle with the new issue, we propose a novel approach for multi-labeled relation extraction with capsule network which acts considerably better than current convolutional or recurrent net in identifying the highly overlapped relations within an individual sentence. To better cluster the features and precisely extract the relations, we further devise attention-based routing algorithm and sliding-margin loss function, and embed them into our capsule network. The experimental results show that the proposed approach can indeed extract the highly overlapped features and achieve significant performance improvement for relation extraction comparing to the state-of-the-art works.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\6ZURCIPI\\Zhang et al. - 2019 - Multi-Labeled Relation Extraction with Attentive C.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\S2E7DK2Z\\Zhang et al. - 2019 - Multi-Labeled Relation Extraction with Attentive C.pdf},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  language = {en}
}

@article{zhang_zhu_2019,
  title = {{{RAVEN}}: {{A Dataset}} for {{Relational}} and {{Analogical Visual rEasoNing}}},
  shorttitle = {{{RAVEN}}},
  author = {Zhang, Chi and Gao, Feng and Jia, Baoxiong and Zhu, Yixin and Zhu, Song-Chun},
  year = {2019},
  month = mar,
  abstract = {Dramatic progress has been witnessed in basic vision tasks involving low-level perception, such as object recognition, detection, and tracking. Unfortunately, there is still an enormous performance gap between artificial vision systems and human intelligence in terms of higher-level vision problems, especially ones involving reasoning. Earlier attempts in equipping machines with high-level reasoning have hovered around Visual Question Answering (VQA), one typical task associating vision and language understanding. In this work, we propose a new dataset, built in the context of Raven's Progressive Matrices (RPM) and aimed at lifting machine intelligence by associating vision with structural, relational, and analogical reasoning in a hierarchical representation. Unlike previous works in measuring abstract reasoning using RPM, we establish a semantic link between vision and reasoning by providing structure representation. This addition enables a new type of abstract reasoning by jointly operating on the structure representation. Machine reasoning ability using modern computer vision is evaluated in this newly proposed dataset. Additionally, we also provide human performance as a reference. Finally, we show consistent improvement across all models by incorporating a simple neural module that combines visual understanding and structure reasoning.},
  archivePrefix = {arXiv},
  eprint = {1903.02741},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\KEIUAFWH\\Zhang et al. - 2019 - RAVEN A Dataset for Relational and Analogical Vis.pdf},
  journal = {arXiv:1903.02741 [cs]},
  language = {en},
  primaryClass = {cs}
}

@article{zhong_cangelosi_2018,
  title = {Encoding {{Longer}}-Term {{Contextual Multi}}-Modal {{Information}} in a {{Predictive Coding Model}}},
  author = {Zhong, Junpei and Ogata, Tetsuya and Cangelosi, Angelo},
  year = {2018},
  abstract = {\textemdash Studies suggest that within the hierarchical architec-ture, the topological higher level possibly represents a conscious category of the current sensory events with a slower changing activities. They attempt to predict the activities on the lower level by relaying the predicted information. On the other hand, the incoming sensory information corrects such prediction of the events on the higher level by the novel or surprising signal. We propose a predictive hierarchical artificial neural network model that examines this hypothesis on neurorobotic platforms, based on the AFA-PredNet model. In this neural network model, there are different temporal scales of predictions exist on different levels of the hierarchical predictive coding, which are defined in the temporal parameters in the neurons. Also, both the fast-and the slow-changing neural activities are modulated by the active motor activities. A neurorobotic experiment based on the architecture was also conducted based on the data collected from the VRep simulator.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\L3LJ4X86\\Zhong, Ogata, Cangelosi - 2018 - Encoding Longer-term Contextual Multi-modal Information in a Predictive Coding Model.pdf}
}

@article{zhong_ogata_2018,
  title = {{{AFA}}-{{PredNet}}: {{The}} Action Modulation within Predictive Coding},
  author = {Zhong, Junpei and Cangelosi, Angelo and Zhang, Xinzheng and Ogata, Tetsuya},
  year = {2018},
  abstract = {\textemdash{} The predictive processing (PP) hypothesizes that the predictive inference of our sensorimotor system is encoded implicitly in the regularities between perception and action. We propose a neural architecture in which such regularities of active inference are encoded hierarchically. We further suggest that this encoding emerges during the embodied learning process when the appropriate action is selected to minimize the prediction error in perception. Therefore, this predictive stream in the sensorimotor loop is generated in a top-down manner. Specifically, it is constantly modulated by the motor actions and is updated by the bottom-up prediction error signals. In this way, the top-down prediction originally comes from the prior experience from both perception and action representing the higher levels of this hierarchical cognition. In our proposed embodied model, we extend the PredNet Network, a hierarchical predictive coding network, with the motor action units implemented by a multi-layer perceptron network (MLP) to modulate the network top-down prediction. Two experiments, a minimalistic world experiment, and a mobile robot experiment are conducted to evaluate the proposed model in a qualitative way. In the neural representation, it can be observed that the causal inference of predictive percept from motor actions can be also observed while the agent is interacting with the environment.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PBMKWWY3\\Zhong et al. - 2018 - AFA-PredNet The action modulation within predictive coding.pdf}
}

@article{zhou_bickford_2017,
  title = {The Mouse Pulvinar Nucleus: {{Organization}} of the Tectorecipient Zones},
  shorttitle = {The Mouse Pulvinar Nucleus},
  author = {Zhou, Na and Maire, Phillip S. and Masterson, Sean P. and Bickford, Martha E.},
  year = {2017},
  volume = {34},
  pages = {E011},
  issn = {0952-5238, 1469-8714},
  doi = {10.1017/S0952523817000050},
  abstract = {Comparative studies have greatly contributed to our understanding of the organization and function of visual pathways of the brain, including that of humans. This comparative approach is a particularly useful tactic for studying the pulvinar nucleus, an enigmatic structure which comprises the largest territory of the human thalamus. This review focuses on the regions of the mouse pulvinar that receive input from the superior colliculus, and highlights similarities of the tectorecipient pulvinar identified across species. Open questions are discussed, as well as the potential contributions of the mouse model for endeavors to elucidate the function of the pulvinar nucleus.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LXTQBVQ5\\Zhou et al. - 2017 - The mouse pulvinar nucleus Organization of the te.pdf},
  journal = {Visual Neuroscience},
  language = {en}
}

@article{zhou_desimone_2016,
  title = {Pulvinar-{{Cortex Interactions}} in {{Vision}} and {{Attention}}},
  author = {Zhou, Huihui and Schafer, Robert John and Desimone, Robert},
  year = {2016},
  month = jan,
  volume = {89},
  pages = {209--220},
  issn = {08966273},
  doi = {10.1016/j.neuron.2015.11.034},
  abstract = {The ventro-lateral pulvinar is reciprocally connected with the visual areas of the ventral stream that are important for object recognition. To understand the mechanisms of attentive stimulus processing in this pulvinar-cortex loop, we investigated the interactions between the pulvinar, area V4, and IT cortex in a spatial-attention task. Sensory processing and the influence of attention in the pulvinar appeared to reflect its cortical inputs. However, pulvinar deactivation led to a reduction of attentional effects on firing rates and gamma synchrony in V4, a reduction of sensory-evoked responses and overall gamma coherence within V4, and severe behavioral deficits in the affected portion of the visual field. Conversely, pulvinar deactivation caused an increase in low-frequency cortical oscillations, often associated with inattention or sleep. Thus, cortical interactions with the ventro-lateral pulvinar are necessary for normal attention and sensory processing and for maintaining the cortex in an active state.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2Z26AAH2\\Zhou et al. - 2016 - Pulvinar-Cortex Interactions in Vision and Attenti.pdf},
  journal = {Neuron},
  language = {en},
  number = {1}
}

@article{zhou_freedman_2019,
  title = {Posterior Parietal Cortex Plays a Causal Role in Perceptual and Categorical Decisions},
  author = {Zhou, Yang and Freedman, David J.},
  year = {2019},
  month = jul,
  volume = {365},
  pages = {180--185},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aaw8347},
  abstract = {Perceptual decision-making in primates Past investigations of the posterior parietal cortex (PPC) in perceptual decisions tested only its contribution to motor aspects of decisions. However, Zhou and Freedman tested the primate PPC's role in both sensory and motor aspects of decisions. Inactivation of the lateral intraparietal area strongly impaired sensory processing aspects of decision-making, more so than motor aspects. Lateral intraparietal area neurons targeted for inactivation were highly correlated with the monkeys' trial-by-trial decisions about stimuli in the neurons' receptive fields. Thus, the posterior parietal cortex is indeed involved in decision-making but plays a more sensory role than predicted. Science, this issue p. 180 Posterior parietal cortex (PPC) activity correlates with monkeys' decisions during visual discrimination and categorization tasks. However, recent work has questioned whether decision-correlated PPC activity plays a causal role in such decisions. That study focused on PPC's contribution to motor aspects of decisions (deciding where to move), but not sensory evaluation aspects (deciding what you are looking at). We employed reversible inactivation to compare PPC's contributions to motor and sensory aspects of decisions. Inactivation affected both aspects of behavior, but preferentially impaired decisions when visual stimuli, rather than motor response targets, were in the inactivated visual field. This demonstrates a causal role for PPC in decision-making, with preferential involvement in evaluating attended task-relevant sensory stimuli compared with motor planning. Neurons in the lateral intraparietal area are involved in accumulating sensory evidence for perceptual categorization. Neurons in the lateral intraparietal area are involved in accumulating sensory evidence for perceptual categorization.},
  copyright = {Copyright \textcopyright{} 2019 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. http://www.sciencemag.org/about/science-licenses-journal-article-reuseThis is an article distributed under the terms of the Science Journals Default License.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BI4BTC22\\Zhou and Freedman - 2019 - Posterior parietal cortex plays a causal role in p.html},
  journal = {Science},
  language = {en},
  number = {6449},
  pmid = {31296771}
}

@article{zhou_sun_2019,
  title = {Graph {{Neural Networks}}: {{A Review}} of {{Methods}} and {{Applications}}},
  shorttitle = {Graph {{Neural Networks}}},
  author = {Zhou, Jie and Cui, Ganqu and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Wang, Lifeng and Li, Changcheng and Sun, Maosong},
  year = {2019},
  month = jul,
  abstract = {Lots of learning tasks require dealing with graph data which contains rich relation information among elements. Modeling physics system, learning molecular fingerprints, predicting protein interface, and classifying diseases require a model to learn from graph inputs. In other domains such as learning from non-structural data like texts and images, reasoning on extracted structures, like the dependency tree of sentences and the scene graph of images, is an important research topic which also needs graph reasoning models. Graph neural networks (GNNs) are connectionist models that capture the dependence of graphs via message passing between the nodes of graphs. Unlike standard neural networks, graph neural networks retain a state that can represent information from its neighborhood with arbitrary depth. Although the primitive GNNs have been found difficult to train for a fixed point, recent advances in network architectures, optimization techniques, and parallel computation have enabled successful learning with them. In recent years, systems based on variants of graph neural networks such as graph convolutional network (GCN), graph attention network (GAT), gated graph neural network (GGNN) have demonstrated ground-breaking performance on many tasks mentioned above. In this survey, we provide a detailed review over existing graph neural network models, systematically categorize the applications, and propose four open problems for future research.},
  archivePrefix = {arXiv},
  eprint = {1812.08434},
  eprinttype = {arxiv},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\FKYTD6JE\\zhou_sun_2019.pdf;C\:\\Users\\wchapman\\Zotero\\storage\\UYCCVA9N\\1812.html},
  journal = {arXiv:1812.08434 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{zhu_hasselmo_2017,
  title = {Feature {{Extraction}} in {{Q}}-{{Learning}} Using {{Neural Networks}}},
  booktitle = {{{IEEE}} 56th {{Annual Conference}} on {{Decision}} and {{Control}} ({{CDC}})},
  author = {Zhu, Henghui and Ch Paschalidis, Ioannis and Hasselmo, Michael E},
  year = {2017},
  month = dec,
  pages = {3330--3335},
  publisher = {{IEEE}},
  doi = {10.1109/CDC.2017.8264148},
  abstract = {\textemdash{} Integrating deep neural networks with reinforce-ment learning has exhibited excellent performance in the liter-ature, highlighting the ability of neural networks to extract fea-tures. This paper begins with a simple Markov decision process inspired from a cognitive task. We show that Q-learning, and approximate Q-learning using a linear function approximation fail in this task. Instead, we show that Q-learning combined with a neural network-based function approximator can learn the optimal policy. Motivated by this finding, we outline procedures that allow the use of a neural network to extract appropriate features, which can then be used in a Q-learning framework with a linear function approximation, obtaining performance similar to that observed using Q-learning with neural networks. Our work suggests that neural networks can be used as feature extractors in the context of Q-learning.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\2DF7XNI5\\Zhu, Ch Paschalidis, Hasselmo - 2017 - Feature Extraction in Q-Learning using Neural Networks.pdf},
  isbn = {978-1-5090-2872-6},
  keywords = {Learning,Markov processes,Neural networks}
}

@article{zhu_hasselmo_2018,
  title = {Neural Circuits for Learning Context-Dependent Associations of Stimuli},
  author = {Zhu, Henghui and Paschalidis, Ioannis Ch. and Hasselmo, Michael E},
  year = {2018},
  issn = {08936080},
  doi = {10.1016/j.neunet.2018.07.018},
  abstract = {The use of reinforcement learning combined with neural networks provides a powerful framework for solving certain tasks in engineering and cogni-tive science. Previous research shows that neural networks have the power to automatically extract features and learn hierarchical decision rules. In this work, we investigate reinforcement learning methods for performing a context-dependent association task using two kinds of neural network models (using continuous firing rate neurons), as well as a neural circuit gating model. The task allows examination of the ability of different models to extract hierarchical decision rules and generalize beyond the examples presented to the models in the training phase. We find that the simple neural circuit gating model, trained using response-based regulation of Hebbian associations , performs almost at the same level as a reinforcement learning algorithm combined with neural networks trained with more sophisticated back-propagation of error methods. A potential explanation is that hierarchical reasoning is the key to performance and the specific learning method is less important.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\PSBFYQ2C\\Zhu, Paschalidis, Hasselmo - 2018 - Neural circuits for learning context-dependent associations of stimuli.pdf},
  journal = {Neural Networks}
}

@article{zhu_saligrama_2017,
  title = {Sequential {{Dynamic Decision Making}} with {{Deep Neural Nets}} on a {{Test}}-{{Time Budget}}},
  author = {Zhu, Henghui and Nan, Feng and Paschalidis, Ioannis and Saligrama, Venkatesh},
  year = {2017},
  abstract = {Deep neural network (DNN) based approaches hold significant potential for reinforcement learning (RL) and have already shown remarkable gains over state-of-art methods in a number of applications. The effectiveness of DNN methods can be attributed to leveraging the abundance of supervised data to learn value functions, Q-functions, and policy function approximations without the need for feature engineering. Nevertheless, the deployment of DNN-based predictors with very deep architectures can pose an issue due to computational and other resource constraints at test-time in a number of applications. We propose a novel approach for reducing the average latency by learning a computationally efficient gating function that is capable of recognizing states in a sequential decision process for which policy prescriptions of a shallow network suffices and deeper layers of the DNN have little marginal utility. The overall system is adaptive in that it dynamically switches control actions based on state-estimates in order to reduce average latency without sacrificing terminal performance. We experiment with a number of alternative loss-functions to train gating functions and shallow policies and show that in a number of applications a speed-up of up to almost 5X can be obtained with little loss in performance.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VTZMM93E\\Saligrama et al. - 2017 - Sequential Dynamic Decision Making with Deep Neural Nets on a Test-Time Budget.pdf}
}

@article{zielinski_jadhav_2019,
  title = {Coherent {{Coding}} of {{Spatial Position Mediated}} by {{Theta Oscillations}} in the {{Hippocampus}} and {{Prefrontal Cortex}}},
  author = {Zielinski, Mark C. and Shin, Justin D. and Jadhav, Shantanu P.},
  year = {2019},
  month = jun,
  volume = {39},
  pages = {4550--4565},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0106-19.2019},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\WAV7J8VM\\Zielinski et al. - 2019 - Coherent Coding of Spatial Position Mediated by Th.pdf},
  journal = {The Journal of Neuroscience},
  language = {en},
  number = {23}
}

@phdthesis{zilli_zilli_2008,
  title = {Modeling the {{Role}} of {{Episodic Memory}} in {{Goal}}-{{Directed Behavior}}},
  author = {Zilli, Eric Andrew},
  year = {2008},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\LQHY6XCJ\\Zilli - 2008 - Modeling the Role of Episodic Memory in Goal-Directed Behavior.pdf},
  school = {Boston University},
  type = {{{PhD Thesis}}}
}

@article{zilli_zilli_2012,
  title = {Models of Grid Cell Spatial Firing Published 2005-2011.},
  author = {a Zilli, Eric},
  year = {2012},
  month = jan,
  volume = {6},
  pages = {16},
  issn = {1662-5110},
  doi = {10.3389/fncir.2012.00016},
  abstract = {Since the discovery of grid cells in rat entorhinal cortex, many models of their hexagonally arrayed spatial firing fields have been suggested. We review the models and organize them according to the mechanisms they use to encode position, update the positional code, read it out in the spatial grid pattern, and learn any patterned synaptic connections needed. We mention biological implementations of the models, but focus on the models on Marr's algorithmic level, where they are not things to individually prove or disprove, but rather are a valuable collection of metaphors of the grid cell system for guiding research that are all likely true to some degree, with each simply emphasizing different aspects of the system. For the convenience of interested researchers, MATLAB implementations of the discussed grid cell models are provided at ModelDB accession 144006 or http://people.bu.edu/zilli/gridmodels.html.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\IWZHMNQX\\Zilli - 2012 - Models of grid cell spatial firing published 2005-2011.pdf},
  journal = {Frontiers in neural circuits},
  keywords = {medial temporal lobe,path integration,place cell,ring attractor,self-organization},
  number = {April},
  pmid = {22529780}
}

@article{zitella_johnson_2013,
  title = {Computational Modeling of Pedunculopontine Nucleus Deep Brain Stimulation.},
  author = {Zitella, Laura M and Mohsenian, Kevin and Pahwa, Mrinal and Gloeckner, Cory and Johnson, Matthew D},
  year = {2013},
  month = aug,
  volume = {10},
  pages = {45005},
  issn = {1741-2552},
  doi = {10.1088/1741-2560/10/4/045005},
  abstract = {OBJECTIVE: Deep brain stimulation (DBS) near the pedunculopontine nucleus (PPN) has been posited to improve medication-intractable gait and balance problems in patients with Parkinson's disease. However, clinical studies evaluating this DBS target have not demonstrated consistent therapeutic effects, with several studies reporting the emergence of paresthesia and oculomotor side effects. The spatial and pathway-specific extent to which brainstem regions are modulated during PPN-DBS is not well understood. APPROACH: Here, we describe two computational models that estimate the direct effects of DBS in the PPN region for human and translational non-human primate (NHP) studies. The three-dimensional models were constructed from segmented histological images from each species, multi-compartment neuron models and inhomogeneous finite element models of the voltage distribution in the brainstem during DBS. MAIN RESULTS: The computational models predicted that: (1) the majority of PPN neurons are activated with -3 V monopolar cathodic stimulation; (2) surgical targeting errors of as little as 1 mm in both species decrement activation selectivity; (3) specifically, monopolar stimulation in caudal, medial, or anterior PPN activates a significant proportion of the superior cerebellar peduncle (up to 60\{\%\} in the human model and 90\{\%\} in the NHP model at -3 V); (4) monopolar stimulation in rostral, lateral or anterior PPN activates a large percentage of medial lemniscus fibers (up to 33\{\%\} in the human model and 40\{\%\} in the NHP model at -3 V) and (5) the current clinical cylindrical electrode design is suboptimal for isolating the modulatory effects to PPN neurons. SIGNIFICANCE: We show that a DBS lead design with radially-segmented electrodes may yield improved functional outcome for PPN-DBS.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\UBC6HHNR\\Zitella et al. - 2013 - Computational modeling of pedunculopontine nucleus deep brain stimulation.pdf},
  journal = {Journal of neural engineering},
  keywords = {Animals,Computer Simulation,Deep Brain Stimulation,Deep Brain Stimulation: methods,Evoked Potentials,Evoked Potentials: physiology,Humans,Models,Nerve Net,Nerve Net: physiology,Neurological,Neurons,Neurons: physiology,Primates,Species Specificity},
  number = {4},
  pmid = {23723145}
}

@article{zoltowski_linderman_,
  title = {A General Recurrent State Space Framework for Modeling Neural Dynamics during Decision-Making},
  author = {Zoltowski, David M and Pillow, Jonathan W and Linderman, Scott W},
  pages = {12},
  abstract = {An open question in systems and computational neuroscience is how neural circuits accumulate evidence towards a decision. Fitting models of decision-making theory to neural activity helps answer this question, but current approaches limit the number of these models that we can fit to neural data. Here we propose a general framework for modeling neural activity during decisionmaking. The framework includes the canonical drift-diffusion model and enables extensions such as multi-dimensional accumulators, variable and collapsing boundaries, and discrete jumps. Our framework is based on constraining the parameters of recurrent state space models, for which we introduce a scalable variational Laplace EM inference algorithm. We applied the modeling approach to spiking responses recorded from monkey parietal cortex during two decision-making tasks. We found that a two-dimensional accumulator better captured the responses of a set of parietal neurons than a single accumulator model, and we identified a variable lower boundary in the responses of a parietal neuron during a random dot motion task. We expect this framework will be useful for modeling neural dynamics in a variety of decision-making settings.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\QY9F39J6\\Zoltowski et al. - A general recurrent state space framework for mode.pdf},
  language = {en}
}

@article{zumer_jensen_2014,
  title = {Occipital {{Alpha Activity}} during {{Stimulus Processing Gates}} the {{Information Flow}} to {{Object}}-{{Selective Cortex}}},
  author = {Zumer, Johanna M and Scheeringa, Ren{\'e} and Schoffelen, Jan Mathijs and Norris, David G and Jensen, Ole},
  year = {2014},
  volume = {12},
  pages = {1001965},
  issn = {15457885},
  doi = {10.1371/journal.pbio.1001965},
  abstract = {Given the limited processing capabilities of the sensory system, it is essential that attended information is gated to downstream areas, whereas unattended information is blocked. While it has been proposed that alpha band (8-13 Hz) activity serves to route information to downstream regions by inhibiting neuronal processing in task-irrelevant regions, this hypothesis remains untested. Here we investigate how neuronal oscillations detected by electroencephalography in visual areas during working memory encoding serve to gate information reflected in the simultaneously recorded blood-oxygenation-level-dependent (BOLD) signals recorded by functional magnetic resonance imaging in downstream ventral regions. We used a paradigm in which 16 participants were presented with faces and landscapes in the right and left hemifields; one hemifield was attended and the other unattended. We observed that decreased alpha power contralateral to the attended object predicted the BOLD signal representing the attended object in ventral object-selective regions. Furthermore, increased alpha power ipsilateral to the attended object predicted a decrease in the BOLD signal representing the unattended object. We also found that the BOLD signal in the dorsal attention network inversely correlated with visual alpha power. This is the first demonstration, to our knowledge, that oscillations in the alpha band are implicated in the gating of information from the visual cortex to the ventral stream, as reflected in the representationally specific BOLD signal. This link of sensory alpha to downstream activity provides a neurophysiological substrate for the mechanism of selective attention during stimulus processing, which not only boosts the attended information but also suppresses distraction. Although previous studies have shown a relation between the BOLD signal from the dorsal attention network and the alpha band at rest, we demonstrate such a relation during a visuospatial task, indicating that the dorsal attention network exercises top-down control of visual alpha activity.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\VM9QAM3E\\Zumer et al. - 2014 - Occipital Alpha Activity during Stimulus Processing Gates the Information Flow to Object-Selective Cortex.pdf},
  journal = {PLoS Biology},
  keywords = {alpha,eeg,fef,ffa,fmri,glm,ips,ppa},
  number = {10},
  pmid = {25333286}
}

@article{zutshi_leutgeb_2018,
  title = {Recurrent Circuits within Medial Entorhinal Cortex Superficial Layers Support Grid Cell Firing},
  author = {Zutshi, Ipshita and Fu, Maylin L and Lilascharoen, Varoth and Leutgeb, Jill K and Lim, Byung Kook and Leutgeb, Stefan},
  year = {2018},
  doi = {10.1038/s41467-018-06104-5},
  abstract = {Specialized cells in the medial entorhinal cortex (mEC), such as speed cells, head direction (HD) cells, and grid cells, are thought to support spatial navigation. To determine whether these computations are dependent on local circuits, we record neuronal activity in mEC layers II and III and optogenetically perturb locally projecting layer II pyramidal cells. We find that sharply tuned HD cells are only weakly responsive while speed, broadly tuned HD cells, and grid cells show pronounced transient excitatory and inhibitory responses. During the brief period of feedback inhibition, there is a reduction in specifically grid accuracy, which is corrected as firing rates return to baseline. These results suggest that sharp HD cells are embedded in a separate mEC sub-network from broad HD cells, speed cells, and grid cells. Furthermore, grid tuning is not only dependent on local processing but also rapidly updated by HD, speed, or other afferent inputs to mEC.},
  file = {C\:\\Users\\wchapman\\Zotero\\storage\\BFABMYRB\\Zutshi et al. - Unknown - Recurrent circuits within medial entorhinal cortex superficial layers support grid cell firing.pdf}
}


